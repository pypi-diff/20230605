# Comparing `tmp/acryl-datahub-tc-0.10.2.0rc3.tar.gz` & `tmp/acryl-datahub-tc-0.10.2rc1.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "dist/acryl-datahub-tc-0.10.2.0rc3.tar", last modified: Mon Jun  5 16:28:19 2023, max compression
+gzip compressed data, was "dist/acryl-datahub-tc-0.10.2rc1.tar", last modified: Wed May 31 19:14:29 2023, max compression
```

## Comparing `acryl-datahub-tc-0.10.2.0rc3.tar` & `acryl-datahub-tc-0.10.2rc1.tar`

### file list

```diff
@@ -1,634 +1,634 @@
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/
--rw-r--r--   0 runner    (1001) docker     (123)    15540 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/PKG-INFO
--rw-r--r--   0 runner    (1001) docker     (123)    10870 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/README.md
--rw-r--r--   0 runner    (1001) docker     (123)      928 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/pyproject.toml
--rw-r--r--   0 runner    (1001) docker     (123)     2189 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/setup.cfg
--rw-r--r--   0 runner    (1001) docker     (123)    27001 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/setup.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/acryl_datahub_tc.egg-info/
--rw-r--r--   0 runner    (1001) docker     (123)    15540 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/acryl_datahub_tc.egg-info/PKG-INFO
--rw-r--r--   0 runner    (1001) docker     (123)    24526 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/acryl_datahub_tc.egg-info/SOURCES.txt
--rw-r--r--   0 runner    (1001) docker     (123)        1 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/acryl_datahub_tc.egg-info/dependency_links.txt
--rw-r--r--   0 runner    (1001) docker     (123)     6651 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/acryl_datahub_tc.egg-info/entry_points.txt
--rw-r--r--   0 runner    (1001) docker     (123)        1 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/acryl_datahub_tc.egg-info/not-zip-safe
--rw-r--r--   0 runner    (1001) docker     (123)    33655 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/acryl_datahub_tc.egg-info/requires.txt
--rw-r--r--   0 runner    (1001) docker     (123)       25 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/acryl_datahub_tc.egg-info/top_level.txt
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/
--rw-r--r--   0 runner    (1001) docker     (123)      581 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)      106 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/__main__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/api/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/api/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/api/circuit_breaker/
--rw-r--r--   0 runner    (1001) docker     (123)      268 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/api/circuit_breaker/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     5324 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/api/circuit_breaker/assertion_circuit_breaker.py
--rw-r--r--   0 runner    (1001) docker     (123)     1471 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/api/circuit_breaker/circuit_breaker.py
--rw-r--r--   0 runner    (1001) docker     (123)     2908 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/api/circuit_breaker/operation_circuit_breaker.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/api/entities/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/api/entities/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/api/entities/corpgroup/
--rw-r--r--   0 runner    (1001) docker     (123)       63 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/api/entities/corpgroup/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     9873 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/api/entities/corpgroup/corpgroup.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/api/entities/corpuser/
--rw-r--r--   0 runner    (1001) docker     (123)       60 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/api/entities/corpuser/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     5889 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/api/entities/corpuser/corpuser.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/api/entities/datajob/
--rw-r--r--   0 runner    (1001) docker     (123)      116 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/api/entities/datajob/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     4265 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/api/entities/datajob/dataflow.py
--rw-r--r--   0 runner    (1001) docker     (123)     7492 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/api/entities/datajob/datajob.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/api/entities/dataprocess/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/api/entities/dataprocess/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)    14547 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/api/entities/dataprocess/dataprocess_instance.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/api/graphql/
--rw-r--r--   0 runner    (1001) docker     (123)      104 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/api/graphql/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     2818 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/api/graphql/assertion.py
--rw-r--r--   0 runner    (1001) docker     (123)     1566 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/api/graphql/base.py
--rw-r--r--   0 runner    (1001) docker     (123)     5116 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/api/graphql/operation.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/cli/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/cli/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     2725 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/cli/check_cli.py
--rw-r--r--   0 runner    (1001) docker     (123)    24292 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/cli/cli_utils.py
--rw-r--r--   0 runner    (1001) docker     (123)    16533 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/cli/delete_cli.py
--rw-r--r--   0 runner    (1001) docker     (123)     7362 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/cli/docker_check.py
--rw-r--r--   0 runner    (1001) docker     (123)    34107 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/cli/docker_cli.py
--rw-r--r--   0 runner    (1001) docker     (123)     1431 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/cli/get_cli.py
--rw-r--r--   0 runner    (1001) docker     (123)    13132 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/cli/ingest_cli.py
--rw-r--r--   0 runner    (1001) docker     (123)      888 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/cli/json_file.py
--rw-r--r--   0 runner    (1001) docker     (123)    12786 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/cli/lite_cli.py
--rw-r--r--   0 runner    (1001) docker     (123)    16505 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/cli/migrate.py
--rw-r--r--   0 runner    (1001) docker     (123)     8936 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/cli/migration_utils.py
--rw-r--r--   0 runner    (1001) docker     (123)     3067 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/cli/put_cli.py
--rw-r--r--   0 runner    (1001) docker     (123)     5509 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/cli/quickstart_versioning.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/cli/specific/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/cli/specific/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     1275 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/cli/specific/file_loader.py
--rw-r--r--   0 runner    (1001) docker     (123)     1966 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/cli/specific/group_cli.py
--rw-r--r--   0 runner    (1001) docker     (123)     1874 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/cli/specific/user_cli.py
--rw-r--r--   0 runner    (1001) docker     (123)     1819 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/cli/state_cli.py
--rw-r--r--   0 runner    (1001) docker     (123)      489 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/cli/telemetry.py
--rw-r--r--   0 runner    (1001) docker     (123)     7352 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/cli/timeline_cli.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/configuration/
--rw-r--r--   0 runner    (1001) docker     (123)      114 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/configuration/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)      934 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/configuration/_config_enum.py
--rw-r--r--   0 runner    (1001) docker     (123)    10548 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/configuration/common.py
--rw-r--r--   0 runner    (1001) docker     (123)     3770 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/configuration/config_loader.py
--rw-r--r--   0 runner    (1001) docker     (123)     5594 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/configuration/git.py
--rw-r--r--   0 runner    (1001) docker     (123)      369 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/configuration/import_resolver.py
--rw-r--r--   0 runner    (1001) docker     (123)     2105 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/configuration/kafka.py
--rw-r--r--   0 runner    (1001) docker     (123)      386 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/configuration/pattern_utils.py
--rw-r--r--   0 runner    (1001) docker     (123)      768 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/configuration/pydantic_field_deprecation.py
--rw-r--r--   0 runner    (1001) docker     (123)     2200 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/configuration/source_common.py
--rw-r--r--   0 runner    (1001) docker     (123)     2363 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/configuration/time_window_config.py
--rw-r--r--   0 runner    (1001) docker     (123)      380 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/configuration/toml.py
--rw-r--r--   0 runner    (1001) docker     (123)      688 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/configuration/validate_field_removal.py
--rw-r--r--   0 runner    (1001) docker     (123)     1848 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/configuration/validate_field_rename.py
--rw-r--r--   0 runner    (1001) docker     (123)      867 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/configuration/validate_host_port.py
--rw-r--r--   0 runner    (1001) docker     (123)      301 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/configuration/yaml.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/emitter/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/emitter/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)      292 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/emitter/aspect.py
--rw-r--r--   0 runner    (1001) docker     (123)     5761 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/emitter/kafka_emitter.py
--rw-r--r--   0 runner    (1001) docker     (123)    14740 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/emitter/mce_builder.py
--rw-r--r--   0 runner    (1001) docker     (123)     8579 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/emitter/mcp.py
--rw-r--r--   0 runner    (1001) docker     (123)     9187 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/emitter/mcp_builder.py
--rw-r--r--   0 runner    (1001) docker     (123)     2523 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/emitter/mcp_patch_builder.py
--rw-r--r--   0 runner    (1001) docker     (123)      706 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/emitter/request_helper.py
--rw-r--r--   0 runner    (1001) docker     (123)    11252 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/emitter/rest_emitter.py
--rw-r--r--   0 runner    (1001) docker     (123)     3652 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/emitter/serialization_helper.py
--rw-r--r--   0 runner    (1001) docker     (123)     6799 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/entrypoints.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/api/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/api/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)      449 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/api/closeable.py
--rw-r--r--   0 runner    (1001) docker     (123)      886 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/api/committable.py
--rw-r--r--   0 runner    (1001) docker     (123)     2753 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/api/common.py
--rw-r--r--   0 runner    (1001) docker     (123)     3428 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/api/decorators.py
--rw-r--r--   0 runner    (1001) docker     (123)     1870 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/api/ingestion_job_checkpointing_provider_base.py
--rw-r--r--   0 runner    (1001) docker     (123)      608 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/api/pipeline_run_listener.py
--rw-r--r--   0 runner    (1001) docker     (123)     7150 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/api/registry.py
--rw-r--r--   0 runner    (1001) docker     (123)     4752 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/api/report.py
--rw-r--r--   0 runner    (1001) docker     (123)      994 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/api/report_helpers.py
--rw-r--r--   0 runner    (1001) docker     (123)     4503 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/api/sink.py
--rw-r--r--   0 runner    (1001) docker     (123)     6074 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/api/source.py
--rw-r--r--   0 runner    (1001) docker     (123)      582 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/api/transform.py
--rw-r--r--   0 runner    (1001) docker     (123)     3316 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/api/workunit.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/extractor/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/extractor/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)      342 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/extractor/extractor_registry.py
--rw-r--r--   0 runner    (1001) docker     (123)     1454 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/extractor/json_ref_patch.py
--rw-r--r--   0 runner    (1001) docker     (123)    24286 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/extractor/json_schema_util.py
--rw-r--r--   0 runner    (1001) docker     (123)     3649 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/extractor/mce_extractor.py
--rw-r--r--   0 runner    (1001) docker     (123)    13147 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/extractor/protobuf_util.py
--rw-r--r--   0 runner    (1001) docker     (123)    21985 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/extractor/schema_util.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/glossary/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/glossary/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     6189 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/glossary/classification_mixin.py
--rw-r--r--   0 runner    (1001) docker     (123)     2675 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/glossary/classifier.py
--rw-r--r--   0 runner    (1001) docker     (123)      307 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/glossary/classifier_registry.py
--rw-r--r--   0 runner    (1001) docker     (123)     4813 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/glossary/datahub_classifier.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/graph/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/graph/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)    20384 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/graph/client.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/reporting/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/reporting/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     8506 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/reporting/datahub_ingestion_run_summary_provider.py
--rw-r--r--   0 runner    (1001) docker     (123)     1576 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/reporting/file_reporter.py
--rw-r--r--   0 runner    (1001) docker     (123)      310 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/reporting/reporting_provider_registry.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/run/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/run/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     1474 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/run/connection.py
--rw-r--r--   0 runner    (1001) docker     (123)    24179 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/run/pipeline.py
--rw-r--r--   0 runner    (1001) docker     (123)     3920 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/run/pipeline_config.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/sink/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/sink/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)      557 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/sink/blackhole.py
--rw-r--r--   0 runner    (1001) docker     (123)      591 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/sink/console.py
--rw-r--r--   0 runner    (1001) docker     (123)     2838 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/sink/datahub_kafka.py
--rw-r--r--   0 runner    (1001) docker     (123)     1991 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/sink/datahub_lite.py
--rw-r--r--   0 runner    (1001) docker     (123)     8138 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/sink/datahub_rest.py
--rw-r--r--   0 runner    (1001) docker     (123)     2743 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/sink/file.py
--rw-r--r--   0 runner    (1001) docker     (123)      490 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/sink/sink_registry.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/aws/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/aws/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     8114 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/aws/aws_common.py
--rw-r--r--   0 runner    (1001) docker     (123)    47697 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/aws/glue.py
--rw-r--r--   0 runner    (1001) docker     (123)     8485 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/aws/path_spec.py
--rw-r--r--   0 runner    (1001) docker     (123)     3892 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/aws/s3_boto_utils.py
--rw-r--r--   0 runner    (1001) docker     (123)     1694 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/aws/s3_util.py
--rw-r--r--   0 runner    (1001) docker     (123)     3809 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/aws/sagemaker.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/aws/sagemaker_processors/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/aws/sagemaker_processors/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     1554 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/aws/sagemaker_processors/common.py
--rw-r--r--   0 runner    (1001) docker     (123)    10383 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/aws/sagemaker_processors/feature_groups.py
--rw-r--r--   0 runner    (1001) docker     (123)    10165 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/aws/sagemaker_processors/job_classes.py
--rw-r--r--   0 runner    (1001) docker     (123)    35124 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/aws/sagemaker_processors/jobs.py
--rw-r--r--   0 runner    (1001) docker     (123)     9290 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/aws/sagemaker_processors/lineage.py
--rw-r--r--   0 runner    (1001) docker     (123)    19207 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/aws/sagemaker_processors/models.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/azure/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/azure/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     3706 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/azure/azure_common.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/bigquery_v2/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/bigquery_v2/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)    51101 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/bigquery_v2/bigquery.py
--rw-r--r--   0 runner    (1001) docker     (123)    24168 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/bigquery_v2/bigquery_audit.py
--rw-r--r--   0 runner    (1001) docker     (123)    12893 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/bigquery_v2/bigquery_config.py
--rw-r--r--   0 runner    (1001) docker     (123)     4316 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/bigquery_v2/bigquery_report.py
--rw-r--r--   0 runner    (1001) docker     (123)    23505 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/bigquery_v2/bigquery_schema.py
--rw-r--r--   0 runner    (1001) docker     (123)     1640 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/bigquery_v2/common.py
--rw-r--r--   0 runner    (1001) docker     (123)    28643 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/bigquery_v2/lineage.py
--rw-r--r--   0 runner    (1001) docker     (123)    12225 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/bigquery_v2/profiler.py
--rw-r--r--   0 runner    (1001) docker     (123)    36592 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/bigquery_v2/usage.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/common/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/common/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)      980 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/common/subtypes.py
--rw-r--r--   0 runner    (1001) docker     (123)    16833 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/confluent_schema_registry.py
--rw-r--r--   0 runner    (1001) docker     (123)    26249 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/csv_enricher.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/dbt/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/dbt/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)    12796 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/dbt/dbt_cloud.py
--rw-r--r--   0 runner    (1001) docker     (123)    56247 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/dbt/dbt_common.py
--rw-r--r--   0 runner    (1001) docker     (123)    17244 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/dbt/dbt_core.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/delta_lake/
--rw-r--r--   0 runner    (1001) docker     (123)       71 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/delta_lake/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     3342 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/delta_lake/config.py
--rw-r--r--   0 runner    (1001) docker     (123)     2006 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/delta_lake/delta_lake_utils.py
--rw-r--r--   0 runner    (1001) docker     (123)      467 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/delta_lake/report.py
--rw-r--r--   0 runner    (1001) docker     (123)    12467 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/delta_lake/source.py
--rw-r--r--   0 runner    (1001) docker     (123)     1228 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/demo_data.py
--rw-r--r--   0 runner    (1001) docker     (123)    17398 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/elastic_search.py
--rw-r--r--   0 runner    (1001) docker     (123)    14671 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/feast.py
--rw-r--r--   0 runner    (1001) docker     (123)    16770 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/file.py
--rw-r--r--   0 runner    (1001) docker     (123)    44577 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/ge_data_profiler.py
--rw-r--r--   0 runner    (1001) docker     (123)     8830 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/ge_profiling_config.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/git/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/git/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     2563 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/git/git_import.py
--rw-r--r--   0 runner    (1001) docker     (123)     2010 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/glue_profiling_config.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/iceberg/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/iceberg/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)    19281 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/iceberg/iceberg.py
--rw-r--r--   0 runner    (1001) docker     (123)     7823 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/iceberg/iceberg_common.py
--rw-r--r--   0 runner    (1001) docker     (123)     9563 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/iceberg/iceberg_profiler.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/identity/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/identity/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)    29532 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/identity/azure_ad.py
--rw-r--r--   0 runner    (1001) docker     (123)    32064 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/identity/okta.py
--rw-r--r--   0 runner    (1001) docker     (123)    17692 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/kafka.py
--rw-r--r--   0 runner    (1001) docker     (123)    46297 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/kafka_connect.py
--rw-r--r--   0 runner    (1001) docker     (123)      321 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/kafka_schema_registry_base.py
--rw-r--r--   0 runner    (1001) docker     (123)    17596 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/ldap.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/looker/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/looker/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)    43834 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/looker/looker_common.py
--rw-r--r--   0 runner    (1001) docker     (123)     7480 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/looker/looker_lib_wrapper.py
--rw-r--r--   0 runner    (1001) docker     (123)     2202 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/looker/looker_query_model.py
--rw-r--r--   0 runner    (1001) docker     (123)    53361 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/looker/looker_source.py
--rw-r--r--   0 runner    (1001) docker     (123)    24029 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/looker/looker_usage.py
--rw-r--r--   0 runner    (1001) docker     (123)    81876 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/looker/lookml_source.py
--rw-r--r--   0 runner    (1001) docker     (123)    22826 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/metabase.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/metadata/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/metadata/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)    16789 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/metadata/business_glossary.py
--rw-r--r--   0 runner    (1001) docker     (123)     6717 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/metadata/lineage.py
--rw-r--r--   0 runner    (1001) docker     (123)    30160 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/mode.py
--rw-r--r--   0 runner    (1001) docker     (123)    17143 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/mongodb.py
--rw-r--r--   0 runner    (1001) docker     (123)    43231 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/nifi.py
--rwxr-xr-x   0 runner    (1001) docker     (123)    13322 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/openapi.py
--rwxr-xr-x   0 runner    (1001) docker     (123)    13526 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/openapi_parser.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/powerbi/
--rw-r--r--   0 runner    (1001) docker     (123)       76 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/powerbi/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)    13454 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/powerbi/config.py
--rw-r--r--   0 runner    (1001) docker     (123)     2265 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/powerbi/dataplatform_instance_resolver.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/powerbi/m_query/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/powerbi/m_query/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     1147 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/powerbi/m_query/data_classes.py
--rw-r--r--   0 runner    (1001) docker     (123)     1578 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/powerbi/m_query/native_sql_parser.py
--rw-r--r--   0 runner    (1001) docker     (123)     3204 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/powerbi/m_query/parser.py
--rw-r--r--   0 runner    (1001) docker     (123)    29227 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/powerbi/m_query/resolver.py
--rw-r--r--   0 runner    (1001) docker     (123)     6111 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/powerbi/m_query/tree_function.py
--rw-r--r--   0 runner    (1001) docker     (123)     1052 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/powerbi/m_query/validator.py
--rw-r--r--   0 runner    (1001) docker     (123)    17764 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/powerbi/powerbi-lexical-grammar.rule
--rw-r--r--   0 runner    (1001) docker     (123)    35205 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/powerbi/powerbi.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/powerbi/rest_api_wrapper/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/powerbi/rest_api_wrapper/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     4290 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/powerbi/rest_api_wrapper/data_classes.py
--rw-r--r--   0 runner    (1001) docker     (123)    27836 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/powerbi/rest_api_wrapper/data_resolver.py
--rw-r--r--   0 runner    (1001) docker     (123)    13689 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/powerbi/rest_api_wrapper/powerbi_api.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/powerbi_report_server/
--rw-r--r--   0 runner    (1001) docker     (123)      324 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/powerbi_report_server/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     3689 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/powerbi_report_server/constants.py
--rw-r--r--   0 runner    (1001) docker     (123)    20049 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/powerbi_report_server/report_server.py
--rw-r--r--   0 runner    (1001) docker     (123)    11684 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/powerbi_report_server/report_server_domain.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/profiling/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/profiling/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     1426 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/profiling/common.py
--rw-r--r--   0 runner    (1001) docker     (123)    20413 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/pulsar.py
--rw-r--r--   0 runner    (1001) docker     (123)    32287 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/redash.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/redshift/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/redshift/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)      362 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/redshift/common.py
--rw-r--r--   0 runner    (1001) docker     (123)     5163 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/redshift/config.py
--rw-r--r--   0 runner    (1001) docker     (123)    17491 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/redshift/lineage.py
--rw-r--r--   0 runner    (1001) docker     (123)     5607 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/redshift/profile.py
--rw-r--r--   0 runner    (1001) docker     (123)    17388 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/redshift/query.py
--rw-r--r--   0 runner    (1001) docker     (123)    34186 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/redshift/redshift.py
--rw-r--r--   0 runner    (1001) docker     (123)    12416 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/redshift/redshift_schema.py
--rw-r--r--   0 runner    (1001) docker     (123)     1389 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/redshift/report.py
--rw-r--r--   0 runner    (1001) docker     (123)    15002 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/redshift/usage.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/s3/
--rw-r--r--   0 runner    (1001) docker     (123)       56 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/s3/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     5167 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/s3/config.py
--rw-r--r--   0 runner    (1001) docker     (123)     4126 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/s3/data_lake_utils.py
--rw-r--r--   0 runner    (1001) docker     (123)    20777 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/s3/profiling.py
--rw-r--r--   0 runner    (1001) docker     (123)      466 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/s3/report.py
--rw-r--r--   0 runner    (1001) docker     (123)    32051 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/s3/source.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/sagemaker_processors/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/sagemaker_processors/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)    27170 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/salesforce.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/schema/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/schema/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)    15812 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/schema/json_schema.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/schema_inference/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/schema_inference/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)      563 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/schema_inference/avro.py
--rw-r--r--   0 runner    (1001) docker     (123)      379 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/schema_inference/base.py
--rw-r--r--   0 runner    (1001) docker     (123)     2229 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/schema_inference/csv_tsv.py
--rw-r--r--   0 runner    (1001) docker     (123)     2103 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/schema_inference/json.py
--rw-r--r--   0 runner    (1001) docker     (123)     5760 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/schema_inference/object.py
--rw-r--r--   0 runner    (1001) docker     (123)     3426 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/schema_inference/parquet.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/snowflake/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/snowflake/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     1581 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/snowflake/constants.py
--rw-r--r--   0 runner    (1001) docker     (123)     7116 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/snowflake/snowflake_config.py
--rw-r--r--   0 runner    (1001) docker     (123)    29016 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/snowflake/snowflake_lineage_legacy.py
--rw-r--r--   0 runner    (1001) docker     (123)    21942 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/snowflake/snowflake_lineage_v2.py
--rw-r--r--   0 runner    (1001) docker     (123)     6966 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/snowflake/snowflake_profiler.py
--rw-r--r--   0 runner    (1001) docker     (123)    33575 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/snowflake/snowflake_query.py
--rw-r--r--   0 runner    (1001) docker     (123)     3665 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/snowflake/snowflake_report.py
--rw-r--r--   0 runner    (1001) docker     (123)    19448 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/snowflake/snowflake_schema.py
--rw-r--r--   0 runner    (1001) docker     (123)     6141 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/snowflake/snowflake_tag.py
--rw-r--r--   0 runner    (1001) docker     (123)    18561 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/snowflake/snowflake_usage_v2.py
--rw-r--r--   0 runner    (1001) docker     (123)    10596 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/snowflake/snowflake_utils.py
--rw-r--r--   0 runner    (1001) docker     (123)    62420 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/snowflake/snowflake_v2.py
--rw-r--r--   0 runner    (1001) docker     (123)     1313 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/source_registry.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/sql/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/sql/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     9739 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/sql/athena.py
--rw-r--r--   0 runner    (1001) docker     (123)    25177 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/sql/clickhouse.py
--rw-r--r--   0 runner    (1001) docker     (123)     2346 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/sql/druid.py
--rw-r--r--   0 runner    (1001) docker     (123)     1342 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/sql/hana.py
--rw-r--r--   0 runner    (1001) docker     (123)     6454 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/sql/hive.py
--rw-r--r--   0 runner    (1001) docker     (123)      737 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/sql/mariadb.py
--rw-r--r--   0 runner    (1001) docker     (123)    10973 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/sql/mssql.py
--rw-r--r--   0 runner    (1001) docker     (123)     2650 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/sql/mysql.py
--rw-r--r--   0 runner    (1001) docker     (123)     2316 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/sql/oauth_generator.py
--rw-r--r--   0 runner    (1001) docker     (123)     6923 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/sql/oracle.py
--rw-r--r--   0 runner    (1001) docker     (123)    10476 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/sql/postgres.py
--rw-r--r--   0 runner    (1001) docker     (123)     3606 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/sql/presto.py
--rw-r--r--   0 runner    (1001) docker     (123)    33112 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/sql/presto_on_hive.py
--rw-r--r--   0 runner    (1001) docker     (123)    45775 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/sql/redshift.py
--rw-r--r--   0 runner    (1001) docker     (123)    44223 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/sql/sql_common.py
--rw-r--r--   0 runner    (1001) docker     (123)     7105 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/sql/sql_config.py
--rw-r--r--   0 runner    (1001) docker     (123)     2731 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/sql/sql_generic.py
--rw-r--r--   0 runner    (1001) docker     (123)     6881 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/sql/sql_generic_profiler.py
--rw-r--r--   0 runner    (1001) docker     (123)    11475 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/sql/sql_types.py
--rw-r--r--   0 runner    (1001) docker     (123)     7629 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/sql/sql_utils.py
--rw-r--r--   0 runner    (1001) docker     (123)    10551 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/sql/trino.py
--rw-r--r--   0 runner    (1001) docker     (123)     4936 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/sql/two_tier_sql_source.py
--rw-r--r--   0 runner    (1001) docker     (123)    53109 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/sql/vertica.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/state/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/state/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     8797 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/state/checkpoint.py
--rw-r--r--   0 runner    (1001) docker     (123)     4220 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/state/entity_removal_state.py
--rw-r--r--   0 runner    (1001) docker     (123)      512 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/state/profiling_state.py
--rw-r--r--   0 runner    (1001) docker     (123)     4209 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/state/profiling_state_handler.py
--rw-r--r--   0 runner    (1001) docker     (123)     5544 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/state/redundant_run_skip_handler.py
--rw-r--r--   0 runner    (1001) docker     (123)      143 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/state/sql_common_state.py
--rw-r--r--   0 runner    (1001) docker     (123)    13129 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/state/stale_entity_removal_handler.py
--rw-r--r--   0 runner    (1001) docker     (123)    15642 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/state/stateful_ingestion_base.py
--rw-r--r--   0 runner    (1001) docker     (123)      463 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/state/usage_common_state.py
--rw-r--r--   0 runner    (1001) docker     (123)     1271 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/state/use_case_handler.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/state_provider/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/state_provider/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     5226 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/state_provider/datahub_ingestion_checkpointing_provider.py
--rw-r--r--   0 runner    (1001) docker     (123)      401 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/state_provider/state_provider_registry.py
--rw-r--r--   0 runner    (1001) docker     (123)    14641 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/superset.py
--rw-r--r--   0 runner    (1001) docker     (123)    91756 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/tableau.py
--rw-r--r--   0 runner    (1001) docker     (123)    15651 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/tableau_common.py
--rw-r--r--   0 runner    (1001) docker     (123)     2284 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/tableau_constant.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/unity/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/unity/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     3164 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/unity/config.py
--rw-r--r--   0 runner    (1001) docker     (123)    11625 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/unity/proxy.py
--rw-r--r--   0 runner    (1001) docker     (123)      585 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/unity/report.py
--rw-r--r--   0 runner    (1001) docker     (123)    19523 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/unity/source.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/usage/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/usage/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     9827 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/usage/clickhouse_usage.py
--rw-r--r--   0 runner    (1001) docker     (123)    15306 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/usage/redshift_usage.py
--rw-r--r--   0 runner    (1001) docker     (123)    10155 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/usage/starburst_trino_usage.py
--rw-r--r--   0 runner    (1001) docker     (123)     6281 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/usage/usage_common.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source_config/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source_config/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     1654 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source_config/bigquery.py
--rw-r--r--   0 runner    (1001) docker     (123)     1688 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source_config/csv_enricher.py
--rw-r--r--   0 runner    (1001) docker     (123)     5615 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source_config/pulsar.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source_config/sql/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source_config/sql/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)    16134 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source_config/sql/snowflake.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source_config/usage/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source_config/usage/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     7702 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source_config/usage/bigquery_usage.py
--rw-r--r--   0 runner    (1001) docker     (123)      565 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source_config/usage/snowflake_usage.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source_report/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source_report/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     1037 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source_report/pulsar.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source_report/sql/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source_report/sql/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     1864 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source_report/sql/bigquery.py
--rw-r--r--   0 runner    (1001) docker     (123)     1331 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source_report/sql/snowflake.py
--rw-r--r--   0 runner    (1001) docker     (123)      229 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source_report/time_window.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source_report/usage/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source_report/usage/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     1374 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source_report/usage/bigquery_usage.py
--rw-r--r--   0 runner    (1001) docker     (123)      780 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source_report/usage/snowflake_usage.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/transformer/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/transformer/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     3420 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/transformer/add_dataset_browse_path.py
--rw-r--r--   0 runner    (1001) docker     (123)     6849 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/transformer/add_dataset_ownership.py
--rw-r--r--   0 runner    (1001) docker     (123)     5605 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/transformer/add_dataset_properties.py
--rw-r--r--   0 runner    (1001) docker     (123)     5664 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/transformer/add_dataset_schema_tags.py
--rw-r--r--   0 runner    (1001) docker     (123)     6239 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/transformer/add_dataset_schema_terms.py
--rw-r--r--   0 runner    (1001) docker     (123)     4911 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/transformer/add_dataset_tags.py
--rw-r--r--   0 runner    (1001) docker     (123)     5707 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/transformer/add_dataset_terms.py
--rw-r--r--   0 runner    (1001) docker     (123)    10623 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/transformer/base_transformer.py
--rw-r--r--   0 runner    (1001) docker     (123)     6241 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/transformer/dataset_domain.py
--rw-r--r--   0 runner    (1001) docker     (123)     1598 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/transformer/dataset_transformer.py
--rw-r--r--   0 runner    (1001) docker     (123)     1323 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/transformer/mark_dataset_status.py
--rw-r--r--   0 runner    (1001) docker     (123)     1218 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/transformer/remove_dataset_ownership.py
--rw-r--r--   0 runner    (1001) docker     (123)      251 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/transformer/transform_registry.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/integrations/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/integrations/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/integrations/great_expectations/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/integrations/great_expectations/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)    34843 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/integrations/great_expectations/action.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/lite/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/lite/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)    32549 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/lite/duckdb_lite.py
--rw-r--r--   0 runner    (1001) docker     (123)      157 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/lite/duckdb_lite_config.py
--rw-r--r--   0 runner    (1001) docker     (123)     2846 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/lite/lite_local.py
--rw-r--r--   0 runner    (1001) docker     (123)      286 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/lite/lite_registry.py
--rw-r--r--   0 runner    (1001) docker     (123)     1949 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/lite/lite_server.py
--rw-r--r--   0 runner    (1001) docker     (123)     4503 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/lite/lite_util.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/
--rw-r--r--   0 runner    (1001) docker     (123)      197 2023-06-05 16:28:17.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/
--rw-r--r--   0 runner    (1001) docker     (123)      161 2023-06-05 16:28:17.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/
--rw-r--r--   0 runner    (1001) docker     (123)      161 2023-06-05 16:28:17.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/events/
--rw-r--r--   0 runner    (1001) docker     (123)      257 2023-06-05 16:28:17.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/events/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/
--rw-r--r--   0 runner    (1001) docker     (123)      161 2023-06-05 16:28:17.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/access/
--rw-r--r--   0 runner    (1001) docker     (123)      161 2023-06-05 16:28:17.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/access/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/access/token/
--rw-r--r--   0 runner    (1001) docker     (123)      277 2023-06-05 16:28:17.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/access/token/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/assertion/
--rw-r--r--   0 runner    (1001) docker     (123)     1589 2023-06-05 16:28:17.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/assertion/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/chart/
--rw-r--r--   0 runner    (1001) docker     (123)      807 2023-06-05 16:28:17.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/chart/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/common/
--rw-r--r--   0 runner    (1001) docker     (123)     3456 2023-06-05 16:28:17.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/common/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/common/fieldtransformer/
--rw-r--r--   0 runner    (1001) docker     (123)      355 2023-06-05 16:28:17.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/common/fieldtransformer/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/container/
--rw-r--r--   0 runner    (1001) docker     (123)      469 2023-06-05 16:28:17.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/container/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/dashboard/
--rw-r--r--   0 runner    (1001) docker     (123)      615 2023-06-05 16:28:17.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/dashboard/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/datajob/
--rw-r--r--   0 runner    (1001) docker     (123)      828 2023-06-05 16:28:17.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/datajob/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/datajob/azkaban/
--rw-r--r--   0 runner    (1001) docker     (123)      253 2023-06-05 16:28:17.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/datajob/azkaban/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/datajob/datahub/
--rw-r--r--   0 runner    (1001) docker     (123)      535 2023-06-05 16:28:17.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/datajob/datahub/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/dataplatform/
--rw-r--r--   0 runner    (1001) docker     (123)      341 2023-06-05 16:28:17.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/dataplatform/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/dataplatforminstance/
--rw-r--r--   0 runner    (1001) docker     (123)      300 2023-06-05 16:28:17.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/dataplatforminstance/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/dataprocess/
--rw-r--r--   0 runner    (1001) docker     (123)     1317 2023-06-05 16:28:17.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/dataprocess/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/dataset/
--rw-r--r--   0 runner    (1001) docker     (123)     2204 2023-06-05 16:28:17.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/dataset/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/domain/
--rw-r--r--   0 runner    (1001) docker     (123)      326 2023-06-05 16:28:17.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/domain/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/events/
--rw-r--r--   0 runner    (1001) docker     (123)      161 2023-06-05 16:28:17.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/events/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/events/metadata/
--rw-r--r--   0 runner    (1001) docker     (123)      241 2023-06-05 16:28:17.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/events/metadata/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/execution/
--rw-r--r--   0 runner    (1001) docker     (123)      734 2023-06-05 16:28:17.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/execution/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/glossary/
--rw-r--r--   0 runner    (1001) docker     (123)      460 2023-06-05 16:28:17.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/glossary/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/identity/
--rw-r--r--   0 runner    (1001) docker     (123)     1443 2023-06-05 16:28:17.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/identity/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/ingestion/
--rw-r--r--   0 runner    (1001) docker     (123)      556 2023-06-05 16:28:17.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/ingestion/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/metadata/
--rw-r--r--   0 runner    (1001) docker     (123)      161 2023-06-05 16:28:17.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/metadata/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/metadata/key/
--rw-r--r--   0 runner    (1001) docker     (123)     3859 2023-06-05 16:28:17.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/metadata/key/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/metadata/query/
--rw-r--r--   0 runner    (1001) docker     (123)      161 2023-06-05 16:28:17.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/metadata/query/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/metadata/query/filter/
--rw-r--r--   0 runner    (1001) docker     (123)      491 2023-06-05 16:28:17.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/metadata/query/filter/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/metadata/snapshot/
--rw-r--r--   0 runner    (1001) docker     (123)     2317 2023-06-05 16:28:17.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/metadata/snapshot/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/ml/
--rw-r--r--   0 runner    (1001) docker     (123)      161 2023-06-05 16:28:17.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/ml/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/ml/metadata/
--rw-r--r--   0 runner    (1001) docker     (123)     3151 2023-06-05 16:28:17.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/ml/metadata/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/mxe/
--rw-r--r--   0 runner    (1001) docker     (123)      932 2023-06-05 16:28:17.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/mxe/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/notebook/
--rw-r--r--   0 runner    (1001) docker     (123)      860 2023-06-05 16:28:17.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/notebook/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/platform/
--rw-r--r--   0 runner    (1001) docker     (123)      161 2023-06-05 16:28:17.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/platform/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/platform/event/
--rw-r--r--   0 runner    (1001) docker     (123)      161 2023-06-05 16:28:17.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/platform/event/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/platform/event/v1/
--rw-r--r--   0 runner    (1001) docker     (123)      342 2023-06-05 16:28:17.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/platform/event/v1/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/policy/
--rw-r--r--   0 runner    (1001) docker     (123)      876 2023-06-05 16:28:17.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/policy/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/post/
--rw-r--r--   0 runner    (1001) docker     (123)      477 2023-06-05 16:28:17.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/post/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/query/
--rw-r--r--   0 runner    (1001) docker     (123)      679 2023-06-05 16:28:17.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/query/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/retention/
--rw-r--r--   0 runner    (1001) docker     (123)      561 2023-06-05 16:28:17.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/retention/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/schema/
--rw-r--r--   0 runner    (1001) docker     (123)     2822 2023-06-05 16:28:17.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/schema/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/secret/
--rw-r--r--   0 runner    (1001) docker     (123)      264 2023-06-05 16:28:17.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/secret/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/settings/
--rw-r--r--   0 runner    (1001) docker     (123)      161 2023-06-05 16:28:17.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/settings/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/settings/global/
--rw-r--r--   0 runner    (1001) docker     (123)      370 2023-06-05 16:28:17.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/settings/global/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/step/
--rw-r--r--   0 runner    (1001) docker     (123)      288 2023-06-05 16:28:17.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/step/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/tag/
--rw-r--r--   0 runner    (1001) docker     (123)      249 2023-06-05 16:28:17.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/tag/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/telemetry/
--rw-r--r--   0 runner    (1001) docker     (123)      261 2023-06-05 16:28:17.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/telemetry/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/test/
--rw-r--r--   0 runner    (1001) docker     (123)      670 2023-06-05 16:28:17.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/test/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/timeseries/
--rw-r--r--   0 runner    (1001) docker     (123)      596 2023-06-05 16:28:17.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/timeseries/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/upgrade/
--rw-r--r--   0 runner    (1001) docker     (123)      380 2023-06-05 16:28:17.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/upgrade/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/usage/
--rw-r--r--   0 runner    (1001) docker     (123)      561 2023-06-05 16:28:17.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/usage/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/view/
--rw-r--r--   0 runner    (1001) docker     (123)      457 2023-06-05 16:28:17.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/view/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)   429628 2023-06-05 16:28:17.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/schema.avsc
--rw-r--r--   0 runner    (1001) docker     (123)   653521 2023-06-05 16:28:17.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/schema_classes.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/schemas/
--rw-r--r--   0 runner    (1001) docker     (123)   333312 2023-06-05 16:28:17.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/schemas/MetadataChangeEvent.avsc
--rw-r--r--   0 runner    (1001) docker     (123)     8438 2023-06-05 16:28:17.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/schemas/MetadataChangeProposal.avsc
--rw-r--r--   0 runner    (1001) docker     (123)      540 2023-06-05 16:28:17.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/schemas/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/py.typed
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/specific/
--rw-r--r--   0 runner    (1001) docker     (123)       88 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/specific/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)      994 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/specific/custom_properties.py
--rw-r--r--   0 runner    (1001) docker     (123)     7642 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/specific/dataset.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/telemetry/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/telemetry/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)      967 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/telemetry/stats.py
--rw-r--r--   0 runner    (1001) docker     (123)    11734 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/telemetry/telemetry.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/upgrade/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/upgrade/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)    15375 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/upgrade/upgrade.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)      444 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/_markupsafe_compat.py
--rw-r--r--   0 runner    (1001) docker     (123)     3147 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/bigquery_sql_parser.py
--rw-r--r--   0 runner    (1001) docker     (123)     1138 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/checkpoint_state_util.py
--rw-r--r--   0 runner    (1001) docker     (123)      459 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/config_clean.py
--rw-r--r--   0 runner    (1001) docker     (123)      468 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/dedup_list.py
--rw-r--r--   0 runner    (1001) docker     (123)      645 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/delayed_iter.py
--rw-r--r--   0 runner    (1001) docker     (123)    15335 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/file_backed_collections.py
--rw-r--r--   0 runner    (1001) docker     (123)      261 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/global_warning_util.py
--rw-r--r--   0 runner    (1001) docker     (123)    10998 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/hive_schema_to_avro.py
--rw-r--r--   0 runner    (1001) docker     (123)     6609 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/logging_manager.py
--rw-r--r--   0 runner    (1001) docker     (123)     4614 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/lossy_collections.py
--rw-r--r--   0 runner    (1001) docker     (123)    10590 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/mapping.py
--rw-r--r--   0 runner    (1001) docker     (123)     1564 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/memory_footprint.py
--rw-r--r--   0 runner    (1001) docker     (123)     3933 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/memory_leak_detector.py
--rw-r--r--   0 runner    (1001) docker     (123)      598 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/parsing_util.py
--rw-r--r--   0 runner    (1001) docker     (123)     1097 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/perf_timer.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/registries/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/registries/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     2452 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/registries/domain_registry.py
--rw-r--r--   0 runner    (1001) docker     (123)      766 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/sample_data.py
--rw-r--r--   0 runner    (1001) docker     (123)      698 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/server_config_util.py
--rw-r--r--   0 runner    (1001) docker     (123)     4779 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/source_helpers.py
--rw-r--r--   0 runner    (1001) docker     (123)      871 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/sql_formatter.py
--rw-r--r--   0 runner    (1001) docker     (123)     6522 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/sql_lineage_parser_impl.py
--rw-r--r--   0 runner    (1001) docker     (123)     5814 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/sql_parser.py
--rw-r--r--   0 runner    (1001) docker     (123)      456 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/sql_parser_base.py
--rw-r--r--   0 runner    (1001) docker     (123)    14786 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/sqlalchemy_query_combiner.py
--rw-r--r--   0 runner    (1001) docker     (123)     1990 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/sqllineage_patch.py
--rw-r--r--   0 runner    (1001) docker     (123)     1390 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/stats_collections.py
--rw-r--r--   0 runner    (1001) docker     (123)      601 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/tee_io.py
--rw-r--r--   0 runner    (1001) docker     (123)      358 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/time.py
--rw-r--r--   0 runner    (1001) docker     (123)      970 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/type_annotations.py
--rw-r--r--   0 runner    (1001) docker     (123)      172 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/url_util.py
--rw-r--r--   0 runner    (1001) docker     (123)      984 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/urn_encoder.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/urns/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/urns/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     1317 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/urns/corp_group_urn.py
--rw-r--r--   0 runner    (1001) docker     (123)     1307 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/urns/corpuser_urn.py
--rw-r--r--   0 runner    (1001) docker     (123)     2847 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/urns/data_flow_urn.py
--rw-r--r--   0 runner    (1001) docker     (123)     1744 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/urns/data_job_urn.py
--rw-r--r--   0 runner    (1001) docker     (123)     1097 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/urns/data_platform_urn.py
--rw-r--r--   0 runner    (1001) docker     (123)     1587 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/urns/data_process_instance_urn.py
--rw-r--r--   0 runner    (1001) docker     (123)     3877 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/urns/dataset_urn.py
--rw-r--r--   0 runner    (1001) docker     (123)     1292 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/urns/domain_urn.py
--rw-r--r--   0 runner    (1001) docker     (123)       98 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/urns/error.py
--rw-r--r--   0 runner    (1001) docker     (123)     1533 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/urns/notebook_urn.py
--rw-r--r--   0 runner    (1001) docker     (123)     1247 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/urns/tag_urn.py
--rw-r--r--   0 runner    (1001) docker     (123)     5447 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/urns/urn.py
--rw-r--r--   0 runner    (1001) docker     (123)     4176 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/urns/urn_iter.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub_provider/
--rw-r--r--   0 runner    (1001) docker     (123)     1073 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub_provider/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)      291 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub_provider/_airflow_compat.py
--rw-r--r--   0 runner    (1001) docker     (123)      844 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub_provider/_airflow_shims.py
--rw-r--r--   0 runner    (1001) docker     (123)     3564 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub_provider/_lineage_core.py
--rw-r--r--   0 runner    (1001) docker     (123)    12902 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub_provider/_plugin.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub_provider/client/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub_provider/client/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)    19475 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub_provider/client/airflow_generator.py
--rw-r--r--   0 runner    (1001) docker     (123)      994 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub_provider/entities.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub_provider/example_dags/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub_provider/example_dags/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     1319 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub_provider/example_dags/generic_recipe_sample_dag.py
--rw-r--r--   0 runner    (1001) docker     (123)     1348 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub_provider/example_dags/lineage_backend_demo.py
--rw-r--r--   0 runner    (1001) docker     (123)     1414 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub_provider/example_dags/lineage_backend_taskflow_demo.py
--rw-r--r--   0 runner    (1001) docker     (123)     2283 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub_provider/example_dags/lineage_emission_dag.py
--rw-r--r--   0 runner    (1001) docker     (123)     1922 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub_provider/example_dags/mysql_sample_dag.py
--rw-r--r--   0 runner    (1001) docker     (123)     3234 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub_provider/example_dags/snowflake_sample_dag.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub_provider/hooks/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub_provider/hooks/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     6980 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub_provider/hooks/datahub.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub_provider/lineage/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub_provider/lineage/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     3286 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub_provider/lineage/datahub.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-06-05 16:28:19.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub_provider/operators/
--rw-r--r--   0 runner    (1001) docker     (123)        0 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub_provider/operators/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     1848 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub_provider/operators/datahub.py
--rw-r--r--   0 runner    (1001) docker     (123)     2900 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub_provider/operators/datahub_assertion_operator.py
--rw-r--r--   0 runner    (1001) docker     (123)     2903 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub_provider/operators/datahub_assertion_sensor.py
--rw-r--r--   0 runner    (1001) docker     (123)     3338 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub_provider/operators/datahub_operation_operator.py
--rw-r--r--   0 runner    (1001) docker     (123)     3606 2023-06-05 16:26:25.000000 acryl-datahub-tc-0.10.2.0rc3/src/datahub_provider/operators/datahub_operation_sensor.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/
+-rw-r--r--   0 runner    (1001) docker     (123)    15538 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/PKG-INFO
+-rw-r--r--   0 runner    (1001) docker     (123)    10870 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/README.md
+-rw-r--r--   0 runner    (1001) docker     (123)      928 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/pyproject.toml
+-rw-r--r--   0 runner    (1001) docker     (123)     2189 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/setup.cfg
+-rw-r--r--   0 runner    (1001) docker     (123)    27001 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/setup.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/acryl_datahub_tc.egg-info/
+-rw-r--r--   0 runner    (1001) docker     (123)    15538 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/acryl_datahub_tc.egg-info/PKG-INFO
+-rw-r--r--   0 runner    (1001) docker     (123)    24526 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/acryl_datahub_tc.egg-info/SOURCES.txt
+-rw-r--r--   0 runner    (1001) docker     (123)        1 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/acryl_datahub_tc.egg-info/dependency_links.txt
+-rw-r--r--   0 runner    (1001) docker     (123)     6651 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/acryl_datahub_tc.egg-info/entry_points.txt
+-rw-r--r--   0 runner    (1001) docker     (123)        1 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/acryl_datahub_tc.egg-info/not-zip-safe
+-rw-r--r--   0 runner    (1001) docker     (123)    33655 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/acryl_datahub_tc.egg-info/requires.txt
+-rw-r--r--   0 runner    (1001) docker     (123)       25 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/acryl_datahub_tc.egg-info/top_level.txt
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/
+-rw-r--r--   0 runner    (1001) docker     (123)      580 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)      106 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/__main__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/api/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/api/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/api/circuit_breaker/
+-rw-r--r--   0 runner    (1001) docker     (123)      268 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/api/circuit_breaker/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5324 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/api/circuit_breaker/assertion_circuit_breaker.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1471 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/api/circuit_breaker/circuit_breaker.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2908 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/api/circuit_breaker/operation_circuit_breaker.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/api/entities/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/api/entities/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/api/entities/corpgroup/
+-rw-r--r--   0 runner    (1001) docker     (123)       63 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/api/entities/corpgroup/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     9873 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/api/entities/corpgroup/corpgroup.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/api/entities/corpuser/
+-rw-r--r--   0 runner    (1001) docker     (123)       60 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/api/entities/corpuser/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5889 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/api/entities/corpuser/corpuser.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/api/entities/datajob/
+-rw-r--r--   0 runner    (1001) docker     (123)      116 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/api/entities/datajob/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4265 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/api/entities/datajob/dataflow.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7492 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/api/entities/datajob/datajob.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/api/entities/dataprocess/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/api/entities/dataprocess/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    14547 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/api/entities/dataprocess/dataprocess_instance.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/api/graphql/
+-rw-r--r--   0 runner    (1001) docker     (123)      104 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/api/graphql/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2818 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/api/graphql/assertion.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1566 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/api/graphql/base.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5116 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/api/graphql/operation.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/cli/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/cli/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2725 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/cli/check_cli.py
+-rw-r--r--   0 runner    (1001) docker     (123)    24292 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/cli/cli_utils.py
+-rw-r--r--   0 runner    (1001) docker     (123)    16533 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/cli/delete_cli.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7362 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/cli/docker_check.py
+-rw-r--r--   0 runner    (1001) docker     (123)    34107 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/cli/docker_cli.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1431 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/cli/get_cli.py
+-rw-r--r--   0 runner    (1001) docker     (123)    13132 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/cli/ingest_cli.py
+-rw-r--r--   0 runner    (1001) docker     (123)      888 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/cli/json_file.py
+-rw-r--r--   0 runner    (1001) docker     (123)    12786 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/cli/lite_cli.py
+-rw-r--r--   0 runner    (1001) docker     (123)    16454 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/cli/migrate.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8936 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/cli/migration_utils.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3067 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/cli/put_cli.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5509 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/cli/quickstart_versioning.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/cli/specific/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/cli/specific/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1275 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/cli/specific/file_loader.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1966 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/cli/specific/group_cli.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1874 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/cli/specific/user_cli.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1819 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/cli/state_cli.py
+-rw-r--r--   0 runner    (1001) docker     (123)      489 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/cli/telemetry.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7352 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/cli/timeline_cli.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/configuration/
+-rw-r--r--   0 runner    (1001) docker     (123)      114 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/configuration/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)      934 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/configuration/_config_enum.py
+-rw-r--r--   0 runner    (1001) docker     (123)    10548 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/configuration/common.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3770 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/configuration/config_loader.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5594 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/configuration/git.py
+-rw-r--r--   0 runner    (1001) docker     (123)      369 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/configuration/import_resolver.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2105 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/configuration/kafka.py
+-rw-r--r--   0 runner    (1001) docker     (123)      386 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/configuration/pattern_utils.py
+-rw-r--r--   0 runner    (1001) docker     (123)      768 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/configuration/pydantic_field_deprecation.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2200 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/configuration/source_common.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2363 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/configuration/time_window_config.py
+-rw-r--r--   0 runner    (1001) docker     (123)      380 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/configuration/toml.py
+-rw-r--r--   0 runner    (1001) docker     (123)      688 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/configuration/validate_field_removal.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1848 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/configuration/validate_field_rename.py
+-rw-r--r--   0 runner    (1001) docker     (123)      867 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/configuration/validate_host_port.py
+-rw-r--r--   0 runner    (1001) docker     (123)      301 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/configuration/yaml.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/emitter/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/emitter/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)      292 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/emitter/aspect.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5761 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/emitter/kafka_emitter.py
+-rw-r--r--   0 runner    (1001) docker     (123)    14740 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/emitter/mce_builder.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8579 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/emitter/mcp.py
+-rw-r--r--   0 runner    (1001) docker     (123)     9187 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/emitter/mcp_builder.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2523 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/emitter/mcp_patch_builder.py
+-rw-r--r--   0 runner    (1001) docker     (123)      706 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/emitter/request_helper.py
+-rw-r--r--   0 runner    (1001) docker     (123)    11252 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/emitter/rest_emitter.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3652 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/emitter/serialization_helper.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6799 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/entrypoints.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/api/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/api/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)      449 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/api/closeable.py
+-rw-r--r--   0 runner    (1001) docker     (123)      886 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/api/committable.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2753 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/api/common.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3428 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/api/decorators.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1870 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/api/ingestion_job_checkpointing_provider_base.py
+-rw-r--r--   0 runner    (1001) docker     (123)      608 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/api/pipeline_run_listener.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7150 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/api/registry.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4752 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/api/report.py
+-rw-r--r--   0 runner    (1001) docker     (123)      994 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/api/report_helpers.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4503 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/api/sink.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6074 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/api/source.py
+-rw-r--r--   0 runner    (1001) docker     (123)      582 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/api/transform.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3316 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/api/workunit.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/extractor/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/extractor/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)      342 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/extractor/extractor_registry.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1454 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/extractor/json_ref_patch.py
+-rw-r--r--   0 runner    (1001) docker     (123)    24286 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/extractor/json_schema_util.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3649 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/extractor/mce_extractor.py
+-rw-r--r--   0 runner    (1001) docker     (123)    13147 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/extractor/protobuf_util.py
+-rw-r--r--   0 runner    (1001) docker     (123)    21985 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/extractor/schema_util.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/glossary/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/glossary/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6189 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/glossary/classification_mixin.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2675 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/glossary/classifier.py
+-rw-r--r--   0 runner    (1001) docker     (123)      307 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/glossary/classifier_registry.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4813 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/glossary/datahub_classifier.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/graph/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/graph/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    20384 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/graph/client.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/reporting/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/reporting/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8506 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/reporting/datahub_ingestion_run_summary_provider.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1576 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/reporting/file_reporter.py
+-rw-r--r--   0 runner    (1001) docker     (123)      310 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/reporting/reporting_provider_registry.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/run/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/run/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1474 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/run/connection.py
+-rw-r--r--   0 runner    (1001) docker     (123)    24179 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/run/pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3920 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/run/pipeline_config.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/sink/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/sink/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)      557 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/sink/blackhole.py
+-rw-r--r--   0 runner    (1001) docker     (123)      591 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/sink/console.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2838 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/sink/datahub_kafka.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1991 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/sink/datahub_lite.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8138 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/sink/datahub_rest.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2743 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/sink/file.py
+-rw-r--r--   0 runner    (1001) docker     (123)      490 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/sink/sink_registry.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/aws/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/aws/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8114 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/aws/aws_common.py
+-rw-r--r--   0 runner    (1001) docker     (123)    47697 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/aws/glue.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8485 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/aws/path_spec.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3892 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/aws/s3_boto_utils.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1694 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/aws/s3_util.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3809 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/aws/sagemaker.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/aws/sagemaker_processors/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/aws/sagemaker_processors/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1554 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/aws/sagemaker_processors/common.py
+-rw-r--r--   0 runner    (1001) docker     (123)    10383 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/aws/sagemaker_processors/feature_groups.py
+-rw-r--r--   0 runner    (1001) docker     (123)    10165 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/aws/sagemaker_processors/job_classes.py
+-rw-r--r--   0 runner    (1001) docker     (123)    35124 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/aws/sagemaker_processors/jobs.py
+-rw-r--r--   0 runner    (1001) docker     (123)     9290 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/aws/sagemaker_processors/lineage.py
+-rw-r--r--   0 runner    (1001) docker     (123)    19207 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/aws/sagemaker_processors/models.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/azure/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/azure/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3706 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/azure/azure_common.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/bigquery_v2/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/bigquery_v2/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    51101 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/bigquery_v2/bigquery.py
+-rw-r--r--   0 runner    (1001) docker     (123)    24168 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/bigquery_v2/bigquery_audit.py
+-rw-r--r--   0 runner    (1001) docker     (123)    12893 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/bigquery_v2/bigquery_config.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4316 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/bigquery_v2/bigquery_report.py
+-rw-r--r--   0 runner    (1001) docker     (123)    23505 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/bigquery_v2/bigquery_schema.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1640 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/bigquery_v2/common.py
+-rw-r--r--   0 runner    (1001) docker     (123)    28643 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/bigquery_v2/lineage.py
+-rw-r--r--   0 runner    (1001) docker     (123)    12225 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/bigquery_v2/profiler.py
+-rw-r--r--   0 runner    (1001) docker     (123)    36592 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/bigquery_v2/usage.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/common/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/common/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)      980 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/common/subtypes.py
+-rw-r--r--   0 runner    (1001) docker     (123)    16833 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/confluent_schema_registry.py
+-rw-r--r--   0 runner    (1001) docker     (123)    26249 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/csv_enricher.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/dbt/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/dbt/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    12796 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/dbt/dbt_cloud.py
+-rw-r--r--   0 runner    (1001) docker     (123)    56247 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/dbt/dbt_common.py
+-rw-r--r--   0 runner    (1001) docker     (123)    17244 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/dbt/dbt_core.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/delta_lake/
+-rw-r--r--   0 runner    (1001) docker     (123)       71 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/delta_lake/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3342 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/delta_lake/config.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2006 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/delta_lake/delta_lake_utils.py
+-rw-r--r--   0 runner    (1001) docker     (123)      467 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/delta_lake/report.py
+-rw-r--r--   0 runner    (1001) docker     (123)    12467 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/delta_lake/source.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1228 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/demo_data.py
+-rw-r--r--   0 runner    (1001) docker     (123)    17398 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/elastic_search.py
+-rw-r--r--   0 runner    (1001) docker     (123)    14671 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/feast.py
+-rw-r--r--   0 runner    (1001) docker     (123)    16770 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/file.py
+-rw-r--r--   0 runner    (1001) docker     (123)    44577 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/ge_data_profiler.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8830 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/ge_profiling_config.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/git/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/git/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2563 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/git/git_import.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2010 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/glue_profiling_config.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/iceberg/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/iceberg/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    19281 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/iceberg/iceberg.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7823 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/iceberg/iceberg_common.py
+-rw-r--r--   0 runner    (1001) docker     (123)     9563 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/iceberg/iceberg_profiler.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/identity/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/identity/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    29532 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/identity/azure_ad.py
+-rw-r--r--   0 runner    (1001) docker     (123)    32064 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/identity/okta.py
+-rw-r--r--   0 runner    (1001) docker     (123)    17692 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/kafka.py
+-rw-r--r--   0 runner    (1001) docker     (123)    46297 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/kafka_connect.py
+-rw-r--r--   0 runner    (1001) docker     (123)      321 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/kafka_schema_registry_base.py
+-rw-r--r--   0 runner    (1001) docker     (123)    17596 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/ldap.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/looker/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/looker/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    43834 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/looker/looker_common.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7480 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/looker/looker_lib_wrapper.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2202 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/looker/looker_query_model.py
+-rw-r--r--   0 runner    (1001) docker     (123)    53361 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/looker/looker_source.py
+-rw-r--r--   0 runner    (1001) docker     (123)    24029 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/looker/looker_usage.py
+-rw-r--r--   0 runner    (1001) docker     (123)    81876 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/looker/lookml_source.py
+-rw-r--r--   0 runner    (1001) docker     (123)    22826 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/metabase.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/metadata/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/metadata/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    16789 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/metadata/business_glossary.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6717 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/metadata/lineage.py
+-rw-r--r--   0 runner    (1001) docker     (123)    30160 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/mode.py
+-rw-r--r--   0 runner    (1001) docker     (123)    17143 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/mongodb.py
+-rw-r--r--   0 runner    (1001) docker     (123)    43231 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/nifi.py
+-rwxr-xr-x   0 runner    (1001) docker     (123)    13322 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/openapi.py
+-rwxr-xr-x   0 runner    (1001) docker     (123)    13526 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/openapi_parser.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/powerbi/
+-rw-r--r--   0 runner    (1001) docker     (123)       76 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/powerbi/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    13454 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/powerbi/config.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2265 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/powerbi/dataplatform_instance_resolver.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/powerbi/m_query/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/powerbi/m_query/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1147 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/powerbi/m_query/data_classes.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1578 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/powerbi/m_query/native_sql_parser.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3204 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/powerbi/m_query/parser.py
+-rw-r--r--   0 runner    (1001) docker     (123)    29227 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/powerbi/m_query/resolver.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6111 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/powerbi/m_query/tree_function.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1052 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/powerbi/m_query/validator.py
+-rw-r--r--   0 runner    (1001) docker     (123)    17764 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/powerbi/powerbi-lexical-grammar.rule
+-rw-r--r--   0 runner    (1001) docker     (123)    35205 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/powerbi/powerbi.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/powerbi/rest_api_wrapper/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/powerbi/rest_api_wrapper/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4290 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/powerbi/rest_api_wrapper/data_classes.py
+-rw-r--r--   0 runner    (1001) docker     (123)    27836 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/powerbi/rest_api_wrapper/data_resolver.py
+-rw-r--r--   0 runner    (1001) docker     (123)    13689 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/powerbi/rest_api_wrapper/powerbi_api.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/powerbi_report_server/
+-rw-r--r--   0 runner    (1001) docker     (123)      324 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/powerbi_report_server/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3689 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/powerbi_report_server/constants.py
+-rw-r--r--   0 runner    (1001) docker     (123)    20049 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/powerbi_report_server/report_server.py
+-rw-r--r--   0 runner    (1001) docker     (123)    11684 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/powerbi_report_server/report_server_domain.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/profiling/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/profiling/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1426 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/profiling/common.py
+-rw-r--r--   0 runner    (1001) docker     (123)    20413 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/pulsar.py
+-rw-r--r--   0 runner    (1001) docker     (123)    32287 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/redash.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/redshift/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/redshift/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)      362 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/redshift/common.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5163 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/redshift/config.py
+-rw-r--r--   0 runner    (1001) docker     (123)    17491 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/redshift/lineage.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5607 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/redshift/profile.py
+-rw-r--r--   0 runner    (1001) docker     (123)    17388 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/redshift/query.py
+-rw-r--r--   0 runner    (1001) docker     (123)    34186 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/redshift/redshift.py
+-rw-r--r--   0 runner    (1001) docker     (123)    12416 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/redshift/redshift_schema.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1389 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/redshift/report.py
+-rw-r--r--   0 runner    (1001) docker     (123)    15002 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/redshift/usage.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/s3/
+-rw-r--r--   0 runner    (1001) docker     (123)       56 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/s3/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5167 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/s3/config.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4126 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/s3/data_lake_utils.py
+-rw-r--r--   0 runner    (1001) docker     (123)    20777 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/s3/profiling.py
+-rw-r--r--   0 runner    (1001) docker     (123)      466 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/s3/report.py
+-rw-r--r--   0 runner    (1001) docker     (123)    32051 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/s3/source.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/sagemaker_processors/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/sagemaker_processors/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    27170 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/salesforce.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/schema/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/schema/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    15812 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/schema/json_schema.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/schema_inference/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/schema_inference/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)      563 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/schema_inference/avro.py
+-rw-r--r--   0 runner    (1001) docker     (123)      379 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/schema_inference/base.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2229 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/schema_inference/csv_tsv.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2103 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/schema_inference/json.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5760 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/schema_inference/object.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3426 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/schema_inference/parquet.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/snowflake/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/snowflake/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1581 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/snowflake/constants.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7116 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/snowflake/snowflake_config.py
+-rw-r--r--   0 runner    (1001) docker     (123)    29016 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/snowflake/snowflake_lineage_legacy.py
+-rw-r--r--   0 runner    (1001) docker     (123)    21942 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/snowflake/snowflake_lineage_v2.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6966 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/snowflake/snowflake_profiler.py
+-rw-r--r--   0 runner    (1001) docker     (123)    33575 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/snowflake/snowflake_query.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3665 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/snowflake/snowflake_report.py
+-rw-r--r--   0 runner    (1001) docker     (123)    19448 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/snowflake/snowflake_schema.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6141 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/snowflake/snowflake_tag.py
+-rw-r--r--   0 runner    (1001) docker     (123)    18561 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/snowflake/snowflake_usage_v2.py
+-rw-r--r--   0 runner    (1001) docker     (123)    10596 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/snowflake/snowflake_utils.py
+-rw-r--r--   0 runner    (1001) docker     (123)    62420 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/snowflake/snowflake_v2.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1313 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/source_registry.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/sql/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/sql/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     9739 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/sql/athena.py
+-rw-r--r--   0 runner    (1001) docker     (123)    25177 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/sql/clickhouse.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2346 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/sql/druid.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1342 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/sql/hana.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6454 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/sql/hive.py
+-rw-r--r--   0 runner    (1001) docker     (123)      737 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/sql/mariadb.py
+-rw-r--r--   0 runner    (1001) docker     (123)    10973 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/sql/mssql.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2650 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/sql/mysql.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2316 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/sql/oauth_generator.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6923 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/sql/oracle.py
+-rw-r--r--   0 runner    (1001) docker     (123)    10476 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/sql/postgres.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3606 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/sql/presto.py
+-rw-r--r--   0 runner    (1001) docker     (123)    33112 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/sql/presto_on_hive.py
+-rw-r--r--   0 runner    (1001) docker     (123)    45775 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/sql/redshift.py
+-rw-r--r--   0 runner    (1001) docker     (123)    44223 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/sql/sql_common.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7105 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/sql/sql_config.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2731 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/sql/sql_generic.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6881 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/sql/sql_generic_profiler.py
+-rw-r--r--   0 runner    (1001) docker     (123)    11475 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/sql/sql_types.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7629 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/sql/sql_utils.py
+-rw-r--r--   0 runner    (1001) docker     (123)    10551 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/sql/trino.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4936 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/sql/two_tier_sql_source.py
+-rw-r--r--   0 runner    (1001) docker     (123)    53109 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/sql/vertica.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/state/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/state/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8797 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/state/checkpoint.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4220 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/state/entity_removal_state.py
+-rw-r--r--   0 runner    (1001) docker     (123)      512 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/state/profiling_state.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4209 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/state/profiling_state_handler.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5544 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/state/redundant_run_skip_handler.py
+-rw-r--r--   0 runner    (1001) docker     (123)      143 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/state/sql_common_state.py
+-rw-r--r--   0 runner    (1001) docker     (123)    13129 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/state/stale_entity_removal_handler.py
+-rw-r--r--   0 runner    (1001) docker     (123)    15642 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/state/stateful_ingestion_base.py
+-rw-r--r--   0 runner    (1001) docker     (123)      463 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/state/usage_common_state.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1271 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/state/use_case_handler.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/state_provider/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/state_provider/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5226 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/state_provider/datahub_ingestion_checkpointing_provider.py
+-rw-r--r--   0 runner    (1001) docker     (123)      401 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/state_provider/state_provider_registry.py
+-rw-r--r--   0 runner    (1001) docker     (123)    14641 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/superset.py
+-rw-r--r--   0 runner    (1001) docker     (123)    91756 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/tableau.py
+-rw-r--r--   0 runner    (1001) docker     (123)    15651 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/tableau_common.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2284 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/tableau_constant.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/unity/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/unity/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3164 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/unity/config.py
+-rw-r--r--   0 runner    (1001) docker     (123)    11625 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/unity/proxy.py
+-rw-r--r--   0 runner    (1001) docker     (123)      585 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/unity/report.py
+-rw-r--r--   0 runner    (1001) docker     (123)    19523 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/unity/source.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/usage/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/usage/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     9827 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/usage/clickhouse_usage.py
+-rw-r--r--   0 runner    (1001) docker     (123)    15306 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/usage/redshift_usage.py
+-rw-r--r--   0 runner    (1001) docker     (123)    10155 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/usage/starburst_trino_usage.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6281 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/usage/usage_common.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source_config/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source_config/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1654 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source_config/bigquery.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1688 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source_config/csv_enricher.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5615 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source_config/pulsar.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source_config/sql/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source_config/sql/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    16134 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source_config/sql/snowflake.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source_config/usage/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source_config/usage/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7702 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source_config/usage/bigquery_usage.py
+-rw-r--r--   0 runner    (1001) docker     (123)      565 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source_config/usage/snowflake_usage.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source_report/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source_report/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1037 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source_report/pulsar.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source_report/sql/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source_report/sql/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1864 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source_report/sql/bigquery.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1331 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source_report/sql/snowflake.py
+-rw-r--r--   0 runner    (1001) docker     (123)      229 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source_report/time_window.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source_report/usage/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source_report/usage/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1374 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source_report/usage/bigquery_usage.py
+-rw-r--r--   0 runner    (1001) docker     (123)      780 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source_report/usage/snowflake_usage.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/transformer/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/transformer/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3420 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/transformer/add_dataset_browse_path.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6849 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/transformer/add_dataset_ownership.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5605 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/transformer/add_dataset_properties.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5664 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/transformer/add_dataset_schema_tags.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6239 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/transformer/add_dataset_schema_terms.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4911 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/transformer/add_dataset_tags.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5707 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/transformer/add_dataset_terms.py
+-rw-r--r--   0 runner    (1001) docker     (123)    10623 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/transformer/base_transformer.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6241 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/transformer/dataset_domain.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1598 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/transformer/dataset_transformer.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1323 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/transformer/mark_dataset_status.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1218 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/transformer/remove_dataset_ownership.py
+-rw-r--r--   0 runner    (1001) docker     (123)      251 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/transformer/transform_registry.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/integrations/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/integrations/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/integrations/great_expectations/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/integrations/great_expectations/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    34843 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/integrations/great_expectations/action.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/lite/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/lite/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    32549 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/lite/duckdb_lite.py
+-rw-r--r--   0 runner    (1001) docker     (123)      157 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/lite/duckdb_lite_config.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2846 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/lite/lite_local.py
+-rw-r--r--   0 runner    (1001) docker     (123)      286 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/lite/lite_registry.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1949 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/lite/lite_server.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4503 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/lite/lite_util.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/
+-rw-r--r--   0 runner    (1001) docker     (123)      197 2023-05-31 19:14:26.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/
+-rw-r--r--   0 runner    (1001) docker     (123)      161 2023-05-31 19:14:26.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/
+-rw-r--r--   0 runner    (1001) docker     (123)      161 2023-05-31 19:14:26.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/events/
+-rw-r--r--   0 runner    (1001) docker     (123)      257 2023-05-31 19:14:26.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/events/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/
+-rw-r--r--   0 runner    (1001) docker     (123)      161 2023-05-31 19:14:26.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/access/
+-rw-r--r--   0 runner    (1001) docker     (123)      161 2023-05-31 19:14:26.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/access/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/access/token/
+-rw-r--r--   0 runner    (1001) docker     (123)      277 2023-05-31 19:14:26.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/access/token/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/assertion/
+-rw-r--r--   0 runner    (1001) docker     (123)     1589 2023-05-31 19:14:26.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/assertion/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/chart/
+-rw-r--r--   0 runner    (1001) docker     (123)      807 2023-05-31 19:14:26.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/chart/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/common/
+-rw-r--r--   0 runner    (1001) docker     (123)     3456 2023-05-31 19:14:26.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/common/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/common/fieldtransformer/
+-rw-r--r--   0 runner    (1001) docker     (123)      355 2023-05-31 19:14:26.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/common/fieldtransformer/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/container/
+-rw-r--r--   0 runner    (1001) docker     (123)      469 2023-05-31 19:14:26.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/container/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/dashboard/
+-rw-r--r--   0 runner    (1001) docker     (123)      615 2023-05-31 19:14:26.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/dashboard/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/datajob/
+-rw-r--r--   0 runner    (1001) docker     (123)      828 2023-05-31 19:14:26.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/datajob/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/datajob/azkaban/
+-rw-r--r--   0 runner    (1001) docker     (123)      253 2023-05-31 19:14:26.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/datajob/azkaban/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/datajob/datahub/
+-rw-r--r--   0 runner    (1001) docker     (123)      535 2023-05-31 19:14:26.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/datajob/datahub/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/dataplatform/
+-rw-r--r--   0 runner    (1001) docker     (123)      341 2023-05-31 19:14:26.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/dataplatform/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/dataplatforminstance/
+-rw-r--r--   0 runner    (1001) docker     (123)      300 2023-05-31 19:14:26.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/dataplatforminstance/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/dataprocess/
+-rw-r--r--   0 runner    (1001) docker     (123)     1317 2023-05-31 19:14:26.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/dataprocess/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/dataset/
+-rw-r--r--   0 runner    (1001) docker     (123)     2204 2023-05-31 19:14:26.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/dataset/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/domain/
+-rw-r--r--   0 runner    (1001) docker     (123)      326 2023-05-31 19:14:26.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/domain/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/events/
+-rw-r--r--   0 runner    (1001) docker     (123)      161 2023-05-31 19:14:26.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/events/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/events/metadata/
+-rw-r--r--   0 runner    (1001) docker     (123)      241 2023-05-31 19:14:26.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/events/metadata/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/execution/
+-rw-r--r--   0 runner    (1001) docker     (123)      734 2023-05-31 19:14:26.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/execution/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/glossary/
+-rw-r--r--   0 runner    (1001) docker     (123)      460 2023-05-31 19:14:26.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/glossary/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/identity/
+-rw-r--r--   0 runner    (1001) docker     (123)     1443 2023-05-31 19:14:26.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/identity/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/ingestion/
+-rw-r--r--   0 runner    (1001) docker     (123)      556 2023-05-31 19:14:26.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/ingestion/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/metadata/
+-rw-r--r--   0 runner    (1001) docker     (123)      161 2023-05-31 19:14:26.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/metadata/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/metadata/key/
+-rw-r--r--   0 runner    (1001) docker     (123)     3859 2023-05-31 19:14:26.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/metadata/key/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/metadata/query/
+-rw-r--r--   0 runner    (1001) docker     (123)      161 2023-05-31 19:14:26.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/metadata/query/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/metadata/query/filter/
+-rw-r--r--   0 runner    (1001) docker     (123)      491 2023-05-31 19:14:26.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/metadata/query/filter/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/metadata/snapshot/
+-rw-r--r--   0 runner    (1001) docker     (123)     2317 2023-05-31 19:14:26.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/metadata/snapshot/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/ml/
+-rw-r--r--   0 runner    (1001) docker     (123)      161 2023-05-31 19:14:26.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/ml/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/ml/metadata/
+-rw-r--r--   0 runner    (1001) docker     (123)     3151 2023-05-31 19:14:26.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/ml/metadata/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/mxe/
+-rw-r--r--   0 runner    (1001) docker     (123)      932 2023-05-31 19:14:26.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/mxe/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/notebook/
+-rw-r--r--   0 runner    (1001) docker     (123)      860 2023-05-31 19:14:26.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/notebook/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/platform/
+-rw-r--r--   0 runner    (1001) docker     (123)      161 2023-05-31 19:14:26.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/platform/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/platform/event/
+-rw-r--r--   0 runner    (1001) docker     (123)      161 2023-05-31 19:14:26.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/platform/event/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/platform/event/v1/
+-rw-r--r--   0 runner    (1001) docker     (123)      342 2023-05-31 19:14:26.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/platform/event/v1/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/policy/
+-rw-r--r--   0 runner    (1001) docker     (123)      876 2023-05-31 19:14:26.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/policy/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/post/
+-rw-r--r--   0 runner    (1001) docker     (123)      477 2023-05-31 19:14:26.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/post/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/query/
+-rw-r--r--   0 runner    (1001) docker     (123)      679 2023-05-31 19:14:26.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/query/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/retention/
+-rw-r--r--   0 runner    (1001) docker     (123)      561 2023-05-31 19:14:26.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/retention/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/schema/
+-rw-r--r--   0 runner    (1001) docker     (123)     2822 2023-05-31 19:14:26.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/schema/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/secret/
+-rw-r--r--   0 runner    (1001) docker     (123)      264 2023-05-31 19:14:26.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/secret/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/settings/
+-rw-r--r--   0 runner    (1001) docker     (123)      161 2023-05-31 19:14:26.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/settings/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/settings/global/
+-rw-r--r--   0 runner    (1001) docker     (123)      370 2023-05-31 19:14:26.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/settings/global/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/step/
+-rw-r--r--   0 runner    (1001) docker     (123)      288 2023-05-31 19:14:26.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/step/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/tag/
+-rw-r--r--   0 runner    (1001) docker     (123)      249 2023-05-31 19:14:26.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/tag/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/telemetry/
+-rw-r--r--   0 runner    (1001) docker     (123)      261 2023-05-31 19:14:26.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/telemetry/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/test/
+-rw-r--r--   0 runner    (1001) docker     (123)      670 2023-05-31 19:14:26.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/test/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/timeseries/
+-rw-r--r--   0 runner    (1001) docker     (123)      596 2023-05-31 19:14:26.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/timeseries/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/upgrade/
+-rw-r--r--   0 runner    (1001) docker     (123)      380 2023-05-31 19:14:26.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/upgrade/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/usage/
+-rw-r--r--   0 runner    (1001) docker     (123)      561 2023-05-31 19:14:26.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/usage/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/view/
+-rw-r--r--   0 runner    (1001) docker     (123)      457 2023-05-31 19:14:26.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/view/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)   421524 2023-05-31 19:14:26.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/schema.avsc
+-rw-r--r--   0 runner    (1001) docker     (123)   788555 2023-05-31 19:14:26.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/schema_classes.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/schemas/
+-rw-r--r--   0 runner    (1001) docker     (123)   333312 2023-05-31 19:14:26.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/schemas/MetadataChangeEvent.avsc
+-rw-r--r--   0 runner    (1001) docker     (123)     8438 2023-05-31 19:14:26.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/schemas/MetadataChangeProposal.avsc
+-rw-r--r--   0 runner    (1001) docker     (123)      540 2023-05-31 19:14:26.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/schemas/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/py.typed
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/specific/
+-rw-r--r--   0 runner    (1001) docker     (123)       88 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/specific/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)      994 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/specific/custom_properties.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7642 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/specific/dataset.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/telemetry/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/telemetry/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)      967 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/telemetry/stats.py
+-rw-r--r--   0 runner    (1001) docker     (123)    11734 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/telemetry/telemetry.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/upgrade/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/upgrade/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    15375 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/upgrade/upgrade.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)      444 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/_markupsafe_compat.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3147 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/bigquery_sql_parser.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1138 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/checkpoint_state_util.py
+-rw-r--r--   0 runner    (1001) docker     (123)      459 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/config_clean.py
+-rw-r--r--   0 runner    (1001) docker     (123)      468 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/dedup_list.py
+-rw-r--r--   0 runner    (1001) docker     (123)      645 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/delayed_iter.py
+-rw-r--r--   0 runner    (1001) docker     (123)    15335 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/file_backed_collections.py
+-rw-r--r--   0 runner    (1001) docker     (123)      261 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/global_warning_util.py
+-rw-r--r--   0 runner    (1001) docker     (123)    10998 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/hive_schema_to_avro.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6609 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/logging_manager.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4614 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/lossy_collections.py
+-rw-r--r--   0 runner    (1001) docker     (123)    10590 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/mapping.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1564 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/memory_footprint.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3933 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/memory_leak_detector.py
+-rw-r--r--   0 runner    (1001) docker     (123)      598 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/parsing_util.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1097 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/perf_timer.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/registries/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/registries/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2452 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/registries/domain_registry.py
+-rw-r--r--   0 runner    (1001) docker     (123)      766 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/sample_data.py
+-rw-r--r--   0 runner    (1001) docker     (123)      698 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/server_config_util.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4779 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/source_helpers.py
+-rw-r--r--   0 runner    (1001) docker     (123)      871 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/sql_formatter.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6522 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/sql_lineage_parser_impl.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5814 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/sql_parser.py
+-rw-r--r--   0 runner    (1001) docker     (123)      456 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/sql_parser_base.py
+-rw-r--r--   0 runner    (1001) docker     (123)    14786 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/sqlalchemy_query_combiner.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1990 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/sqllineage_patch.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1390 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/stats_collections.py
+-rw-r--r--   0 runner    (1001) docker     (123)      601 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/tee_io.py
+-rw-r--r--   0 runner    (1001) docker     (123)      358 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/time.py
+-rw-r--r--   0 runner    (1001) docker     (123)      970 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/type_annotations.py
+-rw-r--r--   0 runner    (1001) docker     (123)      172 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/url_util.py
+-rw-r--r--   0 runner    (1001) docker     (123)      984 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/urn_encoder.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/urns/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/urns/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1317 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/urns/corp_group_urn.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1307 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/urns/corpuser_urn.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2847 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/urns/data_flow_urn.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1744 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/urns/data_job_urn.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1097 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/urns/data_platform_urn.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1587 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/urns/data_process_instance_urn.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3877 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/urns/dataset_urn.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1292 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/urns/domain_urn.py
+-rw-r--r--   0 runner    (1001) docker     (123)       98 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/urns/error.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1533 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/urns/notebook_urn.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1247 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/urns/tag_urn.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5447 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/urns/urn.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4176 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/urns/urn_iter.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub_provider/
+-rw-r--r--   0 runner    (1001) docker     (123)     1073 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub_provider/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)      291 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub_provider/_airflow_compat.py
+-rw-r--r--   0 runner    (1001) docker     (123)      844 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub_provider/_airflow_shims.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3564 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub_provider/_lineage_core.py
+-rw-r--r--   0 runner    (1001) docker     (123)    12902 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub_provider/_plugin.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub_provider/client/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub_provider/client/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    19475 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub_provider/client/airflow_generator.py
+-rw-r--r--   0 runner    (1001) docker     (123)      994 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub_provider/entities.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub_provider/example_dags/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub_provider/example_dags/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1319 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub_provider/example_dags/generic_recipe_sample_dag.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1348 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub_provider/example_dags/lineage_backend_demo.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1414 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub_provider/example_dags/lineage_backend_taskflow_demo.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2283 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub_provider/example_dags/lineage_emission_dag.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1922 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub_provider/example_dags/mysql_sample_dag.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3234 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub_provider/example_dags/snowflake_sample_dag.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub_provider/hooks/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub_provider/hooks/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6980 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub_provider/hooks/datahub.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub_provider/lineage/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub_provider/lineage/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3286 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub_provider/lineage/datahub.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-05-31 19:14:29.000000 acryl-datahub-tc-0.10.2rc1/src/datahub_provider/operators/
+-rw-r--r--   0 runner    (1001) docker     (123)        0 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub_provider/operators/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1848 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub_provider/operators/datahub.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2900 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub_provider/operators/datahub_assertion_operator.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2903 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub_provider/operators/datahub_assertion_sensor.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3338 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub_provider/operators/datahub_operation_operator.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3606 2023-05-31 19:12:13.000000 acryl-datahub-tc-0.10.2rc1/src/datahub_provider/operators/datahub_operation_sensor.py
```

### Comparing `acryl-datahub-tc-0.10.2.0rc3/PKG-INFO` & `acryl-datahub-tc-0.10.2rc1/PKG-INFO`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: acryl-datahub-tc
-Version: 0.10.2.0rc3
+Version: 0.10.2rc1
 Summary: A CLI to work with DataHub metadata
 Home-page: https://datahubproject.io/
 License: Apache License 2.0
 Project-URL: Documentation, https://datahubproject.io/docs/
 Project-URL: Source, https://github.com/datahub-project/datahub
 Project-URL: Changelog, https://github.com/datahub-project/datahub/releases
 Description: # Introduction to Metadata Ingestion
```

### Comparing `acryl-datahub-tc-0.10.2.0rc3/README.md` & `acryl-datahub-tc-0.10.2rc1/README.md`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/pyproject.toml` & `acryl-datahub-tc-0.10.2rc1/pyproject.toml`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/setup.cfg` & `acryl-datahub-tc-0.10.2rc1/setup.cfg`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/setup.py` & `acryl-datahub-tc-0.10.2rc1/setup.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/acryl_datahub_tc.egg-info/PKG-INFO` & `acryl-datahub-tc-0.10.2rc1/src/acryl_datahub_tc.egg-info/PKG-INFO`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: acryl-datahub-tc
-Version: 0.10.2.0rc3
+Version: 0.10.2rc1
 Summary: A CLI to work with DataHub metadata
 Home-page: https://datahubproject.io/
 License: Apache License 2.0
 Project-URL: Documentation, https://datahubproject.io/docs/
 Project-URL: Source, https://github.com/datahub-project/datahub
 Project-URL: Changelog, https://github.com/datahub-project/datahub/releases
 Description: # Introduction to Metadata Ingestion
```

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/acryl_datahub_tc.egg-info/SOURCES.txt` & `acryl-datahub-tc-0.10.2rc1/src/acryl_datahub_tc.egg-info/SOURCES.txt`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/acryl_datahub_tc.egg-info/entry_points.txt` & `acryl-datahub-tc-0.10.2rc1/src/acryl_datahub_tc.egg-info/entry_points.txt`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/acryl_datahub_tc.egg-info/requires.txt` & `acryl-datahub-tc-0.10.2rc1/src/acryl_datahub_tc.egg-info/requires.txt`

 * *Ordering differences only*

 * *Files 14% similar despite different names*

```diff
@@ -1,2361 +1,2361 @@
-ratelimiter
-python-dateutil>=2.8.0
-jsonschema
-progressbar2
-packaging
+avro<1.11,>=1.10.2
+cached_property
 click>=7.1.2
-ijson
-mixpanel>=4.9.0
-click-default-group
-expandvars>=0.6.5
+jsonref
+packaging
 tabulate
-entrypoints
-avro<1.11,>=1.10.2
-Deprecated
+docker
+aiohttp<4
+expandvars>=0.6.5
+avro-gen3==0.7.10
+PyYAML
+click-spinner
 mypy_extensions>=0.4.3
+requests_file
+mixpanel>=4.9.0
+pydantic!=1.10.3,>=1.5.1
+ratelimiter
 humanfriendly
+jsonschema
+click-default-group
 toml>=0.10.0
-aiohttp<4
-docker
-PyYAML
 typing-inspect
-pydantic!=1.10.3,>=1.5.1
-termcolor>=1.0.0
 psutil>=5.8.0
-requests_file
-click-spinner
-cached_property
-jsonref
-avro-gen3==0.7.10
+python-dateutil>=2.8.0
+progressbar2
+entrypoints
+Deprecated
+ijson
+termcolor>=1.0.0
 
 [:python_version < "3.8"]
 typing_extensions>=3.7.4.3
 
 [:python_version >= "3.8"]
 typing_extensions>=3.10.0.2
 
 [airflow]
-ratelimiter
-python-dateutil>=2.8.0
-jsonschema
-apache-airflow>=2.0.2
-progressbar2
-packaging
+avro<1.11,>=1.10.2
+cached_property
 click>=7.1.2
-ijson
-click-default-group
-expandvars>=0.6.5
+jsonref
+packaging
 tabulate
-entrypoints
-avro<1.11,>=1.10.2
-requests
-Deprecated
-humanfriendly
-toml>=0.10.0
-aiohttp<4
 docker
+aiohttp<4
+expandvars>=0.6.5
+avro-gen3==0.7.10
 PyYAML
-termcolor>=1.0.0
-psutil>=5.8.0
 click-spinner
 requests_file
-cached_property
-jsonref
-avro-gen3==0.7.10
-
-[all]
-moto[s3]
 jsonschema
-progressbar2
-pandas
-okta~=1.7.0
-sqlalchemy<2,>=1.3.24
-msal
-spacy==3.4.3
-entrypoints
-lark[regex]==1.1.4
+click-default-group
+ratelimiter
 humanfriendly
 toml>=0.10.0
-great-expectations<=0.15.50,>=0.15.12
-sqlalchemy
-sql-metadata==2.2.2
-cryptography
-termcolor>=1.0.0
-trino[sqlalchemy]!=0.317,>=0.308
-requests_file
-sqlalchemy-bigquery>=1.4.1
-cached_property
-cx_Oracle
-flask-openid>=1.3.0
-avro-gen3==0.7.10
-databricks-cli==0.17.3
-looker-sdk==23.0.0
+requests
+psutil>=5.8.0
 python-dateutil>=2.8.0
-snowflake-sqlalchemy!=1.2.5,>=1.2.4
-requests_ntlm
-networkx>=2.6.2
-packaging
-SQLAlchemy<1.4.42
-click-default-group
-pyarrow>=6.0.1
-boto3
-GitPython>2
-pymongo[srv]>=3.11
-msal==1.16.0
-fastavro>=1.2.0
-more-itertools>=8.12.0
-acryl-iceberg-legacy==0.0.4
-grpcio-tools<2,>=1.44.0
+progressbar2
+entrypoints
 Deprecated
-grpcio<2,>=1.44.0
-typeguard<3
-smart-open[s3]>=5.2.1
+ijson
+apache-airflow>=2.0.2
+termcolor>=1.0.0
+
+[all]
+pymysql>=1.0.2
+more-itertools>=8.12.0
+wcmatch
 sql_metadata
-sqlalchemy-redshift
+google-cloud-datacatalog-lineage==0.2.0
+great_expectations
+GeoAlchemy2
+requests_ntlm
+acryl-pyhive[hive]>=0.6.13
+avro-gen3==0.7.10
+PyYAML
+click-spinner
+requests_file
+PyAthena[sqlalchemy]==2.4.1
+clickhouse-sqlalchemy>=0.1.8
+azure-identity==1.10.0
+JPype1
+toml>=0.10.0
+requests
+moto[s3]
+scipy>=1.7.2
 psutil>=5.8.0
-tableauserverclient>=0.17.0
-jsonref
-pydruid>=0.6.2
-tableschema>=1.20.2
-google-cloud-logging<=3.5.0
+flask-openid>=1.3.0
+typeguard<3
 sqllineage==1.3.6
-ratelimiter
+smart-open[s3]>=5.2.1
+pandas
+snowflake-sqlalchemy!=1.2.5,>=1.2.4
+progressbar2
+entrypoints
+msal
+parse>=1.19.0
+deltalake!=0.6.4,>=0.6.3
 gql[requests]>=3.3.0
-pydeequ>=1.0.1
-pymysql>=1.0.2
-redshift-connector
+greenlet
+google-cloud-bigquery
+avro<1.11,>=1.10.2
 click>=7.1.2
+sql-metadata==2.2.2
+jsonref
+acryl-datahub-classify==0.0.6
+tabulate
+aiohttp<4
+lkml>=1.3.0b5
+click-default-group
+grpcio<2,>=1.44.0
+google-cloud-logging<=3.5.0
+pymongo[srv]>=3.11
+sqlparse
+tableauserverclient>=0.17.0
+pyspark==3.0.3
 databricks-dbapi
+tenacity>=8.0.1
+python-dateutil>=2.8.0
+snowflake-connector-python!=2.8.2,<3.0.0
+psycopg2-binary
+python-ldap>=2.4
+great-expectations!=0.15.23,!=0.15.24,!=0.15.25,!=0.15.26
+botocore!=1.23.0
 ijson
-sql-metadata
-great_expectations
-gql>=3.3.0
-vertica-sqlalchemy-dialect[vertica-python]==0.0.1
-pyspark==3.0.3
+pydeequ>=1.0.1
+termcolor>=1.0.0
+okta~=1.7.0
 elasticsearch==7.13.4
-acryl-pyhive[hive]>=0.6.13
-acryl-pyhive[hive]>=0.6.12
-ujson>=5.2.0
-google-cloud-bigquery
+packaging
+pydruid>=0.6.2
+cx_Oracle
 docker
-great-expectations!=0.15.23,!=0.15.24,!=0.15.25,!=0.15.26
-deltalake!=0.6.4,>=0.6.3
-PyYAML
-traitlets<5.2.2
-sqlalchemy-pytds>=0.3
-greenlet
-tenacity>=8.0.1
-lkml>=1.3.0b5
-sqlparse
-google-cloud-datacatalog-lineage==0.2.0
+tableschema>=1.20.2
+trino[sqlalchemy]!=0.317,>=0.308
 redash-toolbelt
-acryl-datahub-classify==0.0.6
-botocore!=1.23.0
-JPype1
-azure-identity==1.10.0
-PyAthena[sqlalchemy]==2.4.1
+spacy==3.4.3
+acryl-iceberg-legacy==0.0.4
+ratelimiter
+humanfriendly
+feast~=0.29.0
+msal==1.16.0
+ujson>=5.2.0
+pyarrow>=6.0.1
+redshift-connector
+fastavro>=1.2.0
+boto3
+GitPython>2
 apache-airflow>=2.0.2
+vertica-sqlalchemy-dialect[vertica-python]==0.0.1
+sql-metadata
+sqlalchemy-redshift
+databricks-cli==0.17.3
+cached_property
+looker-sdk==23.0.0
 expandvars>=0.6.5
-tabulate
-simple-salesforce
-scipy>=1.7.2
-clickhouse-sqlalchemy>=0.1.8
-avro<1.11,>=1.10.2
-requests
-wcmatch
-GeoAlchemy2
-snowflake-connector-python!=2.8.2,<3.0.0
-feast~=0.29.0
-aiohttp<4
-psycopg2-binary
-python-ldap>=2.4
-click-spinner
 confluent_kafka>=1.5.0
-parse>=1.19.0
+jsonschema
+acryl-pyhive[hive]>=0.6.12
+SQLAlchemy<1.4.42
+sqlalchemy-pytds>=0.3
+cryptography
+great-expectations<=0.15.50,>=0.15.12
+lark[regex]==1.1.4
+sqlalchemy
+grpcio-tools<2,>=1.44.0
+networkx>=2.6.2
+traitlets<5.2.2
+sqlalchemy-bigquery>=1.4.1
+sqlalchemy<2,>=1.3.24
+Deprecated
+gql>=3.3.0
+simple-salesforce
 
 [all:platform_machine != "aarch64" and platform_machine != "arm64"]
 sqlalchemy-hana>=0.5.0
 hdbcli>=2.11.20
 
 [all:platform_system != "Darwin" and (platform_machine == "aarch64" or platform_machine == "arm64")]
 confluent_kafka<1.9.0
 
 [athena]
-ratelimiter
-python-dateutil>=2.8.0
-PyAthena[sqlalchemy]==2.4.1
-jsonschema
-progressbar2
-packaging
+avro<1.11,>=1.10.2
+cached_property
 click>=7.1.2
-ijson
-click-default-group
-expandvars>=0.6.5
+jsonref
+packaging
 tabulate
-sqlalchemy<2,>=1.3.24
-scipy>=1.7.2
-entrypoints
-avro<1.11,>=1.10.2
-Deprecated
-humanfriendly
-toml>=0.10.0
-great-expectations<=0.15.50,>=0.15.12
-aiohttp<4
 docker
+aiohttp<4
+expandvars>=0.6.5
+avro-gen3==0.7.10
 PyYAML
-termcolor>=1.0.0
-psutil>=5.8.0
 click-spinner
-greenlet
 requests_file
+jsonschema
+click-default-group
+PyAthena[sqlalchemy]==2.4.1
+ratelimiter
+humanfriendly
+great-expectations<=0.15.50,>=0.15.12
+toml>=0.10.0
+scipy>=1.7.2
+psutil>=5.8.0
+python-dateutil>=2.8.0
 traitlets<5.2.2
+progressbar2
+entrypoints
+sqlalchemy<2,>=1.3.24
+Deprecated
+ijson
+greenlet
+termcolor>=1.0.0
+
+[azure-ad]
+avro<1.11,>=1.10.2
 cached_property
+click>=7.1.2
 jsonref
+packaging
+tabulate
+docker
+aiohttp<4
+expandvars>=0.6.5
 avro-gen3==0.7.10
-
-[azure-ad]
+PyYAML
+click-spinner
+requests_file
+jsonschema
+click-default-group
 ratelimiter
+humanfriendly
+toml>=0.10.0
+psutil>=5.8.0
 python-dateutil>=2.8.0
-jsonschema
 progressbar2
-packaging
-click>=7.1.2
-ijson
-click-default-group
-expandvars>=0.6.5
-tabulate
 entrypoints
-avro<1.11,>=1.10.2
 Deprecated
-humanfriendly
-toml>=0.10.0
-aiohttp<4
+ijson
+termcolor>=1.0.0
+
+[base]
+packaging
 docker
+avro-gen3==0.7.10
 PyYAML
-termcolor>=1.0.0
-psutil>=5.8.0
 click-spinner
 requests_file
-cached_property
-jsonref
-avro-gen3==0.7.10
-
-[base]
 ratelimiter
-jsonref
-jsonschema
+humanfriendly
+toml>=0.10.0
+psutil>=5.8.0
 progressbar2
+entrypoints
+avro<1.11,>=1.10.2
+cached_property
 click>=7.1.2
+jsonref
+tabulate
+aiohttp<4
+expandvars>=0.6.5
+jsonschema
+click-default-group
+python-dateutil>=2.8.0
+Deprecated
 ijson
-entrypoints
-humanfriendly
-toml>=0.10.0
-docker
-PyYAML
 termcolor>=1.0.0
-requests_file
+
+[bigquery]
+avro<1.11,>=1.10.2
 cached_property
-avro-gen3==0.7.10
-python-dateutil>=2.8.0
-click-default-group
-expandvars>=0.6.5
+click>=7.1.2
+more-itertools>=8.12.0
+jsonref
+sql_metadata
+packaging
+google-cloud-datacatalog-lineage==0.2.0
 tabulate
-avro<1.11,>=1.10.2
-Deprecated
+docker
 aiohttp<4
-psutil>=5.8.0
+expandvars>=0.6.5
+avro-gen3==0.7.10
+PyYAML
 click-spinner
-packaging
-
-[bigquery]
-ratelimiter
-python-dateutil>=2.8.0
+requests_file
 jsonschema
-progressbar2
-packaging
-click>=7.1.2
-ijson
 click-default-group
-expandvars>=0.6.5
-tabulate
-sqlalchemy<2,>=1.3.24
+great-expectations<=0.15.50,>=0.15.12
+ratelimiter
+humanfriendly
 google-cloud-logging<=3.5.0
+toml>=0.10.0
 scipy>=1.7.2
+psutil>=5.8.0
+python-dateutil>=2.8.0
+traitlets<5.2.2
+sqllineage==1.3.6
+progressbar2
+sqlalchemy-bigquery>=1.4.1
 entrypoints
-avro<1.11,>=1.10.2
-more-itertools>=8.12.0
+sqlalchemy<2,>=1.3.24
 Deprecated
-humanfriendly
-toml>=0.10.0
-great-expectations<=0.15.50,>=0.15.12
-aiohttp<4
+ijson
+greenlet
 google-cloud-bigquery
-docker
-sql_metadata
-PyYAML
 termcolor>=1.0.0
-psutil>=5.8.0
-click-spinner
-traitlets<5.2.2
-requests_file
-greenlet
+
+[bigquery-beta]
+avro<1.11,>=1.10.2
 cached_property
-sqlalchemy-bigquery>=1.4.1
+click>=7.1.2
+more-itertools>=8.12.0
 jsonref
+sql_metadata
+packaging
+tabulate
+docker
+aiohttp<4
+expandvars>=0.6.5
 avro-gen3==0.7.10
-google-cloud-datacatalog-lineage==0.2.0
-sqllineage==1.3.6
-
-[bigquery-beta]
-ratelimiter
-python-dateutil>=2.8.0
+PyYAML
+click-spinner
+requests_file
 jsonschema
-progressbar2
-packaging
-click>=7.1.2
-ijson
 click-default-group
-expandvars>=0.6.5
-tabulate
-sqlalchemy<2,>=1.3.24
+great-expectations<=0.15.50,>=0.15.12
+ratelimiter
+humanfriendly
 google-cloud-logging<=3.5.0
+toml>=0.10.0
 scipy>=1.7.2
+psutil>=5.8.0
+python-dateutil>=2.8.0
+traitlets<5.2.2
+sqllineage==1.3.6
+progressbar2
+sqlalchemy-bigquery>=1.4.1
 entrypoints
-avro<1.11,>=1.10.2
-more-itertools>=8.12.0
+sqlalchemy<2,>=1.3.24
 Deprecated
-humanfriendly
-toml>=0.10.0
-great-expectations<=0.15.50,>=0.15.12
-aiohttp<4
+ijson
+greenlet
 google-cloud-bigquery
-docker
-sql_metadata
-PyYAML
 termcolor>=1.0.0
-psutil>=5.8.0
-click-spinner
-traitlets<5.2.2
-requests_file
-greenlet
+
+[circuit-breaker]
+avro<1.11,>=1.10.2
 cached_property
-sqlalchemy-bigquery>=1.4.1
+click>=7.1.2
 jsonref
+packaging
+tabulate
+docker
+aiohttp<4
+expandvars>=0.6.5
 avro-gen3==0.7.10
-sqllineage==1.3.6
-
-[circuit-breaker]
+PyYAML
+click-spinner
+requests_file
+jsonschema
+click-default-group
 ratelimiter
+humanfriendly
+toml>=0.10.0
+psutil>=5.8.0
 python-dateutil>=2.8.0
-gql[requests]>=3.3.0
-jsonschema
 progressbar2
-packaging
-click>=7.1.2
+entrypoints
+Deprecated
 ijson
-click-default-group
-expandvars>=0.6.5
-tabulate
+gql[requests]>=3.3.0
 gql>=3.3.0
-entrypoints
+termcolor>=1.0.0
+
+[clickhouse]
 avro<1.11,>=1.10.2
-Deprecated
-humanfriendly
-toml>=0.10.0
-aiohttp<4
+cached_property
+click>=7.1.2
+jsonref
+packaging
+tabulate
 docker
+aiohttp<4
+expandvars>=0.6.5
+avro-gen3==0.7.10
 PyYAML
-termcolor>=1.0.0
-psutil>=5.8.0
 click-spinner
 requests_file
-cached_property
-jsonref
-avro-gen3==0.7.10
-
-[clickhouse]
-ratelimiter
-python-dateutil>=2.8.0
 jsonschema
-progressbar2
-packaging
-click>=7.1.2
-ijson
 click-default-group
-expandvars>=0.6.5
-tabulate
-sqlalchemy<2,>=1.3.24
-scipy>=1.7.2
-entrypoints
-avro<1.11,>=1.10.2
 clickhouse-sqlalchemy>=0.1.8
-Deprecated
+ratelimiter
 humanfriendly
-toml>=0.10.0
 great-expectations<=0.15.50,>=0.15.12
-aiohttp<4
-docker
-PyYAML
-termcolor>=1.0.0
+toml>=0.10.0
+scipy>=1.7.2
 psutil>=5.8.0
-click-spinner
-greenlet
-requests_file
+python-dateutil>=2.8.0
 traitlets<5.2.2
+progressbar2
+entrypoints
+sqlalchemy<2,>=1.3.24
+Deprecated
+ijson
+greenlet
+termcolor>=1.0.0
+
+[clickhouse-usage]
+avro<1.11,>=1.10.2
 cached_property
+click>=7.1.2
 jsonref
+packaging
+tabulate
+docker
+aiohttp<4
+expandvars>=0.6.5
 avro-gen3==0.7.10
-
-[clickhouse-usage]
-ratelimiter
-python-dateutil>=2.8.0
+PyYAML
+click-spinner
+requests_file
 jsonschema
-progressbar2
-packaging
-click>=7.1.2
-ijson
 click-default-group
-expandvars>=0.6.5
-tabulate
-sqlalchemy<2,>=1.3.24
-scipy>=1.7.2
-entrypoints
-avro<1.11,>=1.10.2
 clickhouse-sqlalchemy>=0.1.8
-Deprecated
+ratelimiter
 humanfriendly
-toml>=0.10.0
 great-expectations<=0.15.50,>=0.15.12
-aiohttp<4
-docker
-PyYAML
-termcolor>=1.0.0
+toml>=0.10.0
+scipy>=1.7.2
 psutil>=5.8.0
-click-spinner
-greenlet
-requests_file
-traitlets<5.2.2
-cached_property
-jsonref
 sqlparse
-avro-gen3==0.7.10
-
-[datahub-business-glossary]
-ratelimiter
 python-dateutil>=2.8.0
-jsonschema
+traitlets<5.2.2
 progressbar2
-packaging
-click>=7.1.2
-ijson
-click-default-group
-expandvars>=0.6.5
-tabulate
 entrypoints
-avro<1.11,>=1.10.2
+sqlalchemy<2,>=1.3.24
 Deprecated
-humanfriendly
-toml>=0.10.0
-aiohttp<4
-docker
-PyYAML
+ijson
+greenlet
 termcolor>=1.0.0
-psutil>=5.8.0
-click-spinner
-requests_file
+
+[datahub-business-glossary]
+avro<1.11,>=1.10.2
 cached_property
+click>=7.1.2
 jsonref
+packaging
+tabulate
+docker
+aiohttp<4
+expandvars>=0.6.5
 avro-gen3==0.7.10
-
-[datahub-kafka]
+PyYAML
+click-spinner
+requests_file
+jsonschema
+click-default-group
 ratelimiter
+humanfriendly
+toml>=0.10.0
+psutil>=5.8.0
 python-dateutil>=2.8.0
-jsonschema
 progressbar2
-packaging
-click>=7.1.2
+entrypoints
+Deprecated
 ijson
-click-default-group
-expandvars>=0.6.5
+termcolor>=1.0.0
+
+[datahub-kafka]
+avro<1.11,>=1.10.2
+cached_property
+click>=7.1.2
+jsonref
+packaging
 tabulate
+docker
+aiohttp<4
+expandvars>=0.6.5
 confluent_kafka>=1.5.0
+avro-gen3==0.7.10
+PyYAML
+click-spinner
+requests_file
+jsonschema
+click-default-group
+ratelimiter
+humanfriendly
+toml>=0.10.0
+psutil>=5.8.0
+python-dateutil>=2.8.0
 fastavro>=1.2.0
+progressbar2
 entrypoints
-avro<1.11,>=1.10.2
 Deprecated
-humanfriendly
-toml>=0.10.0
-aiohttp<4
-docker
-PyYAML
+ijson
 termcolor>=1.0.0
-psutil>=5.8.0
-click-spinner
-requests_file
-cached_property
-jsonref
-avro-gen3==0.7.10
 
 [datahub-kafka:platform_system != "Darwin" and (platform_machine == "aarch64" or platform_machine == "arm64")]
 confluent_kafka<1.9.0
 
 [datahub-lineage-file]
-ratelimiter
-python-dateutil>=2.8.0
-jsonschema
-progressbar2
-packaging
+avro<1.11,>=1.10.2
+cached_property
 click>=7.1.2
-ijson
-click-default-group
-expandvars>=0.6.5
+jsonref
+packaging
 tabulate
-entrypoints
-avro<1.11,>=1.10.2
-Deprecated
-humanfriendly
-toml>=0.10.0
-aiohttp<4
 docker
+aiohttp<4
+expandvars>=0.6.5
+avro-gen3==0.7.10
 PyYAML
-termcolor>=1.0.0
-psutil>=5.8.0
 click-spinner
 requests_file
-cached_property
-jsonref
-avro-gen3==0.7.10
-
-[datahub-lite]
+jsonschema
+click-default-group
 ratelimiter
+humanfriendly
+toml>=0.10.0
+psutil>=5.8.0
 python-dateutil>=2.8.0
-fastapi
-jsonschema
 progressbar2
-packaging
-click>=7.1.2
-ijson
-click-default-group
-expandvars>=0.6.5
-tabulate
 entrypoints
-avro<1.11,>=1.10.2
 Deprecated
-humanfriendly
-toml>=0.10.0
-duckdb
-aiohttp<4
-docker
-PyYAML
+ijson
 termcolor>=1.0.0
-psutil>=5.8.0
-click-spinner
-requests_file
+
+[datahub-lite]
+avro<1.11,>=1.10.2
 cached_property
-uvicorn
+click>=7.1.2
 jsonref
+packaging
+tabulate
+docker
+aiohttp<4
+expandvars>=0.6.5
+fastapi
 avro-gen3==0.7.10
-
-[datahub-rest]
+PyYAML
+click-spinner
+requests_file
+jsonschema
+click-default-group
 ratelimiter
+humanfriendly
+toml>=0.10.0
+psutil>=5.8.0
+duckdb
 python-dateutil>=2.8.0
-jsonschema
+uvicorn
 progressbar2
-packaging
-click>=7.1.2
-ijson
-click-default-group
-expandvars>=0.6.5
-tabulate
 entrypoints
-avro<1.11,>=1.10.2
-requests
 Deprecated
-humanfriendly
-toml>=0.10.0
-aiohttp<4
+ijson
+termcolor>=1.0.0
+
+[datahub-rest]
+avro<1.11,>=1.10.2
+cached_property
+click>=7.1.2
+jsonref
+packaging
+tabulate
 docker
+aiohttp<4
+expandvars>=0.6.5
+avro-gen3==0.7.10
 PyYAML
-termcolor>=1.0.0
-psutil>=5.8.0
 click-spinner
 requests_file
+jsonschema
+click-default-group
+ratelimiter
+humanfriendly
+toml>=0.10.0
+requests
+psutil>=5.8.0
+python-dateutil>=2.8.0
+progressbar2
+entrypoints
+Deprecated
+ijson
+termcolor>=1.0.0
+
+[dbt]
+avro<1.11,>=1.10.2
 cached_property
+click>=7.1.2
 jsonref
+packaging
+tabulate
+docker
+aiohttp<4
+expandvars>=0.6.5
 avro-gen3==0.7.10
-
-[dbt]
+PyYAML
+click-spinner
+requests_file
+jsonschema
+click-default-group
 ratelimiter
+humanfriendly
+toml>=0.10.0
+requests
+psutil>=5.8.0
 python-dateutil>=2.8.0
 botocore!=1.23.0
-jsonschema
 progressbar2
-packaging
-click>=7.1.2
-ijson
-click-default-group
-expandvars>=0.6.5
-tabulate
 boto3
 entrypoints
-avro<1.11,>=1.10.2
-requests
 Deprecated
-humanfriendly
-toml>=0.10.0
-aiohttp<4
-docker
-PyYAML
+ijson
 termcolor>=1.0.0
-psutil>=5.8.0
-click-spinner
-requests_file
-cached_property
-jsonref
-avro-gen3==0.7.10
 
 [dbt-cloud]
-ratelimiter
-python-dateutil>=2.8.0
-jsonschema
-progressbar2
-packaging
+avro<1.11,>=1.10.2
+cached_property
 click>=7.1.2
-ijson
-click-default-group
-expandvars>=0.6.5
+jsonref
+packaging
 tabulate
-entrypoints
-avro<1.11,>=1.10.2
-requests
-Deprecated
-humanfriendly
-toml>=0.10.0
-aiohttp<4
 docker
+aiohttp<4
+expandvars>=0.6.5
+avro-gen3==0.7.10
 PyYAML
-termcolor>=1.0.0
-psutil>=5.8.0
 click-spinner
 requests_file
-cached_property
-jsonref
-avro-gen3==0.7.10
-
-[delta-lake]
+jsonschema
+click-default-group
 ratelimiter
+humanfriendly
+toml>=0.10.0
+requests
+psutil>=5.8.0
 python-dateutil>=2.8.0
-botocore!=1.23.0
-moto[s3]
-pydeequ>=1.0.1
-jsonschema
 progressbar2
-packaging
-click>=7.1.2
-ijson
-click-default-group
-expandvars>=0.6.5
-tabulate
-pyarrow>=6.0.1
-boto3
-tableschema>=1.20.2
 entrypoints
+Deprecated
+ijson
+termcolor>=1.0.0
+
+[delta-lake]
 avro<1.11,>=1.10.2
+cached_property
+click>=7.1.2
+jsonref
 wcmatch
-Deprecated
-pyspark==3.0.3
+packaging
+tabulate
+docker
+aiohttp<4
+tableschema>=1.20.2
+expandvars>=0.6.5
+avro-gen3==0.7.10
+PyYAML
+click-spinner
+requests_file
+jsonschema
+click-default-group
+ratelimiter
 humanfriendly
 toml>=0.10.0
+moto[s3]
 ujson>=5.2.0
-aiohttp<4
-docker
+psutil>=5.8.0
+pyspark==3.0.3
+pyarrow>=6.0.1
+python-dateutil>=2.8.0
 smart-open[s3]>=5.2.1
 deltalake!=0.6.4,>=0.6.3
-PyYAML
-termcolor>=1.0.0
-psutil>=5.8.0
-click-spinner
-requests_file
-cached_property
-jsonref
-avro-gen3==0.7.10
+botocore!=1.23.0
+progressbar2
+boto3
+entrypoints
+Deprecated
+ijson
+pydeequ>=1.0.1
 parse>=1.19.0
+termcolor>=1.0.0
 
 [dev]
-deepdiff
-pandas
-sqlalchemy<2,>=1.3.24
-spacy==3.4.3
-entrypoints
-types-toml
-twine
-lark[regex]==1.1.4
-humanfriendly
-great-expectations<=0.15.50,>=0.15.12
-types-tabulate
-cryptography
-trino[sqlalchemy]!=0.317,>=0.308
-types-freezegun
+types-dataclasses
+more-itertools>=8.12.0
+types-PyMySQL
+acryl-pyhive[hive]>=0.6.13
 avro-gen3==0.7.10
-looker-sdk==23.0.0
-python-dateutil>=2.8.0
-snowflake-sqlalchemy!=1.2.5,>=1.2.4
+PyYAML
+click-spinner
+requests_file
+clickhouse-sqlalchemy>=0.1.8
+mixpanel>=4.9.0
+types-Deprecated
+types-protobuf>=4.21.0.1
+toml>=0.10.0
+requests
+scipy>=1.7.2
+psutil>=5.8.0
+isort>=5.7.0
+smart-open[s3]>=5.2.1
+types-pkg_resources
+progressbar2
+types-pytz
+msal
+coverage>=5.1
+greenlet
+click>=7.1.2
+sql-metadata==2.2.2
+jsonref
+acryl-datahub-classify==0.0.6
+pytest-cov>=2.8.1
+requests-mock
+apache-airflow[snowflake]>=2.0.2
+types-termcolor>=1.0.0
+boto3-stubs[glue,s3,sagemaker,sts]
+sqlparse
+tableauserverclient>=0.17.0
+pyspark==3.0.3
+snowflake-connector-python!=2.8.2,<3.0.0
+freezegun
+python-ldap>=2.4
 types-requests>=2.28.11.6
-SQLAlchemy<1.4.42
-click-default-group
-pyarrow>=6.0.1
-boto3
-grpcio-tools<2,>=1.44.0
+types-python-dateutil
+botocore!=1.23.0
+types-click==0.1.12
+ijson
+pydeequ>=1.0.1
+okta~=1.7.0
+packaging
+cx_Oracle
+tableschema>=1.20.2
+trino[sqlalchemy]!=0.317,>=0.308
+spacy==3.4.3
+ratelimiter
+msal==1.16.0
 black==22.12.0
-mypy_extensions>=0.4.3
-grpcio<2,>=1.44.0
-sql_metadata
+pyarrow>=6.0.1
+redshift-connector
+fastavro>=1.2.0
+flake8>=3.8.3
+types-click-spinner>=0.1.13.1
 sqlalchemy-redshift
-tableauserverclient>=0.17.0
-uvicorn
-jsonref
-pydruid>=0.6.2
-types-pkg_resources
-sqllineage==1.3.6
-pydeequ>=1.0.1
+cached_property
+pydantic>=1.9.0
+looker-sdk==23.0.0
+expandvars>=0.6.5
+confluent_kafka>=1.5.0
 fastapi
-acryl-pyhive[hive]>=0.6.13
-ujson>=5.2.0
-google-cloud-bigquery
+flake8-bugbear==23.3.12
+acryl-pyhive[hive]>=0.6.12
+mypy_extensions>=0.4.3
+SQLAlchemy<1.4.42
+great-expectations<=0.15.50,>=0.15.12
+cryptography
+lark[regex]==1.1.4
+networkx>=2.6.2
 duckdb
-great-expectations!=0.15.23,!=0.15.24,!=0.15.25,!=0.15.26
-PyYAML
-typing-inspect
-types-pytz
+sqlalchemy<2,>=1.3.24
+requests_ntlm
+types-PyYAML
+deepdiff
+pymysql>=1.0.2
+wcmatch
 types-six
-greenlet
-requests-mock
-lkml>=1.3.0b5
+sql_metadata
 google-cloud-datacatalog-lineage==0.2.0
-redash-toolbelt
-acryl-datahub-classify==0.0.6
-types-cachetools
-expandvars>=0.6.5
 GeoAlchemy2
-requests
-aiohttp<4
-build
-confluent_kafka>=1.5.0
-parse>=1.19.0
+azure-identity==1.10.0
 moto[s3]
-jsonschema
-virtualenv
-progressbar2
-flake8>=3.8.3
-types-protobuf>=4.21.0.1
-mixpanel>=4.9.0
-okta~=1.7.0
-types-PyMySQL
-msal
-toml>=0.10.0
-types-click-spinner>=0.1.13.1
-sql-metadata==2.2.2
-termcolor>=1.0.0
-mypy==1.0.0
-apache-airflow[snowflake]>=2.0.2
-requests_file
-pytest-cov>=2.8.1
-cached_property
-sqlalchemy-bigquery>=1.4.1
-cx_Oracle
-databricks-cli==0.17.3
 types-pyOpenSSL
 pytest-asyncio>=0.16.0
-requests_ntlm
-networkx>=2.6.2
-coverage>=5.1
-GitPython>2
-msal==1.16.0
-more-itertools>=8.12.0
-acryl-iceberg-legacy==0.0.4
-fastavro>=1.2.0
-Deprecated
-smart-open[s3]>=5.2.1
-flake8-bugbear==23.3.12
-pydantic!=1.10.3,>=1.5.1
-psutil>=5.8.0
-tableschema>=1.20.2
-google-cloud-logging<=3.5.0
-ratelimiter
+sqllineage==1.3.6
+pandas
+snowflake-sqlalchemy!=1.2.5,>=1.2.4
+entrypoints
+parse>=1.19.0
+deltalake!=0.6.4,>=0.6.3
+google-cloud-bigquery
+avro<1.11,>=1.10.2
+tabulate
+aiohttp<4
 pytest>=6.2.2
-jsonpickle
-pymysql>=1.0.2
-redshift-connector
-click>=7.1.2
+lkml>=1.3.0b5
 types-ujson>=5.2.0
-ijson
-types-dataclasses
-sql-metadata
+click-default-group
+twine
+grpcio<2,>=1.44.0
+google-cloud-logging<=3.5.0
+typing-inspect
 databricks-dbapi
-pyspark==3.0.3
+python-dateutil>=2.8.0
+types-cachetools
+psycopg2-binary
+uvicorn
+great-expectations!=0.15.23,!=0.15.24,!=0.15.25,!=0.15.26
+types-freezegun
+types-toml
+mypy==1.0.0
+pytest-docker>=1.0.1
+termcolor>=1.0.0
 elasticsearch==7.13.4
-acryl-pyhive[hive]>=0.6.12
+pydruid>=0.6.2
 docker
-freezegun
-types-python-dateutil
-boto3-stubs[glue,s3,sagemaker,sts]
-isort>=5.7.0
-deltalake!=0.6.4,>=0.6.3
-pytest-docker>=1.0.1
+build
+flake8-tidy-imports>=4.3.0
+redash-toolbelt
+acryl-iceberg-legacy==0.0.4
+pydantic!=1.10.3,>=1.5.1
+types-tabulate
+humanfriendly
+ujson>=5.2.0
+boto3
+GitPython>2
+sql-metadata
+databricks-cli==0.17.3
+jsonschema
+grpcio-tools<2,>=1.44.0
+jsonpickle
 traitlets<5.2.2
-types-termcolor>=1.0.0
-sqlparse
-botocore!=1.23.0
-azure-identity==1.10.0
-types-PyYAML
-types-click==0.1.12
-tabulate
-pydantic>=1.9.0
+virtualenv
+sqlalchemy-bigquery>=1.4.1
+Deprecated
 simple-salesforce
-scipy>=1.7.2
-clickhouse-sqlalchemy>=0.1.8
-avro<1.11,>=1.10.2
-wcmatch
-snowflake-connector-python!=2.8.2,<3.0.0
-psycopg2-binary
-python-ldap>=2.4
-types-Deprecated
-click-spinner
-flake8-tidy-imports>=4.3.0
-packaging
 
 [dev:platform_system != "Darwin" and (platform_machine == "aarch64" or platform_machine == "arm64")]
 confluent_kafka<1.9.0
 
 [dev:python_version < "3.8"]
 typing_extensions>=3.7.4.3
 
 [dev:python_version >= "3.8"]
 typing_extensions>=3.10.0.2
 
 [druid]
-ratelimiter
-python-dateutil>=2.8.0
-jsonschema
-progressbar2
-packaging
+avro<1.11,>=1.10.2
+cached_property
 click>=7.1.2
-ijson
-click-default-group
-expandvars>=0.6.5
+jsonref
+packaging
+pydruid>=0.6.2
 tabulate
-sqlalchemy<2,>=1.3.24
-scipy>=1.7.2
-entrypoints
-avro<1.11,>=1.10.2
-Deprecated
-humanfriendly
-toml>=0.10.0
-great-expectations<=0.15.50,>=0.15.12
-aiohttp<4
 docker
+aiohttp<4
+expandvars>=0.6.5
+avro-gen3==0.7.10
 PyYAML
-termcolor>=1.0.0
-psutil>=5.8.0
 click-spinner
-greenlet
 requests_file
-pydruid>=0.6.2
-cached_property
-traitlets<5.2.2
-jsonref
-avro-gen3==0.7.10
-
-[elasticsearch]
+jsonschema
+click-default-group
+great-expectations<=0.15.50,>=0.15.12
 ratelimiter
+humanfriendly
+toml>=0.10.0
+scipy>=1.7.2
+psutil>=5.8.0
 python-dateutil>=2.8.0
-jsonschema
+traitlets<5.2.2
 progressbar2
-packaging
-click>=7.1.2
-ijson
-click-default-group
-expandvars>=0.6.5
-tabulate
 entrypoints
-avro<1.11,>=1.10.2
+sqlalchemy<2,>=1.3.24
 Deprecated
-humanfriendly
-toml>=0.10.0
+ijson
+greenlet
+termcolor>=1.0.0
+
+[elasticsearch]
+avro<1.11,>=1.10.2
+cached_property
+click>=7.1.2
 elasticsearch==7.13.4
-aiohttp<4
+jsonref
+packaging
+tabulate
 docker
+aiohttp<4
+expandvars>=0.6.5
+avro-gen3==0.7.10
 PyYAML
-termcolor>=1.0.0
-psutil>=5.8.0
 click-spinner
 requests_file
-cached_property
-jsonref
-avro-gen3==0.7.10
-
-[feast]
+jsonschema
+click-default-group
 ratelimiter
+humanfriendly
+toml>=0.10.0
+psutil>=5.8.0
 python-dateutil>=2.8.0
-jsonschema
 progressbar2
-packaging
-click>=7.1.2
-ijson
-click-default-group
-expandvars>=0.6.5
-tabulate
 entrypoints
-avro<1.11,>=1.10.2
 Deprecated
-humanfriendly
-toml>=0.10.0
-feast~=0.29.0
-aiohttp<4
-typeguard<3
+ijson
+termcolor>=1.0.0
+
+[feast]
+avro<1.11,>=1.10.2
+cached_property
+click>=7.1.2
+jsonref
+packaging
+tabulate
 docker
+aiohttp<4
+expandvars>=0.6.5
+avro-gen3==0.7.10
 PyYAML
-termcolor>=1.0.0
-psutil>=5.8.0
 click-spinner
 requests_file
-cached_property
-jsonref
+jsonschema
+click-default-group
+ratelimiter
+humanfriendly
+feast~=0.29.0
+toml>=0.10.0
 flask-openid>=1.3.0
-avro-gen3==0.7.10
+typeguard<3
+psutil>=5.8.0
+python-dateutil>=2.8.0
+progressbar2
+entrypoints
+Deprecated
+ijson
+termcolor>=1.0.0
 
 [glue]
+avro<1.11,>=1.10.2
+cached_property
+click>=7.1.2
+jsonref
+packaging
+tabulate
+docker
+aiohttp<4
+expandvars>=0.6.5
+avro-gen3==0.7.10
+PyYAML
+click-spinner
+requests_file
+jsonschema
+click-default-group
 ratelimiter
+humanfriendly
+toml>=0.10.0
+psutil>=5.8.0
 python-dateutil>=2.8.0
 botocore!=1.23.0
-jsonschema
 progressbar2
-packaging
-click>=7.1.2
-ijson
-click-default-group
-expandvars>=0.6.5
-tabulate
 boto3
 entrypoints
-avro<1.11,>=1.10.2
 Deprecated
-humanfriendly
-toml>=0.10.0
-aiohttp<4
-docker
-PyYAML
+ijson
 termcolor>=1.0.0
-psutil>=5.8.0
-click-spinner
-requests_file
-cached_property
-jsonref
-avro-gen3==0.7.10
 
 [great-expectations]
-ratelimiter
-python-dateutil>=2.8.0
-jsonschema
-progressbar2
-packaging
+avro<1.11,>=1.10.2
+cached_property
 click>=7.1.2
-ijson
-click-default-group
-expandvars>=0.6.5
+jsonref
+packaging
 tabulate
-sqlalchemy<2,>=1.3.24
-scipy>=1.7.2
-entrypoints
-avro<1.11,>=1.10.2
-Deprecated
-humanfriendly
-toml>=0.10.0
-great-expectations<=0.15.50,>=0.15.12
-aiohttp<4
 docker
+aiohttp<4
+expandvars>=0.6.5
+avro-gen3==0.7.10
 PyYAML
-termcolor>=1.0.0
-psutil>=5.8.0
 click-spinner
-greenlet
 requests_file
+jsonschema
+click-default-group
+great-expectations<=0.15.50,>=0.15.12
+ratelimiter
+humanfriendly
+toml>=0.10.0
+scipy>=1.7.2
+psutil>=5.8.0
+python-dateutil>=2.8.0
 traitlets<5.2.2
-cached_property
-jsonref
-avro-gen3==0.7.10
 sqllineage==1.3.6
+progressbar2
+entrypoints
+sqlalchemy<2,>=1.3.24
+Deprecated
+ijson
+greenlet
+termcolor>=1.0.0
 
 [hana]
-ratelimiter
-python-dateutil>=2.8.0
-jsonschema
-progressbar2
-packaging
+avro<1.11,>=1.10.2
+cached_property
 click>=7.1.2
-ijson
-click-default-group
-expandvars>=0.6.5
+jsonref
+packaging
 tabulate
-sqlalchemy<2,>=1.3.24
-scipy>=1.7.2
-entrypoints
-avro<1.11,>=1.10.2
-Deprecated
-humanfriendly
-toml>=0.10.0
-great-expectations<=0.15.50,>=0.15.12
-aiohttp<4
 docker
+aiohttp<4
+expandvars>=0.6.5
+avro-gen3==0.7.10
 PyYAML
-termcolor>=1.0.0
-psutil>=5.8.0
 click-spinner
-greenlet
 requests_file
+jsonschema
+click-default-group
+great-expectations<=0.15.50,>=0.15.12
+ratelimiter
+humanfriendly
+toml>=0.10.0
+scipy>=1.7.2
+psutil>=5.8.0
+python-dateutil>=2.8.0
 traitlets<5.2.2
-cached_property
-jsonref
-avro-gen3==0.7.10
+progressbar2
+entrypoints
+sqlalchemy<2,>=1.3.24
+Deprecated
+ijson
+greenlet
+termcolor>=1.0.0
 
 [hana:platform_machine != "aarch64" and platform_machine != "arm64"]
 sqlalchemy-hana>=0.5.0
 hdbcli>=2.11.20
 
 [hive]
-ratelimiter
-python-dateutil>=2.8.0
-jsonschema
-progressbar2
-packaging
+avro<1.11,>=1.10.2
+cached_property
 click>=7.1.2
-databricks-dbapi
-ijson
-click-default-group
-expandvars>=0.6.5
+jsonref
+packaging
 tabulate
-sqlalchemy<2,>=1.3.24
-scipy>=1.7.2
-entrypoints
-avro<1.11,>=1.10.2
-Deprecated
-humanfriendly
-toml>=0.10.0
-great-expectations<=0.15.50,>=0.15.12
-acryl-pyhive[hive]>=0.6.13
-aiohttp<4
 docker
-great-expectations!=0.15.23,!=0.15.24,!=0.15.25,!=0.15.26
+aiohttp<4
+expandvars>=0.6.5
+acryl-pyhive[hive]>=0.6.13
+avro-gen3==0.7.10
 PyYAML
-termcolor>=1.0.0
-psutil>=5.8.0
 click-spinner
-greenlet
 requests_file
+jsonschema
+click-default-group
+great-expectations<=0.15.50,>=0.15.12
+ratelimiter
+humanfriendly
+toml>=0.10.0
+scipy>=1.7.2
+psutil>=5.8.0
+databricks-dbapi
+python-dateutil>=2.8.0
 traitlets<5.2.2
+great-expectations!=0.15.23,!=0.15.24,!=0.15.25,!=0.15.26
+progressbar2
+entrypoints
+sqlalchemy<2,>=1.3.24
+Deprecated
+ijson
+greenlet
+termcolor>=1.0.0
+
+[iceberg]
+avro<1.11,>=1.10.2
 cached_property
+click>=7.1.2
 jsonref
+packaging
+tabulate
+docker
+aiohttp<4
+expandvars>=0.6.5
 avro-gen3==0.7.10
-
-[iceberg]
+PyYAML
+click-spinner
+requests_file
+jsonschema
+click-default-group
+azure-identity==1.10.0
 ratelimiter
+humanfriendly
+acryl-iceberg-legacy==0.0.4
+toml>=0.10.0
+psutil>=5.8.0
 python-dateutil>=2.8.0
-azure-identity==1.10.0
-jsonschema
 progressbar2
-packaging
-click>=7.1.2
-ijson
-click-default-group
-expandvars>=0.6.5
-tabulate
 entrypoints
-avro<1.11,>=1.10.2
-acryl-iceberg-legacy==0.0.4
 Deprecated
-humanfriendly
-toml>=0.10.0
-aiohttp<4
-docker
-PyYAML
+ijson
 termcolor>=1.0.0
-psutil>=5.8.0
-click-spinner
-requests_file
-cached_property
-jsonref
-avro-gen3==0.7.10
 
 [integration-tests]
-gql[requests]>=3.3.0
-moto[s3]
-pydeequ>=1.0.1
 pymysql>=1.0.2
-databricks-dbapi
-sql-metadata
-sqlalchemy<2,>=1.3.24
-gql>=3.3.0
-pyspark==3.0.3
-acryl-pyhive[hive]>=0.6.13
-great-expectations<=0.15.50,>=0.15.12
-ujson>=5.2.0
-great-expectations!=0.15.23,!=0.15.24,!=0.15.25,!=0.15.26
-deltalake!=0.6.4,>=0.6.3
-traitlets<5.2.2
+wcmatch
+packaging
 pydruid>=0.6.2
-greenlet
-sqlalchemy-pytds>=0.3
-redash-toolbelt
-botocore!=1.23.0
-JPype1
+tableschema>=1.20.2
+acryl-pyhive[hive]>=0.6.13
 azure-identity==1.10.0
-PyAthena[sqlalchemy]==2.4.1
-pyarrow>=6.0.1
-boto3
-pymongo[srv]>=3.11
-scipy>=1.7.2
 clickhouse-sqlalchemy>=0.1.8
-wcmatch
+redash-toolbelt
+PyAthena[sqlalchemy]==2.4.1
 acryl-iceberg-legacy==0.0.4
+JPype1
 requests
+moto[s3]
+scipy>=1.7.2
+ujson>=5.2.0
+pyarrow>=6.0.1
 smart-open[s3]>=5.2.1
-python-ldap>=2.4
-packaging
-tableschema>=1.20.2
 sqllineage==1.3.6
+boto3
 parse>=1.19.0
+deltalake!=0.6.4,>=0.6.3
+greenlet
+gql[requests]>=3.3.0
+sql-metadata
+sqlalchemy-pytds>=0.3
+great-expectations<=0.15.50,>=0.15.12
+pymongo[srv]>=3.11
+pyspark==3.0.3
+databricks-dbapi
+traitlets<5.2.2
+python-ldap>=2.4
+great-expectations!=0.15.23,!=0.15.24,!=0.15.25,!=0.15.26
+botocore!=1.23.0
+sqlalchemy<2,>=1.3.24
+gql>=3.3.0
+pydeequ>=1.0.1
 
 [integration-tests:platform_machine != "aarch64" and platform_machine != "arm64"]
 sqlalchemy-hana>=0.5.0
 hdbcli>=2.11.20
 
 [json-schema]
-ratelimiter
-python-dateutil>=2.8.0
-jsonschema
-progressbar2
-packaging
+avro<1.11,>=1.10.2
+cached_property
 click>=7.1.2
-ijson
-click-default-group
-expandvars>=0.6.5
+jsonref
+packaging
 tabulate
-entrypoints
-avro<1.11,>=1.10.2
-Deprecated
-humanfriendly
-toml>=0.10.0
-aiohttp<4
 docker
+aiohttp<4
+expandvars>=0.6.5
+avro-gen3==0.7.10
 PyYAML
-termcolor>=1.0.0
-psutil>=5.8.0
 click-spinner
 requests_file
-cached_property
-jsonref
-avro-gen3==0.7.10
-
-[kafka]
+jsonschema
+click-default-group
 ratelimiter
+humanfriendly
+toml>=0.10.0
+psutil>=5.8.0
 python-dateutil>=2.8.0
-networkx>=2.6.2
-jsonschema
 progressbar2
-packaging
-click>=7.1.2
-ijson
-click-default-group
-expandvars>=0.6.5
-tabulate
-confluent_kafka>=1.5.0
-fastavro>=1.2.0
 entrypoints
-avro<1.11,>=1.10.2
-grpcio-tools<2,>=1.44.0
 Deprecated
-humanfriendly
-toml>=0.10.0
-grpcio<2,>=1.44.0
-aiohttp<4
-docker
-PyYAML
+ijson
 termcolor>=1.0.0
-psutil>=5.8.0
-click-spinner
-requests_file
+
+[kafka]
+avro<1.11,>=1.10.2
 cached_property
+click>=7.1.2
 jsonref
+packaging
+tabulate
+docker
+aiohttp<4
+expandvars>=0.6.5
+confluent_kafka>=1.5.0
 avro-gen3==0.7.10
-
-[kafka-connect]
+PyYAML
+click-spinner
+requests_file
+jsonschema
+click-default-group
+grpcio<2,>=1.44.0
 ratelimiter
+humanfriendly
+toml>=0.10.0
+psutil>=5.8.0
+grpcio-tools<2,>=1.44.0
+networkx>=2.6.2
 python-dateutil>=2.8.0
-JPype1
-jsonschema
+fastavro>=1.2.0
 progressbar2
-packaging
-click>=7.1.2
-ijson
-click-default-group
-expandvars>=0.6.5
-tabulate
-sqlalchemy<2,>=1.3.24
-scipy>=1.7.2
 entrypoints
-avro<1.11,>=1.10.2
-requests
 Deprecated
-humanfriendly
-toml>=0.10.0
-great-expectations<=0.15.50,>=0.15.12
-aiohttp<4
+ijson
+termcolor>=1.0.0
+
+[kafka-connect]
+avro<1.11,>=1.10.2
+cached_property
+click>=7.1.2
+jsonref
+packaging
+tabulate
 docker
+aiohttp<4
+expandvars>=0.6.5
+avro-gen3==0.7.10
 PyYAML
-termcolor>=1.0.0
-psutil>=5.8.0
 click-spinner
-greenlet
 requests_file
+jsonschema
+click-default-group
+great-expectations<=0.15.50,>=0.15.12
+ratelimiter
+humanfriendly
+JPype1
+toml>=0.10.0
+requests
+scipy>=1.7.2
+psutil>=5.8.0
+python-dateutil>=2.8.0
 traitlets<5.2.2
-cached_property
-jsonref
-avro-gen3==0.7.10
+progressbar2
+entrypoints
+sqlalchemy<2,>=1.3.24
+Deprecated
+ijson
+greenlet
+termcolor>=1.0.0
 
 [kafka:platform_system != "Darwin" and (platform_machine == "aarch64" or platform_machine == "arm64")]
 confluent_kafka<1.9.0
 
 [ldap]
-ratelimiter
-python-dateutil>=2.8.0
-jsonschema
-progressbar2
-packaging
+avro<1.11,>=1.10.2
+cached_property
 click>=7.1.2
-ijson
-click-default-group
-expandvars>=0.6.5
+jsonref
+packaging
 tabulate
-entrypoints
-avro<1.11,>=1.10.2
-Deprecated
-humanfriendly
-toml>=0.10.0
-aiohttp<4
 docker
+aiohttp<4
+expandvars>=0.6.5
+avro-gen3==0.7.10
 PyYAML
-python-ldap>=2.4
-termcolor>=1.0.0
-psutil>=5.8.0
 click-spinner
 requests_file
-cached_property
-jsonref
-avro-gen3==0.7.10
-
-[looker]
+jsonschema
+click-default-group
 ratelimiter
+humanfriendly
+toml>=0.10.0
+psutil>=5.8.0
 python-dateutil>=2.8.0
-jsonschema
+python-ldap>=2.4
 progressbar2
-packaging
-click>=7.1.2
-ijson
-click-default-group
-expandvars>=0.6.5
-tabulate
-GitPython>2
 entrypoints
-avro<1.11,>=1.10.2
-sqllineage==1.3.6
 Deprecated
-humanfriendly
-toml>=0.10.0
-aiohttp<4
-docker
-PyYAML
-sql-metadata==2.2.2
+ijson
 termcolor>=1.0.0
-psutil>=5.8.0
-click-spinner
-requests_file
+
+[looker]
+avro<1.11,>=1.10.2
 cached_property
-lkml>=1.3.0b5
+click>=7.1.2
+sql-metadata==2.2.2
 jsonref
-avro-gen3==0.7.10
+packaging
+tabulate
+docker
+aiohttp<4
+lkml>=1.3.0b5
+expandvars>=0.6.5
 looker-sdk==23.0.0
-
-[lookml]
+avro-gen3==0.7.10
+PyYAML
+click-spinner
+requests_file
+jsonschema
+click-default-group
 ratelimiter
+humanfriendly
+toml>=0.10.0
+psutil>=5.8.0
 python-dateutil>=2.8.0
-jsonschema
+sqllineage==1.3.6
 progressbar2
-packaging
-click>=7.1.2
-ijson
-click-default-group
-expandvars>=0.6.5
-tabulate
-GitPython>2
 entrypoints
-avro<1.11,>=1.10.2
-sqllineage==1.3.6
+GitPython>2
 Deprecated
-humanfriendly
-toml>=0.10.0
-aiohttp<4
-docker
-PyYAML
-sql-metadata==2.2.2
+ijson
 termcolor>=1.0.0
-psutil>=5.8.0
-click-spinner
-requests_file
+
+[lookml]
+avro<1.11,>=1.10.2
 cached_property
-lkml>=1.3.0b5
+click>=7.1.2
+sql-metadata==2.2.2
 jsonref
-avro-gen3==0.7.10
+packaging
+tabulate
+docker
+aiohttp<4
+lkml>=1.3.0b5
+expandvars>=0.6.5
 looker-sdk==23.0.0
-
-[mariadb]
+avro-gen3==0.7.10
+PyYAML
+click-spinner
+requests_file
+jsonschema
+click-default-group
 ratelimiter
+humanfriendly
+toml>=0.10.0
+psutil>=5.8.0
 python-dateutil>=2.8.0
-jsonschema
+sqllineage==1.3.6
 progressbar2
-packaging
-click>=7.1.2
-pymysql>=1.0.2
-ijson
-click-default-group
-expandvars>=0.6.5
-tabulate
-sqlalchemy<2,>=1.3.24
-scipy>=1.7.2
 entrypoints
-avro<1.11,>=1.10.2
+GitPython>2
 Deprecated
-humanfriendly
-toml>=0.10.0
-great-expectations<=0.15.50,>=0.15.12
-aiohttp<4
+ijson
+termcolor>=1.0.0
+
+[mariadb]
+pymysql>=1.0.2
+avro<1.11,>=1.10.2
+cached_property
+click>=7.1.2
+jsonref
+packaging
+tabulate
 docker
+aiohttp<4
+expandvars>=0.6.5
+avro-gen3==0.7.10
 PyYAML
-termcolor>=1.0.0
-psutil>=5.8.0
 click-spinner
-greenlet
 requests_file
+jsonschema
+click-default-group
+great-expectations<=0.15.50,>=0.15.12
+ratelimiter
+humanfriendly
+toml>=0.10.0
+scipy>=1.7.2
+psutil>=5.8.0
+python-dateutil>=2.8.0
 traitlets<5.2.2
+progressbar2
+entrypoints
+sqlalchemy<2,>=1.3.24
+Deprecated
+ijson
+greenlet
+termcolor>=1.0.0
+
+[metabase]
+avro<1.11,>=1.10.2
 cached_property
+click>=7.1.2
 jsonref
+packaging
+tabulate
+docker
+aiohttp<4
+expandvars>=0.6.5
 avro-gen3==0.7.10
-
-[metabase]
+PyYAML
+click-spinner
+requests_file
+jsonschema
+click-default-group
 ratelimiter
+humanfriendly
+toml>=0.10.0
+requests
+psutil>=5.8.0
 python-dateutil>=2.8.0
-jsonschema
+sqllineage==1.3.6
 progressbar2
-packaging
-click>=7.1.2
-ijson
-click-default-group
-expandvars>=0.6.5
-tabulate
 entrypoints
-avro<1.11,>=1.10.2
-requests
 Deprecated
-humanfriendly
-toml>=0.10.0
-aiohttp<4
-docker
-PyYAML
+ijson
 termcolor>=1.0.0
-psutil>=5.8.0
-click-spinner
-requests_file
+
+[mode]
+avro<1.11,>=1.10.2
 cached_property
+click>=7.1.2
 jsonref
+packaging
+tabulate
+docker
+aiohttp<4
+expandvars>=0.6.5
 avro-gen3==0.7.10
-sqllineage==1.3.6
-
-[mode]
-ratelimiter
-python-dateutil>=2.8.0
+PyYAML
+click-spinner
+requests_file
 jsonschema
-progressbar2
-packaging
-click>=7.1.2
-ijson
 click-default-group
-expandvars>=0.6.5
-tabulate
-entrypoints
-avro<1.11,>=1.10.2
-requests
-Deprecated
+ratelimiter
 humanfriendly
 toml>=0.10.0
-aiohttp<4
-docker
-PyYAML
-termcolor>=1.0.0
+requests
 psutil>=5.8.0
-click-spinner
 tenacity>=8.0.1
-requests_file
-cached_property
-jsonref
-avro-gen3==0.7.10
+python-dateutil>=2.8.0
 sqllineage==1.3.6
+progressbar2
+entrypoints
+Deprecated
+ijson
+termcolor>=1.0.0
 
 [mongodb]
-ratelimiter
-python-dateutil>=2.8.0
-jsonschema
-progressbar2
-packaging
+avro<1.11,>=1.10.2
+cached_property
 click>=7.1.2
-ijson
-click-default-group
-expandvars>=0.6.5
+jsonref
+packaging
 tabulate
-pymongo[srv]>=3.11
-entrypoints
-avro<1.11,>=1.10.2
-Deprecated
-humanfriendly
-toml>=0.10.0
-aiohttp<4
 docker
+aiohttp<4
+expandvars>=0.6.5
+avro-gen3==0.7.10
 PyYAML
-termcolor>=1.0.0
-psutil>=5.8.0
 click-spinner
 requests_file
-cached_property
-jsonref
-avro-gen3==0.7.10
-
-[mssql]
+jsonschema
+click-default-group
 ratelimiter
+humanfriendly
+toml>=0.10.0
+pymongo[srv]>=3.11
+psutil>=5.8.0
 python-dateutil>=2.8.0
-jsonschema
 progressbar2
-packaging
-click>=7.1.2
-ijson
-click-default-group
-expandvars>=0.6.5
-tabulate
-sqlalchemy<2,>=1.3.24
-scipy>=1.7.2
 entrypoints
-avro<1.11,>=1.10.2
 Deprecated
-humanfriendly
-toml>=0.10.0
-great-expectations<=0.15.50,>=0.15.12
-aiohttp<4
+ijson
+termcolor>=1.0.0
+
+[mssql]
+avro<1.11,>=1.10.2
+cached_property
+click>=7.1.2
+jsonref
+packaging
+tabulate
 docker
+aiohttp<4
+expandvars>=0.6.5
+avro-gen3==0.7.10
 PyYAML
-termcolor>=1.0.0
-psutil>=5.8.0
 click-spinner
-greenlet
 requests_file
+jsonschema
+click-default-group
 sqlalchemy-pytds>=0.3
-cached_property
-traitlets<5.2.2
-jsonref
-avro-gen3==0.7.10
-
-[mssql-odbc]
 ratelimiter
+humanfriendly
+great-expectations<=0.15.50,>=0.15.12
+toml>=0.10.0
+scipy>=1.7.2
+psutil>=5.8.0
 python-dateutil>=2.8.0
-jsonschema
+traitlets<5.2.2
 progressbar2
-packaging
-click>=7.1.2
-ijson
-click-default-group
-expandvars>=0.6.5
-tabulate
-sqlalchemy<2,>=1.3.24
-scipy>=1.7.2
 entrypoints
-avro<1.11,>=1.10.2
+sqlalchemy<2,>=1.3.24
 Deprecated
-humanfriendly
-toml>=0.10.0
-great-expectations<=0.15.50,>=0.15.12
-aiohttp<4
-pyodbc
-docker
-PyYAML
-termcolor>=1.0.0
-psutil>=5.8.0
-click-spinner
+ijson
 greenlet
-requests_file
-traitlets<5.2.2
+termcolor>=1.0.0
+
+[mssql-odbc]
+avro<1.11,>=1.10.2
 cached_property
+click>=7.1.2
 jsonref
-avro-gen3==0.7.10
-
-[mysql]
-ratelimiter
-python-dateutil>=2.8.0
-jsonschema
-progressbar2
 packaging
-click>=7.1.2
-pymysql>=1.0.2
-ijson
-click-default-group
-expandvars>=0.6.5
 tabulate
-sqlalchemy<2,>=1.3.24
-scipy>=1.7.2
-entrypoints
-avro<1.11,>=1.10.2
-Deprecated
-humanfriendly
-toml>=0.10.0
-great-expectations<=0.15.50,>=0.15.12
-aiohttp<4
 docker
+aiohttp<4
+expandvars>=0.6.5
+avro-gen3==0.7.10
 PyYAML
-termcolor>=1.0.0
-psutil>=5.8.0
 click-spinner
-greenlet
 requests_file
-traitlets<5.2.2
-cached_property
-jsonref
-avro-gen3==0.7.10
-
-[nifi]
+jsonschema
+click-default-group
+great-expectations<=0.15.50,>=0.15.12
 ratelimiter
+humanfriendly
+toml>=0.10.0
+scipy>=1.7.2
+psutil>=5.8.0
+pyodbc
 python-dateutil>=2.8.0
-jsonschema
+traitlets<5.2.2
 progressbar2
-packaging
-click>=7.1.2
-ijson
-click-default-group
-expandvars>=0.6.5
-tabulate
 entrypoints
-avro<1.11,>=1.10.2
-requests
+sqlalchemy<2,>=1.3.24
 Deprecated
-humanfriendly
-toml>=0.10.0
-aiohttp<4
-docker
-PyYAML
+ijson
+greenlet
 termcolor>=1.0.0
-psutil>=5.8.0
-click-spinner
-requests_file
+
+[mysql]
+pymysql>=1.0.2
+avro<1.11,>=1.10.2
 cached_property
+click>=7.1.2
 jsonref
+packaging
+tabulate
+docker
+aiohttp<4
+expandvars>=0.6.5
 avro-gen3==0.7.10
-
-[okta]
+PyYAML
+click-spinner
+requests_file
+jsonschema
+click-default-group
+great-expectations<=0.15.50,>=0.15.12
 ratelimiter
+humanfriendly
+toml>=0.10.0
+scipy>=1.7.2
+psutil>=5.8.0
 python-dateutil>=2.8.0
-jsonschema
+traitlets<5.2.2
 progressbar2
-packaging
-click>=7.1.2
-ijson
-click-default-group
-expandvars>=0.6.5
-tabulate
-okta~=1.7.0
 entrypoints
-avro<1.11,>=1.10.2
+sqlalchemy<2,>=1.3.24
 Deprecated
-humanfriendly
-toml>=0.10.0
-aiohttp<4
-docker
-PyYAML
+ijson
+greenlet
 termcolor>=1.0.0
-psutil>=5.8.0
-click-spinner
-requests_file
+
+[nifi]
+avro<1.11,>=1.10.2
 cached_property
+click>=7.1.2
 jsonref
+packaging
+tabulate
+docker
+aiohttp<4
+expandvars>=0.6.5
 avro-gen3==0.7.10
-
-[oracle]
+PyYAML
+click-spinner
+requests_file
+jsonschema
+click-default-group
 ratelimiter
+humanfriendly
+toml>=0.10.0
+requests
+psutil>=5.8.0
 python-dateutil>=2.8.0
-jsonschema
 progressbar2
-packaging
-click>=7.1.2
-ijson
-click-default-group
-expandvars>=0.6.5
-tabulate
-sqlalchemy<2,>=1.3.24
-scipy>=1.7.2
 entrypoints
-avro<1.11,>=1.10.2
 Deprecated
-humanfriendly
-toml>=0.10.0
-great-expectations<=0.15.50,>=0.15.12
-aiohttp<4
-docker
-PyYAML
+ijson
 termcolor>=1.0.0
-psutil>=5.8.0
-click-spinner
-greenlet
-requests_file
-traitlets<5.2.2
+
+[okta]
+avro<1.11,>=1.10.2
 cached_property
-cx_Oracle
+click>=7.1.2
+okta~=1.7.0
 jsonref
+packaging
+tabulate
+docker
+aiohttp<4
+expandvars>=0.6.5
 avro-gen3==0.7.10
-
-[postgres]
+PyYAML
+click-spinner
+requests_file
+jsonschema
+click-default-group
 ratelimiter
+humanfriendly
+toml>=0.10.0
+psutil>=5.8.0
 python-dateutil>=2.8.0
-jsonschema
 progressbar2
-packaging
-click>=7.1.2
-ijson
-click-default-group
-expandvars>=0.6.5
-tabulate
-sqlalchemy<2,>=1.3.24
-scipy>=1.7.2
 entrypoints
-avro<1.11,>=1.10.2
-GeoAlchemy2
 Deprecated
-humanfriendly
-toml>=0.10.0
-great-expectations<=0.15.50,>=0.15.12
-aiohttp<4
+ijson
+termcolor>=1.0.0
+
+[oracle]
+avro<1.11,>=1.10.2
+cached_property
+click>=7.1.2
+jsonref
+packaging
+cx_Oracle
+tabulate
 docker
+aiohttp<4
+expandvars>=0.6.5
+avro-gen3==0.7.10
 PyYAML
-psycopg2-binary
-termcolor>=1.0.0
-psutil>=5.8.0
 click-spinner
-greenlet
 requests_file
+jsonschema
+click-default-group
+great-expectations<=0.15.50,>=0.15.12
+ratelimiter
+humanfriendly
+toml>=0.10.0
+scipy>=1.7.2
+psutil>=5.8.0
+python-dateutil>=2.8.0
 traitlets<5.2.2
+progressbar2
+entrypoints
+sqlalchemy<2,>=1.3.24
+Deprecated
+ijson
+greenlet
+termcolor>=1.0.0
+
+[postgres]
+avro<1.11,>=1.10.2
 cached_property
+click>=7.1.2
 jsonref
+packaging
+tabulate
+docker
+aiohttp<4
+GeoAlchemy2
+expandvars>=0.6.5
 avro-gen3==0.7.10
-
-[powerbi]
+PyYAML
+click-spinner
+requests_file
+jsonschema
+click-default-group
+great-expectations<=0.15.50,>=0.15.12
 ratelimiter
+humanfriendly
+toml>=0.10.0
+scipy>=1.7.2
+psutil>=5.8.0
 python-dateutil>=2.8.0
-jsonschema
+psycopg2-binary
+traitlets<5.2.2
 progressbar2
-packaging
-click>=7.1.2
-ijson
-click-default-group
-expandvars>=0.6.5
-tabulate
-msal==1.16.0
 entrypoints
-avro<1.11,>=1.10.2
-lark[regex]==1.1.4
+sqlalchemy<2,>=1.3.24
 Deprecated
-humanfriendly
-toml>=0.10.0
-aiohttp<4
-docker
-PyYAML
+ijson
+greenlet
 termcolor>=1.0.0
-psutil>=5.8.0
-click-spinner
-requests_file
+
+[powerbi]
+avro<1.11,>=1.10.2
 cached_property
+click>=7.1.2
 jsonref
-sqlparse
+packaging
+tabulate
+docker
+aiohttp<4
+expandvars>=0.6.5
 avro-gen3==0.7.10
-
-[powerbi-report-server]
+PyYAML
+click-spinner
+requests_file
+jsonschema
+click-default-group
+lark[regex]==1.1.4
 ratelimiter
+humanfriendly
+toml>=0.10.0
+msal==1.16.0
+sqlparse
+psutil>=5.8.0
 python-dateutil>=2.8.0
-requests_ntlm
-jsonschema
 progressbar2
-packaging
-click>=7.1.2
-ijson
-click-default-group
-expandvars>=0.6.5
-tabulate
 entrypoints
-avro<1.11,>=1.10.2
-requests
 Deprecated
-humanfriendly
-toml>=0.10.0
-aiohttp<4
-docker
-PyYAML
+ijson
 termcolor>=1.0.0
-psutil>=5.8.0
-click-spinner
-requests_file
+
+[powerbi-report-server]
+avro<1.11,>=1.10.2
 cached_property
+click>=7.1.2
 jsonref
+packaging
+tabulate
+docker
+aiohttp<4
+expandvars>=0.6.5
 avro-gen3==0.7.10
-
-[presto]
+PyYAML
+click-spinner
+requests_file
+jsonschema
+click-default-group
 ratelimiter
+humanfriendly
+toml>=0.10.0
+requests
+psutil>=5.8.0
 python-dateutil>=2.8.0
-jsonschema
 progressbar2
-packaging
-click>=7.1.2
-ijson
-click-default-group
-expandvars>=0.6.5
-tabulate
-sqlalchemy<2,>=1.3.24
-scipy>=1.7.2
 entrypoints
-avro<1.11,>=1.10.2
 Deprecated
-humanfriendly
-toml>=0.10.0
-great-expectations<=0.15.50,>=0.15.12
-acryl-pyhive[hive]>=0.6.12
-aiohttp<4
-docker
-PyYAML
+ijson
+requests_ntlm
 termcolor>=1.0.0
-psutil>=5.8.0
-click-spinner
-greenlet
-requests_file
-trino[sqlalchemy]!=0.317,>=0.308
+
+[presto]
+avro<1.11,>=1.10.2
 cached_property
-traitlets<5.2.2
+click>=7.1.2
 jsonref
+packaging
+tabulate
+docker
+aiohttp<4
+trino[sqlalchemy]!=0.317,>=0.308
+expandvars>=0.6.5
 avro-gen3==0.7.10
-
-[presto-on-hive]
-ratelimiter
-python-dateutil>=2.8.0
+PyYAML
+click-spinner
+requests_file
 jsonschema
-progressbar2
-packaging
-click>=7.1.2
-pymysql>=1.0.2
-ijson
 click-default-group
-expandvars>=0.6.5
-tabulate
-sqlalchemy<2,>=1.3.24
+acryl-pyhive[hive]>=0.6.12
+ratelimiter
+humanfriendly
+great-expectations<=0.15.50,>=0.15.12
+toml>=0.10.0
 scipy>=1.7.2
+psutil>=5.8.0
+python-dateutil>=2.8.0
+traitlets<5.2.2
+progressbar2
 entrypoints
-avro<1.11,>=1.10.2
+sqlalchemy<2,>=1.3.24
 Deprecated
-humanfriendly
-toml>=0.10.0
-great-expectations<=0.15.50,>=0.15.12
-acryl-pyhive[hive]>=0.6.12
-aiohttp<4
+ijson
+greenlet
+termcolor>=1.0.0
+
+[presto-on-hive]
+pymysql>=1.0.2
+avro<1.11,>=1.10.2
+cached_property
+click>=7.1.2
+jsonref
+packaging
+tabulate
 docker
+aiohttp<4
+expandvars>=0.6.5
+avro-gen3==0.7.10
 PyYAML
-psycopg2-binary
-termcolor>=1.0.0
-psutil>=5.8.0
 click-spinner
-greenlet
 requests_file
+jsonschema
+click-default-group
+acryl-pyhive[hive]>=0.6.12
+ratelimiter
+humanfriendly
+great-expectations<=0.15.50,>=0.15.12
+toml>=0.10.0
+scipy>=1.7.2
+psutil>=5.8.0
+python-dateutil>=2.8.0
+psycopg2-binary
 traitlets<5.2.2
+progressbar2
+entrypoints
+sqlalchemy<2,>=1.3.24
+Deprecated
+ijson
+greenlet
+termcolor>=1.0.0
+
+[pulsar]
+avro<1.11,>=1.10.2
 cached_property
+click>=7.1.2
 jsonref
+packaging
+tabulate
+docker
+aiohttp<4
+expandvars>=0.6.5
 avro-gen3==0.7.10
-
-[pulsar]
+PyYAML
+click-spinner
+requests_file
+jsonschema
+click-default-group
 ratelimiter
+humanfriendly
+toml>=0.10.0
+requests
+psutil>=5.8.0
 python-dateutil>=2.8.0
-jsonschema
 progressbar2
-packaging
-click>=7.1.2
-ijson
-click-default-group
-expandvars>=0.6.5
-tabulate
 entrypoints
-avro<1.11,>=1.10.2
-requests
 Deprecated
-humanfriendly
-toml>=0.10.0
-aiohttp<4
-docker
-PyYAML
+ijson
 termcolor>=1.0.0
-psutil>=5.8.0
-click-spinner
-requests_file
+
+[redash]
+avro<1.11,>=1.10.2
 cached_property
+click>=7.1.2
 jsonref
+packaging
+tabulate
+docker
+aiohttp<4
+expandvars>=0.6.5
 avro-gen3==0.7.10
-
-[redash]
+PyYAML
+click-spinner
+requests_file
+jsonschema
+click-default-group
+redash-toolbelt
 ratelimiter
+humanfriendly
+toml>=0.10.0
+psutil>=5.8.0
 python-dateutil>=2.8.0
-jsonschema
+sqllineage==1.3.6
 progressbar2
-packaging
-click>=7.1.2
-sql-metadata
-ijson
-click-default-group
-expandvars>=0.6.5
-tabulate
 entrypoints
-avro<1.11,>=1.10.2
 Deprecated
-humanfriendly
-toml>=0.10.0
-aiohttp<4
+ijson
+sql-metadata
+termcolor>=1.0.0
+
+[redshift]
+wcmatch
+packaging
+GeoAlchemy2
 docker
-redash-toolbelt
+avro-gen3==0.7.10
 PyYAML
-termcolor>=1.0.0
-psutil>=5.8.0
 click-spinner
 requests_file
-cached_property
-jsonref
-avro-gen3==0.7.10
-sqllineage==1.3.6
-
-[redshift]
 ratelimiter
-jsonref
-jsonschema
-progressbar2
-redshift-connector
-click>=7.1.2
-ijson
-sqlalchemy<2,>=1.3.24
-entrypoints
 humanfriendly
 toml>=0.10.0
-great-expectations<=0.15.50,>=0.15.12
-docker
-PyYAML
-termcolor>=1.0.0
-traitlets<5.2.2
+scipy>=1.7.2
+psutil>=5.8.0
+redshift-connector
+sqllineage==1.3.6
+progressbar2
+entrypoints
+parse>=1.19.0
 greenlet
-requests_file
+sqlalchemy-redshift
+avro<1.11,>=1.10.2
 cached_property
-sqlparse
-avro-gen3==0.7.10
-python-dateutil>=2.8.0
-click-default-group
-expandvars>=0.6.5
+click>=7.1.2
+jsonref
 tabulate
-scipy>=1.7.2
-avro<1.11,>=1.10.2
-GeoAlchemy2
-Deprecated
-wcmatch
 aiohttp<4
+expandvars>=0.6.5
+jsonschema
+click-default-group
+great-expectations<=0.15.50,>=0.15.12
+sqlparse
+python-dateutil>=2.8.0
+traitlets<5.2.2
 psycopg2-binary
-sqlalchemy-redshift
-psutil>=5.8.0
-click-spinner
-packaging
-sqllineage==1.3.6
-parse>=1.19.0
+sqlalchemy<2,>=1.3.24
+Deprecated
+ijson
+termcolor>=1.0.0
 
 [redshift-legacy]
-ratelimiter
-python-dateutil>=2.8.0
-jsonschema
-progressbar2
-packaging
+avro<1.11,>=1.10.2
+cached_property
 click>=7.1.2
-ijson
-click-default-group
-expandvars>=0.6.5
+jsonref
+wcmatch
+packaging
 tabulate
-sqlalchemy<2,>=1.3.24
-scipy>=1.7.2
-entrypoints
-avro<1.11,>=1.10.2
+docker
+aiohttp<4
 GeoAlchemy2
-Deprecated
-wcmatch
+expandvars>=0.6.5
+avro-gen3==0.7.10
+PyYAML
+click-spinner
+requests_file
+jsonschema
+click-default-group
+great-expectations<=0.15.50,>=0.15.12
+ratelimiter
 humanfriendly
 toml>=0.10.0
-great-expectations<=0.15.50,>=0.15.12
-aiohttp<4
-docker
-PyYAML
-psycopg2-binary
-sqlalchemy-redshift
-termcolor>=1.0.0
+scipy>=1.7.2
 psutil>=5.8.0
-click-spinner
+python-dateutil>=2.8.0
 traitlets<5.2.2
-requests_file
-greenlet
-cached_property
-jsonref
-avro-gen3==0.7.10
 sqllineage==1.3.6
+psycopg2-binary
+progressbar2
+entrypoints
+sqlalchemy<2,>=1.3.24
+Deprecated
+ijson
 parse>=1.19.0
+greenlet
+sqlalchemy-redshift
+termcolor>=1.0.0
 
 [redshift-usage-legacy]
-ratelimiter
-python-dateutil>=2.8.0
-jsonschema
-progressbar2
-packaging
-click>=7.1.2
-ijson
-click-default-group
-expandvars>=0.6.5
-tabulate
-sqlalchemy<2,>=1.3.24
-scipy>=1.7.2
-entrypoints
 avro<1.11,>=1.10.2
+cached_property
+click>=7.1.2
+jsonref
 wcmatch
-Deprecated
-GeoAlchemy2
-humanfriendly
-toml>=0.10.0
-great-expectations<=0.15.50,>=0.15.12
-aiohttp<4
+packaging
+tabulate
 docker
+aiohttp<4
+GeoAlchemy2
+expandvars>=0.6.5
+avro-gen3==0.7.10
 PyYAML
-psycopg2-binary
-sqlalchemy-redshift
-termcolor>=1.0.0
-psutil>=5.8.0
 click-spinner
-traitlets<5.2.2
 requests_file
-greenlet
-cached_property
-jsonref
+jsonschema
+click-default-group
+great-expectations<=0.15.50,>=0.15.12
+ratelimiter
+humanfriendly
+toml>=0.10.0
+scipy>=1.7.2
+psutil>=5.8.0
 sqlparse
-avro-gen3==0.7.10
+python-dateutil>=2.8.0
+traitlets<5.2.2
 sqllineage==1.3.6
+psycopg2-binary
+progressbar2
+entrypoints
+sqlalchemy<2,>=1.3.24
+Deprecated
+ijson
 parse>=1.19.0
+greenlet
+sqlalchemy-redshift
+termcolor>=1.0.0
 
 [s3]
-ratelimiter
-python-dateutil>=2.8.0
-botocore!=1.23.0
-moto[s3]
-pydeequ>=1.0.1
-jsonschema
-progressbar2
-packaging
+avro<1.11,>=1.10.2
+cached_property
 click>=7.1.2
-ijson
-click-default-group
-expandvars>=0.6.5
+jsonref
+wcmatch
+packaging
 tabulate
-pyarrow>=6.0.1
-boto3
+docker
+aiohttp<4
 tableschema>=1.20.2
-entrypoints
-avro<1.11,>=1.10.2
-wcmatch
-Deprecated
-pyspark==3.0.3
+expandvars>=0.6.5
+avro-gen3==0.7.10
+PyYAML
+click-spinner
+requests_file
+jsonschema
+click-default-group
+ratelimiter
 humanfriendly
 toml>=0.10.0
+moto[s3]
 ujson>=5.2.0
-aiohttp<4
-docker
+psutil>=5.8.0
+pyarrow>=6.0.1
+pyspark==3.0.3
+python-dateutil>=2.8.0
 smart-open[s3]>=5.2.1
-PyYAML
+botocore!=1.23.0
+progressbar2
+boto3
+entrypoints
+Deprecated
+ijson
+pydeequ>=1.0.1
+parse>=1.19.0
 termcolor>=1.0.0
-psutil>=5.8.0
-click-spinner
-requests_file
+
+[sagemaker]
+avro<1.11,>=1.10.2
 cached_property
+click>=7.1.2
 jsonref
+packaging
+tabulate
+docker
+aiohttp<4
+expandvars>=0.6.5
 avro-gen3==0.7.10
-parse>=1.19.0
-
-[sagemaker]
+PyYAML
+click-spinner
+requests_file
+jsonschema
+click-default-group
 ratelimiter
+humanfriendly
+toml>=0.10.0
+psutil>=5.8.0
 python-dateutil>=2.8.0
 botocore!=1.23.0
-jsonschema
 progressbar2
-packaging
-click>=7.1.2
-ijson
-click-default-group
-expandvars>=0.6.5
-tabulate
 boto3
 entrypoints
-avro<1.11,>=1.10.2
 Deprecated
-humanfriendly
-toml>=0.10.0
-aiohttp<4
-docker
-PyYAML
+ijson
 termcolor>=1.0.0
-psutil>=5.8.0
-click-spinner
-requests_file
+
+[salesforce]
+avro<1.11,>=1.10.2
 cached_property
+click>=7.1.2
 jsonref
+packaging
+tabulate
+docker
+aiohttp<4
+expandvars>=0.6.5
 avro-gen3==0.7.10
-
-[salesforce]
+PyYAML
+click-spinner
+requests_file
+jsonschema
+click-default-group
 ratelimiter
+humanfriendly
+toml>=0.10.0
+psutil>=5.8.0
 python-dateutil>=2.8.0
-jsonschema
 progressbar2
-packaging
-click>=7.1.2
-ijson
-click-default-group
-expandvars>=0.6.5
-tabulate
-simple-salesforce
 entrypoints
-avro<1.11,>=1.10.2
 Deprecated
-humanfriendly
-toml>=0.10.0
-aiohttp<4
+ijson
+simple-salesforce
+termcolor>=1.0.0
+
+[snowflake]
+packaging
 docker
+avro-gen3==0.7.10
 PyYAML
-termcolor>=1.0.0
-psutil>=5.8.0
 click-spinner
 requests_file
-cached_property
-jsonref
-avro-gen3==0.7.10
-
-[snowflake]
-ratelimiter
-jsonref
-jsonschema
-progressbar2
-click>=7.1.2
-ijson
-pandas
-sqlalchemy<2,>=1.3.24
-msal
 spacy==3.4.3
-entrypoints
+ratelimiter
 humanfriendly
 toml>=0.10.0
-great-expectations<=0.15.50,>=0.15.12
-docker
-PyYAML
-cryptography
-termcolor>=1.0.0
-traitlets<5.2.2
+scipy>=1.7.2
+psutil>=5.8.0
+pandas
+snowflake-sqlalchemy!=1.2.5,>=1.2.4
+progressbar2
+entrypoints
+msal
 greenlet
-requests_file
+avro<1.11,>=1.10.2
 cached_property
-sqlparse
-avro-gen3==0.7.10
+click>=7.1.2
 acryl-datahub-classify==0.0.6
-python-dateutil>=2.8.0
-snowflake-sqlalchemy!=1.2.5,>=1.2.4
+jsonref
+tabulate
+aiohttp<4
+expandvars>=0.6.5
 SQLAlchemy<1.4.42
+jsonschema
+cryptography
 click-default-group
-expandvars>=0.6.5
-tabulate
-scipy>=1.7.2
-avro<1.11,>=1.10.2
-Deprecated
+great-expectations<=0.15.50,>=0.15.12
+sqlparse
+python-dateutil>=2.8.0
 snowflake-connector-python!=2.8.2,<3.0.0
-aiohttp<4
-psutil>=5.8.0
-click-spinner
-packaging
+traitlets<5.2.2
+sqlalchemy<2,>=1.3.24
+Deprecated
+ijson
+termcolor>=1.0.0
 
 [snowflake-beta]
-ratelimiter
-jsonref
-jsonschema
-progressbar2
-click>=7.1.2
-ijson
-pandas
-sqlalchemy<2,>=1.3.24
-msal
+packaging
+docker
+avro-gen3==0.7.10
+PyYAML
+click-spinner
+requests_file
 spacy==3.4.3
-entrypoints
+ratelimiter
 humanfriendly
 toml>=0.10.0
-great-expectations<=0.15.50,>=0.15.12
-docker
-PyYAML
-cryptography
-termcolor>=1.0.0
-traitlets<5.2.2
+scipy>=1.7.2
+psutil>=5.8.0
+pandas
+snowflake-sqlalchemy!=1.2.5,>=1.2.4
+progressbar2
+entrypoints
+msal
 greenlet
-requests_file
+avro<1.11,>=1.10.2
 cached_property
-sqlparse
-avro-gen3==0.7.10
+click>=7.1.2
 acryl-datahub-classify==0.0.6
-python-dateutil>=2.8.0
-snowflake-sqlalchemy!=1.2.5,>=1.2.4
+jsonref
+tabulate
+aiohttp<4
+expandvars>=0.6.5
 SQLAlchemy<1.4.42
+jsonschema
+cryptography
 click-default-group
-expandvars>=0.6.5
-tabulate
-scipy>=1.7.2
-avro<1.11,>=1.10.2
-Deprecated
+great-expectations<=0.15.50,>=0.15.12
+sqlparse
+python-dateutil>=2.8.0
 snowflake-connector-python!=2.8.2,<3.0.0
-aiohttp<4
-psutil>=5.8.0
-click-spinner
-packaging
+traitlets<5.2.2
+sqlalchemy<2,>=1.3.24
+Deprecated
+ijson
+termcolor>=1.0.0
 
 [sqlalchemy]
-ratelimiter
-python-dateutil>=2.8.0
-jsonschema
-progressbar2
-packaging
+avro<1.11,>=1.10.2
+cached_property
 click>=7.1.2
-ijson
-click-default-group
-expandvars>=0.6.5
+jsonref
+packaging
 tabulate
-sqlalchemy<2,>=1.3.24
-scipy>=1.7.2
-entrypoints
-avro<1.11,>=1.10.2
-Deprecated
-humanfriendly
-toml>=0.10.0
-great-expectations<=0.15.50,>=0.15.12
-aiohttp<4
 docker
+aiohttp<4
+expandvars>=0.6.5
+avro-gen3==0.7.10
 PyYAML
-termcolor>=1.0.0
-psutil>=5.8.0
 click-spinner
-traitlets<5.2.2
 requests_file
-greenlet
-cached_property
-jsonref
-avro-gen3==0.7.10
-
-[starburst-trino-usage]
-ratelimiter
-python-dateutil>=2.8.0
 jsonschema
-progressbar2
-packaging
-click>=7.1.2
-ijson
 click-default-group
-expandvars>=0.6.5
-tabulate
-sqlalchemy<2,>=1.3.24
-scipy>=1.7.2
-entrypoints
-avro<1.11,>=1.10.2
-Deprecated
+great-expectations<=0.15.50,>=0.15.12
+ratelimiter
 humanfriendly
 toml>=0.10.0
-great-expectations<=0.15.50,>=0.15.12
-aiohttp<4
-docker
-PyYAML
-termcolor>=1.0.0
+scipy>=1.7.2
 psutil>=5.8.0
-click-spinner
+python-dateutil>=2.8.0
+traitlets<5.2.2
+progressbar2
+entrypoints
+sqlalchemy<2,>=1.3.24
+Deprecated
+ijson
 greenlet
-requests_file
-trino[sqlalchemy]!=0.317,>=0.308
+termcolor>=1.0.0
+
+[starburst-trino-usage]
+avro<1.11,>=1.10.2
 cached_property
-traitlets<5.2.2
+click>=7.1.2
 jsonref
-sqlparse
+packaging
+tabulate
+docker
+aiohttp<4
+trino[sqlalchemy]!=0.317,>=0.308
+expandvars>=0.6.5
 avro-gen3==0.7.10
-
-[superset]
+PyYAML
+click-spinner
+requests_file
+jsonschema
+click-default-group
+great-expectations<=0.15.50,>=0.15.12
 ratelimiter
+humanfriendly
+toml>=0.10.0
+scipy>=1.7.2
+psutil>=5.8.0
+sqlparse
 python-dateutil>=2.8.0
-jsonschema
+traitlets<5.2.2
 progressbar2
-packaging
+entrypoints
+sqlalchemy<2,>=1.3.24
+Deprecated
+ijson
+greenlet
+termcolor>=1.0.0
+
+[superset]
+avro<1.11,>=1.10.2
+cached_property
 click>=7.1.2
+jsonref
+packaging
 great_expectations
-ijson
-click-default-group
-expandvars>=0.6.5
 tabulate
-entrypoints
-avro<1.11,>=1.10.2
-requests
-Deprecated
+docker
+aiohttp<4
+expandvars>=0.6.5
+avro-gen3==0.7.10
+PyYAML
+click-spinner
+requests_file
+jsonschema
+click-default-group
+ratelimiter
 humanfriendly
 toml>=0.10.0
-aiohttp<4
-docker
+requests
 sqlalchemy
-PyYAML
-termcolor>=1.0.0
 psutil>=5.8.0
-click-spinner
+python-dateutil>=2.8.0
+progressbar2
+entrypoints
+Deprecated
+ijson
 greenlet
-requests_file
+termcolor>=1.0.0
+
+[tableau]
+avro<1.11,>=1.10.2
 cached_property
+click>=7.1.2
 jsonref
+packaging
+tabulate
+docker
+aiohttp<4
+expandvars>=0.6.5
 avro-gen3==0.7.10
-
-[tableau]
-ratelimiter
-python-dateutil>=2.8.0
+PyYAML
+click-spinner
+requests_file
 jsonschema
-progressbar2
-packaging
-click>=7.1.2
-ijson
 click-default-group
-expandvars>=0.6.5
-tabulate
-entrypoints
-avro<1.11,>=1.10.2
-Deprecated
+ratelimiter
 humanfriendly
 toml>=0.10.0
-aiohttp<4
-docker
-PyYAML
-termcolor>=1.0.0
 psutil>=5.8.0
-click-spinner
 tableauserverclient>=0.17.0
-requests_file
-cached_property
-jsonref
-avro-gen3==0.7.10
+python-dateutil>=2.8.0
 sqllineage==1.3.6
+progressbar2
+entrypoints
+Deprecated
+ijson
+termcolor>=1.0.0
 
 [trino]
-ratelimiter
-python-dateutil>=2.8.0
-jsonschema
-progressbar2
-packaging
+avro<1.11,>=1.10.2
+cached_property
 click>=7.1.2
-ijson
-click-default-group
-expandvars>=0.6.5
+jsonref
+packaging
 tabulate
-sqlalchemy<2,>=1.3.24
-scipy>=1.7.2
-entrypoints
-avro<1.11,>=1.10.2
-Deprecated
-humanfriendly
-toml>=0.10.0
-great-expectations<=0.15.50,>=0.15.12
-aiohttp<4
 docker
+aiohttp<4
+trino[sqlalchemy]!=0.317,>=0.308
+expandvars>=0.6.5
+avro-gen3==0.7.10
 PyYAML
-termcolor>=1.0.0
-psutil>=5.8.0
 click-spinner
-greenlet
 requests_file
-trino[sqlalchemy]!=0.317,>=0.308
-cached_property
-traitlets<5.2.2
-jsonref
-avro-gen3==0.7.10
-
-[unity-catalog]
+jsonschema
+click-default-group
+great-expectations<=0.15.50,>=0.15.12
 ratelimiter
+humanfriendly
+toml>=0.10.0
+scipy>=1.7.2
+psutil>=5.8.0
 python-dateutil>=2.8.0
-jsonschema
+traitlets<5.2.2
 progressbar2
-packaging
-click>=7.1.2
-ijson
-click-default-group
-expandvars>=0.6.5
-tabulate
-databricks-cli==0.17.3
 entrypoints
-avro<1.11,>=1.10.2
-requests
+sqlalchemy<2,>=1.3.24
 Deprecated
-humanfriendly
-toml>=0.10.0
-aiohttp<4
-docker
-PyYAML
+ijson
+greenlet
 termcolor>=1.0.0
-psutil>=5.8.0
-click-spinner
-requests_file
+
+[unity-catalog]
+avro<1.11,>=1.10.2
 cached_property
+click>=7.1.2
+databricks-cli==0.17.3
 jsonref
+packaging
+tabulate
+docker
+aiohttp<4
+expandvars>=0.6.5
 avro-gen3==0.7.10
-
-[vertica]
+PyYAML
+click-spinner
+requests_file
+jsonschema
+click-default-group
 ratelimiter
+humanfriendly
+toml>=0.10.0
+requests
+psutil>=5.8.0
 python-dateutil>=2.8.0
-jsonschema
 progressbar2
-packaging
-click>=7.1.2
-ijson
-click-default-group
-expandvars>=0.6.5
-tabulate
-sqlalchemy<2,>=1.3.24
-scipy>=1.7.2
 entrypoints
-avro<1.11,>=1.10.2
 Deprecated
-vertica-sqlalchemy-dialect[vertica-python]==0.0.1
-humanfriendly
-toml>=0.10.0
-great-expectations<=0.15.50,>=0.15.12
-aiohttp<4
+ijson
+termcolor>=1.0.0
+
+[vertica]
+avro<1.11,>=1.10.2
+cached_property
+click>=7.1.2
+jsonref
+packaging
+tabulate
 docker
+aiohttp<4
+expandvars>=0.6.5
+avro-gen3==0.7.10
 PyYAML
-termcolor>=1.0.0
-psutil>=5.8.0
 click-spinner
-greenlet
 requests_file
+jsonschema
+click-default-group
+great-expectations<=0.15.50,>=0.15.12
+ratelimiter
+humanfriendly
+toml>=0.10.0
+scipy>=1.7.2
+psutil>=5.8.0
+python-dateutil>=2.8.0
 traitlets<5.2.2
-cached_property
-jsonref
-avro-gen3==0.7.10
+progressbar2
+entrypoints
+sqlalchemy<2,>=1.3.24
+Deprecated
+ijson
+vertica-sqlalchemy-dialect[vertica-python]==0.0.1
+greenlet
+termcolor>=1.0.0
```

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/__init__.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 import sys
 import warnings
 
 # Published at https://pypi.org/project/acryl-datahub/.
 __package_name__ = "acryl-datahub-tc"
-__version__ = "0.10.2.0rc3"
+__version__ = "0.10.2.rc1"
  
 
 
 def is_dev_mode() -> bool:
     return __version__.endswith("dev0")
```

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/api/circuit_breaker/assertion_circuit_breaker.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/api/circuit_breaker/assertion_circuit_breaker.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/api/circuit_breaker/circuit_breaker.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/api/circuit_breaker/circuit_breaker.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/api/circuit_breaker/operation_circuit_breaker.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/api/circuit_breaker/operation_circuit_breaker.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/api/entities/corpgroup/corpgroup.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/api/entities/corpgroup/corpgroup.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/api/entities/corpuser/corpuser.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/api/entities/corpuser/corpuser.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/api/entities/datajob/dataflow.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/api/entities/datajob/dataflow.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/api/entities/datajob/datajob.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/api/entities/datajob/datajob.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/api/entities/dataprocess/dataprocess_instance.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/api/entities/dataprocess/dataprocess_instance.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/api/graphql/assertion.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/api/graphql/assertion.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/api/graphql/base.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/api/graphql/base.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/api/graphql/operation.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/api/graphql/operation.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/cli/check_cli.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/cli/check_cli.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/cli/cli_utils.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/cli/cli_utils.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/cli/delete_cli.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/cli/delete_cli.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/cli/docker_check.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/cli/docker_check.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/cli/docker_cli.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/cli/docker_cli.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/cli/get_cli.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/cli/get_cli.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/cli/ingest_cli.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/cli/ingest_cli.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/cli/json_file.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/cli/json_file.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/cli/lite_cli.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/cli/lite_cli.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/cli/migrate.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/cli/migrate.py`

 * *Files 1% similar despite different names*

```diff
@@ -136,21 +136,19 @@
     click.echo(
         f"Starting migration: platform:{platform}, instance={instance}, force={force}, dry-run={dry_run}"
     )
     run_id: str = f"migrate-{uuid.uuid4()}"
     migration_report = MigrationReport(run_id, dry_run, keep)
     system_metadata = SystemMetadataClass(runId=run_id)
 
-    rest_emitter = None # add default
-    
     if not dry_run:
         rest_emitter = DatahubRestEmitter(
             gms_server=cli_utils.get_session_and_host()[1]
         )
-        
+
     urns_to_migrate = []
 
     # we first calculate all the urns we will be migrating
     for src_entity_urn in cli_utils.get_urns_by_filter(platform=platform, env=env):
         key = dataset_urn_to_key(src_entity_urn)
         assert key
         # Does this urn already have a platform instance associated with it?
```

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/cli/migration_utils.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/cli/migration_utils.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/cli/put_cli.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/cli/put_cli.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/cli/quickstart_versioning.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/cli/quickstart_versioning.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/cli/specific/file_loader.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/cli/specific/file_loader.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/cli/specific/group_cli.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/cli/specific/group_cli.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/cli/specific/user_cli.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/cli/specific/user_cli.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/cli/state_cli.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/cli/state_cli.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/cli/timeline_cli.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/cli/timeline_cli.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/configuration/_config_enum.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/configuration/_config_enum.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/configuration/common.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/configuration/common.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/configuration/config_loader.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/configuration/config_loader.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/configuration/git.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/configuration/git.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/configuration/kafka.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/configuration/kafka.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/configuration/pydantic_field_deprecation.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/configuration/pydantic_field_deprecation.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/configuration/source_common.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/configuration/source_common.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/configuration/time_window_config.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/configuration/time_window_config.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/configuration/validate_field_removal.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/configuration/validate_field_removal.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/configuration/validate_field_rename.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/configuration/validate_field_rename.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/configuration/validate_host_port.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/configuration/validate_host_port.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/emitter/kafka_emitter.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/emitter/kafka_emitter.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/emitter/mce_builder.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/emitter/mce_builder.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/emitter/mcp.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/emitter/mcp.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/emitter/mcp_builder.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/emitter/mcp_builder.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/emitter/mcp_patch_builder.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/emitter/mcp_patch_builder.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/emitter/request_helper.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/emitter/request_helper.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/emitter/rest_emitter.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/emitter/rest_emitter.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/emitter/serialization_helper.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/emitter/serialization_helper.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/entrypoints.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/entrypoints.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/api/committable.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/api/committable.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/api/common.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/api/common.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/api/decorators.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/api/decorators.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/api/ingestion_job_checkpointing_provider_base.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/api/ingestion_job_checkpointing_provider_base.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/api/pipeline_run_listener.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/api/pipeline_run_listener.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/api/registry.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/api/registry.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/api/report.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/api/report.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/api/report_helpers.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/api/report_helpers.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/api/sink.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/api/sink.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/api/source.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/api/source.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/api/transform.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/api/transform.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/api/workunit.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/api/workunit.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/extractor/json_ref_patch.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/extractor/json_ref_patch.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/extractor/json_schema_util.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/extractor/json_schema_util.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/extractor/mce_extractor.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/extractor/mce_extractor.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/extractor/protobuf_util.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/extractor/protobuf_util.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/extractor/schema_util.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/extractor/schema_util.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/glossary/classification_mixin.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/glossary/classification_mixin.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/glossary/classifier.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/glossary/classifier.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/glossary/datahub_classifier.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/glossary/datahub_classifier.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/graph/client.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/graph/client.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/reporting/datahub_ingestion_run_summary_provider.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/reporting/datahub_ingestion_run_summary_provider.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/reporting/file_reporter.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/reporting/file_reporter.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/run/connection.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/run/connection.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/run/pipeline.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/run/pipeline.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/run/pipeline_config.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/run/pipeline_config.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/sink/blackhole.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/sink/blackhole.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/sink/console.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/sink/console.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/sink/datahub_kafka.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/sink/datahub_kafka.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/sink/datahub_lite.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/sink/datahub_lite.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/sink/datahub_rest.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/sink/datahub_rest.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/sink/file.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/sink/file.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/aws/aws_common.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/aws/aws_common.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/aws/glue.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/aws/glue.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/aws/path_spec.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/aws/path_spec.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/aws/s3_boto_utils.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/aws/s3_boto_utils.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/aws/s3_util.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/aws/s3_util.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/aws/sagemaker.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/aws/sagemaker.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/aws/sagemaker_processors/common.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/aws/sagemaker_processors/common.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/aws/sagemaker_processors/feature_groups.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/aws/sagemaker_processors/feature_groups.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/aws/sagemaker_processors/job_classes.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/aws/sagemaker_processors/job_classes.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/aws/sagemaker_processors/jobs.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/aws/sagemaker_processors/jobs.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/aws/sagemaker_processors/lineage.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/aws/sagemaker_processors/lineage.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/aws/sagemaker_processors/models.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/aws/sagemaker_processors/models.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/azure/azure_common.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/azure/azure_common.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/bigquery_v2/bigquery.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/bigquery_v2/bigquery.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/bigquery_v2/bigquery_audit.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/bigquery_v2/bigquery_audit.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/bigquery_v2/bigquery_config.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/bigquery_v2/bigquery_config.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/bigquery_v2/bigquery_report.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/bigquery_v2/bigquery_report.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/bigquery_v2/bigquery_schema.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/bigquery_v2/bigquery_schema.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/bigquery_v2/common.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/bigquery_v2/common.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/bigquery_v2/lineage.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/bigquery_v2/lineage.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/bigquery_v2/profiler.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/bigquery_v2/profiler.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/bigquery_v2/usage.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/bigquery_v2/usage.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/common/subtypes.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/common/subtypes.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/confluent_schema_registry.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/confluent_schema_registry.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/csv_enricher.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/csv_enricher.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/dbt/dbt_cloud.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/dbt/dbt_cloud.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/dbt/dbt_common.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/dbt/dbt_common.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/dbt/dbt_core.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/dbt/dbt_core.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/delta_lake/config.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/delta_lake/config.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/delta_lake/delta_lake_utils.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/delta_lake/delta_lake_utils.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/delta_lake/source.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/delta_lake/source.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/demo_data.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/demo_data.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/elastic_search.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/elastic_search.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/feast.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/feast.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/file.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/file.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/ge_data_profiler.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/ge_data_profiler.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/ge_profiling_config.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/ge_profiling_config.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/git/git_import.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/git/git_import.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/glue_profiling_config.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/glue_profiling_config.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/iceberg/iceberg.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/iceberg/iceberg.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/iceberg/iceberg_common.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/iceberg/iceberg_common.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/iceberg/iceberg_profiler.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/iceberg/iceberg_profiler.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/identity/azure_ad.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/identity/azure_ad.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/identity/okta.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/identity/okta.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/kafka.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/kafka.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/kafka_connect.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/kafka_connect.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/ldap.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/ldap.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/looker/looker_common.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/looker/looker_common.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/looker/looker_lib_wrapper.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/looker/looker_lib_wrapper.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/looker/looker_query_model.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/looker/looker_query_model.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/looker/looker_source.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/looker/looker_source.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/looker/looker_usage.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/looker/looker_usage.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/looker/lookml_source.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/looker/lookml_source.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/metabase.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/metabase.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/metadata/business_glossary.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/metadata/business_glossary.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/metadata/lineage.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/metadata/lineage.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/mode.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/mode.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/mongodb.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/mongodb.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/nifi.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/nifi.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/openapi.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/openapi.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/openapi_parser.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/openapi_parser.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/powerbi/config.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/powerbi/config.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/powerbi/dataplatform_instance_resolver.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/powerbi/dataplatform_instance_resolver.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/powerbi/m_query/data_classes.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/powerbi/m_query/data_classes.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/powerbi/m_query/native_sql_parser.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/powerbi/m_query/native_sql_parser.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/powerbi/m_query/parser.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/powerbi/m_query/parser.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/powerbi/m_query/resolver.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/powerbi/m_query/resolver.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/powerbi/m_query/tree_function.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/powerbi/m_query/tree_function.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/powerbi/m_query/validator.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/powerbi/m_query/validator.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/powerbi/powerbi-lexical-grammar.rule` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/powerbi/powerbi-lexical-grammar.rule`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/powerbi/powerbi.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/powerbi/powerbi.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/powerbi/rest_api_wrapper/data_classes.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/powerbi/rest_api_wrapper/data_classes.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/powerbi/rest_api_wrapper/data_resolver.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/powerbi/rest_api_wrapper/data_resolver.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/powerbi/rest_api_wrapper/powerbi_api.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/powerbi/rest_api_wrapper/powerbi_api.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/powerbi_report_server/constants.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/powerbi_report_server/constants.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/powerbi_report_server/report_server.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/powerbi_report_server/report_server.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/powerbi_report_server/report_server_domain.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/powerbi_report_server/report_server_domain.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/profiling/common.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/profiling/common.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/pulsar.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/pulsar.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/redash.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/redash.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/redshift/config.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/redshift/config.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/redshift/lineage.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/redshift/lineage.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/redshift/profile.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/redshift/profile.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/redshift/query.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/redshift/query.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/redshift/redshift.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/redshift/redshift.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/redshift/redshift_schema.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/redshift/redshift_schema.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/redshift/report.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/redshift/report.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/redshift/usage.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/redshift/usage.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/s3/config.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/s3/config.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/s3/data_lake_utils.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/s3/data_lake_utils.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/s3/profiling.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/s3/profiling.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/s3/source.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/s3/source.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/salesforce.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/salesforce.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/schema/json_schema.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/schema/json_schema.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/schema_inference/avro.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/schema_inference/avro.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/schema_inference/csv_tsv.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/schema_inference/csv_tsv.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/schema_inference/json.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/schema_inference/json.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/schema_inference/object.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/schema_inference/object.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/schema_inference/parquet.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/schema_inference/parquet.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/snowflake/constants.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/snowflake/constants.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/snowflake/snowflake_config.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/snowflake/snowflake_config.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/snowflake/snowflake_lineage_legacy.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/snowflake/snowflake_lineage_legacy.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/snowflake/snowflake_lineage_v2.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/snowflake/snowflake_lineage_v2.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/snowflake/snowflake_profiler.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/snowflake/snowflake_profiler.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/snowflake/snowflake_query.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/snowflake/snowflake_query.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/snowflake/snowflake_report.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/snowflake/snowflake_report.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/snowflake/snowflake_schema.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/snowflake/snowflake_schema.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/snowflake/snowflake_tag.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/snowflake/snowflake_tag.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/snowflake/snowflake_usage_v2.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/snowflake/snowflake_usage_v2.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/snowflake/snowflake_utils.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/snowflake/snowflake_utils.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/snowflake/snowflake_v2.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/snowflake/snowflake_v2.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/source_registry.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/source_registry.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/sql/athena.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/sql/athena.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/sql/clickhouse.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/sql/clickhouse.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/sql/druid.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/sql/druid.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/sql/hana.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/sql/hana.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/sql/hive.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/sql/hive.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/sql/mariadb.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/sql/mariadb.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/sql/mssql.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/sql/mssql.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/sql/mysql.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/sql/mysql.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/sql/oauth_generator.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/sql/oauth_generator.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/sql/oracle.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/sql/oracle.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/sql/postgres.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/sql/postgres.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/sql/presto.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/sql/presto.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/sql/presto_on_hive.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/sql/presto_on_hive.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/sql/redshift.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/sql/redshift.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/sql/sql_common.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/sql/sql_common.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/sql/sql_config.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/sql/sql_config.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/sql/sql_generic.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/sql/sql_generic.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/sql/sql_generic_profiler.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/sql/sql_generic_profiler.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/sql/sql_types.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/sql/sql_types.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/sql/sql_utils.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/sql/sql_utils.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/sql/trino.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/sql/trino.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/sql/two_tier_sql_source.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/sql/two_tier_sql_source.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/sql/vertica.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/sql/vertica.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/state/checkpoint.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/state/checkpoint.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/state/entity_removal_state.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/state/entity_removal_state.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/state/profiling_state.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/state/profiling_state.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/state/profiling_state_handler.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/state/profiling_state_handler.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/state/redundant_run_skip_handler.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/state/redundant_run_skip_handler.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/state/stale_entity_removal_handler.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/state/stale_entity_removal_handler.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/state/stateful_ingestion_base.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/state/stateful_ingestion_base.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/state/use_case_handler.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/state/use_case_handler.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/state_provider/datahub_ingestion_checkpointing_provider.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/state_provider/datahub_ingestion_checkpointing_provider.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/superset.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/superset.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/tableau.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/tableau.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/tableau_common.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/tableau_common.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/tableau_constant.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/tableau_constant.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/unity/config.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/unity/config.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/unity/proxy.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/unity/proxy.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/unity/report.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/unity/report.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/unity/source.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/unity/source.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/usage/clickhouse_usage.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/usage/clickhouse_usage.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/usage/redshift_usage.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/usage/redshift_usage.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/usage/starburst_trino_usage.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/usage/starburst_trino_usage.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source/usage/usage_common.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source/usage/usage_common.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source_config/bigquery.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source_config/bigquery.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source_config/csv_enricher.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source_config/csv_enricher.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source_config/pulsar.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source_config/pulsar.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source_config/sql/snowflake.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source_config/sql/snowflake.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source_config/usage/bigquery_usage.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source_config/usage/bigquery_usage.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source_config/usage/snowflake_usage.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source_config/usage/snowflake_usage.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source_report/pulsar.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source_report/pulsar.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source_report/sql/bigquery.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source_report/sql/bigquery.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source_report/sql/snowflake.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source_report/sql/snowflake.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source_report/usage/bigquery_usage.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source_report/usage/bigquery_usage.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/source_report/usage/snowflake_usage.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/source_report/usage/snowflake_usage.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/transformer/add_dataset_browse_path.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/transformer/add_dataset_browse_path.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/transformer/add_dataset_ownership.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/transformer/add_dataset_ownership.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/transformer/add_dataset_properties.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/transformer/add_dataset_properties.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/transformer/add_dataset_schema_tags.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/transformer/add_dataset_schema_tags.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/transformer/add_dataset_schema_terms.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/transformer/add_dataset_schema_terms.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/transformer/add_dataset_tags.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/transformer/add_dataset_tags.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/transformer/add_dataset_terms.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/transformer/add_dataset_terms.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/transformer/base_transformer.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/transformer/base_transformer.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/transformer/dataset_domain.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/transformer/dataset_domain.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/transformer/dataset_transformer.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/transformer/dataset_transformer.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/transformer/mark_dataset_status.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/transformer/mark_dataset_status.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/ingestion/transformer/remove_dataset_ownership.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/ingestion/transformer/remove_dataset_ownership.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/integrations/great_expectations/action.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/integrations/great_expectations/action.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/lite/duckdb_lite.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/lite/duckdb_lite.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/lite/lite_local.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/lite/lite_local.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/lite/lite_server.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/lite/lite_server.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/lite/lite_util.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/lite/lite_util.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/assertion/__init__.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/assertion/__init__.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/chart/__init__.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/chart/__init__.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/common/__init__.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/common/__init__.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/dashboard/__init__.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/dashboard/__init__.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/datajob/__init__.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/datajob/__init__.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/datajob/datahub/__init__.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/datajob/datahub/__init__.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/dataprocess/__init__.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/dataprocess/__init__.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/dataset/__init__.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/dataset/__init__.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/execution/__init__.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/execution/__init__.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/identity/__init__.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/identity/__init__.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/ingestion/__init__.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/ingestion/__init__.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/metadata/key/__init__.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/metadata/key/__init__.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/metadata/snapshot/__init__.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/metadata/snapshot/__init__.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/ml/metadata/__init__.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/ml/metadata/__init__.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/mxe/__init__.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/mxe/__init__.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/notebook/__init__.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/notebook/__init__.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/policy/__init__.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/policy/__init__.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/query/__init__.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/query/__init__.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/retention/__init__.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/retention/__init__.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/schema/__init__.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/schema/__init__.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/test/__init__.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/test/__init__.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/timeseries/__init__.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/timeseries/__init__.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/com/linkedin/pegasus2avro/usage/__init__.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/com/linkedin/pegasus2avro/usage/__init__.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/schema.avsc` & `acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/schema.avsc`

 * *Files 0% similar despite different names*

#### Pretty-printed

 * *Similarity: 0.46721214217492935%*

 * *Differences: {'1': "{'Aspect': {'name': 'editableDataJobProperties'}, 'name': 'EditableDataJobProperties', "*

 * *      "'namespace': 'com.linkedin.pegasus2avro.datajob', 'fields': {2: {'type': {insert: [(1, "*

 * *      "'com.linkedin.pegasus2avro.common.AuditStamp')], delete: [1]}, 'name': 'deleted', 'doc': "*

 * *      "'An AuditStamp corresponding to the deletion of this resource/association/sub-resource. "*

 * *      'Logically, deleted MUST have a later timestamp than creation. It may or may not have the '*

 * *      'same time as lastMod []*

```diff
@@ -1,901 +1,690 @@
 [
     "null",
     {
         "Aspect": {
-            "name": "globalSettingsInfo"
-        },
-        "doc": "DataHub Global platform settings. Careful - these should not be modified by the outside world!",
-        "fields": [
-            {
-                "default": null,
-                "doc": "Settings related to the Views Feature",
-                "name": "views",
-                "type": [
-                    "null",
-                    {
-                        "doc": "Settings for DataHub Views feature.",
-                        "fields": [
-                            {
-                                "Urn": "Urn",
-                                "default": null,
-                                "doc": "The default View for the instance, or organization.",
-                                "java": {
-                                    "class": "com.linkedin.pegasus2avro.common.urn.Urn"
-                                },
-                                "name": "defaultView",
-                                "type": [
-                                    "null",
-                                    "string"
-                                ]
-                            }
-                        ],
-                        "name": "GlobalViewsSettings",
-                        "namespace": "com.linkedin.pegasus2avro.settings.global",
-                        "type": "record"
-                    }
-                ]
-            }
-        ],
-        "name": "GlobalSettingsInfo",
-        "namespace": "com.linkedin.pegasus2avro.settings.global",
-        "type": "record"
-    },
-    {
-        "Aspect": {
-            "name": "dataHubAccessTokenInfo"
+            "name": "editableDataJobProperties"
         },
-        "doc": "Information about a DataHub Access Token",
+        "doc": "Stores editable changes made to properties. This separates changes made from\ningestion pipelines and edits in the UI to avoid accidental overwrites of user-provided data by ingestion pipelines",
         "fields": [
             {
-                "Searchable": {
-                    "fieldType": "TEXT_PARTIAL"
-                },
-                "doc": "User defined name for the access token if defined.",
-                "name": "name",
-                "type": "string"
-            },
-            {
-                "Searchable": {
-                    "fieldType": "URN"
-                },
-                "Urn": "Urn",
-                "doc": "Urn of the actor to which this access token belongs to.",
-                "java": {
-                    "class": "com.linkedin.pegasus2avro.common.urn.Urn"
-                },
-                "name": "actorUrn",
-                "type": "string"
-            },
-            {
-                "Searchable": {
-                    "fieldType": "URN"
-                },
-                "Urn": "Urn",
-                "doc": "Urn of the actor which created this access token.",
-                "java": {
-                    "class": "com.linkedin.pegasus2avro.common.urn.Urn"
+                "default": {
+                    "actor": "urn:li:corpuser:unknown",
+                    "impersonator": null,
+                    "message": null,
+                    "time": 0
                 },
-                "name": "ownerUrn",
-                "type": "string"
+                "doc": "An AuditStamp corresponding to the creation of this resource/association/sub-resource. A value of 0 for time indicates missing data.",
+                "name": "created",
+                "type": {
+                    "doc": "Data captured on a resource/association/sub-resource level giving insight into when that resource/association/sub-resource moved into a particular lifecycle stage, and who acted to move it into that specific lifecycle stage.",
+                    "fields": [
+                        {
+                            "doc": "When did the resource/association/sub-resource move into the specific lifecycle stage represented by this AuditEvent.",
+                            "name": "time",
+                            "type": "long"
+                        },
+                        {
+                            "Urn": "Urn",
+                            "doc": "The entity (e.g. a member URN) which will be credited for moving the resource/association/sub-resource into the specific lifecycle stage. It is also the one used to authorize the change.",
+                            "java": {
+                                "class": "com.linkedin.pegasus2avro.common.urn.Urn"
+                            },
+                            "name": "actor",
+                            "type": "string"
+                        },
+                        {
+                            "Urn": "Urn",
+                            "default": null,
+                            "doc": "The entity (e.g. a service URN) which performs the change on behalf of the Actor and must be authorized to act as the Actor.",
+                            "java": {
+                                "class": "com.linkedin.pegasus2avro.common.urn.Urn"
+                            },
+                            "name": "impersonator",
+                            "type": [
+                                "null",
+                                "string"
+                            ]
+                        },
+                        {
+                            "default": null,
+                            "doc": "Additional context around how DataHub was informed of the particular change. For example: was the change created by an automated process, or manually.",
+                            "name": "message",
+                            "type": [
+                                "null",
+                                "string"
+                            ]
+                        }
+                    ],
+                    "name": "AuditStamp",
+                    "namespace": "com.linkedin.pegasus2avro.common",
+                    "type": "record"
+                }
             },
             {
-                "Searchable": {
-                    "fieldType": "COUNT",
-                    "queryByDefault": false
+                "default": {
+                    "actor": "urn:li:corpuser:unknown",
+                    "impersonator": null,
+                    "message": null,
+                    "time": 0
                 },
-                "doc": "When the token was created.",
-                "name": "createdAt",
-                "type": "long"
+                "doc": "An AuditStamp corresponding to the last modification of this resource/association/sub-resource. If no modification has happened since creation, lastModified should be the same as created. A value of 0 for time indicates missing data.",
+                "name": "lastModified",
+                "type": "com.linkedin.pegasus2avro.common.AuditStamp"
             },
             {
-                "Searchable": {
-                    "fieldType": "COUNT",
-                    "queryByDefault": false
-                },
                 "default": null,
-                "doc": "When the token expires.",
-                "name": "expiresAt",
+                "doc": "An AuditStamp corresponding to the deletion of this resource/association/sub-resource. Logically, deleted MUST have a later timestamp than creation. It may or may not have the same time as lastModified depending upon the resource/association/sub-resource semantics.",
+                "name": "deleted",
                 "type": [
                     "null",
-                    "long"
+                    "com.linkedin.pegasus2avro.common.AuditStamp"
                 ]
             },
             {
+                "Searchable": {
+                    "fieldName": "editedDescription",
+                    "fieldType": "TEXT"
+                },
                 "default": null,
-                "doc": "Description of the token if defined.",
+                "doc": "Edited documentation of the data job ",
                 "name": "description",
                 "type": [
                     "null",
                     "string"
                 ]
             }
         ],
-        "name": "DataHubAccessTokenInfo",
-        "namespace": "com.linkedin.pegasus2avro.access.token",
+        "name": "EditableDataJobProperties",
+        "namespace": "com.linkedin.pegasus2avro.datajob",
         "type": "record"
     },
     {
         "Aspect": {
-            "name": "mlHyperParam"
+            "name": "dataFlowInfo"
         },
-        "doc": "Properties associated with an ML Hyper Param",
+        "doc": "Information about a Data processing flow",
         "fields": [
             {
-                "doc": "Name of the MLHyperParam",
-                "name": "name",
-                "type": "string"
+                "Searchable": {
+                    "/*": {
+                        "queryByDefault": true
+                    }
+                },
+                "default": {},
+                "doc": "Custom property bag.",
+                "name": "customProperties",
+                "type": {
+                    "type": "map",
+                    "values": "string"
+                }
             },
             {
                 "default": null,
-                "doc": "Documentation of the MLHyperParam",
-                "name": "description",
+                "doc": "URL where the reference exist",
+                "java": {
+                    "class": "com.linkedin.pegasus2avro.common.url.Url",
+                    "coercerClass": "com.linkedin.pegasus2avro.common.url.UrlCoercer"
+                },
+                "name": "externalUrl",
                 "type": [
                     "null",
                     "string"
                 ]
             },
             {
-                "default": null,
-                "doc": "The value of the MLHyperParam",
-                "name": "value",
-                "type": [
-                    "null",
-                    "string"
-                ]
+                "Searchable": {
+                    "boostScore": 10.0,
+                    "enableAutocomplete": true,
+                    "fieldType": "TEXT_PARTIAL"
+                },
+                "doc": "Flow name",
+                "name": "name",
+                "type": "string"
             },
             {
+                "Searchable": {
+                    "fieldType": "TEXT",
+                    "hasValuesFieldName": "hasDescription"
+                },
                 "default": null,
-                "doc": "Date when the MLHyperParam was developed",
-                "name": "createdAt",
-                "type": [
-                    "null",
-                    "long"
-                ]
-            }
-        ],
-        "name": "MLHyperParam",
-        "namespace": "com.linkedin.pegasus2avro.ml.metadata",
-        "type": "record"
-    },
-    {
-        "Aspect": {
-            "name": "mlModelEvaluationData"
-        },
-        "doc": "All referenced datasets would ideally point to any set of documents that provide visibility into the source and composition of the dataset.",
-        "fields": [
-            {
-                "doc": "Details on the dataset(s) used for the quantitative analyses in the MLModel",
-                "name": "evaluationData",
-                "type": {
-                    "items": {
-                        "doc": "BaseData record",
-                        "fields": [
-                            {
-                                "Urn": "DatasetUrn",
-                                "doc": "What dataset were used in the MLModel?",
-                                "java": {
-                                    "class": "com.linkedin.pegasus2avro.common.urn.DatasetUrn"
-                                },
-                                "name": "dataset",
-                                "type": "string"
-                            },
-                            {
-                                "default": null,
-                                "doc": "Why was this dataset chosen?",
-                                "name": "motivation",
-                                "type": [
-                                    "null",
-                                    "string"
-                                ]
-                            },
-                            {
-                                "default": null,
-                                "doc": "How was the data preprocessed (e.g., tokenization of sentences, cropping of images, any filtering such as dropping images without faces)?",
-                                "name": "preProcessing",
-                                "type": [
-                                    "null",
-                                    {
-                                        "items": "string",
-                                        "type": "array"
-                                    }
-                                ]
-                            }
-                        ],
-                        "name": "BaseData",
-                        "namespace": "com.linkedin.pegasus2avro.ml.metadata",
-                        "type": "record"
-                    },
-                    "type": "array"
-                }
-            }
-        ],
-        "name": "EvaluationData",
-        "namespace": "com.linkedin.pegasus2avro.ml.metadata",
-        "type": "record"
-    },
-    {
-        "Aspect": {
-            "name": "mlPrimaryKeyProperties"
-        },
-        "doc": "Properties associated with a MLPrimaryKey",
-        "fields": [
-            {
-                "default": null,
-                "doc": "Documentation of the MLPrimaryKey",
+                "doc": "Flow description",
                 "name": "description",
                 "type": [
                     "null",
                     "string"
                 ]
             },
             {
+                "Searchable": {
+                    "fieldType": "TEXT_PARTIAL",
+                    "queryByDefault": false
+                },
                 "default": null,
-                "doc": "Data Type of the MLPrimaryKey",
-                "name": "dataType",
+                "doc": "Optional project/namespace associated with the flow",
+                "name": "project",
                 "type": [
                     "null",
-                    {
-                        "doc": "MLFeature Data Type",
-                        "name": "MLFeatureDataType",
-                        "namespace": "com.linkedin.pegasus2avro.common",
-                        "symbolDocs": {
-                            "AUDIO": "Audio Data",
-                            "BINARY": "Binary data is discrete data that can be in only one of two categories - either yes or no, 1 or 0, off or on, etc",
-                            "BYTE": "Bytes data are binary-encoded values that can represent complex objects.",
-                            "CONTINUOUS": "Continuous data are made of uncountable values, often the result of a measurement such as height, weight, age etc.",
-                            "COUNT": "Count data is discrete whole number data - no negative numbers here.\nCount data often has many small values, such as zero and one.",
-                            "IMAGE": "Image Data",
-                            "INTERVAL": "Interval data has equal spaces between the numbers and does not represent a temporal pattern.\nExamples include percentages, temperatures, and income.",
-                            "MAP": "Mapping Data Type ex: dict, map",
-                            "NOMINAL": "Nominal data is made of discrete values with no numerical relationship between the different categories - mean and median are meaningless.\nAnimal species is one example. For example, pig is not higher than bird and lower than fish.",
-                            "ORDINAL": "Ordinal data are discrete integers that can be ranked or sorted.\nFor example, the distance between first and second may not be the same as the distance between second and third.",
-                            "SEQUENCE": "Sequence Data Type ex: list, tuple, range",
-                            "SET": "Set Data Type ex: set, frozenset",
-                            "TEXT": "Text Data",
-                            "TIME": "Time data is a cyclical, repeating continuous form of data.\nThe relevant time features can be any period- daily, weekly, monthly, annual, etc.",
-                            "UNKNOWN": "Unknown data are data that we don't know the type for.",
-                            "USELESS": "Useless data is unique, discrete data with no potential relationship with the outcome variable.\nA useless feature has high cardinality. An example would be bank account numbers that were generated randomly.",
-                            "VIDEO": "Video Data"
-                        },
-                        "symbols": [
-                            "USELESS",
-                            "NOMINAL",
-                            "ORDINAL",
-                            "BINARY",
-                            "COUNT",
-                            "TIME",
-                            "INTERVAL",
-                            "IMAGE",
-                            "VIDEO",
-                            "AUDIO",
-                            "TEXT",
-                            "MAP",
-                            "SEQUENCE",
-                            "SET",
-                            "CONTINUOUS",
-                            "BYTE",
-                            "UNKNOWN"
-                        ],
-                        "type": "enum"
-                    }
+                    "string"
                 ]
             },
             {
+                "Searchable": {
+                    "/time": {
+                        "fieldName": "createdAt",
+                        "fieldType": "DATETIME"
+                    }
+                },
                 "default": null,
-                "doc": "Version of the MLPrimaryKey",
-                "name": "version",
+                "doc": "A timestamp documenting when the asset was created in the source Data Platform (not on DataHub)",
+                "name": "created",
                 "type": [
                     "null",
                     {
-                        "doc": "A resource-defined string representing the resource state for the purpose of concurrency control",
+                        "doc": "A standard event timestamp",
                         "fields": [
                             {
+                                "doc": "When did the event occur",
+                                "name": "time",
+                                "type": "long"
+                            },
+                            {
+                                "Urn": "Urn",
                                 "default": null,
-                                "name": "versionTag",
+                                "doc": "Optional: The actor urn involved in the event.",
+                                "java": {
+                                    "class": "com.linkedin.pegasus2avro.common.urn.Urn"
+                                },
+                                "name": "actor",
                                 "type": [
                                     "null",
                                     "string"
                                 ]
                             }
                         ],
-                        "name": "VersionTag",
+                        "name": "TimeStamp",
                         "namespace": "com.linkedin.pegasus2avro.common",
                         "type": "record"
                     }
                 ]
             },
             {
-                "Relationship": {
-                    "/*": {
-                        "entityTypes": [
-                            "dataset"
-                        ],
-                        "isLineage": true,
-                        "name": "DerivedFrom"
+                "Searchable": {
+                    "/time": {
+                        "fieldName": "lastModifiedAt",
+                        "fieldType": "DATETIME"
                     }
                 },
-                "Urn": "Urn",
-                "doc": "Source of the MLPrimaryKey",
-                "name": "sources",
-                "type": {
-                    "items": "string",
-                    "type": "array"
-                },
-                "urn_is_array": true
-            }
-        ],
-        "name": "MLPrimaryKeyProperties",
-        "namespace": "com.linkedin.pegasus2avro.ml.metadata",
-        "type": "record"
-    },
-    {
-        "Aspect": {
-            "name": "mlMetric"
-        },
-        "doc": "Properties associated with an ML Metric",
-        "fields": [
-            {
-                "doc": "Name of the mlMetric",
-                "name": "name",
-                "type": "string"
-            },
-            {
                 "default": null,
-                "doc": "Documentation of the mlMetric",
-                "name": "description",
-                "type": [
-                    "null",
-                    "string"
-                ]
-            },
-            {
-                "default": null,
-                "doc": "The value of the mlMetric",
-                "name": "value",
-                "type": [
-                    "null",
-                    "string"
-                ]
-            },
-            {
-                "default": null,
-                "doc": "Date when the mlMetric was developed",
-                "name": "createdAt",
+                "doc": "A timestamp documenting when the asset was last modified in the source Data Platform (not on DataHub)",
+                "name": "lastModified",
                 "type": [
                     "null",
-                    "long"
+                    "com.linkedin.pegasus2avro.common.TimeStamp"
                 ]
             }
         ],
-        "name": "MLMetric",
-        "namespace": "com.linkedin.pegasus2avro.ml.metadata",
+        "name": "DataFlowInfo",
+        "namespace": "com.linkedin.pegasus2avro.datajob",
         "type": "record"
     },
     {
         "Aspect": {
-            "name": "editableMlFeatureProperties"
+            "name": "editableDataFlowProperties"
         },
-        "doc": "Properties associated with a MLFeature editable from the UI",
+        "doc": "Stores editable changes made to properties. This separates changes made from\ningestion pipelines and edits in the UI to avoid accidental overwrites of user-provided data by ingestion pipelines",
         "fields": [
             {
-                "Searchable": {
-                    "fieldName": "editedDescription",
-                    "fieldType": "TEXT"
+                "default": {
+                    "actor": "urn:li:corpuser:unknown",
+                    "impersonator": null,
+                    "message": null,
+                    "time": 0
                 },
-                "default": null,
-                "doc": "Documentation of the MLFeature",
-                "name": "description",
-                "type": [
-                    "null",
-                    "string"
-                ]
-            }
-        ],
-        "name": "EditableMLFeatureProperties",
-        "namespace": "com.linkedin.pegasus2avro.ml.metadata",
-        "type": "record"
-    },
-    {
-        "Aspect": {
-            "name": "mlModelMetrics"
-        },
-        "doc": "Metrics to be featured for the MLModel.",
-        "fields": [
+                "doc": "An AuditStamp corresponding to the creation of this resource/association/sub-resource. A value of 0 for time indicates missing data.",
+                "name": "created",
+                "type": "com.linkedin.pegasus2avro.common.AuditStamp"
+            },
             {
-                "default": null,
-                "doc": "Measures of MLModel performance",
-                "name": "performanceMeasures",
-                "type": [
-                    "null",
-                    {
-                        "items": "string",
-                        "type": "array"
-                    }
-                ]
+                "default": {
+                    "actor": "urn:li:corpuser:unknown",
+                    "impersonator": null,
+                    "message": null,
+                    "time": 0
+                },
+                "doc": "An AuditStamp corresponding to the last modification of this resource/association/sub-resource. If no modification has happened since creation, lastModified should be the same as created. A value of 0 for time indicates missing data.",
+                "name": "lastModified",
+                "type": "com.linkedin.pegasus2avro.common.AuditStamp"
             },
             {
                 "default": null,
-                "doc": "Decision Thresholds used (if any)?",
-                "name": "decisionThreshold",
+                "doc": "An AuditStamp corresponding to the deletion of this resource/association/sub-resource. Logically, deleted MUST have a later timestamp than creation. It may or may not have the same time as lastModified depending upon the resource/association/sub-resource semantics.",
+                "name": "deleted",
                 "type": [
                     "null",
-                    {
-                        "items": "string",
-                        "type": "array"
-                    }
+                    "com.linkedin.pegasus2avro.common.AuditStamp"
                 ]
-            }
-        ],
-        "name": "Metrics",
-        "namespace": "com.linkedin.pegasus2avro.ml.metadata",
-        "type": "record"
-    },
-    {
-        "Aspect": {
-            "name": "editableMlFeatureTableProperties"
-        },
-        "doc": "Properties associated with a MLFeatureTable editable from the ui",
-        "fields": [
+            },
             {
                 "Searchable": {
                     "fieldName": "editedDescription",
                     "fieldType": "TEXT"
                 },
                 "default": null,
-                "doc": "Documentation of the MLFeatureTable",
+                "doc": "Edited documentation of the data flow",
                 "name": "description",
                 "type": [
                     "null",
                     "string"
                 ]
             }
         ],
-        "name": "EditableMLFeatureTableProperties",
-        "namespace": "com.linkedin.pegasus2avro.ml.metadata",
+        "name": "EditableDataFlowProperties",
+        "namespace": "com.linkedin.pegasus2avro.datajob",
         "type": "record"
     },
     {
         "Aspect": {
-            "name": "sourceCode"
+            "name": "dataJobInputOutput"
         },
-        "doc": "Source Code",
+        "doc": "Information about the inputs and outputs of a Data processing job",
         "fields": [
             {
-                "doc": "Source Code along with types",
-                "name": "sourceCode",
-                "type": {
-                    "items": {
-                        "doc": "Source Code Url Entity",
-                        "fields": [
-                            {
-                                "doc": "Source Code Url Types",
-                                "name": "type",
-                                "type": {
-                                    "name": "SourceCodeUrlType",
-                                    "namespace": "com.linkedin.pegasus2avro.ml.metadata",
-                                    "symbols": [
-                                        "ML_MODEL_SOURCE_CODE",
-                                        "TRAINING_PIPELINE_SOURCE_CODE",
-                                        "EVALUATION_PIPELINE_SOURCE_CODE"
-                                    ],
-                                    "type": "enum"
-                                }
-                            },
-                            {
-                                "doc": "Source Code Url",
-                                "java": {
-                                    "class": "com.linkedin.pegasus2avro.common.url.Url",
-                                    "coercerClass": "com.linkedin.pegasus2avro.common.url.UrlCoercer"
-                                },
-                                "name": "sourceCodeUrl",
-                                "type": "string"
-                            }
+                "Relationship": {
+                    "/*": {
+                        "entityTypes": [
+                            "dataset"
                         ],
-                        "name": "SourceCodeUrl",
-                        "namespace": "com.linkedin.pegasus2avro.ml.metadata",
-                        "type": "record"
-                    },
-                    "type": "array"
-                }
-            }
-        ],
-        "name": "SourceCode",
-        "namespace": "com.linkedin.pegasus2avro.ml.metadata",
-        "type": "record"
-    },
-    {
-        "Aspect": {
-            "name": "intendedUse"
-        },
-        "doc": "Intended Use for the ML Model",
-        "fields": [
-            {
-                "default": null,
-                "doc": "Primary Use cases for the MLModel.",
-                "name": "primaryUses",
-                "type": [
-                    "null",
-                    {
-                        "items": "string",
-                        "type": "array"
-                    }
-                ]
-            },
-            {
-                "default": null,
-                "doc": "Primary Intended Users - For example, was the MLModel developed for entertainment purposes, for hobbyists, or enterprise solutions?",
-                "name": "primaryUsers",
-                "type": [
-                    "null",
-                    {
-                        "items": {
-                            "name": "IntendedUserType",
-                            "namespace": "com.linkedin.pegasus2avro.ml.metadata",
-                            "symbols": [
-                                "ENTERPRISE",
-                                "HOBBY",
-                                "ENTERTAINMENT"
-                            ],
-                            "type": "enum"
-                        },
-                        "type": "array"
-                    }
-                ]
-            },
-            {
-                "default": null,
-                "doc": "Highlight technology that the MLModel might easily be confused with, or related contexts that users could try to apply the MLModel to.",
-                "name": "outOfScopeUses",
-                "type": [
-                    "null",
-                    {
-                        "items": "string",
-                        "type": "array"
+                        "isLineage": true,
+                        "name": "Consumes"
                     }
-                ]
-            }
-        ],
-        "name": "IntendedUse",
-        "namespace": "com.linkedin.pegasus2avro.ml.metadata",
-        "type": "record"
-    },
-    {
-        "Aspect": {
-            "name": "editableMlPrimaryKeyProperties"
-        },
-        "doc": "Properties associated with a MLPrimaryKey editable from the UI",
-        "fields": [
-            {
-                "default": null,
-                "doc": "Documentation of the MLPrimaryKey",
-                "name": "description",
-                "type": [
-                    "null",
-                    "string"
-                ]
-            }
-        ],
-        "name": "EditableMLPrimaryKeyProperties",
-        "namespace": "com.linkedin.pegasus2avro.ml.metadata",
-        "type": "record"
-    },
-    {
-        "Aspect": {
-            "name": "mlModelProperties"
-        },
-        "doc": "Properties associated with a ML Model",
-        "fields": [
-            {
+                },
                 "Searchable": {
                     "/*": {
-                        "queryByDefault": true
+                        "fieldName": "inputs",
+                        "fieldType": "URN",
+                        "numValuesFieldName": "numInputDatasets",
+                        "queryByDefault": false
                     }
                 },
-                "default": {},
-                "doc": "Custom property bag.",
-                "name": "customProperties",
+                "Urn": "DatasetUrn",
+                "deprecated": true,
+                "doc": "Input datasets consumed by the data job during processing\nDeprecated! Use inputDatasetEdges instead.",
+                "name": "inputDatasets",
                 "type": {
-                    "type": "map",
-                    "values": "string"
-                }
-            },
-            {
-                "default": null,
-                "doc": "URL where the reference exist",
-                "java": {
-                    "class": "com.linkedin.pegasus2avro.common.url.Url",
-                    "coercerClass": "com.linkedin.pegasus2avro.common.url.UrlCoercer"
+                    "items": "string",
+                    "type": "array"
                 },
-                "name": "externalUrl",
-                "type": [
-                    "null",
-                    "string"
-                ]
+                "urn_is_array": true
             },
             {
-                "Searchable": {
-                    "fieldType": "TEXT",
-                    "hasValuesFieldName": "hasDescription"
+                "Relationship": {
+                    "/*/destinationUrn": {
+                        "createdActor": "inputDatasetEdges/*/created/actor",
+                        "createdOn": "inputDatasetEdges/*/created/time",
+                        "entityTypes": [
+                            "dataset"
+                        ],
+                        "isLineage": true,
+                        "name": "Consumes",
+                        "properties": "inputDatasetEdges/*/properties",
+                        "updatedActor": "inputDatasetEdges/*/lastModified/actor",
+                        "updatedOn": "inputDatasetEdges/*/lastModified/time"
+                    }
                 },
-                "default": null,
-                "doc": "Documentation of the MLModel",
-                "name": "description",
-                "type": [
-                    "null",
-                    "string"
-                ]
-            },
-            {
-                "default": null,
-                "doc": "Date when the MLModel was developed",
-                "name": "date",
-                "type": [
-                    "null",
-                    "long"
-                ]
-            },
-            {
-                "default": null,
-                "doc": "Version of the MLModel",
-                "name": "version",
-                "type": [
-                    "null",
-                    "com.linkedin.pegasus2avro.common.VersionTag"
-                ]
-            },
-            {
                 "Searchable": {
-                    "fieldType": "TEXT_PARTIAL"
-                },
-                "default": null,
-                "doc": "Type of Algorithm or MLModel such as whether it is a Naive Bayes classifier, Convolutional Neural Network, etc",
-                "name": "type",
-                "type": [
-                    "null",
-                    "string"
-                ]
-            },
-            {
-                "default": null,
-                "doc": "Hyper Parameters of the MLModel\n\nNOTE: these are deprecated in favor of hyperParams",
-                "name": "hyperParameters",
-                "type": [
-                    "null",
-                    {
-                        "type": "map",
-                        "values": [
-                            "string",
-                            "int",
-                            "float",
-                            "double",
-                            "boolean"
-                        ]
+                    "/*/destinationUrn": {
+                        "fieldName": "inputDatasetEdges",
+                        "fieldType": "URN",
+                        "numValuesFieldName": "numInputDatasets",
+                        "queryByDefault": false
                     }
-                ]
-            },
-            {
+                },
                 "default": null,
-                "doc": "Hyperparameters of the MLModel",
-                "name": "hyperParams",
+                "doc": "Input datasets consumed by the data job during processing",
+                "name": "inputDatasetEdges",
                 "type": [
                     "null",
                     {
-                        "items": "com.linkedin.pegasus2avro.ml.metadata.MLHyperParam",
+                        "items": {
+                            "doc": "Information about a relatonship edge.",
+                            "fields": [
+                                {
+                                    "Urn": "Urn",
+                                    "doc": "Urn of the source of this relationship edge.",
+                                    "java": {
+                                        "class": "com.linkedin.pegasus2avro.common.urn.Urn"
+                                    },
+                                    "name": "sourceUrn",
+                                    "type": "string"
+                                },
+                                {
+                                    "Urn": "Urn",
+                                    "doc": "Urn of the destination of this relationship edge.",
+                                    "java": {
+                                        "class": "com.linkedin.pegasus2avro.common.urn.Urn"
+                                    },
+                                    "name": "destinationUrn",
+                                    "type": "string"
+                                },
+                                {
+                                    "doc": "Audit stamp containing who created this relationship edge and when",
+                                    "name": "created",
+                                    "type": "com.linkedin.pegasus2avro.common.AuditStamp"
+                                },
+                                {
+                                    "doc": "Audit stamp containing who last modified this relationship edge and when",
+                                    "name": "lastModified",
+                                    "type": "com.linkedin.pegasus2avro.common.AuditStamp"
+                                },
+                                {
+                                    "default": null,
+                                    "doc": "A generic properties bag that allows us to store specific information on this graph edge.",
+                                    "name": "properties",
+                                    "type": [
+                                        "null",
+                                        {
+                                            "type": "map",
+                                            "values": "string"
+                                        }
+                                    ]
+                                }
+                            ],
+                            "name": "Edge",
+                            "namespace": "com.linkedin.pegasus2avro.common",
+                            "type": "record"
+                        },
                         "type": "array"
                     }
                 ]
             },
             {
-                "default": null,
-                "doc": "Metrics of the MLModel used in training",
-                "name": "trainingMetrics",
-                "type": [
-                    "null",
-                    {
-                        "items": "com.linkedin.pegasus2avro.ml.metadata.MLMetric",
-                        "type": "array"
+                "Relationship": {
+                    "/*": {
+                        "entityTypes": [
+                            "dataset"
+                        ],
+                        "isLineage": true,
+                        "isUpstream": false,
+                        "name": "Produces"
                     }
-                ]
-            },
-            {
-                "default": null,
-                "doc": "Metrics of the MLModel used in production",
-                "name": "onlineMetrics",
-                "type": [
-                    "null",
-                    {
-                        "items": "com.linkedin.pegasus2avro.ml.metadata.MLMetric",
-                        "type": "array"
+                },
+                "Searchable": {
+                    "/*": {
+                        "fieldName": "outputs",
+                        "fieldType": "URN",
+                        "numValuesFieldName": "numOutputDatasets",
+                        "queryByDefault": false
                     }
-                ]
+                },
+                "Urn": "DatasetUrn",
+                "deprecated": true,
+                "doc": "Output datasets produced by the data job during processing\nDeprecated! Use outputDatasetEdges instead.",
+                "name": "outputDatasets",
+                "type": {
+                    "items": "string",
+                    "type": "array"
+                },
+                "urn_is_array": true
             },
             {
                 "Relationship": {
-                    "/*": {
+                    "/*/destinationUrn": {
+                        "createdActor": "outputDatasetEdges/*/created/actor",
+                        "createdOn": "outputDatasetEdges/*/created/time",
                         "entityTypes": [
-                            "mlFeature"
+                            "dataset"
                         ],
                         "isLineage": true,
-                        "name": "Consumes"
+                        "isUpstream": false,
+                        "name": "Produces",
+                        "properties": "outputDatasetEdges/*/properties",
+                        "updatedActor": "outputDatasetEdges/*/lastModified/actor",
+                        "updatedOn": "outputDatasetEdges/*/lastModified/time"
+                    }
+                },
+                "Searchable": {
+                    "/*/destinationUrn": {
+                        "fieldName": "outputDatasetEdges",
+                        "fieldType": "URN",
+                        "numValuesFieldName": "numOutputDatasets",
+                        "queryByDefault": false
                     }
                 },
-                "Urn": "MLFeatureUrn",
                 "default": null,
-                "doc": "List of features used for MLModel training",
-                "name": "mlFeatures",
+                "doc": "Output datasets produced by the data job during processing",
+                "name": "outputDatasetEdges",
                 "type": [
                     "null",
                     {
-                        "items": "string",
+                        "items": "com.linkedin.pegasus2avro.common.Edge",
                         "type": "array"
                     }
-                ],
-                "urn_is_array": true
-            },
-            {
-                "default": [],
-                "doc": "Tags for the MLModel",
-                "name": "tags",
-                "type": {
-                    "items": "string",
-                    "type": "array"
-                }
+                ]
             },
             {
                 "Relationship": {
                     "/*": {
                         "entityTypes": [
-                            "mlModelDeployment"
+                            "dataJob"
                         ],
-                        "name": "DeployedTo"
+                        "isLineage": true,
+                        "name": "DownstreamOf"
                     }
                 },
-                "Urn": "Urn",
+                "Urn": "DataJobUrn",
                 "default": null,
-                "doc": "Deployments for the MLModel",
-                "name": "deployments",
+                "deprecated": true,
+                "doc": "Input datajobs that this data job depends on\nDeprecated! Use inputDatajobEdges instead.",
+                "name": "inputDatajobs",
                 "type": [
                     "null",
                     {
                         "items": "string",
                         "type": "array"
                     }
                 ],
                 "urn_is_array": true
             },
             {
                 "Relationship": {
-                    "/*": {
+                    "/*/destinationUrn": {
+                        "createdActor": "inputDatajobEdges/*/created/actor",
+                        "createdOn": "inputDatajobEdges/*/created/time",
                         "entityTypes": [
                             "dataJob"
                         ],
                         "isLineage": true,
-                        "name": "TrainedBy"
+                        "name": "DownstreamOf",
+                        "properties": "inputDatajobEdges/*/properties",
+                        "updatedActor": "inputDatajobEdges/*/lastModified/actor",
+                        "updatedOn": "inputDatajobEdges/*/lastModified/time"
                     }
                 },
-                "Urn": "Urn",
                 "default": null,
-                "doc": "List of jobs (if any) used to train the model",
-                "name": "trainingJobs",
+                "doc": "Input datajobs that this data job depends on",
+                "name": "inputDatajobEdges",
                 "type": [
                     "null",
                     {
-                        "items": "string",
+                        "items": "com.linkedin.pegasus2avro.common.Edge",
                         "type": "array"
                     }
-                ],
-                "urn_is_array": true
+                ]
             },
             {
                 "Relationship": {
                     "/*": {
                         "entityTypes": [
-                            "dataJob"
+                            "schemaField"
                         ],
-                        "isLineage": true,
-                        "isUpstream": false,
-                        "name": "UsedBy"
+                        "name": "Consumes"
+                    }
+                },
+                "Searchable": {
+                    "/*": {
+                        "fieldName": "inputFields",
+                        "fieldType": "URN",
+                        "numValuesFieldName": "numInputFields",
+                        "queryByDefault": false
                     }
                 },
                 "Urn": "Urn",
                 "default": null,
-                "doc": "List of jobs (if any) that use the model",
-                "name": "downstreamJobs",
+                "doc": "Fields of the input datasets used by this job",
+                "name": "inputDatasetFields",
                 "type": [
                     "null",
                     {
                         "items": "string",
                         "type": "array"
                     }
                 ],
                 "urn_is_array": true
             },
             {
                 "Relationship": {
                     "/*": {
                         "entityTypes": [
-                            "mlModelGroup"
+                            "schemaField"
                         ],
-                        "isLineage": true,
-                        "isUpstream": false,
-                        "name": "MemberOf"
+                        "name": "Produces"
+                    }
+                },
+                "Searchable": {
+                    "/*": {
+                        "fieldName": "outputFields",
+                        "fieldType": "URN",
+                        "numValuesFieldName": "numOutputFields",
+                        "queryByDefault": false
                     }
                 },
                 "Urn": "Urn",
                 "default": null,
-                "doc": "Groups the model belongs to",
-                "name": "groups",
+                "doc": "Fields of the output datasets this job writes to",
+                "name": "outputDatasetFields",
                 "type": [
                     "null",
                     {
                         "items": "string",
                         "type": "array"
                     }
                 ],
                 "urn_is_array": true
-            }
-        ],
-        "name": "MLModelProperties",
-        "namespace": "com.linkedin.pegasus2avro.ml.metadata",
-        "type": "record"
-    },
-    {
-        "Aspect": {
-            "name": "mlModelTrainingData"
-        },
-        "doc": "Ideally, the MLModel card would contain as much information about the training data as the evaluation data. However, there might be cases where it is not feasible to provide this level of detailed information about the training data. For example, the data may be proprietary, or require a non-disclosure agreement. In these cases, we advocate for basic details about the distributions over groups in the data, as well as any other details that could inform stakeholders on the kinds of biases the model may have encoded.",
-        "fields": [
-            {
-                "doc": "Details on the dataset(s) used for training the MLModel",
-                "name": "trainingData",
-                "type": {
-                    "items": "com.linkedin.pegasus2avro.ml.metadata.BaseData",
-                    "type": "array"
-                }
-            }
-        ],
-        "name": "TrainingData",
-        "namespace": "com.linkedin.pegasus2avro.ml.metadata",
-        "type": "record"
-    },
-    {
-        "Aspect": {
-            "name": "mlModelQuantitativeAnalyses"
-        },
-        "doc": "Quantitative analyses should be disaggregated, that is, broken down by the chosen factors. Quantitative analyses should provide the results of evaluating the MLModel according to the chosen metrics, providing confidence interval values when possible.",
-        "fields": [
-            {
-                "default": null,
-                "doc": "Link to a dashboard with results showing how the MLModel performed with respect to each factor",
-                "name": "unitaryResults",
-                "type": [
-                    "null",
-                    "string"
-                ]
             },
             {
                 "default": null,
-                "doc": "Link to a dashboard with results showing how the MLModel performed with respect to the intersection of evaluated factors?",
-                "name": "intersectionalResults",
+                "doc": "Fine-grained column-level lineages",
+                "name": "fineGrainedLineages",
                 "type": [
                     "null",
-                    "string"
+                    {
+                        "items": {
+                            "doc": "A fine-grained lineage from upstream fields/datasets to downstream field(s)",
+                            "fields": [
+                                {
+                                    "doc": "The type of upstream entity",
+                                    "name": "upstreamType",
+                                    "type": {
+                                        "doc": "The type of upstream entity in a fine-grained lineage",
+                                        "name": "FineGrainedLineageUpstreamType",
+                                        "namespace": "com.linkedin.pegasus2avro.dataset",
+                                        "symbolDocs": {
+                                            "DATASET": " Indicates that this lineage is originating from upstream dataset(s)",
+                                            "FIELD_SET": " Indicates that this lineage is originating from upstream field(s)",
+                                            "NONE": " Indicates that there is no upstream lineage i.e. the downstream field is not a derived field"
+                                        },
+                                        "symbols": [
+                                            "FIELD_SET",
+                                            "DATASET",
+                                            "NONE"
+                                        ],
+                                        "type": "enum"
+                                    }
+                                },
+                                {
+                                    "Urn": "Urn",
+                                    "default": null,
+                                    "doc": "Upstream entities in the lineage",
+                                    "name": "upstreams",
+                                    "type": [
+                                        "null",
+                                        {
+                                            "items": "string",
+                                            "type": "array"
+                                        }
+                                    ],
+                                    "urn_is_array": true
+                                },
+                                {
+                                    "doc": "The type of downstream field(s)",
+                                    "name": "downstreamType",
+                                    "type": {
+                                        "doc": "The type of downstream field(s) in a fine-grained lineage",
+                                        "name": "FineGrainedLineageDownstreamType",
+                                        "namespace": "com.linkedin.pegasus2avro.dataset",
+                                        "symbolDocs": {
+                                            "FIELD": " Indicates that the lineage is for a single, specific, downstream field",
+                                            "FIELD_SET": " Indicates that the lineage is for a set of downstream fields"
+                                        },
+                                        "symbols": [
+                                            "FIELD",
+                                            "FIELD_SET"
+                                        ],
+                                        "type": "enum"
+                                    }
+                                },
+                                {
+                                    "Urn": "Urn",
+                                    "default": null,
+                                    "doc": "Downstream fields in the lineage",
+                                    "name": "downstreams",
+                                    "type": [
+                                        "null",
+                                        {
+                                            "items": "string",
+                                            "type": "array"
+                                        }
+                                    ],
+                                    "urn_is_array": true
+                                },
+                                {
+                                    "default": null,
+                                    "doc": "The transform operation applied to the upstream entities to produce the downstream field(s)",
+                                    "name": "transformOperation",
+                                    "type": [
+                                        "null",
+                                        "string"
+                                    ]
+                                },
+                                {
+                                    "default": 1.0,
+                                    "doc": "The confidence in this lineage between 0 (low confidence) and 1 (high confidence)",
+                                    "name": "confidenceScore",
+                                    "type": "float"
+                                }
+                            ],
+                            "name": "FineGrainedLineage",
+                            "namespace": "com.linkedin.pegasus2avro.dataset",
+                            "type": "record"
+                        },
+                        "type": "array"
+                    }
                 ]
             }
         ],
-        "name": "QuantitativeAnalyses",
-        "namespace": "com.linkedin.pegasus2avro.ml.metadata",
+        "name": "DataJobInputOutput",
+        "namespace": "com.linkedin.pegasus2avro.datajob",
         "type": "record"
     },
     {
         "Aspect": {
-            "name": "mlModelDeploymentProperties"
+            "name": "dataJobInfo"
         },
-        "doc": "Properties associated with an ML Model Deployment",
+        "doc": "Information about a Data processing job",
         "fields": [
             {
                 "Searchable": {
                     "/*": {
                         "queryByDefault": true
                     }
                 },
@@ -918,1848 +707,2164 @@
                 "type": [
                     "null",
                     "string"
                 ]
             },
             {
                 "Searchable": {
+                    "boostScore": 10.0,
+                    "enableAutocomplete": true,
+                    "fieldType": "TEXT_PARTIAL"
+                },
+                "doc": "Job name",
+                "name": "name",
+                "type": "string"
+            },
+            {
+                "Searchable": {
                     "fieldType": "TEXT",
                     "hasValuesFieldName": "hasDescription"
                 },
                 "default": null,
-                "doc": "Documentation of the MLModelDeployment",
+                "doc": "Job description",
                 "name": "description",
                 "type": [
                     "null",
                     "string"
                 ]
             },
             {
+                "doc": "Datajob type\n*NOTE**: AzkabanJobType is deprecated. Please use strings instead.",
+                "name": "type",
+                "type": [
+                    {
+                        "doc": "The various types of support azkaban jobs",
+                        "name": "AzkabanJobType",
+                        "namespace": "com.linkedin.pegasus2avro.datajob.azkaban",
+                        "symbolDocs": {
+                            "COMMAND": "The command job type is one of the basic built-in types. It runs multiple UNIX commands using java processbuilder.\nUpon execution, Azkaban spawns off a process to run the command.",
+                            "GLUE": "Glue type is for running AWS Glue job transforms.",
+                            "HADOOP_JAVA": "Runs a java program with ability to access Hadoop cluster.\nhttps://azkaban.readthedocs.io/en/latest/jobTypes.html#java-job-type",
+                            "HADOOP_SHELL": "In large part, this is the same Command type. The difference is its ability to talk to a Hadoop cluster\nsecurely, via Hadoop tokens.",
+                            "HIVE": "Hive type is for running Hive jobs.",
+                            "PIG": "Pig type is for running Pig jobs.",
+                            "SQL": "SQL is for running Presto, mysql queries etc"
+                        },
+                        "symbols": [
+                            "COMMAND",
+                            "HADOOP_JAVA",
+                            "HADOOP_SHELL",
+                            "HIVE",
+                            "PIG",
+                            "SQL",
+                            "GLUE"
+                        ],
+                        "type": "enum"
+                    },
+                    "string"
+                ]
+            },
+            {
+                "Urn": "DataFlowUrn",
                 "default": null,
-                "doc": "Date when the MLModelDeployment was developed",
-                "name": "createdAt",
+                "doc": "DataFlow urn that this job is part of",
+                "java": {
+                    "class": "com.linkedin.pegasus2avro.common.urn.DataFlowUrn"
+                },
+                "name": "flowUrn",
                 "type": [
                     "null",
-                    "long"
+                    "string"
                 ]
             },
             {
+                "Searchable": {
+                    "/time": {
+                        "fieldName": "createdAt",
+                        "fieldType": "DATETIME"
+                    }
+                },
                 "default": null,
-                "doc": "Version of the MLModelDeployment",
-                "name": "version",
+                "doc": "A timestamp documenting when the asset was created in the source Data Platform (not on DataHub)",
+                "name": "created",
                 "type": [
                     "null",
-                    "com.linkedin.pegasus2avro.common.VersionTag"
+                    "com.linkedin.pegasus2avro.common.TimeStamp"
                 ]
             },
             {
+                "Searchable": {
+                    "/time": {
+                        "fieldName": "lastModifiedAt",
+                        "fieldType": "DATETIME"
+                    }
+                },
                 "default": null,
-                "doc": "Status of the deployment",
+                "doc": "A timestamp documenting when the asset was last modified in the source Data Platform (not on DataHub)",
+                "name": "lastModified",
+                "type": [
+                    "null",
+                    "com.linkedin.pegasus2avro.common.TimeStamp"
+                ]
+            },
+            {
+                "default": null,
+                "deprecated": "Use Data Process Instance model, instead",
+                "doc": "Status of the job - Deprecated for Data Process Instance model.",
                 "name": "status",
                 "type": [
                     "null",
                     {
-                        "doc": "Model endpoint statuses",
-                        "name": "DeploymentStatus",
-                        "namespace": "com.linkedin.pegasus2avro.ml.metadata",
+                        "doc": "Job statuses",
+                        "name": "JobStatus",
+                        "namespace": "com.linkedin.pegasus2avro.datajob",
                         "symbolDocs": {
-                            "CREATING": "Deployments being created.",
-                            "DELETING": "Deployments being deleted.",
-                            "FAILED": "Deployments with an error state.",
-                            "IN_SERVICE": "Deployments that are active.",
-                            "OUT_OF_SERVICE": "Deployments out of service.",
-                            "ROLLING_BACK": "Deployments being reverted to a previous version.",
-                            "UNKNOWN": "Deployments with unknown/unmappable state.",
-                            "UPDATING": "Deployments being updated."
+                            "COMPLETED": "Jobs with successful completion.",
+                            "FAILED": "Jobs that have failed.",
+                            "IN_PROGRESS": "Jobs currently running.",
+                            "SKIPPED": "Jobs that have been skipped.",
+                            "STARTING": "Jobs being initialized.",
+                            "STOPPED": "Jobs that have stopped.",
+                            "STOPPING": "Jobs being stopped.",
+                            "UNKNOWN": "Jobs with unknown status (either unmappable or unavailable)"
                         },
                         "symbols": [
-                            "OUT_OF_SERVICE",
-                            "CREATING",
-                            "UPDATING",
-                            "ROLLING_BACK",
-                            "IN_SERVICE",
-                            "DELETING",
+                            "STARTING",
+                            "IN_PROGRESS",
+                            "STOPPING",
+                            "STOPPED",
+                            "COMPLETED",
                             "FAILED",
-                            "UNKNOWN"
+                            "UNKNOWN",
+                            "SKIPPED"
                         ],
                         "type": "enum"
                     }
                 ]
             }
         ],
-        "name": "MLModelDeploymentProperties",
-        "namespace": "com.linkedin.pegasus2avro.ml.metadata",
+        "name": "DataJobInfo",
+        "namespace": "com.linkedin.pegasus2avro.datajob",
         "type": "record"
     },
     {
         "Aspect": {
-            "name": "mlModelEthicalConsiderations"
+            "name": "versionInfo"
         },
-        "doc": "This section is intended to demonstrate the ethical considerations that went into MLModel development, surfacing ethical challenges and solutions to stakeholders.",
+        "doc": "Information about a Data processing job",
         "fields": [
             {
+                "Searchable": {
+                    "/*": {
+                        "queryByDefault": true
+                    }
+                },
+                "default": {},
+                "doc": "Custom property bag.",
+                "name": "customProperties",
+                "type": {
+                    "type": "map",
+                    "values": "string"
+                }
+            },
+            {
                 "default": null,
-                "doc": "Does the MLModel use any sensitive data (e.g., protected classes)?",
-                "name": "data",
+                "doc": "URL where the reference exist",
+                "java": {
+                    "class": "com.linkedin.pegasus2avro.common.url.Url",
+                    "coercerClass": "com.linkedin.pegasus2avro.common.url.UrlCoercer"
+                },
+                "name": "externalUrl",
                 "type": [
                     "null",
-                    {
-                        "items": "string",
-                        "type": "array"
-                    }
+                    "string"
                 ]
             },
             {
+                "doc": "The version which can indentify a job version like a commit hash or md5 hash",
+                "name": "version",
+                "type": "string"
+            },
+            {
+                "doc": "The type of the version like git hash or md5 hash",
+                "name": "versionType",
+                "type": "string"
+            }
+        ],
+        "name": "VersionInfo",
+        "namespace": "com.linkedin.pegasus2avro.datajob",
+        "type": "record"
+    },
+    {
+        "Aspect": {
+            "name": "datahubIngestionRunSummary",
+            "type": "timeseries"
+        },
+        "doc": "Summary of a datahub ingestion run for a given platform.",
+        "fields": [
+            {
+                "doc": "The event timestamp field as epoch at UTC in milli seconds.",
+                "name": "timestampMillis",
+                "type": "long"
+            },
+            {
                 "default": null,
-                "doc": " Is the MLModel intended to inform decisions about matters central to human life or flourishing - e.g., health or safety? Or could it be used in such a way?",
-                "name": "humanLife",
+                "doc": "Granularity of the event if applicable",
+                "name": "eventGranularity",
                 "type": [
                     "null",
                     {
-                        "items": "string",
-                        "type": "array"
+                        "doc": "Defines the size of a time window.",
+                        "fields": [
+                            {
+                                "doc": "Interval unit such as minute/hour/day etc.",
+                                "name": "unit",
+                                "type": {
+                                    "name": "CalendarInterval",
+                                    "namespace": "com.linkedin.pegasus2avro.timeseries",
+                                    "symbols": [
+                                        "SECOND",
+                                        "MINUTE",
+                                        "HOUR",
+                                        "DAY",
+                                        "WEEK",
+                                        "MONTH",
+                                        "QUARTER",
+                                        "YEAR"
+                                    ],
+                                    "type": "enum"
+                                }
+                            },
+                            {
+                                "default": 1,
+                                "doc": "How many units. Defaults to 1.",
+                                "name": "multiple",
+                                "type": "int"
+                            }
+                        ],
+                        "name": "TimeWindowSize",
+                        "namespace": "com.linkedin.pegasus2avro.timeseries",
+                        "type": "record"
                     }
                 ]
             },
             {
+                "default": {
+                    "partition": "FULL_TABLE_SNAPSHOT",
+                    "timePartition": null,
+                    "type": "FULL_TABLE"
+                },
+                "doc": "The optional partition specification.",
+                "name": "partitionSpec",
+                "type": [
+                    {
+                        "doc": "Defines how the data is partitioned",
+                        "fields": [
+                            {
+                                "default": "PARTITION",
+                                "name": "type",
+                                "type": {
+                                    "name": "PartitionType",
+                                    "namespace": "com.linkedin.pegasus2avro.timeseries",
+                                    "symbols": [
+                                        "FULL_TABLE",
+                                        "QUERY",
+                                        "PARTITION"
+                                    ],
+                                    "type": "enum"
+                                }
+                            },
+                            {
+                                "TimeseriesField": {},
+                                "doc": "String representation of the partition",
+                                "name": "partition",
+                                "type": "string"
+                            },
+                            {
+                                "default": null,
+                                "doc": "Time window of the partition if applicable",
+                                "name": "timePartition",
+                                "type": [
+                                    "null",
+                                    {
+                                        "fields": [
+                                            {
+                                                "doc": "Start time as epoch at UTC.",
+                                                "name": "startTimeMillis",
+                                                "type": "long"
+                                            },
+                                            {
+                                                "doc": "The length of the window.",
+                                                "name": "length",
+                                                "type": "com.linkedin.pegasus2avro.timeseries.TimeWindowSize"
+                                            }
+                                        ],
+                                        "name": "TimeWindow",
+                                        "namespace": "com.linkedin.pegasus2avro.timeseries",
+                                        "type": "record"
+                                    }
+                                ]
+                            }
+                        ],
+                        "name": "PartitionSpec",
+                        "namespace": "com.linkedin.pegasus2avro.timeseries",
+                        "type": "record"
+                    },
+                    "null"
+                ]
+            },
+            {
                 "default": null,
-                "doc": "What risk mitigation strategies were used during MLModel development?",
-                "name": "mitigations",
+                "doc": "The optional messageId, if provided serves as a custom user-defined unique identifier for an aspect value.",
+                "name": "messageId",
                 "type": [
                     "null",
-                    {
-                        "items": "string",
-                        "type": "array"
-                    }
+                    "string"
                 ]
             },
             {
+                "TimeseriesField": {},
+                "doc": "The name of the pipeline that ran ingestion, a stable unique user provided identifier.\n e.g. my_snowflake1-to-datahub.",
+                "name": "pipelineName",
+                "type": "string"
+            },
+            {
+                "TimeseriesField": {},
+                "doc": "The id of the instance against which the ingestion pipeline ran.\ne.g.: Bigquery project ids, MySQL hostnames etc.",
+                "name": "platformInstanceId",
+                "type": "string"
+            },
+            {
+                "TimeseriesField": {},
+                "doc": "The runId for this pipeline instance.",
+                "name": "runId",
+                "type": "string"
+            },
+            {
+                "TimeseriesField": {},
+                "doc": "Run Status - Succeeded/Skipped/Failed etc.",
+                "name": "runStatus",
+                "type": "com.linkedin.pegasus2avro.datajob.JobStatus"
+            },
+            {
                 "default": null,
-                "doc": "What risks may be present in MLModel usage? Try to identify the potential recipients, likelihood, and magnitude of harms. If these cannot be determined, note that they were considered but remain unknown.",
-                "name": "risksAndHarms",
+                "doc": "The number of workunits written to sink.",
+                "name": "numWorkUnitsCommitted",
                 "type": [
                     "null",
-                    {
-                        "items": "string",
-                        "type": "array"
-                    }
+                    "long"
                 ]
             },
             {
                 "default": null,
-                "doc": "Are there any known MLModel use cases that are especially fraught? This may connect directly to the intended use section",
-                "name": "useCases",
+                "doc": "The number of workunits that are produced.",
+                "name": "numWorkUnitsCreated",
                 "type": [
                     "null",
-                    {
-                        "items": "string",
-                        "type": "array"
-                    }
+                    "long"
                 ]
-            }
-        ],
-        "name": "EthicalConsiderations",
-        "namespace": "com.linkedin.pegasus2avro.ml.metadata",
-        "type": "record"
-    },
-    {
-        "Aspect": {
-            "name": "mlModelFactorPrompts"
-        },
-        "doc": "Prompts which affect the performance of the MLModel",
-        "fields": [
+            },
             {
                 "default": null,
-                "doc": "What are foreseeable salient factors for which MLModel performance may vary, and how were these determined?",
-                "name": "relevantFactors",
+                "doc": "The number of events produced (MCE + MCP).",
+                "name": "numEvents",
                 "type": [
                     "null",
-                    {
-                        "items": {
-                            "doc": "Factors affecting the performance of the MLModel.",
-                            "fields": [
-                                {
-                                    "default": null,
-                                    "doc": "Groups refers to distinct categories with similar characteristics that are present in the evaluation data instances.\nFor human-centric machine learning MLModels, groups are people who share one or multiple characteristics.",
-                                    "name": "groups",
-                                    "type": [
-                                        "null",
-                                        {
-                                            "items": "string",
-                                            "type": "array"
-                                        }
-                                    ]
-                                },
-                                {
-                                    "default": null,
-                                    "doc": "The performance of a MLModel can vary depending on what instruments were used to capture the input to the MLModel.\nFor example, a face detection model may perform differently depending on the camera's hardware and software,\nincluding lens, image stabilization, high dynamic range techniques, and background blurring for portrait mode.",
-                                    "name": "instrumentation",
-                                    "type": [
-                                        "null",
-                                        {
-                                            "items": "string",
-                                            "type": "array"
-                                        }
-                                    ]
-                                },
-                                {
-                                    "default": null,
-                                    "doc": "A further factor affecting MLModel performance is the environment in which it is deployed.",
-                                    "name": "environment",
-                                    "type": [
-                                        "null",
-                                        {
-                                            "items": "string",
-                                            "type": "array"
-                                        }
-                                    ]
-                                }
-                            ],
-                            "name": "MLModelFactors",
-                            "namespace": "com.linkedin.pegasus2avro.ml.metadata",
-                            "type": "record"
-                        },
-                        "type": "array"
-                    }
+                    "long"
                 ]
             },
             {
                 "default": null,
-                "doc": "Which factors are being reported, and why were these chosen?",
-                "name": "evaluationFactors",
+                "doc": "The total number of entities produced (unique entity urns).",
+                "name": "numEntities",
                 "type": [
                     "null",
-                    {
-                        "items": "com.linkedin.pegasus2avro.ml.metadata.MLModelFactors",
-                        "type": "array"
-                    }
+                    "long"
                 ]
-            }
-        ],
-        "name": "MLModelFactorPrompts",
-        "namespace": "com.linkedin.pegasus2avro.ml.metadata",
-        "type": "record"
-    },
-    {
-        "Aspect": {
-            "name": "mlModelGroupProperties"
-        },
-        "doc": "Properties associated with an ML Model Group",
-        "fields": [
+            },
             {
-                "Searchable": {
-                    "/*": {
-                        "queryByDefault": true
-                    }
-                },
-                "default": {},
-                "doc": "Custom property bag.",
-                "name": "customProperties",
-                "type": {
-                    "type": "map",
-                    "values": "string"
-                }
+                "default": null,
+                "doc": "The total number of aspects produced across all entities.",
+                "name": "numAspects",
+                "type": [
+                    "null",
+                    "long"
+                ]
             },
             {
-                "Searchable": {
-                    "fieldType": "TEXT",
-                    "hasValuesFieldName": "hasDescription"
-                },
                 "default": null,
-                "doc": "Documentation of the MLModelGroup",
-                "name": "description",
+                "doc": "Total number of source API calls.",
+                "name": "numSourceAPICalls",
                 "type": [
                     "null",
-                    "string"
+                    "long"
                 ]
             },
             {
                 "default": null,
-                "doc": "Date when the MLModelGroup was developed",
-                "name": "createdAt",
+                "doc": "Total latency across all source API calls.",
+                "name": "totalLatencySourceAPICalls",
                 "type": [
                     "null",
                     "long"
                 ]
             },
             {
                 "default": null,
-                "doc": "Version of the MLModelGroup",
-                "name": "version",
+                "doc": "Total number of sink API calls.",
+                "name": "numSinkAPICalls",
                 "type": [
                     "null",
-                    "com.linkedin.pegasus2avro.common.VersionTag"
+                    "long"
                 ]
-            }
-        ],
-        "name": "MLModelGroupProperties",
-        "namespace": "com.linkedin.pegasus2avro.ml.metadata",
-        "type": "record"
-    },
-    {
-        "Aspect": {
-            "name": "mlModelCaveatsAndRecommendations"
-        },
-        "doc": "This section should list additional concerns that were not covered in the previous sections. For example, did the results suggest any further testing? Were there any relevant groups that were not represented in the evaluation dataset? Are there additional recommendations for model use?",
-        "fields": [
+            },
             {
                 "default": null,
-                "doc": "This section should list additional concerns that were not covered in the previous sections. For example, did the results suggest any further testing? Were there any relevant groups that were not represented in the evaluation dataset?",
-                "name": "caveats",
+                "doc": "Total latency across all sink API calls.",
+                "name": "totalLatencySinkAPICalls",
                 "type": [
                     "null",
-                    {
-                        "doc": "This section should list additional concerns that were not covered in the previous sections. For example, did the results suggest any further testing? Were there any relevant groups that were not represented in the evaluation dataset? Are there additional recommendations for model use?",
-                        "fields": [
-                            {
-                                "default": null,
-                                "doc": "Did the results suggest any further testing?",
-                                "name": "needsFurtherTesting",
-                                "type": [
-                                    "null",
-                                    "boolean"
-                                ]
-                            },
-                            {
-                                "default": null,
-                                "doc": "Caveat Description\nFor ex: Given gender classes are binary (male/not male), which we include as male/female. Further work needed to evaluate across a spectrum of genders.",
-                                "name": "caveatDescription",
-                                "type": [
-                                    "null",
-                                    "string"
-                                ]
-                            },
-                            {
-                                "default": null,
-                                "doc": "Relevant groups that were not represented in the evaluation dataset?",
-                                "name": "groupsNotRepresented",
-                                "type": [
-                                    "null",
-                                    {
-                                        "items": "string",
-                                        "type": "array"
-                                    }
-                                ]
-                            }
-                        ],
-                        "name": "CaveatDetails",
-                        "namespace": "com.linkedin.pegasus2avro.ml.metadata",
-                        "type": "record"
-                    }
+                    "long"
                 ]
             },
             {
                 "default": null,
-                "doc": "Recommendations on where this MLModel should be used.",
-                "name": "recommendations",
+                "doc": "Number of warnings generated.",
+                "name": "numWarnings",
                 "type": [
                     "null",
-                    "string"
+                    "long"
                 ]
             },
             {
                 "default": null,
-                "doc": "Ideal characteristics of an evaluation dataset for this MLModel",
-                "name": "idealDatasetCharacteristics",
+                "doc": "Number of errors generated.",
+                "name": "numErrors",
                 "type": [
                     "null",
-                    {
-                        "items": "string",
-                        "type": "array"
-                    }
+                    "long"
                 ]
-            }
-        ],
-        "name": "CaveatsAndRecommendations",
-        "namespace": "com.linkedin.pegasus2avro.ml.metadata",
-        "type": "record"
-    },
-    {
-        "Aspect": {
-            "name": "editableMlModelProperties"
-        },
-        "doc": "Properties associated with a ML Model editable from the UI",
-        "fields": [
+            },
             {
-                "Searchable": {
-                    "fieldName": "editedDescription",
-                    "fieldType": "TEXT"
-                },
                 "default": null,
-                "doc": "Documentation of the ml model",
-                "name": "description",
+                "doc": "Number of entities skipped.",
+                "name": "numEntitiesSkipped",
                 "type": [
                     "null",
-                    "string"
+                    "long"
                 ]
-            }
-        ],
-        "name": "EditableMLModelProperties",
-        "namespace": "com.linkedin.pegasus2avro.ml.metadata",
-        "type": "record"
-    },
-    {
-        "Aspect": {
-            "name": "editableMlModelGroupProperties"
-        },
-        "doc": "Properties associated with an ML Model Group editable from the UI",
-        "fields": [
+            },
             {
-                "Searchable": {
-                    "fieldName": "editedDescription",
-                    "fieldType": "TEXT"
-                },
                 "default": null,
-                "doc": "Documentation of the ml model group",
-                "name": "description",
+                "doc": "The non-sensitive key-value pairs of the yaml config used as json string.",
+                "name": "config",
                 "type": [
                     "null",
                     "string"
                 ]
-            }
-        ],
-        "name": "EditableMLModelGroupProperties",
-        "namespace": "com.linkedin.pegasus2avro.ml.metadata",
-        "type": "record"
-    },
-    {
-        "Aspect": {
-            "name": "mlFeatureProperties"
-        },
-        "doc": "Properties associated with a MLFeature",
-        "fields": [
+            },
             {
-                "Searchable": {
-                    "fieldType": "TEXT",
-                    "hasValuesFieldName": "hasDescription"
-                },
                 "default": null,
-                "doc": "Documentation of the MLFeature",
-                "name": "description",
+                "doc": "Custom value.",
+                "name": "custom_summary",
                 "type": [
                     "null",
                     "string"
                 ]
             },
             {
+                "TimeseriesField": {},
                 "default": null,
-                "doc": "Data Type of the MLFeature",
-                "name": "dataType",
+                "doc": "The software version of this ingestion.",
+                "name": "softwareVersion",
                 "type": [
                     "null",
-                    "com.linkedin.pegasus2avro.common.MLFeatureDataType"
+                    "string"
                 ]
             },
             {
                 "default": null,
-                "doc": "Version of the MLFeature",
-                "name": "version",
+                "doc": "The hostname the ingestion pipeline ran on.",
+                "name": "systemHostName",
                 "type": [
                     "null",
-                    "com.linkedin.pegasus2avro.common.VersionTag"
+                    "string"
                 ]
             },
             {
-                "Relationship": {
-                    "/*": {
-                        "entityTypes": [
-                            "dataset"
-                        ],
-                        "isLineage": true,
-                        "name": "DerivedFrom"
-                    }
-                },
-                "Urn": "Urn",
+                "TimeseriesField": {},
                 "default": null,
-                "doc": "Source of the MLFeature",
-                "name": "sources",
+                "doc": "The os the ingestion pipeline ran on.",
+                "name": "operatingSystemName",
                 "type": [
                     "null",
-                    {
-                        "items": "string",
-                        "type": "array"
-                    }
-                ],
-                "urn_is_array": true
-            }
-        ],
-        "name": "MLFeatureProperties",
-        "namespace": "com.linkedin.pegasus2avro.ml.metadata",
-        "type": "record"
-    },
-    {
-        "Aspect": {
-            "name": "mlFeatureTableProperties"
-        },
-        "doc": "Properties associated with a MLFeatureTable",
-        "fields": [
-            {
-                "Searchable": {
-                    "/*": {
-                        "queryByDefault": true
-                    }
-                },
-                "default": {},
-                "doc": "Custom property bag.",
-                "name": "customProperties",
-                "type": {
-                    "type": "map",
-                    "values": "string"
-                }
+                    "string"
+                ]
             },
             {
-                "Searchable": {
-                    "fieldType": "TEXT",
-                    "hasValuesFieldName": "hasDescription"
-                },
                 "default": null,
-                "doc": "Documentation of the MLFeatureTable",
-                "name": "description",
+                "doc": "The number of processors on the host the ingestion pipeline ran on.",
+                "name": "numProcessors",
                 "type": [
                     "null",
-                    "string"
+                    "int"
                 ]
             },
             {
-                "Relationship": {
-                    "/*": {
-                        "entityTypes": [
-                            "mlFeature"
-                        ],
-                        "name": "Contains"
-                    }
-                },
-                "Searchable": {
-                    "/*": {
-                        "fieldName": "features",
-                        "fieldType": "URN"
-                    }
-                },
-                "Urn": "Urn",
                 "default": null,
-                "doc": "List of features contained in the feature table",
-                "name": "mlFeatures",
+                "doc": "The total amount of memory on the host the ingestion pipeline ran on.",
+                "name": "totalMemory",
                 "type": [
                     "null",
-                    {
-                        "items": "string",
-                        "type": "array"
-                    }
-                ],
-                "urn_is_array": true
+                    "long"
+                ]
             },
             {
-                "Relationship": {
-                    "/*": {
-                        "entityTypes": [
-                            "mlPrimaryKey"
-                        ],
-                        "name": "KeyedBy"
-                    }
-                },
-                "Searchable": {
-                    "/*": {
-                        "fieldName": "primaryKeys",
-                        "fieldType": "URN"
-                    }
-                },
-                "Urn": "Urn",
                 "default": null,
-                "doc": "List of primary keys in the feature table (if multiple, assumed to act as a composite key)",
-                "name": "mlPrimaryKeys",
+                "doc": "The available memory on the host the ingestion pipeline ran on.",
+                "name": "availableMemory",
                 "type": [
                     "null",
-                    {
-                        "items": "string",
-                        "type": "array"
-                    }
-                ],
-                "urn_is_array": true
+                    "long"
+                ]
             }
         ],
-        "name": "MLFeatureTableProperties",
-        "namespace": "com.linkedin.pegasus2avro.ml.metadata",
+        "name": "DatahubIngestionRunSummary",
+        "namespace": "com.linkedin.pegasus2avro.datajob.datahub",
         "type": "record"
     },
     {
         "Aspect": {
-            "name": "dataHubViewInfo"
+            "name": "datahubIngestionCheckpoint",
+            "type": "timeseries"
         },
-        "doc": "Information about a DataHub View. -- TODO: Understand whether an entity type filter is required.",
+        "doc": "Checkpoint of a datahub ingestion run for a given job.",
         "fields": [
             {
-                "Searchable": {
-                    "fieldType": "TEXT_PARTIAL"
+                "doc": "The event timestamp field as epoch at UTC in milli seconds.",
+                "name": "timestampMillis",
+                "type": "long"
+            },
+            {
+                "default": null,
+                "doc": "Granularity of the event if applicable",
+                "name": "eventGranularity",
+                "type": [
+                    "null",
+                    "com.linkedin.pegasus2avro.timeseries.TimeWindowSize"
+                ]
+            },
+            {
+                "default": {
+                    "partition": "FULL_TABLE_SNAPSHOT",
+                    "timePartition": null,
+                    "type": "FULL_TABLE"
                 },
-                "doc": "The name of the View",
-                "name": "name",
-                "type": "string"
+                "doc": "The optional partition specification.",
+                "name": "partitionSpec",
+                "type": [
+                    "com.linkedin.pegasus2avro.timeseries.PartitionSpec",
+                    "null"
+                ]
             },
             {
                 "default": null,
-                "doc": "Description of the view",
-                "name": "description",
+                "doc": "The optional messageId, if provided serves as a custom user-defined unique identifier for an aspect value.",
+                "name": "messageId",
                 "type": [
                     "null",
                     "string"
                 ]
             },
             {
-                "Searchable": {},
-                "doc": "The type of View",
-                "name": "type",
-                "type": {
-                    "name": "DataHubViewType",
-                    "namespace": "com.linkedin.pegasus2avro.view",
-                    "symbolDocs": {
-                        "GLOBAL": "A global view, which all users can see and use.",
-                        "PERSONAL": "A view private for a specific person."
-                    },
-                    "symbols": [
-                        "PERSONAL",
-                        "GLOBAL"
-                    ],
-                    "type": "enum"
-                }
+                "TimeseriesField": {},
+                "doc": "The name of the pipeline that ran ingestion, a stable unique user provided identifier.\n e.g. my_snowflake1-to-datahub.",
+                "name": "pipelineName",
+                "type": "string"
             },
             {
-                "doc": "The view itself",
-                "name": "definition",
+                "TimeseriesField": {},
+                "doc": "The id of the instance against which the ingestion pipeline ran.\ne.g.: Bigquery project ids, MySQL hostnames etc.",
+                "name": "platformInstanceId",
+                "type": "string"
+            },
+            {
+                "doc": "Json-encoded string representation of the non-secret members of the config .",
+                "name": "config",
+                "type": "string"
+            },
+            {
+                "doc": "Opaque blob of the state representation.",
+                "name": "state",
                 "type": {
-                    "doc": "A View definition.",
+                    "doc": "The checkpoint state object of a datahub ingestion run for a given job.",
                     "fields": [
                         {
-                            "doc": "The Entity Types in the scope of the View.",
-                            "name": "entityTypes",
-                            "type": {
-                                "items": "string",
-                                "type": "array"
-                            }
+                            "doc": "The version of the state format.",
+                            "name": "formatVersion",
+                            "type": "string"
                         },
                         {
-                            "doc": "The filter criteria, which represents the view itself",
-                            "name": "filter",
-                            "type": {
-                                "doc": "The filter for finding a record or a collection of records",
-                                "fields": [
+                            "doc": "The serialization/deserialization protocol.",
+                            "name": "serde",
+                            "type": "string"
+                        },
+                        {
+                            "default": null,
+                            "doc": "Opaque blob of the state representation.",
+                            "name": "payload",
+                            "type": [
+                                "null",
+                                "bytes"
+                            ]
+                        }
+                    ],
+                    "name": "IngestionCheckpointState",
+                    "namespace": "com.linkedin.pegasus2avro.datajob.datahub",
+                    "type": "record"
+                }
+            },
+            {
+                "TimeseriesField": {},
+                "doc": "The run identifier of this job.",
+                "name": "runId",
+                "type": "string"
+            }
+        ],
+        "name": "DatahubIngestionCheckpoint",
+        "namespace": "com.linkedin.pegasus2avro.datajob.datahub",
+        "type": "record"
+    },
+    {
+        "Aspect": {
+            "name": "embed"
+        },
+        "doc": "Information regarding rendering an embed for an asset.",
+        "fields": [
+            {
+                "default": null,
+                "doc": "An embed URL to be rendered inside of an iframe.",
+                "name": "renderUrl",
+                "type": [
+                    "null",
+                    "string"
+                ]
+            }
+        ],
+        "name": "Embed",
+        "namespace": "com.linkedin.pegasus2avro.common",
+        "type": "record"
+    },
+    {
+        "Aspect": {
+            "name": "inputFields"
+        },
+        "doc": "Information about the fields a chart or dashboard references",
+        "fields": [
+            {
+                "doc": "List of fields being referenced",
+                "name": "fields",
+                "type": {
+                    "items": {
+                        "doc": "Information about a field a chart or dashboard references",
+                        "fields": [
+                            {
+                                "Relationship": {
+                                    "entityTypes": [
+                                        "schemaField"
+                                    ],
+                                    "name": "consumesField"
+                                },
+                                "Urn": "Urn",
+                                "doc": "Urn of the schema being referenced for lineage purposes",
+                                "java": {
+                                    "class": "com.linkedin.pegasus2avro.common.urn.Urn"
+                                },
+                                "name": "schemaFieldUrn",
+                                "type": "string"
+                            },
+                            {
+                                "default": null,
+                                "doc": "Copied version of the referenced schema field object for indexing purposes",
+                                "name": "schemaField",
+                                "type": [
+                                    "null",
                                     {
-                                        "default": null,
-                                        "doc": "A list of disjunctive criterion for the filter. (or operation to combine filters)",
-                                        "name": "or",
-                                        "type": [
-                                            "null",
+                                        "doc": "SchemaField to describe metadata related to dataset schema.",
+                                        "fields": [
+                                            {
+                                                "Searchable": {
+                                                    "boostScore": 5.0,
+                                                    "fieldName": "fieldPaths",
+                                                    "fieldType": "TEXT"
+                                                },
+                                                "doc": "Flattened name of the field. Field is computed from jsonPath field.",
+                                                "name": "fieldPath",
+                                                "type": "string"
+                                            },
+                                            {
+                                                "Deprecated": true,
+                                                "default": null,
+                                                "doc": "Flattened name of a field in JSON Path notation.",
+                                                "name": "jsonPath",
+                                                "type": [
+                                                    "null",
+                                                    "string"
+                                                ]
+                                            },
+                                            {
+                                                "default": false,
+                                                "doc": "Indicates if this field is optional or nullable",
+                                                "name": "nullable",
+                                                "type": "boolean"
+                                            },
+                                            {
+                                                "Searchable": {
+                                                    "boostScore": 0.1,
+                                                    "fieldName": "fieldDescriptions",
+                                                    "fieldType": "TEXT"
+                                                },
+                                                "default": null,
+                                                "doc": "Description",
+                                                "name": "description",
+                                                "type": [
+                                                    "null",
+                                                    "string"
+                                                ]
+                                            },
+                                            {
+                                                "Searchable": {
+                                                    "boostScore": 0.2,
+                                                    "fieldName": "fieldLabels",
+                                                    "fieldType": "TEXT"
+                                                },
+                                                "default": null,
+                                                "doc": "Label of the field. Provides a more human-readable name for the field than field path. Some sources will\nprovide this metadata but not all sources have the concept of a label. If just one string is associated with\na field in a source, that is most likely a description.",
+                                                "name": "label",
+                                                "type": [
+                                                    "null",
+                                                    "string"
+                                                ]
+                                            },
+                                            {
+                                                "default": null,
+                                                "doc": "An AuditStamp corresponding to the creation of this schema field.",
+                                                "name": "created",
+                                                "type": [
+                                                    "null",
+                                                    "com.linkedin.pegasus2avro.common.AuditStamp"
+                                                ]
+                                            },
                                             {
-                                                "items": {
-                                                    "doc": "A list of criterion and'd together.",
+                                                "default": null,
+                                                "doc": "An AuditStamp corresponding to the last modification of this schema field.",
+                                                "name": "lastModified",
+                                                "type": [
+                                                    "null",
+                                                    "com.linkedin.pegasus2avro.common.AuditStamp"
+                                                ]
+                                            },
+                                            {
+                                                "doc": "Platform independent field type of the field.",
+                                                "name": "type",
+                                                "type": {
+                                                    "doc": "Schema field data types",
                                                     "fields": [
                                                         {
-                                                            "doc": "A list of and criteria the filter applies to the query",
-                                                            "name": "and",
-                                                            "type": {
-                                                                "items": {
-                                                                    "doc": "A criterion for matching a field with given value",
+                                                            "doc": "Data platform specific types",
+                                                            "name": "type",
+                                                            "type": [
+                                                                {
+                                                                    "doc": "Boolean field type.",
+                                                                    "fields": [],
+                                                                    "name": "BooleanType",
+                                                                    "namespace": "com.linkedin.pegasus2avro.schema",
+                                                                    "type": "record"
+                                                                },
+                                                                {
+                                                                    "doc": "Fixed field type.",
+                                                                    "fields": [],
+                                                                    "name": "FixedType",
+                                                                    "namespace": "com.linkedin.pegasus2avro.schema",
+                                                                    "type": "record"
+                                                                },
+                                                                {
+                                                                    "doc": "String field type.",
+                                                                    "fields": [],
+                                                                    "name": "StringType",
+                                                                    "namespace": "com.linkedin.pegasus2avro.schema",
+                                                                    "type": "record"
+                                                                },
+                                                                {
+                                                                    "doc": "Bytes field type.",
+                                                                    "fields": [],
+                                                                    "name": "BytesType",
+                                                                    "namespace": "com.linkedin.pegasus2avro.schema",
+                                                                    "type": "record"
+                                                                },
+                                                                {
+                                                                    "doc": "Number data type: long, integer, short, etc..",
+                                                                    "fields": [],
+                                                                    "name": "NumberType",
+                                                                    "namespace": "com.linkedin.pegasus2avro.schema",
+                                                                    "type": "record"
+                                                                },
+                                                                {
+                                                                    "doc": "Date field type.",
+                                                                    "fields": [],
+                                                                    "name": "DateType",
+                                                                    "namespace": "com.linkedin.pegasus2avro.schema",
+                                                                    "type": "record"
+                                                                },
+                                                                {
+                                                                    "doc": "Time field type. This should also be used for datetimes.",
+                                                                    "fields": [],
+                                                                    "name": "TimeType",
+                                                                    "namespace": "com.linkedin.pegasus2avro.schema",
+                                                                    "type": "record"
+                                                                },
+                                                                {
+                                                                    "doc": "Enum field type.",
+                                                                    "fields": [],
+                                                                    "name": "EnumType",
+                                                                    "namespace": "com.linkedin.pegasus2avro.schema",
+                                                                    "type": "record"
+                                                                },
+                                                                {
+                                                                    "doc": "Null field type.",
+                                                                    "fields": [],
+                                                                    "name": "NullType",
+                                                                    "namespace": "com.linkedin.pegasus2avro.schema",
+                                                                    "type": "record"
+                                                                },
+                                                                {
+                                                                    "doc": "Map field type.",
                                                                     "fields": [
                                                                         {
-                                                                            "doc": "The name of the field that the criterion refers to",
-                                                                            "name": "field",
-                                                                            "type": "string"
+                                                                            "default": null,
+                                                                            "doc": "Key type in a map",
+                                                                            "name": "keyType",
+                                                                            "type": [
+                                                                                "null",
+                                                                                "string"
+                                                                            ]
                                                                         },
                                                                         {
-                                                                            "doc": "The value of the intended field",
-                                                                            "name": "value",
-                                                                            "type": "string"
-                                                                        },
-                                                                        {
-                                                                            "default": [],
-                                                                            "doc": "Values. one of which the intended field should match\nNote, if values is set, the above \"value\" field will be ignored",
-                                                                            "name": "values",
-                                                                            "type": {
-                                                                                "items": "string",
-                                                                                "type": "array"
-                                                                            }
-                                                                        },
+                                                                            "default": null,
+                                                                            "doc": "Type of the value in a map",
+                                                                            "name": "valueType",
+                                                                            "type": [
+                                                                                "null",
+                                                                                "string"
+                                                                            ]
+                                                                        }
+                                                                    ],
+                                                                    "name": "MapType",
+                                                                    "namespace": "com.linkedin.pegasus2avro.schema",
+                                                                    "type": "record"
+                                                                },
+                                                                {
+                                                                    "doc": "Array field type.",
+                                                                    "fields": [
                                                                         {
-                                                                            "default": "EQUAL",
-                                                                            "doc": "The condition for the criterion, e.g. EQUAL, START_WITH",
-                                                                            "name": "condition",
-                                                                            "type": {
-                                                                                "doc": "The matching condition in a filter criterion",
-                                                                                "name": "Condition",
-                                                                                "namespace": "com.linkedin.pegasus2avro.metadata.query.filter",
-                                                                                "symbolDocs": {
-                                                                                    "CONTAIN": "Represent the relation: String field contains value, e.g. name contains Profile",
-                                                                                    "END_WITH": "Represent the relation: String field ends with value, e.g. name ends with Event",
-                                                                                    "EQUAL": "Represent the relation: field = value, e.g. platform = hdfs",
-                                                                                    "GREATER_THAN": "Represent the relation greater than, e.g. ownerCount > 5",
-                                                                                    "GREATER_THAN_OR_EQUAL_TO": "Represent the relation greater than or equal to, e.g. ownerCount >= 5",
-                                                                                    "IN": "Represent the relation: String field is one of the array values to, e.g. name in [\"Profile\", \"Event\"]",
-                                                                                    "IS_NULL": "Represent the relation: field is null, e.g. platform is null",
-                                                                                    "LESS_THAN": "Represent the relation less than, e.g. ownerCount < 3",
-                                                                                    "LESS_THAN_OR_EQUAL_TO": "Represent the relation less than or equal to, e.g. ownerCount <= 3",
-                                                                                    "START_WITH": "Represent the relation: String field starts with value, e.g. name starts with PageView"
-                                                                                },
-                                                                                "symbols": [
-                                                                                    "CONTAIN",
-                                                                                    "END_WITH",
-                                                                                    "EQUAL",
-                                                                                    "IS_NULL",
-                                                                                    "GREATER_THAN",
-                                                                                    "GREATER_THAN_OR_EQUAL_TO",
-                                                                                    "IN",
-                                                                                    "LESS_THAN",
-                                                                                    "LESS_THAN_OR_EQUAL_TO",
-                                                                                    "START_WITH"
-                                                                                ],
-                                                                                "type": "enum"
-                                                                            }
-                                                                        },
+                                                                            "default": null,
+                                                                            "doc": "List of types this array holds.",
+                                                                            "name": "nestedType",
+                                                                            "type": [
+                                                                                "null",
+                                                                                {
+                                                                                    "items": "string",
+                                                                                    "type": "array"
+                                                                                }
+                                                                            ]
+                                                                        }
+                                                                    ],
+                                                                    "name": "ArrayType",
+                                                                    "namespace": "com.linkedin.pegasus2avro.schema",
+                                                                    "type": "record"
+                                                                },
+                                                                {
+                                                                    "doc": "Union field type.",
+                                                                    "fields": [
                                                                         {
-                                                                            "default": false,
-                                                                            "doc": "Whether the condition should be negated",
-                                                                            "name": "negated",
-                                                                            "type": "boolean"
+                                                                            "default": null,
+                                                                            "doc": "List of types in union type.",
+                                                                            "name": "nestedTypes",
+                                                                            "type": [
+                                                                                "null",
+                                                                                {
+                                                                                    "items": "string",
+                                                                                    "type": "array"
+                                                                                }
+                                                                            ]
                                                                         }
                                                                     ],
-                                                                    "name": "Criterion",
-                                                                    "namespace": "com.linkedin.pegasus2avro.metadata.query.filter",
+                                                                    "name": "UnionType",
+                                                                    "namespace": "com.linkedin.pegasus2avro.schema",
                                                                     "type": "record"
                                                                 },
-                                                                "type": "array"
-                                                            }
+                                                                {
+                                                                    "doc": "Record field type.",
+                                                                    "fields": [],
+                                                                    "name": "RecordType",
+                                                                    "namespace": "com.linkedin.pegasus2avro.schema",
+                                                                    "type": "record"
+                                                                }
+                                                            ]
                                                         }
                                                     ],
-                                                    "name": "ConjunctiveCriterion",
-                                                    "namespace": "com.linkedin.pegasus2avro.metadata.query.filter",
+                                                    "name": "SchemaFieldDataType",
+                                                    "namespace": "com.linkedin.pegasus2avro.schema",
                                                     "type": "record"
+                                                }
+                                            },
+                                            {
+                                                "doc": "The native type of the field in the dataset's platform as declared by platform schema.",
+                                                "name": "nativeDataType",
+                                                "type": "string"
+                                            },
+                                            {
+                                                "default": false,
+                                                "doc": "There are use cases when a field in type B references type A. A field in A references field of type B. In such cases, we will mark the first field as recursive.",
+                                                "name": "recursive",
+                                                "type": "boolean"
+                                            },
+                                            {
+                                                "Relationship": {
+                                                    "/tags/*/tag": {
+                                                        "entityTypes": [
+                                                            "tag"
+                                                        ],
+                                                        "name": "SchemaFieldTaggedWith"
+                                                    }
                                                 },
-                                                "type": "array"
-                                            }
-                                        ]
-                                    },
-                                    {
-                                        "default": null,
-                                        "doc": "Deprecated! A list of conjunctive criterion for the filter. If \"or\" field is provided, then this field is ignored.",
-                                        "name": "criteria",
-                                        "type": [
-                                            "null",
+                                                "Searchable": {
+                                                    "/tags/*/tag": {
+                                                        "boostScore": 0.5,
+                                                        "fieldName": "fieldTags",
+                                                        "fieldType": "URN"
+                                                    }
+                                                },
+                                                "default": null,
+                                                "doc": "Tags associated with the field",
+                                                "name": "globalTags",
+                                                "type": [
+                                                    "null",
+                                                    {
+                                                        "Aspect": {
+                                                            "name": "globalTags"
+                                                        },
+                                                        "doc": "Tag aspect used for applying tags to an entity",
+                                                        "fields": [
+                                                            {
+                                                                "Relationship": {
+                                                                    "/*/tag": {
+                                                                        "entityTypes": [
+                                                                            "tag"
+                                                                        ],
+                                                                        "name": "TaggedWith"
+                                                                    }
+                                                                },
+                                                                "Searchable": {
+                                                                    "/*/tag": {
+                                                                        "addToFilters": true,
+                                                                        "boostScore": 0.5,
+                                                                        "fieldName": "tags",
+                                                                        "fieldType": "URN",
+                                                                        "filterNameOverride": "Tag",
+                                                                        "hasValuesFieldName": "hasTags",
+                                                                        "queryByDefault": true
+                                                                    }
+                                                                },
+                                                                "doc": "Tags associated with a given entity",
+                                                                "name": "tags",
+                                                                "type": {
+                                                                    "items": {
+                                                                        "doc": "Properties of an applied tag. For now, just an Urn. In the future we can extend this with other properties, e.g.\npropagation parameters.",
+                                                                        "fields": [
+                                                                            {
+                                                                                "Urn": "TagUrn",
+                                                                                "doc": "Urn of the applied tag",
+                                                                                "java": {
+                                                                                    "class": "com.linkedin.pegasus2avro.common.urn.TagUrn"
+                                                                                },
+                                                                                "name": "tag",
+                                                                                "type": "string"
+                                                                            },
+                                                                            {
+                                                                                "default": null,
+                                                                                "doc": "Additional context about the association",
+                                                                                "name": "context",
+                                                                                "type": [
+                                                                                    "null",
+                                                                                    "string"
+                                                                                ]
+                                                                            }
+                                                                        ],
+                                                                        "name": "TagAssociation",
+                                                                        "namespace": "com.linkedin.pegasus2avro.common",
+                                                                        "type": "record"
+                                                                    },
+                                                                    "type": "array"
+                                                                }
+                                                            }
+                                                        ],
+                                                        "name": "GlobalTags",
+                                                        "namespace": "com.linkedin.pegasus2avro.common",
+                                                        "type": "record"
+                                                    }
+                                                ]
+                                            },
                                             {
-                                                "items": "com.linkedin.pegasus2avro.metadata.query.filter.Criterion",
-                                                "type": "array"
+                                                "Relationship": {
+                                                    "/terms/*/urn": {
+                                                        "entityTypes": [
+                                                            "glossaryTerm"
+                                                        ],
+                                                        "name": "SchemaFieldWithGlossaryTerm"
+                                                    }
+                                                },
+                                                "Searchable": {
+                                                    "/terms/*/urn": {
+                                                        "boostScore": 0.5,
+                                                        "fieldName": "fieldGlossaryTerms",
+                                                        "fieldType": "URN"
+                                                    }
+                                                },
+                                                "default": null,
+                                                "doc": "Glossary terms associated with the field",
+                                                "name": "glossaryTerms",
+                                                "type": [
+                                                    "null",
+                                                    {
+                                                        "Aspect": {
+                                                            "name": "glossaryTerms"
+                                                        },
+                                                        "doc": "Related business terms information",
+                                                        "fields": [
+                                                            {
+                                                                "doc": "The related business terms",
+                                                                "name": "terms",
+                                                                "type": {
+                                                                    "items": {
+                                                                        "doc": "Properties of an applied glossary term.",
+                                                                        "fields": [
+                                                                            {
+                                                                                "Relationship": {
+                                                                                    "entityTypes": [
+                                                                                        "glossaryTerm"
+                                                                                    ],
+                                                                                    "name": "TermedWith"
+                                                                                },
+                                                                                "Searchable": {
+                                                                                    "addToFilters": true,
+                                                                                    "fieldName": "glossaryTerms",
+                                                                                    "fieldType": "URN",
+                                                                                    "filterNameOverride": "Glossary Term",
+                                                                                    "hasValuesFieldName": "hasGlossaryTerms"
+                                                                                },
+                                                                                "Urn": "GlossaryTermUrn",
+                                                                                "doc": "Urn of the applied glossary term",
+                                                                                "java": {
+                                                                                    "class": "com.linkedin.pegasus2avro.common.urn.GlossaryTermUrn"
+                                                                                },
+                                                                                "name": "urn",
+                                                                                "type": "string"
+                                                                            },
+                                                                            {
+                                                                                "default": null,
+                                                                                "doc": "Additional context about the association",
+                                                                                "name": "context",
+                                                                                "type": [
+                                                                                    "null",
+                                                                                    "string"
+                                                                                ]
+                                                                            }
+                                                                        ],
+                                                                        "name": "GlossaryTermAssociation",
+                                                                        "namespace": "com.linkedin.pegasus2avro.common",
+                                                                        "type": "record"
+                                                                    },
+                                                                    "type": "array"
+                                                                }
+                                                            },
+                                                            {
+                                                                "doc": "Audit stamp containing who reported the related business term",
+                                                                "name": "auditStamp",
+                                                                "type": "com.linkedin.pegasus2avro.common.AuditStamp"
+                                                            }
+                                                        ],
+                                                        "name": "GlossaryTerms",
+                                                        "namespace": "com.linkedin.pegasus2avro.common",
+                                                        "type": "record"
+                                                    }
+                                                ]
+                                            },
+                                            {
+                                                "default": false,
+                                                "doc": "For schema fields that are part of complex keys, set this field to true\nWe do this to easily distinguish between value and key fields",
+                                                "name": "isPartOfKey",
+                                                "type": "boolean"
+                                            },
+                                            {
+                                                "default": null,
+                                                "doc": "For Datasets which are partitioned, this determines the partitioning key.",
+                                                "name": "isPartitioningKey",
+                                                "type": [
+                                                    "null",
+                                                    "boolean"
+                                                ]
+                                            },
+                                            {
+                                                "default": null,
+                                                "doc": "For schema fields that have other properties that are not modeled explicitly,\nuse this field to serialize those properties into a JSON string",
+                                                "name": "jsonProps",
+                                                "type": [
+                                                    "null",
+                                                    "string"
+                                                ]
                                             }
-                                        ]
+                                        ],
+                                        "name": "SchemaField",
+                                        "namespace": "com.linkedin.pegasus2avro.schema",
+                                        "type": "record"
                                     }
-                                ],
-                                "name": "Filter",
-                                "namespace": "com.linkedin.pegasus2avro.metadata.query.filter",
-                                "type": "record"
+                                ]
                             }
-                        }
+                        ],
+                        "name": "InputField",
+                        "namespace": "com.linkedin.pegasus2avro.common",
+                        "type": "record"
+                    },
+                    "type": "array"
+                }
+            }
+        ],
+        "name": "InputFields",
+        "namespace": "com.linkedin.pegasus2avro.common",
+        "type": "record"
+    },
+    {
+        "Aspect": {
+            "name": "cost"
+        },
+        "fields": [
+            {
+                "name": "costType",
+                "type": {
+                    "doc": "Type of Cost Code",
+                    "name": "CostType",
+                    "namespace": "com.linkedin.pegasus2avro.common",
+                    "symbolDocs": {
+                        "ORG_COST_TYPE": "Org Cost Type to which the Cost of this entity should be attributed to"
+                    },
+                    "symbols": [
+                        "ORG_COST_TYPE"
                     ],
-                    "name": "DataHubViewDefinition",
-                    "namespace": "com.linkedin.pegasus2avro.view",
-                    "type": "record"
+                    "type": "enum"
                 }
             },
             {
-                "Searchable": {
-                    "/actor": {
-                        "fieldName": "createdBy",
-                        "fieldType": "URN"
-                    },
-                    "/time": {
-                        "fieldName": "createdAt",
-                        "fieldType": "DATETIME"
-                    }
-                },
-                "doc": "Audit stamp capturing the time and actor who created the View.",
-                "name": "created",
+                "name": "cost",
                 "type": {
-                    "doc": "Data captured on a resource/association/sub-resource level giving insight into when that resource/association/sub-resource moved into a particular lifecycle stage, and who acted to move it into that specific lifecycle stage.",
                     "fields": [
                         {
-                            "doc": "When did the resource/association/sub-resource move into the specific lifecycle stage represented by this AuditEvent.",
-                            "name": "time",
-                            "type": "long"
-                        },
-                        {
-                            "Urn": "Urn",
-                            "doc": "The entity (e.g. a member URN) which will be credited for moving the resource/association/sub-resource into the specific lifecycle stage. It is also the one used to authorize the change.",
-                            "java": {
-                                "class": "com.linkedin.pegasus2avro.common.urn.Urn"
-                            },
-                            "name": "actor",
-                            "type": "string"
-                        },
-                        {
-                            "Urn": "Urn",
                             "default": null,
-                            "doc": "The entity (e.g. a service URN) which performs the change on behalf of the Actor and must be authorized to act as the Actor.",
-                            "java": {
-                                "class": "com.linkedin.pegasus2avro.common.urn.Urn"
-                            },
-                            "name": "impersonator",
+                            "name": "costId",
                             "type": [
                                 "null",
-                                "string"
+                                "double"
                             ]
                         },
                         {
                             "default": null,
-                            "doc": "Additional context around how DataHub was informed of the particular change. For example: was the change created by an automated process, or manually.",
-                            "name": "message",
+                            "name": "costCode",
                             "type": [
                                 "null",
                                 "string"
                             ]
+                        },
+                        {
+                            "doc": "Contains the name of the field that has its value set.",
+                            "name": "fieldDiscriminator",
+                            "type": {
+                                "name": "CostCostDiscriminator",
+                                "namespace": "com.linkedin.pegasus2avro.common",
+                                "symbols": [
+                                    "costId",
+                                    "costCode"
+                                ],
+                                "type": "enum"
+                            }
                         }
                     ],
-                    "name": "AuditStamp",
+                    "name": "CostCost",
                     "namespace": "com.linkedin.pegasus2avro.common",
                     "type": "record"
                 }
-            },
+            }
+        ],
+        "name": "Cost",
+        "namespace": "com.linkedin.pegasus2avro.common",
+        "type": "record"
+    },
+    {
+        "Aspect": {
+            "name": "subTypes"
+        },
+        "doc": "Sub Types. Use this aspect to specialize a generic Entity\ne.g. Making a Dataset also be a View or also be a LookerExplore",
+        "fields": [
             {
                 "Searchable": {
-                    "/time": {
-                        "fieldName": "lastModifiedAt",
-                        "fieldType": "DATETIME"
+                    "/*": {
+                        "addToFilters": true,
+                        "fieldType": "KEYWORD",
+                        "filterNameOverride": "Sub Type",
+                        "queryByDefault": true
                     }
                 },
-                "doc": "Audit stamp capturing the time and actor who last modified the View.",
-                "name": "lastModified",
-                "type": "com.linkedin.pegasus2avro.common.AuditStamp"
+                "doc": "The names of the specific types.",
+                "name": "typeNames",
+                "type": {
+                    "items": "string",
+                    "type": "array"
+                }
             }
         ],
-        "name": "DataHubViewInfo",
-        "namespace": "com.linkedin.pegasus2avro.view",
+        "name": "SubTypes",
+        "namespace": "com.linkedin.pegasus2avro.common",
         "type": "record"
     },
+    "com.linkedin.pegasus2avro.common.GlobalTags",
     {
         "Aspect": {
-            "name": "dataProcessInstanceOutput"
+            "name": "siblings"
         },
-        "doc": "Information about the outputs of a Data process",
+        "doc": "Siblings information of an entity.",
         "fields": [
             {
                 "Relationship": {
                     "/*": {
                         "entityTypes": [
                             "dataset"
                         ],
-                        "name": "Produces"
+                        "name": "SiblingOf"
                     }
                 },
                 "Searchable": {
                     "/*": {
-                        "addToFilters": true,
-                        "fieldName": "outputs",
+                        "fieldName": "siblings",
                         "fieldType": "URN",
-                        "numValuesFieldName": "numOutputs",
                         "queryByDefault": false
                     }
                 },
                 "Urn": "Urn",
-                "doc": "Output datasets to be produced",
-                "name": "outputs",
+                "doc": "List of sibling entities",
+                "name": "siblings",
                 "type": {
                     "items": "string",
                     "type": "array"
                 },
                 "urn_is_array": true
+            },
+            {
+                "doc": "If this is the leader entity of the set of siblings",
+                "name": "primary",
+                "type": "boolean"
             }
         ],
-        "name": "DataProcessInstanceOutput",
-        "namespace": "com.linkedin.pegasus2avro.dataprocess",
+        "name": "Siblings",
+        "namespace": "com.linkedin.pegasus2avro.common",
         "type": "record"
     },
     {
         "Aspect": {
-            "name": "dataProcessInstanceRunEvent",
+            "name": "operation",
             "type": "timeseries"
         },
-        "doc": "An event representing the current status of data process run.\nDataProcessRunEvent should be used for reporting the status of a dataProcess' run.",
+        "doc": "Operational info for an entity.",
         "fields": [
             {
                 "doc": "The event timestamp field as epoch at UTC in milli seconds.",
                 "name": "timestampMillis",
                 "type": "long"
             },
             {
                 "default": null,
                 "doc": "Granularity of the event if applicable",
                 "name": "eventGranularity",
                 "type": [
                     "null",
-                    {
-                        "doc": "Defines the size of a time window.",
-                        "fields": [
-                            {
-                                "doc": "Interval unit such as minute/hour/day etc.",
-                                "name": "unit",
-                                "type": {
-                                    "name": "CalendarInterval",
-                                    "namespace": "com.linkedin.pegasus2avro.timeseries",
-                                    "symbols": [
-                                        "SECOND",
-                                        "MINUTE",
-                                        "HOUR",
-                                        "DAY",
-                                        "WEEK",
-                                        "MONTH",
-                                        "QUARTER",
-                                        "YEAR"
-                                    ],
-                                    "type": "enum"
-                                }
-                            },
-                            {
-                                "default": 1,
-                                "doc": "How many units. Defaults to 1.",
-                                "name": "multiple",
-                                "type": "int"
-                            }
-                        ],
-                        "name": "TimeWindowSize",
-                        "namespace": "com.linkedin.pegasus2avro.timeseries",
-                        "type": "record"
-                    }
+                    "com.linkedin.pegasus2avro.timeseries.TimeWindowSize"
                 ]
             },
             {
                 "default": {
                     "partition": "FULL_TABLE_SNAPSHOT",
                     "timePartition": null,
                     "type": "FULL_TABLE"
                 },
                 "doc": "The optional partition specification.",
                 "name": "partitionSpec",
                 "type": [
-                    {
-                        "doc": "Defines how the data is partitioned",
-                        "fields": [
-                            {
-                                "default": "PARTITION",
-                                "name": "type",
-                                "type": {
-                                    "name": "PartitionType",
-                                    "namespace": "com.linkedin.pegasus2avro.timeseries",
-                                    "symbols": [
-                                        "FULL_TABLE",
-                                        "QUERY",
-                                        "PARTITION"
-                                    ],
-                                    "type": "enum"
-                                }
-                            },
-                            {
-                                "TimeseriesField": {},
-                                "doc": "String representation of the partition",
-                                "name": "partition",
-                                "type": "string"
-                            },
-                            {
-                                "default": null,
-                                "doc": "Time window of the partition if applicable",
-                                "name": "timePartition",
-                                "type": [
-                                    "null",
-                                    {
-                                        "fields": [
-                                            {
-                                                "doc": "Start time as epoch at UTC.",
-                                                "name": "startTimeMillis",
-                                                "type": "long"
-                                            },
-                                            {
-                                                "doc": "The length of the window.",
-                                                "name": "length",
-                                                "type": "com.linkedin.pegasus2avro.timeseries.TimeWindowSize"
-                                            }
-                                        ],
-                                        "name": "TimeWindow",
-                                        "namespace": "com.linkedin.pegasus2avro.timeseries",
-                                        "type": "record"
-                                    }
-                                ]
-                            }
-                        ],
-                        "name": "PartitionSpec",
-                        "namespace": "com.linkedin.pegasus2avro.timeseries",
-                        "type": "record"
-                    },
+                    "com.linkedin.pegasus2avro.timeseries.PartitionSpec",
                     "null"
                 ]
             },
             {
                 "default": null,
                 "doc": "The optional messageId, if provided serves as a custom user-defined unique identifier for an aspect value.",
                 "name": "messageId",
                 "type": [
                     "null",
                     "string"
                 ]
             },
             {
+                "TimeseriesField": {},
+                "Urn": "Urn",
                 "default": null,
-                "doc": "URL where the reference exist",
+                "doc": "Actor who issued this operation.",
                 "java": {
-                    "class": "com.linkedin.pegasus2avro.common.url.Url",
-                    "coercerClass": "com.linkedin.pegasus2avro.common.url.UrlCoercer"
+                    "class": "com.linkedin.pegasus2avro.common.urn.Urn"
                 },
-                "name": "externalUrl",
+                "name": "actor",
                 "type": [
                     "null",
                     "string"
                 ]
             },
             {
                 "TimeseriesField": {},
-                "name": "status",
+                "doc": "Operation type of change.",
+                "name": "operationType",
                 "type": {
-                    "name": "DataProcessRunStatus",
-                    "namespace": "com.linkedin.pegasus2avro.dataprocess",
+                    "doc": "Enum to define the operation type when an entity changes.",
+                    "name": "OperationType",
+                    "namespace": "com.linkedin.pegasus2avro.common",
                     "symbolDocs": {
-                        "STARTED": "The status where the Data processing run is in."
+                        "ALTER": "Asset was altered",
+                        "CREATE": "Asset was created",
+                        "CUSTOM": "Custom asset operation",
+                        "DELETE": "Rows were deleted",
+                        "DROP": "Asset was dropped",
+                        "INSERT": "Rows were inserted",
+                        "UPDATE": "Rows were updated"
                     },
                     "symbols": [
-                        "STARTED",
-                        "COMPLETE"
+                        "INSERT",
+                        "UPDATE",
+                        "DELETE",
+                        "CREATE",
+                        "ALTER",
+                        "DROP",
+                        "CUSTOM",
+                        "UNKNOWN"
                     ],
                     "type": "enum"
                 }
             },
             {
+                "TimeseriesField": {},
                 "default": null,
-                "doc": "Return the try number that this Instance Run is in",
-                "name": "attempt",
+                "doc": "A custom type of operation. Required if operationType is CUSTOM.",
+                "name": "customOperationType",
                 "type": [
                     "null",
-                    "int"
+                    "string"
                 ]
             },
             {
                 "TimeseriesField": {},
                 "default": null,
-                "doc": "The final result of the Data Processing run.",
-                "name": "result",
+                "doc": "How many rows were affected by this operation.",
+                "name": "numAffectedRows",
                 "type": [
                     "null",
-                    {
-                        "fields": [
-                            {
-                                "doc": " The final result, e.g. SUCCESS, FAILURE, SKIPPED, or UP_FOR_RETRY.",
-                                "name": "type",
-                                "type": {
-                                    "name": "RunResultType",
-                                    "namespace": "com.linkedin.pegasus2avro.dataprocess",
-                                    "symbolDocs": {
-                                        "FAILURE": " The Run Failed",
-                                        "SKIPPED": " The Run Skipped",
-                                        "SUCCESS": " The Run Succeeded",
-                                        "UP_FOR_RETRY": " The Run Failed and will Retry"
-                                    },
-                                    "symbols": [
-                                        "SUCCESS",
-                                        "FAILURE",
-                                        "SKIPPED",
-                                        "UP_FOR_RETRY"
-                                    ],
-                                    "type": "enum"
-                                }
-                            },
-                            {
-                                "doc": "It identifies the system where the native result comes from like Airflow, Azkaban, etc..",
-                                "name": "nativeResultType",
-                                "type": "string"
-                            }
-                        ],
-                        "name": "DataProcessInstanceRunResult",
-                        "namespace": "com.linkedin.pegasus2avro.dataprocess",
-                        "type": "record"
-                    }
+                    "long"
                 ]
-            }
-        ],
-        "name": "DataProcessInstanceRunEvent",
-        "namespace": "com.linkedin.pegasus2avro.dataprocess",
-        "type": "record"
-    },
-    {
-        "Aspect": {
-            "name": "dataProcessInstanceRelationships"
-        },
-        "doc": "Information about Data process relationships",
-        "fields": [
+            },
             {
-                "Relationship": {
-                    "entityTypes": [
-                        "dataJob",
-                        "dataFlow"
-                    ],
-                    "name": "InstanceOf"
-                },
-                "Searchable": {
-                    "/*": {
-                        "fieldName": "parentTemplate",
-                        "fieldType": "URN",
-                        "queryByDefault": false
-                    }
+                "TimeseriesFieldCollection": {
+                    "key": "datasetName"
                 },
                 "Urn": "Urn",
                 "default": null,
-                "doc": "The parent entity whose run instance it is",
-                "java": {
-                    "class": "com.linkedin.pegasus2avro.common.urn.Urn"
-                },
-                "name": "parentTemplate",
+                "doc": "Which other datasets were affected by this operation.",
+                "name": "affectedDatasets",
                 "type": [
                     "null",
-                    "string"
-                ]
+                    {
+                        "items": "string",
+                        "type": "array"
+                    }
+                ],
+                "urn_is_array": true
             },
             {
-                "Relationship": {
-                    "entityTypes": [
-                        "dataProcessInstance"
-                    ],
-                    "name": "ChildOf"
-                },
-                "Searchable": {
-                    "/*": {
-                        "fieldName": "parentInstance",
-                        "fieldType": "URN",
-                        "queryByDefault": false
-                    }
-                },
-                "Urn": "Urn",
+                "TimeseriesField": {},
                 "default": null,
-                "doc": "The parent DataProcessInstance where it belongs to.\nIf it is a Airflow Task then it should belong to an Airflow Dag run as well\nwhich will be another DataProcessInstance",
-                "java": {
-                    "class": "com.linkedin.pegasus2avro.common.urn.Urn"
-                },
-                "name": "parentInstance",
+                "doc": "Source Type",
+                "name": "sourceType",
                 "type": [
                     "null",
-                    "string"
+                    {
+                        "doc": "The source of an operation",
+                        "name": "OperationSourceType",
+                        "namespace": "com.linkedin.pegasus2avro.common",
+                        "symbolDocs": {
+                            "DATA_PLATFORM": "Rows were updated",
+                            "DATA_PROCESS": "Provided by a Data Process"
+                        },
+                        "symbols": [
+                            "DATA_PROCESS",
+                            "DATA_PLATFORM"
+                        ],
+                        "type": "enum"
+                    }
                 ]
             },
             {
-                "Relationship": {
-                    "/*": {
-                        "entityTypes": [
-                            "dataProcessInstance"
-                        ],
-                        "name": "UpstreamOf"
+                "default": null,
+                "doc": "Custom properties",
+                "name": "customProperties",
+                "type": [
+                    "null",
+                    {
+                        "type": "map",
+                        "values": "string"
                     }
+                ]
+            },
+            {
+                "Searchable": {
+                    "fieldName": "lastOperationTime",
+                    "fieldType": "DATETIME"
                 },
+                "TimeseriesField": {},
+                "doc": "The time at which the operation occurred. Would be better named 'operationTime'",
+                "name": "lastUpdatedTimestamp",
+                "type": "long"
+            }
+        ],
+        "name": "Operation",
+        "namespace": "com.linkedin.pegasus2avro.common",
+        "type": "record"
+    },
+    {
+        "Aspect": {
+            "name": "browsePaths"
+        },
+        "doc": "Shared aspect containing Browse Paths to be indexed for an entity.",
+        "fields": [
+            {
                 "Searchable": {
                     "/*": {
-                        "fieldName": "upstream",
-                        "fieldType": "URN",
-                        "numValuesFieldName": "numUpstreams",
-                        "queryByDefault": false
+                        "fieldName": "browsePaths",
+                        "fieldType": "BROWSE_PATH"
                     }
                 },
-                "Urn": "Urn",
-                "doc": "Input DataProcessInstance which triggered this dataprocess instance",
-                "name": "upstreamInstances",
+                "doc": "A list of valid browse paths for the entity.\n\nBrowse paths are expected to be forward slash-separated strings. For example: 'prod/snowflake/datasetName'",
+                "name": "paths",
                 "type": {
                     "items": "string",
                     "type": "array"
-                },
-                "urn_is_array": true
+                }
             }
         ],
-        "name": "DataProcessInstanceRelationships",
-        "namespace": "com.linkedin.pegasus2avro.dataprocess",
+        "name": "BrowsePaths",
+        "namespace": "com.linkedin.pegasus2avro.common",
         "type": "record"
     },
+    "com.linkedin.pegasus2avro.common.GlossaryTerms",
     {
         "Aspect": {
-            "name": "dataProcessInstanceProperties"
+            "name": "origin"
         },
-        "doc": "The inputs and outputs of this data process",
+        "doc": "Carries information about where an entity originated from.",
         "fields": [
             {
-                "Searchable": {
-                    "/*": {
-                        "queryByDefault": true
-                    }
-                },
-                "default": {},
-                "doc": "Custom property bag.",
-                "name": "customProperties",
+                "doc": "Where an entity originated from. Either NATIVE or EXTERNAL.",
+                "name": "type",
                 "type": {
-                    "type": "map",
-                    "values": "string"
+                    "doc": "Enum to define where an entity originated from.",
+                    "name": "OriginType",
+                    "namespace": "com.linkedin.pegasus2avro.common",
+                    "symbolDocs": {
+                        "EXTERNAL": "The entity is external to DataHub.",
+                        "NATIVE": "The entity is native to DataHub."
+                    },
+                    "symbols": [
+                        "NATIVE",
+                        "EXTERNAL"
+                    ],
+                    "type": "enum"
                 }
             },
             {
                 "default": null,
-                "doc": "URL where the reference exist",
-                "java": {
-                    "class": "com.linkedin.pegasus2avro.common.url.Url",
-                    "coercerClass": "com.linkedin.pegasus2avro.common.url.UrlCoercer"
-                },
-                "name": "externalUrl",
+                "doc": "Only populated if type is EXTERNAL. The externalType of the entity, such as the name of the identity provider.",
+                "name": "externalType",
                 "type": [
                     "null",
                     "string"
                 ]
-            },
-            {
-                "Searchable": {
-                    "boostScore": 10.0,
-                    "enableAutocomplete": true,
-                    "fieldType": "TEXT_PARTIAL"
-                },
-                "doc": "Process name",
-                "name": "name",
-                "type": "string"
-            },
-            {
-                "Searchable": {
-                    "addToFilters": true,
-                    "fieldType": "KEYWORD",
-                    "filterNameOverride": "Process Type"
-                },
-                "default": null,
-                "doc": "Process type",
-                "name": "type",
-                "type": [
-                    "null",
-                    {
-                        "name": "DataProcessType",
-                        "namespace": "com.linkedin.pegasus2avro.dataprocess",
-                        "symbols": [
-                            "BATCH_SCHEDULED",
-                            "BATCH_AD_HOC",
-                            "STREAMING"
-                        ],
-                        "type": "enum"
-                    }
-                ]
-            },
-            {
-                "Searchable": {
-                    "/time": {
-                        "fieldName": "created",
-                        "fieldType": "COUNT",
-                        "queryByDefault": false
-                    }
-                },
-                "doc": "Audit stamp containing who reported the lineage and when",
-                "name": "created",
-                "type": "com.linkedin.pegasus2avro.common.AuditStamp"
             }
         ],
-        "name": "DataProcessInstanceProperties",
-        "namespace": "com.linkedin.pegasus2avro.dataprocess",
+        "name": "Origin",
+        "namespace": "com.linkedin.pegasus2avro.common",
         "type": "record"
     },
     {
         "Aspect": {
-            "name": "dataProcessInfo"
+            "name": "dataPlatformInstance"
         },
-        "doc": "The inputs and outputs of this data process",
+        "doc": "The specific instance of the data platform that this entity belongs to",
         "fields": [
             {
-                "Relationship": {
-                    "/*": {
-                        "entityTypes": [
-                            "dataset"
-                        ],
-                        "isLineage": true,
-                        "name": "Consumes"
-                    }
-                },
                 "Searchable": {
-                    "/*": {
-                        "fieldName": "inputs",
-                        "fieldType": "URN",
-                        "numValuesFieldName": "numInputDatasets",
-                        "queryByDefault": false
-                    }
+                    "addToFilters": true,
+                    "fieldType": "URN",
+                    "filterNameOverride": "Platform"
                 },
-                "Urn": "DatasetUrn",
-                "default": null,
-                "doc": "the inputs of the data process",
-                "name": "inputs",
-                "type": [
-                    "null",
-                    {
-                        "items": "string",
-                        "type": "array"
-                    }
-                ],
-                "urn_is_array": true
+                "Urn": "Urn",
+                "doc": "Data Platform",
+                "java": {
+                    "class": "com.linkedin.pegasus2avro.common.urn.Urn"
+                },
+                "name": "platform",
+                "type": "string"
             },
             {
-                "Relationship": {
-                    "/*": {
-                        "entityTypes": [
-                            "dataset"
-                        ],
-                        "isLineage": true,
-                        "name": "Consumes"
-                    }
-                },
                 "Searchable": {
-                    "/*": {
-                        "fieldName": "outputs",
-                        "fieldType": "URN",
-                        "numValuesFieldName": "numOutputDatasets",
-                        "queryByDefault": false
-                    }
+                    "addToFilters": true,
+                    "fieldName": "platformInstance",
+                    "fieldType": "URN",
+                    "filterNameOverride": "Platform Instance"
                 },
-                "Urn": "DatasetUrn",
+                "Urn": "Urn",
                 "default": null,
-                "doc": "the outputs of the data process",
-                "name": "outputs",
+                "doc": "Instance of the data platform (e.g. db instance)",
+                "java": {
+                    "class": "com.linkedin.pegasus2avro.common.urn.Urn"
+                },
+                "name": "instance",
                 "type": [
                     "null",
-                    {
-                        "items": "string",
-                        "type": "array"
-                    }
-                ],
-                "urn_is_array": true
+                    "string"
+                ]
             }
         ],
-        "name": "DataProcessInfo",
-        "namespace": "com.linkedin.pegasus2avro.dataprocess",
+        "name": "DataPlatformInstance",
+        "namespace": "com.linkedin.pegasus2avro.common",
         "type": "record"
     },
     {
         "Aspect": {
-            "name": "dataProcessInstanceInput"
+            "name": "institutionalMemory"
         },
-        "doc": "Information about the inputs datasets of a Data process",
+        "doc": "Institutional memory of an entity. This is a way to link to relevant documentation and provide description of the documentation. Institutional or tribal knowledge is very important for users to leverage the entity.",
         "fields": [
             {
-                "Relationship": {
-                    "/*": {
-                        "entityTypes": [
-                            "dataset"
-                        ],
-                        "name": "Consumes"
-                    }
-                },
-                "Searchable": {
-                    "/*": {
-                        "addToFilters": true,
-                        "fieldName": "inputs",
-                        "fieldType": "URN",
-                        "numValuesFieldName": "numInputs",
-                        "queryByDefault": false
-                    }
-                },
-                "Urn": "Urn",
-                "doc": "Input datasets to be consumed",
-                "name": "inputs",
+                "doc": "List of records that represent institutional memory of an entity. Each record consists of a link, description, creator and timestamps associated with that record.",
+                "name": "elements",
                 "type": {
-                    "items": "string",
+                    "items": {
+                        "doc": "Metadata corresponding to a record of institutional memory.",
+                        "fields": [
+                            {
+                                "doc": "Link to an engineering design document or a wiki page.",
+                                "java": {
+                                    "class": "com.linkedin.pegasus2avro.common.url.Url",
+                                    "coercerClass": "com.linkedin.pegasus2avro.common.url.UrlCoercer"
+                                },
+                                "name": "url",
+                                "type": "string"
+                            },
+                            {
+                                "doc": "Description of the link.",
+                                "name": "description",
+                                "type": "string"
+                            },
+                            {
+                                "doc": "Audit stamp associated with creation of this record",
+                                "name": "createStamp",
+                                "type": "com.linkedin.pegasus2avro.common.AuditStamp"
+                            }
+                        ],
+                        "name": "InstitutionalMemoryMetadata",
+                        "namespace": "com.linkedin.pegasus2avro.common",
+                        "type": "record"
+                    },
                     "type": "array"
-                },
-                "urn_is_array": true
+                }
             }
         ],
-        "name": "DataProcessInstanceInput",
-        "namespace": "com.linkedin.pegasus2avro.dataprocess",
+        "name": "InstitutionalMemory",
+        "namespace": "com.linkedin.pegasus2avro.common",
         "type": "record"
     },
     {
         "Aspect": {
-            "name": "chartInfo"
+            "name": "deprecation"
         },
-        "doc": "Information about a chart",
+        "doc": "Deprecation status of an entity",
         "fields": [
             {
                 "Searchable": {
-                    "/*": {
-                        "queryByDefault": true
+                    "fieldType": "BOOLEAN",
+                    "weightsPerFieldValue": {
+                        "true": 0.5
                     }
                 },
-                "default": {},
-                "doc": "Custom property bag.",
-                "name": "customProperties",
-                "type": {
-                    "type": "map",
-                    "values": "string"
-                }
+                "doc": "Whether the entity is deprecated.",
+                "name": "deprecated",
+                "type": "boolean"
             },
             {
                 "default": null,
-                "doc": "URL where the reference exist",
-                "java": {
-                    "class": "com.linkedin.pegasus2avro.common.url.Url",
-                    "coercerClass": "com.linkedin.pegasus2avro.common.url.UrlCoercer"
-                },
-                "name": "externalUrl",
+                "doc": "The time user plan to decommission this entity.",
+                "name": "decommissionTime",
                 "type": [
                     "null",
-                    "string"
+                    "long"
                 ]
             },
             {
-                "Searchable": {
-                    "enableAutocomplete": true,
-                    "fieldType": "TEXT_PARTIAL"
-                },
-                "doc": "Title of the chart",
-                "name": "title",
+                "doc": "Additional information about the entity deprecation plan, such as the wiki, doc, RB.",
+                "name": "note",
                 "type": "string"
             },
             {
-                "Searchable": {},
-                "doc": "Detailed description about the chart",
-                "name": "description",
+                "Urn": "Urn",
+                "doc": "The user URN which will be credited for modifying this deprecation content.",
+                "java": {
+                    "class": "com.linkedin.pegasus2avro.common.urn.Urn"
+                },
+                "name": "actor",
                 "type": "string"
-            },
+            }
+        ],
+        "name": "Deprecation",
+        "namespace": "com.linkedin.pegasus2avro.common",
+        "type": "record"
+    },
+    {
+        "Aspect": {
+            "name": "ownership"
+        },
+        "doc": "Ownership information of an entity.",
+        "fields": [
             {
-                "doc": "Captures information about who created/last modified/deleted this chart and when",
-                "name": "lastModified",
+                "doc": "List of owners of the entity.",
+                "name": "owners",
                 "type": {
-                    "doc": "Data captured on a resource/association/sub-resource level giving insight into when that resource/association/sub-resource moved into various lifecycle stages, and who acted to move it into those lifecycle stages. The recommended best practice is to include this record in your record schema, and annotate its fields as @readOnly in your resource. See https://github.com/linkedin/rest.li/wiki/Validation-in-Rest.li#restli-validation-annotations",
-                    "fields": [
-                        {
-                            "default": {
-                                "actor": "urn:li:corpuser:unknown",
-                                "impersonator": null,
-                                "message": null,
-                                "time": 0
+                    "items": {
+                        "doc": "Ownership information",
+                        "fields": [
+                            {
+                                "Relationship": {
+                                    "entityTypes": [
+                                        "corpuser",
+                                        "corpGroup"
+                                    ],
+                                    "name": "OwnedBy"
+                                },
+                                "Searchable": {
+                                    "addToFilters": true,
+                                    "fieldName": "owners",
+                                    "fieldType": "URN",
+                                    "filterNameOverride": "Owned By",
+                                    "hasValuesFieldName": "hasOwners",
+                                    "queryByDefault": false
+                                },
+                                "Urn": "Urn",
+                                "doc": "Owner URN, e.g. urn:li:corpuser:ldap, urn:li:corpGroup:group_name, and urn:li:multiProduct:mp_name\n(Caveat: only corpuser is currently supported in the frontend.)",
+                                "java": {
+                                    "class": "com.linkedin.pegasus2avro.common.urn.Urn"
+                                },
+                                "name": "owner",
+                                "type": "string"
                             },
-                            "doc": "An AuditStamp corresponding to the creation of this resource/association/sub-resource. A value of 0 for time indicates missing data.",
-                            "name": "created",
-                            "type": "com.linkedin.pegasus2avro.common.AuditStamp"
-                        },
-                        {
-                            "default": {
-                                "actor": "urn:li:corpuser:unknown",
-                                "impersonator": null,
-                                "message": null,
-                                "time": 0
+                            {
+                                "doc": "The type of the ownership",
+                                "name": "type",
+                                "type": {
+                                    "deprecatedSymbols": {
+                                        "CONSUMER": true,
+                                        "DATAOWNER": true,
+                                        "DELEGATE": true,
+                                        "DEVELOPER": true,
+                                        "PRODUCER": true,
+                                        "STAKEHOLDER": true
+                                    },
+                                    "doc": "Asset owner types",
+                                    "name": "OwnershipType",
+                                    "namespace": "com.linkedin.pegasus2avro.common",
+                                    "symbolDocs": {
+                                        "BUSINESS_OWNER": "A person or group who is responsible for logical, or business related, aspects of the asset.",
+                                        "CONSUMER": "A person, group, or service that consumes the data\nDeprecated! Use TECHNICAL_OWNER or BUSINESS_OWNER instead.",
+                                        "DATAOWNER": "A person or group that is owning the data\nDeprecated! Use TECHNICAL_OWNER instead.",
+                                        "DATA_STEWARD": "A steward, expert, or delegate responsible for the asset.",
+                                        "DELEGATE": "A person or a group that overseas the operation, e.g. a DBA or SRE.\nDeprecated! Use TECHNICAL_OWNER instead.",
+                                        "DEVELOPER": "A person or group that is in charge of developing the code\nDeprecated! Use TECHNICAL_OWNER instead.",
+                                        "NONE": "No specific type associated to the owner.",
+                                        "PRODUCER": "A person, group, or service that produces/generates the data\nDeprecated! Use TECHNICAL_OWNER instead.",
+                                        "STAKEHOLDER": "A person or a group that has direct business interest\nDeprecated! Use TECHNICAL_OWNER, BUSINESS_OWNER, or STEWARD instead.",
+                                        "TECHNICAL_OWNER": "person or group who is responsible for technical aspects of the asset."
+                                    },
+                                    "symbols": [
+                                        "TECHNICAL_OWNER",
+                                        "BUSINESS_OWNER",
+                                        "DATA_STEWARD",
+                                        "NONE",
+                                        "DEVELOPER",
+                                        "DATAOWNER",
+                                        "DELEGATE",
+                                        "PRODUCER",
+                                        "CONSUMER",
+                                        "STAKEHOLDER"
+                                    ],
+                                    "type": "enum"
+                                }
                             },
-                            "doc": "An AuditStamp corresponding to the last modification of this resource/association/sub-resource. If no modification has happened since creation, lastModified should be the same as created. A value of 0 for time indicates missing data.",
-                            "name": "lastModified",
-                            "type": "com.linkedin.pegasus2avro.common.AuditStamp"
-                        },
-                        {
-                            "default": null,
-                            "doc": "An AuditStamp corresponding to the deletion of this resource/association/sub-resource. Logically, deleted MUST have a later timestamp than creation. It may or may not have the same time as lastModified depending upon the resource/association/sub-resource semantics.",
-                            "name": "deleted",
-                            "type": [
-                                "null",
-                                "com.linkedin.pegasus2avro.common.AuditStamp"
-                            ]
-                        }
-                    ],
-                    "name": "ChangeAuditStamps",
-                    "namespace": "com.linkedin.pegasus2avro.common",
-                    "type": "record"
+                            {
+                                "default": null,
+                                "doc": "Source information for the ownership",
+                                "name": "source",
+                                "type": [
+                                    "null",
+                                    {
+                                        "doc": "Source/provider of the ownership information",
+                                        "fields": [
+                                            {
+                                                "doc": "The type of the source",
+                                                "name": "type",
+                                                "type": {
+                                                    "name": "OwnershipSourceType",
+                                                    "namespace": "com.linkedin.pegasus2avro.common",
+                                                    "symbolDocs": {
+                                                        "AUDIT": "Auditing system or audit logs",
+                                                        "DATABASE": "Database, e.g. GRANTS table",
+                                                        "FILE_SYSTEM": "File system, e.g. file/directory owner",
+                                                        "ISSUE_TRACKING_SYSTEM": "Issue tracking system, e.g. Jira",
+                                                        "MANUAL": "Manually provided by a user",
+                                                        "OTHER": "Other sources",
+                                                        "SERVICE": "Other ownership-like service, e.g. Nuage, ACL service etc",
+                                                        "SOURCE_CONTROL": "SCM system, e.g. GIT, SVN"
+                                                    },
+                                                    "symbols": [
+                                                        "AUDIT",
+                                                        "DATABASE",
+                                                        "FILE_SYSTEM",
+                                                        "ISSUE_TRACKING_SYSTEM",
+                                                        "MANUAL",
+                                                        "SERVICE",
+                                                        "SOURCE_CONTROL",
+                                                        "OTHER"
+                                                    ],
+                                                    "type": "enum"
+                                                }
+                                            },
+                                            {
+                                                "default": null,
+                                                "doc": "A reference URL for the source",
+                                                "name": "url",
+                                                "type": [
+                                                    "null",
+                                                    "string"
+                                                ]
+                                            }
+                                        ],
+                                        "name": "OwnershipSource",
+                                        "namespace": "com.linkedin.pegasus2avro.common",
+                                        "type": "record"
+                                    }
+                                ]
+                            }
+                        ],
+                        "name": "Owner",
+                        "namespace": "com.linkedin.pegasus2avro.common",
+                        "type": "record"
+                    },
+                    "type": "array"
                 }
             },
             {
-                "default": null,
-                "doc": "URL for the chart. This could be used as an external link on DataHub to allow users access/view the chart",
-                "java": {
-                    "class": "com.linkedin.pegasus2avro.common.url.Url",
-                    "coercerClass": "com.linkedin.pegasus2avro.common.url.UrlCoercer"
+                "default": {
+                    "actor": "urn:li:corpuser:unknown",
+                    "impersonator": null,
+                    "message": null,
+                    "time": 0
                 },
-                "name": "chartUrl",
-                "type": [
-                    "null",
-                    "string"
-                ]
-            },
+                "doc": "Audit stamp containing who last modified the record and when. A value of 0 in the time field indicates missing data.",
+                "name": "lastModified",
+                "type": "com.linkedin.pegasus2avro.common.AuditStamp"
+            }
+        ],
+        "name": "Ownership",
+        "namespace": "com.linkedin.pegasus2avro.common",
+        "type": "record"
+    },
+    {
+        "Aspect": {
+            "name": "status"
+        },
+        "doc": "The lifecycle status metadata of an entity, e.g. dataset, metric, feature, etc.\nThis aspect is used to represent soft deletes conventionally.",
+        "fields": [
             {
-                "Relationship": {
-                    "/*/string": {
-                        "entityTypes": [
-                            "dataset"
-                        ],
-                        "isLineage": true,
-                        "name": "Consumes"
-                    }
+                "Searchable": {
+                    "fieldType": "BOOLEAN"
                 },
-                "default": null,
-                "deprecated": true,
-                "doc": "Data sources for the chart\nDeprecated! Use inputEdges instead.",
-                "name": "inputs",
-                "type": [
-                    "null",
-                    {
-                        "items": [
-                            "string"
-                        ],
-                        "type": "array"
-                    }
-                ]
-            },
+                "default": false,
+                "doc": "Whether the entity has been removed (soft-deleted).",
+                "name": "removed",
+                "type": "boolean"
+            }
+        ],
+        "name": "Status",
+        "namespace": "com.linkedin.pegasus2avro.common",
+        "type": "record"
+    },
+    {
+        "Aspect": {
+            "name": "sourceCode"
+        },
+        "doc": "Source Code",
+        "fields": [
             {
-                "Relationship": {
-                    "/*/destinationUrn": {
-                        "createdActor": "inputEdges/*/created/actor",
-                        "createdOn": "inputEdges/*/created/time",
-                        "entityTypes": [
-                            "dataset"
-                        ],
-                        "isLineage": true,
-                        "name": "Consumes",
-                        "properties": "inputEdges/*/properties",
-                        "updatedActor": "inputEdges/*/lastModified/actor",
-                        "updatedOn": "inputEdges/*/lastModified/time"
-                    }
-                },
-                "default": null,
-                "doc": "Data sources for the chart",
-                "name": "inputEdges",
-                "type": [
-                    "null",
-                    {
-                        "items": {
-                            "doc": "Information about a relatonship edge.",
-                            "fields": [
-                                {
-                                    "Urn": "Urn",
-                                    "doc": "Urn of the source of this relationship edge.",
-                                    "java": {
-                                        "class": "com.linkedin.pegasus2avro.common.urn.Urn"
-                                    },
-                                    "name": "sourceUrn",
-                                    "type": "string"
-                                },
-                                {
-                                    "Urn": "Urn",
-                                    "doc": "Urn of the destination of this relationship edge.",
-                                    "java": {
-                                        "class": "com.linkedin.pegasus2avro.common.urn.Urn"
-                                    },
-                                    "name": "destinationUrn",
-                                    "type": "string"
-                                },
-                                {
-                                    "doc": "Audit stamp containing who created this relationship edge and when",
-                                    "name": "created",
-                                    "type": "com.linkedin.pegasus2avro.common.AuditStamp"
-                                },
-                                {
-                                    "doc": "Audit stamp containing who last modified this relationship edge and when",
-                                    "name": "lastModified",
-                                    "type": "com.linkedin.pegasus2avro.common.AuditStamp"
-                                },
-                                {
-                                    "default": null,
-                                    "doc": "A generic properties bag that allows us to store specific information on this graph edge.",
-                                    "name": "properties",
-                                    "type": [
-                                        "null",
-                                        {
-                                            "type": "map",
-                                            "values": "string"
-                                        }
-                                    ]
+                "doc": "Source Code along with types",
+                "name": "sourceCode",
+                "type": {
+                    "items": {
+                        "doc": "Source Code Url Entity",
+                        "fields": [
+                            {
+                                "doc": "Source Code Url Types",
+                                "name": "type",
+                                "type": {
+                                    "name": "SourceCodeUrlType",
+                                    "namespace": "com.linkedin.pegasus2avro.ml.metadata",
+                                    "symbols": [
+                                        "ML_MODEL_SOURCE_CODE",
+                                        "TRAINING_PIPELINE_SOURCE_CODE",
+                                        "EVALUATION_PIPELINE_SOURCE_CODE"
+                                    ],
+                                    "type": "enum"
                                 }
-                            ],
-                            "name": "Edge",
-                            "namespace": "com.linkedin.pegasus2avro.common",
-                            "type": "record"
-                        },
-                        "type": "array"
-                    }
-                ]
-            },
-            {
-                "Searchable": {
-                    "addToFilters": true,
-                    "fieldType": "KEYWORD",
-                    "filterNameOverride": "Chart Type"
-                },
-                "default": null,
-                "doc": "Type of the chart",
-                "name": "type",
-                "type": [
-                    "null",
-                    {
-                        "doc": "The various types of charts",
-                        "name": "ChartType",
-                        "namespace": "com.linkedin.pegasus2avro.chart",
-                        "symbolDocs": {
-                            "BAR": "Chart showing a Bar chart",
-                            "PIE": "Chart showing a Pie chart",
-                            "SCATTER": "Chart showing a Scatter plot",
-                            "TABLE": "Chart showing a table",
-                            "TEXT": "Chart showing Markdown formatted text"
-                        },
-                        "symbols": [
-                            "BAR",
-                            "PIE",
-                            "SCATTER",
-                            "TABLE",
-                            "TEXT",
-                            "LINE",
-                            "AREA",
-                            "HISTOGRAM",
-                            "BOX_PLOT",
-                            "WORD_CLOUD",
-                            "COHORT"
+                            },
+                            {
+                                "doc": "Source Code Url",
+                                "java": {
+                                    "class": "com.linkedin.pegasus2avro.common.url.Url",
+                                    "coercerClass": "com.linkedin.pegasus2avro.common.url.UrlCoercer"
+                                },
+                                "name": "sourceCodeUrl",
+                                "type": "string"
+                            }
                         ],
-                        "type": "enum"
-                    }
-                ]
-            },
+                        "name": "SourceCodeUrl",
+                        "namespace": "com.linkedin.pegasus2avro.ml.metadata",
+                        "type": "record"
+                    },
+                    "type": "array"
+                }
+            }
+        ],
+        "name": "SourceCode",
+        "namespace": "com.linkedin.pegasus2avro.ml.metadata",
+        "type": "record"
+    },
+    {
+        "Aspect": {
+            "name": "editableMlModelProperties"
+        },
+        "doc": "Properties associated with a ML Model editable from the UI",
+        "fields": [
             {
                 "Searchable": {
-                    "addToFilters": true,
-                    "fieldType": "KEYWORD",
-                    "filterNameOverride": "Access Level"
+                    "fieldName": "editedDescription",
+                    "fieldType": "TEXT"
                 },
                 "default": null,
-                "doc": "Access level for the chart",
-                "name": "access",
-                "type": [
-                    "null",
-                    {
-                        "doc": "The various access levels",
-                        "name": "AccessLevel",
-                        "namespace": "com.linkedin.pegasus2avro.common",
-                        "symbolDocs": {
-                            "PRIVATE": "Private availability to certain set of users",
-                            "PUBLIC": "Publicly available access level"
-                        },
-                        "symbols": [
-                            "PUBLIC",
-                            "PRIVATE"
-                        ],
-                        "type": "enum"
-                    }
-                ]
-            },
-            {
-                "default": null,
-                "doc": "The time when this chart last refreshed",
-                "name": "lastRefreshed",
+                "doc": "Documentation of the ml model",
+                "name": "description",
                 "type": [
                     "null",
-                    "long"
+                    "string"
                 ]
             }
         ],
-        "name": "ChartInfo",
-        "namespace": "com.linkedin.pegasus2avro.chart",
+        "name": "EditableMLModelProperties",
+        "namespace": "com.linkedin.pegasus2avro.ml.metadata",
         "type": "record"
     },
     {
         "Aspect": {
-            "name": "editableChartProperties"
+            "name": "editableMlPrimaryKeyProperties"
         },
-        "doc": "Stores editable changes made to properties. This separates changes made from\ningestion pipelines and edits in the UI to avoid accidental overwrites of user-provided data by ingestion pipelines",
+        "doc": "Properties associated with a MLPrimaryKey editable from the UI",
         "fields": [
             {
-                "default": {
-                    "actor": "urn:li:corpuser:unknown",
-                    "impersonator": null,
-                    "message": null,
-                    "time": 0
-                },
-                "doc": "An AuditStamp corresponding to the creation of this resource/association/sub-resource. A value of 0 for time indicates missing data.",
-                "name": "created",
-                "type": "com.linkedin.pegasus2avro.common.AuditStamp"
-            },
-            {
-                "default": {
-                    "actor": "urn:li:corpuser:unknown",
-                    "impersonator": null,
-                    "message": null,
-                    "time": 0
-                },
-                "doc": "An AuditStamp corresponding to the last modification of this resource/association/sub-resource. If no modification has happened since creation, lastModified should be the same as created. A value of 0 for time indicates missing data.",
-                "name": "lastModified",
-                "type": "com.linkedin.pegasus2avro.common.AuditStamp"
-            },
-            {
                 "default": null,
-                "doc": "An AuditStamp corresponding to the deletion of this resource/association/sub-resource. Logically, deleted MUST have a later timestamp than creation. It may or may not have the same time as lastModified depending upon the resource/association/sub-resource semantics.",
-                "name": "deleted",
-                "type": [
-                    "null",
-                    "com.linkedin.pegasus2avro.common.AuditStamp"
-                ]
-            },
-            {
-                "Searchable": {
-                    "fieldName": "editedDescription",
-                    "fieldType": "TEXT"
-                },
-                "default": null,
-                "doc": "Edited documentation of the chart ",
+                "doc": "Documentation of the MLPrimaryKey",
                 "name": "description",
                 "type": [
                     "null",
                     "string"
                 ]
             }
         ],
-        "name": "EditableChartProperties",
-        "namespace": "com.linkedin.pegasus2avro.chart",
+        "name": "EditableMLPrimaryKeyProperties",
+        "namespace": "com.linkedin.pegasus2avro.ml.metadata",
         "type": "record"
     },
     {
         "Aspect": {
-            "name": "chartQuery"
+            "name": "mlModelEvaluationData"
         },
-        "doc": "Information for chart query which is used for getting data of the chart",
+        "doc": "All referenced datasets would ideally point to any set of documents that provide visibility into the source and composition of the dataset.",
         "fields": [
             {
-                "doc": "Raw query to build a chart from input datasets",
-                "name": "rawQuery",
-                "type": "string"
-            },
-            {
-                "Searchable": {
-                    "addToFilters": true,
-                    "fieldName": "queryType",
-                    "fieldType": "KEYWORD",
-                    "filterNameOverride": "Query Type"
-                },
-                "doc": "Chart query type",
-                "name": "type",
+                "doc": "Details on the dataset(s) used for the quantitative analyses in the MLModel",
+                "name": "evaluationData",
                 "type": {
-                    "name": "ChartQueryType",
-                    "namespace": "com.linkedin.pegasus2avro.chart",
-                    "symbolDocs": {
-                        "LOOKML": "LookML queries",
-                        "SQL": "SQL type queries"
+                    "items": {
+                        "doc": "BaseData record",
+                        "fields": [
+                            {
+                                "Urn": "DatasetUrn",
+                                "doc": "What dataset were used in the MLModel?",
+                                "java": {
+                                    "class": "com.linkedin.pegasus2avro.common.urn.DatasetUrn"
+                                },
+                                "name": "dataset",
+                                "type": "string"
+                            },
+                            {
+                                "default": null,
+                                "doc": "Why was this dataset chosen?",
+                                "name": "motivation",
+                                "type": [
+                                    "null",
+                                    "string"
+                                ]
+                            },
+                            {
+                                "default": null,
+                                "doc": "How was the data preprocessed (e.g., tokenization of sentences, cropping of images, any filtering such as dropping images without faces)?",
+                                "name": "preProcessing",
+                                "type": [
+                                    "null",
+                                    {
+                                        "items": "string",
+                                        "type": "array"
+                                    }
+                                ]
+                            }
+                        ],
+                        "name": "BaseData",
+                        "namespace": "com.linkedin.pegasus2avro.ml.metadata",
+                        "type": "record"
                     },
-                    "symbols": [
-                        "LOOKML",
-                        "SQL"
-                    ],
-                    "type": "enum"
+                    "type": "array"
                 }
             }
         ],
-        "name": "ChartQuery",
-        "namespace": "com.linkedin.pegasus2avro.chart",
+        "name": "EvaluationData",
+        "namespace": "com.linkedin.pegasus2avro.ml.metadata",
         "type": "record"
     },
     {
         "Aspect": {
-            "name": "chartUsageStatistics",
-            "type": "timeseries"
+            "name": "editableMlFeatureTableProperties"
         },
-        "doc": "Experimental (Subject to breaking change) -- Stats corresponding to chart's usage.\n\nIf this aspect represents the latest snapshot of the statistics about a Chart, the eventGranularity field should be null.\nIf this aspect represents a bucketed window of usage statistics (e.g. over a day), then the eventGranularity field should be set accordingly.",
+        "doc": "Properties associated with a MLFeatureTable editable from the ui",
         "fields": [
             {
-                "doc": "The event timestamp field as epoch at UTC in milli seconds.",
-                "name": "timestampMillis",
-                "type": "long"
-            },
+                "Searchable": {
+                    "fieldName": "editedDescription",
+                    "fieldType": "TEXT"
+                },
+                "default": null,
+                "doc": "Documentation of the MLFeatureTable",
+                "name": "description",
+                "type": [
+                    "null",
+                    "string"
+                ]
+            }
+        ],
+        "name": "EditableMLFeatureTableProperties",
+        "namespace": "com.linkedin.pegasus2avro.ml.metadata",
+        "type": "record"
+    },
+    {
+        "Aspect": {
+            "name": "mlPrimaryKeyProperties"
+        },
+        "doc": "Properties associated with a MLPrimaryKey",
+        "fields": [
             {
                 "default": null,
-                "doc": "Granularity of the event if applicable",
-                "name": "eventGranularity",
+                "doc": "Documentation of the MLPrimaryKey",
+                "name": "description",
                 "type": [
                     "null",
-                    "com.linkedin.pegasus2avro.timeseries.TimeWindowSize"
+                    "string"
                 ]
             },
             {
-                "default": {
-                    "partition": "FULL_TABLE_SNAPSHOT",
-                    "timePartition": null,
-                    "type": "FULL_TABLE"
-                },
-                "doc": "The optional partition specification.",
-                "name": "partitionSpec",
+                "default": null,
+                "doc": "Data Type of the MLPrimaryKey",
+                "name": "dataType",
                 "type": [
-                    "com.linkedin.pegasus2avro.timeseries.PartitionSpec",
-                    "null"
+                    "null",
+                    {
+                        "doc": "MLFeature Data Type",
+                        "name": "MLFeatureDataType",
+                        "namespace": "com.linkedin.pegasus2avro.common",
+                        "symbolDocs": {
+                            "AUDIO": "Audio Data",
+                            "BINARY": "Binary data is discrete data that can be in only one of two categories - either yes or no, 1 or 0, off or on, etc",
+                            "BYTE": "Bytes data are binary-encoded values that can represent complex objects.",
+                            "CONTINUOUS": "Continuous data are made of uncountable values, often the result of a measurement such as height, weight, age etc.",
+                            "COUNT": "Count data is discrete whole number data - no negative numbers here.\nCount data often has many small values, such as zero and one.",
+                            "IMAGE": "Image Data",
+                            "INTERVAL": "Interval data has equal spaces between the numbers and does not represent a temporal pattern.\nExamples include percentages, temperatures, and income.",
+                            "MAP": "Mapping Data Type ex: dict, map",
+                            "NOMINAL": "Nominal data is made of discrete values with no numerical relationship between the different categories - mean and median are meaningless.\nAnimal species is one example. For example, pig is not higher than bird and lower than fish.",
+                            "ORDINAL": "Ordinal data are discrete integers that can be ranked or sorted.\nFor example, the distance between first and second may not be the same as the distance between second and third.",
+                            "SEQUENCE": "Sequence Data Type ex: list, tuple, range",
+                            "SET": "Set Data Type ex: set, frozenset",
+                            "TEXT": "Text Data",
+                            "TIME": "Time data is a cyclical, repeating continuous form of data.\nThe relevant time features can be any period- daily, weekly, monthly, annual, etc.",
+                            "UNKNOWN": "Unknown data are data that we don't know the type for.",
+                            "USELESS": "Useless data is unique, discrete data with no potential relationship with the outcome variable.\nA useless feature has high cardinality. An example would be bank account numbers that were generated randomly.",
+                            "VIDEO": "Video Data"
+                        },
+                        "symbols": [
+                            "USELESS",
+                            "NOMINAL",
+                            "ORDINAL",
+                            "BINARY",
+                            "COUNT",
+                            "TIME",
+                            "INTERVAL",
+                            "IMAGE",
+                            "VIDEO",
+                            "AUDIO",
+                            "TEXT",
+                            "MAP",
+                            "SEQUENCE",
+                            "SET",
+                            "CONTINUOUS",
+                            "BYTE",
+                            "UNKNOWN"
+                        ],
+                        "type": "enum"
+                    }
                 ]
             },
             {
                 "default": null,
-                "doc": "The optional messageId, if provided serves as a custom user-defined unique identifier for an aspect value.",
-                "name": "messageId",
+                "doc": "Version of the MLPrimaryKey",
+                "name": "version",
                 "type": [
                     "null",
-                    "string"
+                    {
+                        "doc": "A resource-defined string representing the resource state for the purpose of concurrency control",
+                        "fields": [
+                            {
+                                "default": null,
+                                "name": "versionTag",
+                                "type": [
+                                    "null",
+                                    "string"
+                                ]
+                            }
+                        ],
+                        "name": "VersionTag",
+                        "namespace": "com.linkedin.pegasus2avro.common",
+                        "type": "record"
+                    }
                 ]
             },
             {
-                "TimeseriesField": {},
+                "Relationship": {
+                    "/*": {
+                        "entityTypes": [
+                            "dataset"
+                        ],
+                        "isLineage": true,
+                        "name": "DerivedFrom"
+                    }
+                },
+                "Urn": "Urn",
+                "doc": "Source of the MLPrimaryKey",
+                "name": "sources",
+                "type": {
+                    "items": "string",
+                    "type": "array"
+                },
+                "urn_is_array": true
+            }
+        ],
+        "name": "MLPrimaryKeyProperties",
+        "namespace": "com.linkedin.pegasus2avro.ml.metadata",
+        "type": "record"
+    },
+    {
+        "Aspect": {
+            "name": "mlHyperParam"
+        },
+        "doc": "Properties associated with an ML Hyper Param",
+        "fields": [
+            {
+                "doc": "Name of the MLHyperParam",
+                "name": "name",
+                "type": "string"
+            },
+            {
                 "default": null,
-                "doc": "The total number of times chart has been viewed",
-                "name": "viewsCount",
+                "doc": "Documentation of the MLHyperParam",
+                "name": "description",
                 "type": [
                     "null",
-                    "int"
+                    "string"
                 ]
             },
             {
-                "TimeseriesField": {},
                 "default": null,
-                "doc": "Unique user count",
-                "name": "uniqueUserCount",
+                "doc": "The value of the MLHyperParam",
+                "name": "value",
                 "type": [
                     "null",
-                    "int"
+                    "string"
                 ]
             },
             {
-                "TimeseriesFieldCollection": {
-                    "key": "user"
-                },
                 "default": null,
-                "doc": "Users within this bucket, with frequency counts",
-                "name": "userCounts",
+                "doc": "Date when the MLHyperParam was developed",
+                "name": "createdAt",
                 "type": [
                     "null",
-                    {
-                        "items": {
-                            "doc": "Records a single user's usage counts for a given resource",
-                            "fields": [
-                                {
-                                    "Urn": "Urn",
-                                    "doc": "The unique id of the user.",
-                                    "java": {
-                                        "class": "com.linkedin.pegasus2avro.common.urn.Urn"
-                                    },
-                                    "name": "user",
-                                    "type": "string"
-                                },
-                                {
-                                    "TimeseriesField": {},
-                                    "default": null,
-                                    "doc": "The number of times the user has viewed the chart",
-                                    "name": "viewsCount",
-                                    "type": [
-                                        "null",
-                                        "int"
-                                    ]
-                                }
-                            ],
-                            "name": "ChartUserUsageCounts",
-                            "namespace": "com.linkedin.pegasus2avro.chart",
-                            "type": "record"
-                        },
-                        "type": "array"
-                    }
+                    "long"
                 ]
             }
         ],
-        "name": "ChartUsageStatistics",
-        "namespace": "com.linkedin.pegasus2avro.chart",
+        "name": "MLHyperParam",
+        "namespace": "com.linkedin.pegasus2avro.ml.metadata",
         "type": "record"
     },
     {
         "Aspect": {
-            "name": "notebookInfo"
+            "name": "mlModelDeploymentProperties"
         },
-        "doc": "Information about a Notebook\nNote: This is IN BETA version",
+        "doc": "Properties associated with an ML Model Deployment",
         "fields": [
             {
                 "Searchable": {
                     "/*": {
                         "queryByDefault": true
                     }
                 },
@@ -2782,560 +2887,532 @@
                 "type": [
                     "null",
                     "string"
                 ]
             },
             {
                 "Searchable": {
-                    "boostScore": 10.0,
-                    "enableAutocomplete": true,
-                    "fieldType": "TEXT_PARTIAL"
-                },
-                "doc": "Title of the Notebook",
-                "name": "title",
-                "type": "string"
-            },
-            {
-                "Searchable": {
                     "fieldType": "TEXT",
                     "hasValuesFieldName": "hasDescription"
                 },
                 "default": null,
-                "doc": "Detailed description about the Notebook",
+                "doc": "Documentation of the MLModelDeployment",
                 "name": "description",
                 "type": [
                     "null",
                     "string"
                 ]
             },
             {
-                "doc": "Captures information about who created/last modified/deleted this Notebook and when",
-                "name": "changeAuditStamps",
-                "type": "com.linkedin.pegasus2avro.common.ChangeAuditStamps"
+                "default": null,
+                "doc": "Date when the MLModelDeployment was developed",
+                "name": "createdAt",
+                "type": [
+                    "null",
+                    "long"
+                ]
+            },
+            {
+                "default": null,
+                "doc": "Version of the MLModelDeployment",
+                "name": "version",
+                "type": [
+                    "null",
+                    "com.linkedin.pegasus2avro.common.VersionTag"
+                ]
+            },
+            {
+                "default": null,
+                "doc": "Status of the deployment",
+                "name": "status",
+                "type": [
+                    "null",
+                    {
+                        "doc": "Model endpoint statuses",
+                        "name": "DeploymentStatus",
+                        "namespace": "com.linkedin.pegasus2avro.ml.metadata",
+                        "symbolDocs": {
+                            "CREATING": "Deployments being created.",
+                            "DELETING": "Deployments being deleted.",
+                            "FAILED": "Deployments with an error state.",
+                            "IN_SERVICE": "Deployments that are active.",
+                            "OUT_OF_SERVICE": "Deployments out of service.",
+                            "ROLLING_BACK": "Deployments being reverted to a previous version.",
+                            "UNKNOWN": "Deployments with unknown/unmappable state.",
+                            "UPDATING": "Deployments being updated."
+                        },
+                        "symbols": [
+                            "OUT_OF_SERVICE",
+                            "CREATING",
+                            "UPDATING",
+                            "ROLLING_BACK",
+                            "IN_SERVICE",
+                            "DELETING",
+                            "FAILED",
+                            "UNKNOWN"
+                        ],
+                        "type": "enum"
+                    }
+                ]
             }
         ],
-        "name": "NotebookInfo",
-        "namespace": "com.linkedin.pegasus2avro.notebook",
+        "name": "MLModelDeploymentProperties",
+        "namespace": "com.linkedin.pegasus2avro.ml.metadata",
         "type": "record"
     },
     {
         "Aspect": {
-            "name": "notebookContent"
+            "name": "mlModelCaveatsAndRecommendations"
         },
-        "doc": "Content in a Notebook\nNote: This is IN BETA version",
+        "doc": "This section should list additional concerns that were not covered in the previous sections. For example, did the results suggest any further testing? Were there any relevant groups that were not represented in the evaluation dataset? Are there additional recommendations for model use?",
         "fields": [
             {
-                "default": [],
-                "doc": "The content of a Notebook which is composed by a list of NotebookCell",
-                "name": "cells",
-                "type": {
-                    "items": {
-                        "doc": "A record of all supported cells for a Notebook. Only one type of cell will be non-null.",
+                "default": null,
+                "doc": "This section should list additional concerns that were not covered in the previous sections. For example, did the results suggest any further testing? Were there any relevant groups that were not represented in the evaluation dataset?",
+                "name": "caveats",
+                "type": [
+                    "null",
+                    {
+                        "doc": "This section should list additional concerns that were not covered in the previous sections. For example, did the results suggest any further testing? Were there any relevant groups that were not represented in the evaluation dataset? Are there additional recommendations for model use?",
                         "fields": [
                             {
                                 "default": null,
-                                "doc": "The text cell content. The will be non-null only when all other cell field is null.",
-                                "name": "textCell",
+                                "doc": "Did the results suggest any further testing?",
+                                "name": "needsFurtherTesting",
                                 "type": [
                                     "null",
-                                    {
-                                        "doc": "Text cell in a Notebook, which will present content in text format",
-                                        "fields": [
-                                            {
-                                                "default": null,
-                                                "doc": "Title of the cell",
-                                                "name": "cellTitle",
-                                                "type": [
-                                                    "null",
-                                                    "string"
-                                                ]
-                                            },
-                                            {
-                                                "doc": "Unique id for the cell. This id should be globally unique for a Notebook tool even when there are multiple deployments of it. As an example, Notebook URL could be used here for QueryBook such as 'querybook.com/notebook/773/?cellId=1234'",
-                                                "name": "cellId",
-                                                "type": "string"
-                                            },
-                                            {
-                                                "doc": "Captures information about who created/last modified/deleted this Notebook cell and when",
-                                                "name": "changeAuditStamps",
-                                                "type": "com.linkedin.pegasus2avro.common.ChangeAuditStamps"
-                                            },
-                                            {
-                                                "doc": "The actual text in a TextCell in a Notebook",
-                                                "name": "text",
-                                                "type": "string"
-                                            }
-                                        ],
-                                        "name": "TextCell",
-                                        "namespace": "com.linkedin.pegasus2avro.notebook",
-                                        "type": "record"
-                                    }
+                                    "boolean"
                                 ]
                             },
                             {
                                 "default": null,
-                                "doc": "The query cell content. The will be non-null only when all other cell field is null.",
-                                "name": "queryCell",
+                                "doc": "Caveat Description\nFor ex: Given gender classes are binary (male/not male), which we include as male/female. Further work needed to evaluate across a spectrum of genders.",
+                                "name": "caveatDescription",
                                 "type": [
                                     "null",
-                                    {
-                                        "doc": "Query cell in a Notebook, which will present content in query format",
-                                        "fields": [
-                                            {
-                                                "default": null,
-                                                "doc": "Title of the cell",
-                                                "name": "cellTitle",
-                                                "type": [
-                                                    "null",
-                                                    "string"
-                                                ]
-                                            },
-                                            {
-                                                "doc": "Unique id for the cell. This id should be globally unique for a Notebook tool even when there are multiple deployments of it. As an example, Notebook URL could be used here for QueryBook such as 'querybook.com/notebook/773/?cellId=1234'",
-                                                "name": "cellId",
-                                                "type": "string"
-                                            },
-                                            {
-                                                "doc": "Captures information about who created/last modified/deleted this Notebook cell and when",
-                                                "name": "changeAuditStamps",
-                                                "type": "com.linkedin.pegasus2avro.common.ChangeAuditStamps"
-                                            },
-                                            {
-                                                "doc": "Raw query to explain some specific logic in a Notebook",
-                                                "name": "rawQuery",
-                                                "type": "string"
-                                            },
-                                            {
-                                                "default": null,
-                                                "doc": "Captures information about who last executed this query cell and when",
-                                                "name": "lastExecuted",
-                                                "type": [
-                                                    "null",
-                                                    "com.linkedin.pegasus2avro.common.AuditStamp"
-                                                ]
-                                            }
-                                        ],
-                                        "name": "QueryCell",
-                                        "namespace": "com.linkedin.pegasus2avro.notebook",
-                                        "type": "record"
-                                    }
+                                    "string"
                                 ]
                             },
                             {
                                 "default": null,
-                                "doc": "The chart cell content. The will be non-null only when all other cell field is null.",
-                                "name": "chartCell",
+                                "doc": "Relevant groups that were not represented in the evaluation dataset?",
+                                "name": "groupsNotRepresented",
                                 "type": [
                                     "null",
                                     {
-                                        "doc": "Chart cell in a notebook, which will present content in chart format",
-                                        "fields": [
-                                            {
-                                                "default": null,
-                                                "doc": "Title of the cell",
-                                                "name": "cellTitle",
-                                                "type": [
-                                                    "null",
-                                                    "string"
-                                                ]
-                                            },
-                                            {
-                                                "doc": "Unique id for the cell. This id should be globally unique for a Notebook tool even when there are multiple deployments of it. As an example, Notebook URL could be used here for QueryBook such as 'querybook.com/notebook/773/?cellId=1234'",
-                                                "name": "cellId",
-                                                "type": "string"
-                                            },
-                                            {
-                                                "doc": "Captures information about who created/last modified/deleted this Notebook cell and when",
-                                                "name": "changeAuditStamps",
-                                                "type": "com.linkedin.pegasus2avro.common.ChangeAuditStamps"
-                                            }
-                                        ],
-                                        "name": "ChartCell",
-                                        "namespace": "com.linkedin.pegasus2avro.notebook",
-                                        "type": "record"
+                                        "items": "string",
+                                        "type": "array"
                                     }
                                 ]
-                            },
-                            {
-                                "doc": "The type of this Notebook cell",
-                                "name": "type",
-                                "type": {
-                                    "doc": "Type of Notebook Cell",
-                                    "name": "NotebookCellType",
-                                    "namespace": "com.linkedin.pegasus2avro.notebook",
-                                    "symbolDocs": {
-                                        "CHART_CELL": "CHART Notebook cell type. The cell content is chart only.",
-                                        "QUERY_CELL": "QUERY Notebook cell type. The cell context is query only.",
-                                        "TEXT_CELL": "TEXT Notebook cell type. The cell context is text only."
-                                    },
-                                    "symbols": [
-                                        "TEXT_CELL",
-                                        "QUERY_CELL",
-                                        "CHART_CELL"
-                                    ],
-                                    "type": "enum"
-                                }
                             }
                         ],
-                        "name": "NotebookCell",
-                        "namespace": "com.linkedin.pegasus2avro.notebook",
+                        "name": "CaveatDetails",
+                        "namespace": "com.linkedin.pegasus2avro.ml.metadata",
                         "type": "record"
-                    },
-                    "type": "array"
-                }
+                    }
+                ]
+            },
+            {
+                "default": null,
+                "doc": "Recommendations on where this MLModel should be used.",
+                "name": "recommendations",
+                "type": [
+                    "null",
+                    "string"
+                ]
+            },
+            {
+                "default": null,
+                "doc": "Ideal characteristics of an evaluation dataset for this MLModel",
+                "name": "idealDatasetCharacteristics",
+                "type": [
+                    "null",
+                    {
+                        "items": "string",
+                        "type": "array"
+                    }
+                ]
             }
         ],
-        "name": "NotebookContent",
-        "namespace": "com.linkedin.pegasus2avro.notebook",
+        "name": "CaveatsAndRecommendations",
+        "namespace": "com.linkedin.pegasus2avro.ml.metadata",
         "type": "record"
     },
     {
         "Aspect": {
-            "name": "editableNotebookProperties"
+            "name": "mlMetric"
         },
-        "doc": "Stores editable changes made to properties. This separates changes made from\ningestion pipelines and edits in the UI to avoid accidental overwrites of user-provided data by ingestion pipelines\nNote: This is IN BETA version",
+        "doc": "Properties associated with an ML Metric",
         "fields": [
             {
-                "default": {
-                    "actor": "urn:li:corpuser:unknown",
-                    "impersonator": null,
-                    "message": null,
-                    "time": 0
-                },
-                "doc": "An AuditStamp corresponding to the creation of this resource/association/sub-resource. A value of 0 for time indicates missing data.",
-                "name": "created",
-                "type": "com.linkedin.pegasus2avro.common.AuditStamp"
+                "doc": "Name of the mlMetric",
+                "name": "name",
+                "type": "string"
             },
             {
-                "default": {
-                    "actor": "urn:li:corpuser:unknown",
-                    "impersonator": null,
-                    "message": null,
-                    "time": 0
-                },
-                "doc": "An AuditStamp corresponding to the last modification of this resource/association/sub-resource. If no modification has happened since creation, lastModified should be the same as created. A value of 0 for time indicates missing data.",
-                "name": "lastModified",
-                "type": "com.linkedin.pegasus2avro.common.AuditStamp"
+                "default": null,
+                "doc": "Documentation of the mlMetric",
+                "name": "description",
+                "type": [
+                    "null",
+                    "string"
+                ]
             },
             {
                 "default": null,
-                "doc": "An AuditStamp corresponding to the deletion of this resource/association/sub-resource. Logically, deleted MUST have a later timestamp than creation. It may or may not have the same time as lastModified depending upon the resource/association/sub-resource semantics.",
-                "name": "deleted",
+                "doc": "The value of the mlMetric",
+                "name": "value",
                 "type": [
                     "null",
-                    "com.linkedin.pegasus2avro.common.AuditStamp"
+                    "string"
                 ]
             },
             {
-                "Searchable": {
-                    "fieldName": "editedDescription",
-                    "fieldType": "TEXT"
-                },
                 "default": null,
-                "doc": "Edited documentation of the Notebook",
-                "name": "description",
+                "doc": "Date when the mlMetric was developed",
+                "name": "createdAt",
                 "type": [
                     "null",
-                    "string"
+                    "long"
                 ]
             }
         ],
-        "name": "EditableNotebookProperties",
-        "namespace": "com.linkedin.pegasus2avro.notebook",
+        "name": "MLMetric",
+        "namespace": "com.linkedin.pegasus2avro.ml.metadata",
         "type": "record"
     },
     {
         "Aspect": {
-            "name": "roleMembership"
+            "name": "mlModelTrainingData"
         },
-        "doc": "Carries information about which roles a user is assigned to.",
+        "doc": "Ideally, the MLModel card would contain as much information about the training data as the evaluation data. However, there might be cases where it is not feasible to provide this level of detailed information about the training data. For example, the data may be proprietary, or require a non-disclosure agreement. In these cases, we advocate for basic details about the distributions over groups in the data, as well as any other details that could inform stakeholders on the kinds of biases the model may have encoded.",
         "fields": [
             {
-                "Relationship": {
-                    "/*": {
-                        "entityTypes": [
-                            "dataHubRole"
-                        ],
-                        "name": "IsMemberOfRole"
-                    }
-                },
-                "Urn": "Urn",
-                "name": "roles",
+                "doc": "Details on the dataset(s) used for training the MLModel",
+                "name": "trainingData",
                 "type": {
-                    "items": "string",
+                    "items": "com.linkedin.pegasus2avro.ml.metadata.BaseData",
                     "type": "array"
-                },
-                "urn_is_array": true
+                }
             }
         ],
-        "name": "RoleMembership",
-        "namespace": "com.linkedin.pegasus2avro.identity",
+        "name": "TrainingData",
+        "namespace": "com.linkedin.pegasus2avro.ml.metadata",
         "type": "record"
     },
     {
         "Aspect": {
-            "name": "inviteToken"
+            "name": "mlModelGroupProperties"
         },
-        "doc": "Aspect used to store invite tokens.",
+        "doc": "Properties associated with an ML Model Group",
         "fields": [
             {
-                "doc": "The encrypted invite token.",
-                "name": "token",
-                "type": "string"
+                "Searchable": {
+                    "/*": {
+                        "queryByDefault": true
+                    }
+                },
+                "default": {},
+                "doc": "Custom property bag.",
+                "name": "customProperties",
+                "type": {
+                    "type": "map",
+                    "values": "string"
+                }
             },
             {
                 "Searchable": {
-                    "fieldName": "role",
-                    "fieldType": "KEYWORD",
-                    "hasValuesFieldName": "hasRole"
+                    "fieldType": "TEXT",
+                    "hasValuesFieldName": "hasDescription"
                 },
-                "Urn": "Urn",
                 "default": null,
-                "doc": "The role that this invite token may be associated with",
-                "java": {
-                    "class": "com.linkedin.pegasus2avro.common.urn.Urn"
-                },
-                "name": "role",
+                "doc": "Documentation of the MLModelGroup",
+                "name": "description",
                 "type": [
                     "null",
                     "string"
                 ]
+            },
+            {
+                "default": null,
+                "doc": "Date when the MLModelGroup was developed",
+                "name": "createdAt",
+                "type": [
+                    "null",
+                    "long"
+                ]
+            },
+            {
+                "default": null,
+                "doc": "Version of the MLModelGroup",
+                "name": "version",
+                "type": [
+                    "null",
+                    "com.linkedin.pegasus2avro.common.VersionTag"
+                ]
             }
         ],
-        "name": "InviteToken",
-        "namespace": "com.linkedin.pegasus2avro.identity",
+        "name": "MLModelGroupProperties",
+        "namespace": "com.linkedin.pegasus2avro.ml.metadata",
         "type": "record"
     },
     {
         "Aspect": {
-            "name": "groupMembership"
+            "name": "mlModelMetrics"
         },
-        "doc": "Carries information about the CorpGroups a user is in.",
+        "doc": "Metrics to be featured for the MLModel.",
         "fields": [
             {
-                "Relationship": {
-                    "/*": {
-                        "entityTypes": [
-                            "corpGroup"
-                        ],
-                        "name": "IsMemberOfGroup"
+                "default": null,
+                "doc": "Measures of MLModel performance",
+                "name": "performanceMeasures",
+                "type": [
+                    "null",
+                    {
+                        "items": "string",
+                        "type": "array"
                     }
-                },
-                "Urn": "Urn",
-                "name": "groups",
-                "type": {
-                    "items": "string",
-                    "type": "array"
-                },
-                "urn_is_array": true
-            }
-        ],
-        "name": "GroupMembership",
-        "namespace": "com.linkedin.pegasus2avro.identity",
-        "type": "record"
-    },
-    {
-        "Aspect": {
-            "name": "nativeGroupMembership"
-        },
-        "doc": "Carries information about the native CorpGroups a user is in.",
-        "fields": [
+                ]
+            },
             {
-                "Relationship": {
-                    "/*": {
-                        "entityTypes": [
-                            "corpGroup"
-                        ],
-                        "name": "IsMemberOfNativeGroup"
+                "default": null,
+                "doc": "Decision Thresholds used (if any)?",
+                "name": "decisionThreshold",
+                "type": [
+                    "null",
+                    {
+                        "items": "string",
+                        "type": "array"
                     }
-                },
-                "Urn": "Urn",
-                "name": "nativeGroups",
-                "type": {
-                    "items": "string",
-                    "type": "array"
-                },
-                "urn_is_array": true
+                ]
             }
         ],
-        "name": "NativeGroupMembership",
-        "namespace": "com.linkedin.pegasus2avro.identity",
+        "name": "Metrics",
+        "namespace": "com.linkedin.pegasus2avro.ml.metadata",
         "type": "record"
     },
     {
         "Aspect": {
-            "name": "corpGroupEditableInfo"
+            "name": "mlModelFactorPrompts"
         },
-        "doc": "Group information that can be edited from UI",
+        "doc": "Prompts which affect the performance of the MLModel",
         "fields": [
             {
-                "Searchable": {
-                    "fieldName": "editedDescription",
-                    "fieldType": "TEXT"
-                },
-                "default": null,
-                "doc": "A description of the group",
-                "name": "description",
-                "type": [
-                    "null",
-                    "string"
-                ]
-            },
-            {
-                "default": "https://raw.githubusercontent.com/datahub-project/datahub/master/datahub-web-react/src/images/default_avatar.png",
-                "doc": "A URL which points to a picture which user wants to set as the photo for the group",
-                "java": {
-                    "class": "com.linkedin.pegasus2avro.common.url.Url",
-                    "coercerClass": "com.linkedin.pegasus2avro.common.url.UrlCoercer"
-                },
-                "name": "pictureLink",
-                "type": "string"
-            },
-            {
                 "default": null,
-                "doc": "Slack channel for the group",
-                "name": "slack",
+                "doc": "What are foreseeable salient factors for which MLModel performance may vary, and how were these determined?",
+                "name": "relevantFactors",
                 "type": [
                     "null",
-                    "string"
+                    {
+                        "items": {
+                            "doc": "Factors affecting the performance of the MLModel.",
+                            "fields": [
+                                {
+                                    "default": null,
+                                    "doc": "Groups refers to distinct categories with similar characteristics that are present in the evaluation data instances.\nFor human-centric machine learning MLModels, groups are people who share one or multiple characteristics.",
+                                    "name": "groups",
+                                    "type": [
+                                        "null",
+                                        {
+                                            "items": "string",
+                                            "type": "array"
+                                        }
+                                    ]
+                                },
+                                {
+                                    "default": null,
+                                    "doc": "The performance of a MLModel can vary depending on what instruments were used to capture the input to the MLModel.\nFor example, a face detection model may perform differently depending on the camera's hardware and software,\nincluding lens, image stabilization, high dynamic range techniques, and background blurring for portrait mode.",
+                                    "name": "instrumentation",
+                                    "type": [
+                                        "null",
+                                        {
+                                            "items": "string",
+                                            "type": "array"
+                                        }
+                                    ]
+                                },
+                                {
+                                    "default": null,
+                                    "doc": "A further factor affecting MLModel performance is the environment in which it is deployed.",
+                                    "name": "environment",
+                                    "type": [
+                                        "null",
+                                        {
+                                            "items": "string",
+                                            "type": "array"
+                                        }
+                                    ]
+                                }
+                            ],
+                            "name": "MLModelFactors",
+                            "namespace": "com.linkedin.pegasus2avro.ml.metadata",
+                            "type": "record"
+                        },
+                        "type": "array"
+                    }
                 ]
             },
             {
                 "default": null,
-                "doc": "Email address to contact the group",
-                "name": "email",
+                "doc": "Which factors are being reported, and why were these chosen?",
+                "name": "evaluationFactors",
                 "type": [
                     "null",
-                    "string"
+                    {
+                        "items": "com.linkedin.pegasus2avro.ml.metadata.MLModelFactors",
+                        "type": "array"
+                    }
                 ]
             }
         ],
-        "name": "CorpGroupEditableInfo",
-        "namespace": "com.linkedin.pegasus2avro.identity",
+        "name": "MLModelFactorPrompts",
+        "namespace": "com.linkedin.pegasus2avro.ml.metadata",
         "type": "record"
     },
     {
         "Aspect": {
-            "EntityUrns": [
-                "com.linkedin.pegasus2avro.common.CorpuserUrn"
-            ],
-            "name": "corpUserEditableInfo"
+            "name": "mlModelEthicalConsiderations"
         },
-        "doc": "Linkedin corp user information that can be edited from UI",
+        "doc": "This section is intended to demonstrate the ethical considerations that went into MLModel development, surfacing ethical challenges and solutions to stakeholders.",
         "fields": [
             {
                 "default": null,
-                "doc": "About me section of the user",
-                "name": "aboutMe",
+                "doc": "Does the MLModel use any sensitive data (e.g., protected classes)?",
+                "name": "data",
                 "type": [
                     "null",
-                    "string"
+                    {
+                        "items": "string",
+                        "type": "array"
+                    }
                 ]
             },
             {
-                "Searchable": {
-                    "/*": {
-                        "fieldType": "TEXT"
+                "default": null,
+                "doc": " Is the MLModel intended to inform decisions about matters central to human life or flourishing - e.g., health or safety? Or could it be used in such a way?",
+                "name": "humanLife",
+                "type": [
+                    "null",
+                    {
+                        "items": "string",
+                        "type": "array"
                     }
-                },
-                "default": [],
-                "doc": "Teams that the user belongs to e.g. Metadata",
-                "name": "teams",
-                "type": {
-                    "items": "string",
-                    "type": "array"
-                }
+                ]
             },
             {
-                "Searchable": {
-                    "/*": {
-                        "fieldType": "TEXT"
+                "default": null,
+                "doc": "What risk mitigation strategies were used during MLModel development?",
+                "name": "mitigations",
+                "type": [
+                    "null",
+                    {
+                        "items": "string",
+                        "type": "array"
                     }
-                },
-                "default": [],
-                "doc": "Skills that the user possesses e.g. Machine Learning",
-                "name": "skills",
-                "type": {
-                    "items": "string",
-                    "type": "array"
-                }
+                ]
             },
             {
-                "default": "https://raw.githubusercontent.com/datahub-project/datahub/master/datahub-web-react/src/images/default_avatar.png",
-                "doc": "A URL which points to a picture which user wants to set as a profile photo",
-                "java": {
-                    "class": "com.linkedin.pegasus2avro.common.url.Url",
-                    "coercerClass": "com.linkedin.pegasus2avro.common.url.UrlCoercer"
-                },
-                "name": "pictureLink",
-                "type": "string"
+                "default": null,
+                "doc": "What risks may be present in MLModel usage? Try to identify the potential recipients, likelihood, and magnitude of harms. If these cannot be determined, note that they were considered but remain unknown.",
+                "name": "risksAndHarms",
+                "type": [
+                    "null",
+                    {
+                        "items": "string",
+                        "type": "array"
+                    }
+                ]
             },
             {
-                "Searchable": {
-                    "boostScore": 10.0,
-                    "fieldType": "TEXT_PARTIAL",
-                    "queryByDefault": true
-                },
                 "default": null,
-                "doc": "DataHub-native display name",
-                "name": "displayName",
+                "doc": "Are there any known MLModel use cases that are especially fraught? This may connect directly to the intended use section",
+                "name": "useCases",
                 "type": [
                     "null",
-                    "string"
+                    {
+                        "items": "string",
+                        "type": "array"
+                    }
                 ]
-            },
+            }
+        ],
+        "name": "EthicalConsiderations",
+        "namespace": "com.linkedin.pegasus2avro.ml.metadata",
+        "type": "record"
+    },
+    {
+        "Aspect": {
+            "name": "mlFeatureProperties"
+        },
+        "doc": "Properties associated with a MLFeature",
+        "fields": [
             {
+                "Searchable": {
+                    "fieldType": "TEXT",
+                    "hasValuesFieldName": "hasDescription"
+                },
                 "default": null,
-                "doc": "DataHub-native Title, e.g. 'Software Engineer'",
-                "name": "title",
+                "doc": "Documentation of the MLFeature",
+                "name": "description",
                 "type": [
                     "null",
                     "string"
                 ]
             },
             {
                 "default": null,
-                "doc": "Slack handle for the user",
-                "name": "slack",
+                "doc": "Data Type of the MLFeature",
+                "name": "dataType",
                 "type": [
                     "null",
-                    "string"
+                    "com.linkedin.pegasus2avro.common.MLFeatureDataType"
                 ]
             },
             {
                 "default": null,
-                "doc": "Phone number to contact the user",
-                "name": "phone",
+                "doc": "Version of the MLFeature",
+                "name": "version",
                 "type": [
                     "null",
-                    "string"
+                    "com.linkedin.pegasus2avro.common.VersionTag"
                 ]
             },
             {
+                "Relationship": {
+                    "/*": {
+                        "entityTypes": [
+                            "dataset"
+                        ],
+                        "isLineage": true,
+                        "name": "DerivedFrom"
+                    }
+                },
+                "Urn": "Urn",
                 "default": null,
-                "doc": "Email address to contact the user",
-                "name": "email",
+                "doc": "Source of the MLFeature",
+                "name": "sources",
                 "type": [
                     "null",
-                    "string"
-                ]
+                    {
+                        "items": "string",
+                        "type": "array"
+                    }
+                ],
+                "urn_is_array": true
             }
         ],
-        "name": "CorpUserEditableInfo",
-        "namespace": "com.linkedin.pegasus2avro.identity",
+        "name": "MLFeatureProperties",
+        "namespace": "com.linkedin.pegasus2avro.ml.metadata",
         "type": "record"
     },
     {
         "Aspect": {
-            "EntityUrns": [
-                "com.linkedin.pegasus2avro.common.CorpuserUrn"
-            ],
-            "name": "corpUserInfo"
+            "name": "mlModelProperties"
         },
-        "doc": "Linkedin corp user information",
+        "doc": "Properties associated with a ML Model",
         "fields": [
             {
                 "Searchable": {
                     "/*": {
                         "queryByDefault": true
                     }
                 },
@@ -3344,417 +3421,306 @@
                 "name": "customProperties",
                 "type": {
                     "type": "map",
                     "values": "string"
                 }
             },
             {
-                "Searchable": {
-                    "fieldType": "BOOLEAN",
-                    "weightsPerFieldValue": {
-                        "true": 2.0
-                    }
-                },
-                "doc": "Deprecated! Use CorpUserStatus instead. Whether the corpUser is active, ref: https://iwww.corp.linkedin.com/wiki/cf/display/GTSD/Accessing+Active+Directory+via+LDAP+tools",
-                "name": "active",
-                "type": "boolean"
-            },
-            {
-                "Searchable": {
-                    "boostScore": 10.0,
-                    "enableAutocomplete": true,
-                    "fieldType": "TEXT_PARTIAL",
-                    "queryByDefault": true
-                },
                 "default": null,
-                "doc": "displayName of this user ,  e.g.  Hang Zhang(DataHQ)",
-                "name": "displayName",
-                "type": [
-                    "null",
-                    "string"
-                ]
-            },
-            {
-                "Searchable": {
-                    "fieldType": "KEYWORD",
-                    "queryByDefault": true
+                "doc": "URL where the reference exist",
+                "java": {
+                    "class": "com.linkedin.pegasus2avro.common.url.Url",
+                    "coercerClass": "com.linkedin.pegasus2avro.common.url.UrlCoercer"
                 },
-                "default": null,
-                "doc": "email address of this user",
-                "name": "email",
+                "name": "externalUrl",
                 "type": [
                     "null",
                     "string"
                 ]
             },
             {
                 "Searchable": {
-                    "fieldType": "KEYWORD",
-                    "queryByDefault": true
-                },
-                "default": null,
-                "doc": "title of this user",
-                "name": "title",
-                "type": [
-                    "null",
-                    "string"
-                ]
-            },
-            {
-                "Relationship": {
-                    "entityTypes": [
-                        "corpuser"
-                    ],
-                    "name": "ReportsTo"
-                },
-                "Searchable": {
-                    "fieldName": "managerLdap",
-                    "fieldType": "URN",
-                    "queryByDefault": true
+                    "fieldType": "TEXT",
+                    "hasValuesFieldName": "hasDescription"
                 },
-                "Urn": "CorpuserUrn",
                 "default": null,
-                "doc": "direct manager of this user",
-                "java": {
-                    "class": "com.linkedin.pegasus2avro.common.urn.CorpuserUrn"
-                },
-                "name": "managerUrn",
+                "doc": "Documentation of the MLModel",
+                "name": "description",
                 "type": [
                     "null",
                     "string"
                 ]
             },
             {
                 "default": null,
-                "doc": "department id this user belong to",
-                "name": "departmentId",
+                "doc": "Date when the MLModel was developed",
+                "name": "date",
                 "type": [
                     "null",
                     "long"
                 ]
             },
             {
                 "default": null,
-                "doc": "department name this user belong to",
-                "name": "departmentName",
+                "doc": "Version of the MLModel",
+                "name": "version",
                 "type": [
                     "null",
-                    "string"
+                    "com.linkedin.pegasus2avro.common.VersionTag"
                 ]
             },
             {
+                "Searchable": {
+                    "fieldType": "TEXT_PARTIAL"
+                },
                 "default": null,
-                "doc": "first name of this user",
-                "name": "firstName",
+                "doc": "Type of Algorithm or MLModel such as whether it is a Naive Bayes classifier, Convolutional Neural Network, etc",
+                "name": "type",
                 "type": [
                     "null",
                     "string"
                 ]
             },
             {
                 "default": null,
-                "doc": "last name of this user",
-                "name": "lastName",
+                "doc": "Hyper Parameters of the MLModel\n\nNOTE: these are deprecated in favor of hyperParams",
+                "name": "hyperParameters",
                 "type": [
                     "null",
-                    "string"
+                    {
+                        "type": "map",
+                        "values": [
+                            "string",
+                            "int",
+                            "float",
+                            "double",
+                            "boolean"
+                        ]
+                    }
                 ]
             },
             {
-                "Searchable": {
-                    "boostScore": 10.0,
-                    "enableAutocomplete": true,
-                    "fieldType": "TEXT_PARTIAL",
-                    "queryByDefault": true
-                },
                 "default": null,
-                "doc": "Common name of this user, format is firstName + lastName (split by a whitespace)",
-                "name": "fullName",
+                "doc": "Hyperparameters of the MLModel",
+                "name": "hyperParams",
                 "type": [
                     "null",
-                    "string"
+                    {
+                        "items": "com.linkedin.pegasus2avro.ml.metadata.MLHyperParam",
+                        "type": "array"
+                    }
                 ]
             },
             {
                 "default": null,
-                "doc": "two uppercase letters country code. e.g.  US",
-                "name": "countryCode",
+                "doc": "Metrics of the MLModel used in training",
+                "name": "trainingMetrics",
                 "type": [
                     "null",
-                    "string"
+                    {
+                        "items": "com.linkedin.pegasus2avro.ml.metadata.MLMetric",
+                        "type": "array"
+                    }
                 ]
-            }
-        ],
-        "name": "CorpUserInfo",
-        "namespace": "com.linkedin.pegasus2avro.identity",
-        "type": "record"
-    },
-    {
-        "Aspect": {
-            "EntityUrns": [
-                "com.linkedin.pegasus2avro.common.CorpuserUrn"
-            ],
-            "name": "corpUserCredentials"
-        },
-        "doc": "Corp user credentials",
-        "fields": [
-            {
-                "doc": "Salt used to hash password",
-                "name": "salt",
-                "type": "string"
-            },
-            {
-                "doc": "Hashed password generated by concatenating salt and password, then hashing",
-                "name": "hashedPassword",
-                "type": "string"
             },
             {
                 "default": null,
-                "doc": "Optional token needed to reset a user's password. Can only be set by the admin.",
-                "name": "passwordResetToken",
+                "doc": "Metrics of the MLModel used in production",
+                "name": "onlineMetrics",
                 "type": [
                     "null",
-                    "string"
+                    {
+                        "items": "com.linkedin.pegasus2avro.ml.metadata.MLMetric",
+                        "type": "array"
+                    }
                 ]
             },
             {
+                "Relationship": {
+                    "/*": {
+                        "entityTypes": [
+                            "mlFeature"
+                        ],
+                        "isLineage": true,
+                        "name": "Consumes"
+                    }
+                },
+                "Urn": "MLFeatureUrn",
                 "default": null,
-                "doc": "When the password reset token expires.",
-                "name": "passwordResetTokenExpirationTimeMillis",
+                "doc": "List of features used for MLModel training",
+                "name": "mlFeatures",
                 "type": [
                     "null",
-                    "long"
-                ]
-            }
-        ],
-        "name": "CorpUserCredentials",
-        "namespace": "com.linkedin.pegasus2avro.identity",
-        "type": "record"
-    },
-    {
-        "Aspect": {
-            "name": "corpUserSettings"
-        },
-        "doc": "Settings that a user can customize through the datahub ui",
-        "fields": [
+                    {
+                        "items": "string",
+                        "type": "array"
+                    }
+                ],
+                "urn_is_array": true
+            },
             {
-                "doc": "Settings for a user around the appearance of their DataHub U",
-                "name": "appearance",
+                "default": [],
+                "doc": "Tags for the MLModel",
+                "name": "tags",
                 "type": {
-                    "doc": "Settings for a user around the appearance of their DataHub UI",
-                    "fields": [
-                        {
-                            "default": null,
-                            "doc": "Flag whether the user should see a homepage with only datasets, charts and dashboards. Intended for users\nwho have less operational use cases for the datahub tool.",
-                            "name": "showSimplifiedHomepage",
-                            "type": [
-                                "null",
-                                "boolean"
-                            ]
-                        }
-                    ],
-                    "name": "CorpUserAppearanceSettings",
-                    "namespace": "com.linkedin.pegasus2avro.identity",
-                    "type": "record"
+                    "items": "string",
+                    "type": "array"
                 }
             },
             {
-                "default": null,
-                "doc": "User preferences for the Views feature.",
-                "name": "views",
-                "type": [
-                    "null",
-                    {
-                        "doc": "Settings related to the 'Views' feature.",
-                        "fields": [
-                            {
-                                "Urn": "Urn",
-                                "default": null,
-                                "doc": "The default View which is selected for the user.\nIf none is chosen, then this value will be left blank.",
-                                "java": {
-                                    "class": "com.linkedin.pegasus2avro.common.urn.Urn"
-                                },
-                                "name": "defaultView",
-                                "type": [
-                                    "null",
-                                    "string"
-                                ]
-                            }
+                "Relationship": {
+                    "/*": {
+                        "entityTypes": [
+                            "mlModelDeployment"
                         ],
-                        "name": "CorpUserViewsSettings",
-                        "namespace": "com.linkedin.pegasus2avro.identity",
-                        "type": "record"
+                        "name": "DeployedTo"
                     }
-                ]
-            }
-        ],
-        "name": "CorpUserSettings",
-        "namespace": "com.linkedin.pegasus2avro.identity",
-        "type": "record"
-    },
-    {
-        "Aspect": {
-            "name": "corpUserStatus"
-        },
-        "doc": "The status of the user, e.g. provisioned, active, suspended, etc.",
-        "fields": [
-            {
-                "Searchable": {
-                    "fieldType": "KEYWORD"
                 },
-                "doc": "Status of the user, e.g. PROVISIONED / ACTIVE / SUSPENDED",
-                "name": "status",
-                "type": "string"
-            },
-            {
-                "doc": "Audit stamp containing who last modified the status and when.",
-                "name": "lastModified",
-                "type": "com.linkedin.pegasus2avro.common.AuditStamp"
-            }
-        ],
-        "name": "CorpUserStatus",
-        "namespace": "com.linkedin.pegasus2avro.identity",
-        "type": "record"
-    },
-    {
-        "Aspect": {
-            "EntityUrns": [
-                "com.linkedin.pegasus2avro.common.CorpGroupUrn"
-            ],
-            "name": "corpGroupInfo"
-        },
-        "doc": "Information about a Corp Group ingested from a third party source",
-        "fields": [
-            {
-                "Searchable": {
-                    "boostScore": 10.0,
-                    "enableAutocomplete": true,
-                    "fieldType": "TEXT_PARTIAL",
-                    "queryByDefault": true
-                },
-                "default": null,
-                "doc": "The name of the group.",
-                "name": "displayName",
-                "type": [
-                    "null",
-                    "string"
-                ]
-            },
-            {
+                "Urn": "Urn",
                 "default": null,
-                "doc": "email of this group",
-                "name": "email",
+                "doc": "Deployments for the MLModel",
+                "name": "deployments",
                 "type": [
                     "null",
-                    "string"
-                ]
+                    {
+                        "items": "string",
+                        "type": "array"
+                    }
+                ],
+                "urn_is_array": true
             },
             {
                 "Relationship": {
                     "/*": {
                         "entityTypes": [
-                            "corpuser"
+                            "dataJob"
                         ],
-                        "name": "OwnedBy"
+                        "isLineage": true,
+                        "name": "TrainedBy"
                     }
                 },
-                "Urn": "CorpuserUrn",
-                "deprecated": true,
-                "doc": "owners of this group\nDeprecated! Replaced by Ownership aspect.",
-                "name": "admins",
-                "type": {
-                    "items": "string",
-                    "type": "array"
-                },
+                "Urn": "Urn",
+                "default": null,
+                "doc": "List of jobs (if any) used to train the model",
+                "name": "trainingJobs",
+                "type": [
+                    "null",
+                    {
+                        "items": "string",
+                        "type": "array"
+                    }
+                ],
                 "urn_is_array": true
             },
             {
                 "Relationship": {
                     "/*": {
                         "entityTypes": [
-                            "corpuser"
+                            "dataJob"
                         ],
-                        "name": "IsPartOf"
+                        "isLineage": true,
+                        "isUpstream": false,
+                        "name": "UsedBy"
                     }
                 },
-                "Urn": "CorpuserUrn",
-                "deprecated": true,
-                "doc": "List of ldap urn in this group.\nDeprecated! Replaced by GroupMembership aspect.",
-                "name": "members",
-                "type": {
-                    "items": "string",
-                    "type": "array"
-                },
+                "Urn": "Urn",
+                "default": null,
+                "doc": "List of jobs (if any) that use the model",
+                "name": "downstreamJobs",
+                "type": [
+                    "null",
+                    {
+                        "items": "string",
+                        "type": "array"
+                    }
+                ],
                 "urn_is_array": true
             },
             {
                 "Relationship": {
                     "/*": {
                         "entityTypes": [
-                            "corpGroup"
+                            "mlModelGroup"
                         ],
-                        "name": "IsPartOf"
+                        "isLineage": true,
+                        "isUpstream": false,
+                        "name": "MemberOf"
                     }
                 },
-                "Urn": "CorpGroupUrn",
-                "deprecated": true,
-                "doc": "List of groups in this group.\nDeprecated! This field is unused.",
+                "Urn": "Urn",
+                "default": null,
+                "doc": "Groups the model belongs to",
                 "name": "groups",
-                "type": {
-                    "items": "string",
-                    "type": "array"
-                },
+                "type": [
+                    "null",
+                    {
+                        "items": "string",
+                        "type": "array"
+                    }
+                ],
                 "urn_is_array": true
-            },
+            }
+        ],
+        "name": "MLModelProperties",
+        "namespace": "com.linkedin.pegasus2avro.ml.metadata",
+        "type": "record"
+    },
+    {
+        "Aspect": {
+            "name": "editableMlFeatureProperties"
+        },
+        "doc": "Properties associated with a MLFeature editable from the UI",
+        "fields": [
             {
                 "Searchable": {
-                    "fieldType": "TEXT_PARTIAL"
+                    "fieldName": "editedDescription",
+                    "fieldType": "TEXT"
                 },
                 "default": null,
-                "doc": "A description of the group.",
+                "doc": "Documentation of the MLFeature",
                 "name": "description",
                 "type": [
                     "null",
                     "string"
                 ]
-            },
-            {
-                "default": null,
-                "doc": "Slack channel for the group",
-                "name": "slack",
-                "type": [
-                    "null",
-                    "string"
-                ]
-            },
+            }
+        ],
+        "name": "EditableMLFeatureProperties",
+        "namespace": "com.linkedin.pegasus2avro.ml.metadata",
+        "type": "record"
+    },
+    {
+        "Aspect": {
+            "name": "editableMlModelGroupProperties"
+        },
+        "doc": "Properties associated with an ML Model Group editable from the UI",
+        "fields": [
             {
                 "Searchable": {
-                    "/time": {
-                        "fieldName": "createdTime",
-                        "fieldType": "DATETIME"
-                    }
+                    "fieldName": "editedDescription",
+                    "fieldType": "TEXT"
                 },
                 "default": null,
-                "doc": "Created Audit stamp",
-                "name": "created",
+                "doc": "Documentation of the ml model group",
+                "name": "description",
                 "type": [
                     "null",
-                    "com.linkedin.pegasus2avro.common.AuditStamp"
+                    "string"
                 ]
             }
         ],
-        "name": "CorpGroupInfo",
-        "namespace": "com.linkedin.pegasus2avro.identity",
+        "name": "EditableMLModelGroupProperties",
+        "namespace": "com.linkedin.pegasus2avro.ml.metadata",
         "type": "record"
     },
     {
         "Aspect": {
-            "name": "dataPlatformInstanceProperties"
+            "name": "mlFeatureTableProperties"
         },
-        "doc": "Properties associated with a Data Platform Instance",
+        "doc": "Properties associated with a MLFeatureTable",
         "fields": [
             {
                 "Searchable": {
                     "/*": {
                         "queryByDefault": true
                     }
                 },
@@ -3763,617 +3729,453 @@
                 "name": "customProperties",
                 "type": {
                     "type": "map",
                     "values": "string"
                 }
             },
             {
-                "default": null,
-                "doc": "URL where the reference exist",
-                "java": {
-                    "class": "com.linkedin.pegasus2avro.common.url.Url",
-                    "coercerClass": "com.linkedin.pegasus2avro.common.url.UrlCoercer"
+                "Searchable": {
+                    "fieldType": "TEXT",
+                    "hasValuesFieldName": "hasDescription"
                 },
-                "name": "externalUrl",
+                "default": null,
+                "doc": "Documentation of the MLFeatureTable",
+                "name": "description",
                 "type": [
                     "null",
                     "string"
                 ]
             },
             {
+                "Relationship": {
+                    "/*": {
+                        "entityTypes": [
+                            "mlFeature"
+                        ],
+                        "name": "Contains"
+                    }
+                },
                 "Searchable": {
-                    "boostScore": 10.0,
-                    "enableAutocomplete": true,
-                    "fieldType": "TEXT_PARTIAL"
+                    "/*": {
+                        "fieldName": "features",
+                        "fieldType": "URN"
+                    }
                 },
+                "Urn": "Urn",
                 "default": null,
-                "doc": "Display name of the Data Platform Instance",
-                "name": "name",
+                "doc": "List of features contained in the feature table",
+                "name": "mlFeatures",
                 "type": [
                     "null",
-                    "string"
-                ]
+                    {
+                        "items": "string",
+                        "type": "array"
+                    }
+                ],
+                "urn_is_array": true
             },
             {
+                "Relationship": {
+                    "/*": {
+                        "entityTypes": [
+                            "mlPrimaryKey"
+                        ],
+                        "name": "KeyedBy"
+                    }
+                },
                 "Searchable": {
-                    "fieldType": "TEXT",
-                    "hasValuesFieldName": "hasDescription"
+                    "/*": {
+                        "fieldName": "primaryKeys",
+                        "fieldType": "URN"
+                    }
                 },
+                "Urn": "Urn",
                 "default": null,
-                "doc": "Documentation of the Data Platform Instance",
-                "name": "description",
+                "doc": "List of primary keys in the feature table (if multiple, assumed to act as a composite key)",
+                "name": "mlPrimaryKeys",
                 "type": [
                     "null",
-                    "string"
-                ]
+                    {
+                        "items": "string",
+                        "type": "array"
+                    }
+                ],
+                "urn_is_array": true
             }
         ],
-        "name": "DataPlatformInstanceProperties",
-        "namespace": "com.linkedin.pegasus2avro.dataplatforminstance",
+        "name": "MLFeatureTableProperties",
+        "namespace": "com.linkedin.pegasus2avro.ml.metadata",
         "type": "record"
     },
     {
         "Aspect": {
-            "name": "assertionRunEvent",
-            "type": "timeseries"
+            "name": "mlModelQuantitativeAnalyses"
         },
-        "doc": "An event representing the current status of evaluating an assertion on a batch.\nAssertionRunEvent should be used for reporting the status of a run as an assertion evaluation progresses.",
+        "doc": "Quantitative analyses should be disaggregated, that is, broken down by the chosen factors. Quantitative analyses should provide the results of evaluating the MLModel according to the chosen metrics, providing confidence interval values when possible.",
         "fields": [
             {
-                "doc": "The event timestamp field as epoch at UTC in milli seconds.",
-                "name": "timestampMillis",
-                "type": "long"
-            },
-            {
                 "default": null,
-                "doc": "Granularity of the event if applicable",
-                "name": "eventGranularity",
+                "doc": "Link to a dashboard with results showing how the MLModel performed with respect to each factor",
+                "name": "unitaryResults",
                 "type": [
                     "null",
-                    "com.linkedin.pegasus2avro.timeseries.TimeWindowSize"
-                ]
-            },
-            {
-                "default": {
-                    "partition": "FULL_TABLE_SNAPSHOT",
-                    "timePartition": null,
-                    "type": "FULL_TABLE"
-                },
-                "doc": "The optional partition specification.",
-                "name": "partitionSpec",
-                "type": [
-                    "com.linkedin.pegasus2avro.timeseries.PartitionSpec",
-                    "null"
+                    "string"
                 ]
             },
             {
                 "default": null,
-                "doc": "The optional messageId, if provided serves as a custom user-defined unique identifier for an aspect value.",
-                "name": "messageId",
+                "doc": "Link to a dashboard with results showing how the MLModel performed with respect to the intersection of evaluated factors?",
+                "name": "intersectionalResults",
                 "type": [
                     "null",
                     "string"
                 ]
-            },
-            {
-                "doc": " Native (platform-specific) identifier for this run",
-                "name": "runId",
-                "type": "string"
-            },
-            {
-                "TimeseriesField": {},
-                "Urn": "Urn",
-                "java": {
-                    "class": "com.linkedin.pegasus2avro.common.urn.Urn"
-                },
-                "name": "assertionUrn",
-                "type": "string"
-            },
-            {
-                "TimeseriesField": {},
-                "Urn": "Urn",
-                "java": {
-                    "class": "com.linkedin.pegasus2avro.common.urn.Urn"
-                },
-                "name": "asserteeUrn",
-                "type": "string"
-            },
+            }
+        ],
+        "name": "QuantitativeAnalyses",
+        "namespace": "com.linkedin.pegasus2avro.ml.metadata",
+        "type": "record"
+    },
+    {
+        "Aspect": {
+            "name": "intendedUse"
+        },
+        "doc": "Intended Use for the ML Model",
+        "fields": [
             {
                 "default": null,
-                "doc": "Specification of the batch which this run is evaluating",
-                "name": "batchSpec",
+                "doc": "Primary Use cases for the MLModel.",
+                "name": "primaryUses",
                 "type": [
                     "null",
                     {
-                        "doc": "A batch on which certain operations, e.g. data quality evaluation, is done.",
-                        "fields": [
-                            {
-                                "Searchable": {
-                                    "/*": {
-                                        "queryByDefault": true
-                                    }
-                                },
-                                "default": {},
-                                "doc": "Custom property bag.",
-                                "name": "customProperties",
-                                "type": {
-                                    "type": "map",
-                                    "values": "string"
-                                }
-                            },
-                            {
-                                "default": null,
-                                "doc": "The native identifier as specified by the system operating on the batch.",
-                                "name": "nativeBatchId",
-                                "type": [
-                                    "null",
-                                    "string"
-                                ]
-                            },
-                            {
-                                "default": null,
-                                "doc": "A query that identifies a batch of data",
-                                "name": "query",
-                                "type": [
-                                    "null",
-                                    "string"
-                                ]
-                            },
-                            {
-                                "default": null,
-                                "doc": "Any limit to the number of rows in the batch, if applied",
-                                "name": "limit",
-                                "type": [
-                                    "null",
-                                    "int"
-                                ]
-                            }
-                        ],
-                        "name": "BatchSpec",
-                        "namespace": "com.linkedin.pegasus2avro.assertion",
-                        "type": "record"
+                        "items": "string",
+                        "type": "array"
                     }
                 ]
             },
             {
-                "TimeseriesField": {},
-                "doc": "The status of the assertion run as per this timeseries event.",
-                "name": "status",
-                "type": {
-                    "name": "AssertionRunStatus",
-                    "namespace": "com.linkedin.pegasus2avro.assertion",
-                    "symbolDocs": {
-                        "COMPLETE": "The Assertion Run has completed"
-                    },
-                    "symbols": [
-                        "COMPLETE"
-                    ],
-                    "type": "enum"
-                }
-            },
-            {
                 "default": null,
-                "doc": "Results of assertion, present if the status is COMPLETE",
-                "name": "result",
+                "doc": "Primary Intended Users - For example, was the MLModel developed for entertainment purposes, for hobbyists, or enterprise solutions?",
+                "name": "primaryUsers",
                 "type": [
                     "null",
                     {
-                        "doc": "The result of running an assertion",
-                        "fields": [
-                            {
-                                "TimeseriesField": {},
-                                "doc": " The final result, e.g. either SUCCESS or FAILURE.",
-                                "name": "type",
-                                "type": {
-                                    "name": "AssertionResultType",
-                                    "namespace": "com.linkedin.pegasus2avro.assertion",
-                                    "symbolDocs": {
-                                        "FAILURE": " The Assertion Failed",
-                                        "SUCCESS": " The Assertion Succeeded"
-                                    },
-                                    "symbols": [
-                                        "SUCCESS",
-                                        "FAILURE"
-                                    ],
-                                    "type": "enum"
-                                }
-                            },
-                            {
-                                "default": null,
-                                "doc": "Number of rows for evaluated batch",
-                                "name": "rowCount",
-                                "type": [
-                                    "null",
-                                    "long"
-                                ]
-                            },
-                            {
-                                "default": null,
-                                "doc": "Number of rows with missing value for evaluated batch",
-                                "name": "missingCount",
-                                "type": [
-                                    "null",
-                                    "long"
-                                ]
-                            },
-                            {
-                                "default": null,
-                                "doc": "Number of rows with unexpected value for evaluated batch",
-                                "name": "unexpectedCount",
-                                "type": [
-                                    "null",
-                                    "long"
-                                ]
-                            },
-                            {
-                                "default": null,
-                                "doc": "Observed aggregate value for evaluated batch",
-                                "name": "actualAggValue",
-                                "type": [
-                                    "null",
-                                    "float"
-                                ]
-                            },
-                            {
-                                "default": null,
-                                "doc": "Other results of evaluation",
-                                "name": "nativeResults",
-                                "type": [
-                                    "null",
-                                    {
-                                        "type": "map",
-                                        "values": "string"
-                                    }
-                                ]
-                            },
-                            {
-                                "default": null,
-                                "doc": "URL where full results are available",
-                                "name": "externalUrl",
-                                "type": [
-                                    "null",
-                                    "string"
-                                ]
-                            }
-                        ],
-                        "name": "AssertionResult",
-                        "namespace": "com.linkedin.pegasus2avro.assertion",
-                        "type": "record"
+                        "items": {
+                            "name": "IntendedUserType",
+                            "namespace": "com.linkedin.pegasus2avro.ml.metadata",
+                            "symbols": [
+                                "ENTERPRISE",
+                                "HOBBY",
+                                "ENTERTAINMENT"
+                            ],
+                            "type": "enum"
+                        },
+                        "type": "array"
                     }
                 ]
             },
             {
                 "default": null,
-                "doc": "Runtime parameters of evaluation",
-                "name": "runtimeContext",
+                "doc": "Highlight technology that the MLModel might easily be confused with, or related contexts that users could try to apply the MLModel to.",
+                "name": "outOfScopeUses",
                 "type": [
                     "null",
                     {
-                        "type": "map",
-                        "values": "string"
+                        "items": "string",
+                        "type": "array"
                     }
                 ]
             }
         ],
-        "name": "AssertionRunEvent",
-        "namespace": "com.linkedin.pegasus2avro.assertion",
+        "name": "IntendedUse",
+        "namespace": "com.linkedin.pegasus2avro.ml.metadata",
         "type": "record"
     },
     {
         "Aspect": {
-            "name": "assertionInfo"
+            "name": "dataHubPolicyInfo"
         },
-        "doc": "Information about an assertion",
+        "doc": "Information about a DataHub (UI) access policy.",
         "fields": [
             {
                 "Searchable": {
-                    "/*": {
-                        "queryByDefault": true
-                    }
+                    "fieldType": "TEXT_PARTIAL"
                 },
-                "default": {},
-                "doc": "Custom property bag.",
-                "name": "customProperties",
-                "type": {
-                    "type": "map",
-                    "values": "string"
-                }
+                "doc": "Display name of the Policy",
+                "name": "displayName",
+                "type": "string"
             },
             {
-                "default": null,
-                "doc": "URL where the reference exist",
-                "java": {
-                    "class": "com.linkedin.pegasus2avro.common.url.Url",
-                    "coercerClass": "com.linkedin.pegasus2avro.common.url.UrlCoercer"
+                "Searchable": {
+                    "fieldType": "TEXT"
                 },
-                "name": "externalUrl",
-                "type": [
-                    "null",
-                    "string"
-                ]
+                "doc": "Description of the Policy",
+                "name": "description",
+                "type": "string"
             },
             {
-                "doc": "Type of assertion. Assertion types can evolve to span Datasets, Flows (Pipelines), Models, Features etc.",
+                "doc": "The type of policy",
                 "name": "type",
-                "type": {
-                    "name": "AssertionType",
-                    "namespace": "com.linkedin.pegasus2avro.assertion",
-                    "symbols": [
-                        "DATASET"
-                    ],
-                    "type": "enum"
-                }
+                "type": "string"
+            },
+            {
+                "doc": "The state of policy, ACTIVE or INACTIVE",
+                "name": "state",
+                "type": "string"
             },
             {
                 "default": null,
-                "doc": "Dataset Assertion information when type is DATASET",
-                "name": "datasetAssertion",
+                "doc": "The resource that the policy applies to. Not required for some 'Platform' privileges.",
+                "name": "resources",
                 "type": [
                     "null",
                     {
-                        "doc": "Attributes that are applicable to single-Dataset Assertions",
+                        "doc": "Information used to filter DataHub resource.",
                         "fields": [
                             {
-                                "Relationship": {
-                                    "entityTypes": [
-                                        "dataset"
-                                    ],
-                                    "name": "Asserts"
-                                },
-                                "Urn": "Urn",
-                                "doc": "The dataset targeted by this assertion.",
-                                "java": {
-                                    "class": "com.linkedin.pegasus2avro.common.urn.Urn"
-                                },
-                                "name": "dataset",
-                                "type": "string"
-                            },
-                            {
-                                "doc": "Scope of the Assertion. What part of the dataset does this assertion apply to?",
-                                "name": "scope",
-                                "type": {
-                                    "name": "DatasetAssertionScope",
-                                    "namespace": "com.linkedin.pegasus2avro.assertion",
-                                    "symbolDocs": {
-                                        "DATASET_COLUMN": "This assertion applies to dataset columns",
-                                        "DATASET_ROWS": "This assertion applies to entire rows of the dataset",
-                                        "DATASET_SCHEMA": "This assertion applies to the schema of the dataset",
-                                        "UNKNOWN": "The scope of the assertion is unknown"
-                                    },
-                                    "symbols": [
-                                        "DATASET_COLUMN",
-                                        "DATASET_ROWS",
-                                        "DATASET_SCHEMA",
-                                        "UNKNOWN"
-                                    ],
-                                    "type": "enum"
-                                }
-                            },
-                            {
-                                "Relationship": {
-                                    "/*": {
-                                        "entityTypes": [
-                                            "schemaField"
-                                        ],
-                                        "name": "Asserts"
-                                    }
-                                },
-                                "Urn": "Urn",
                                 "default": null,
-                                "doc": "One or more dataset schema fields that are targeted by this assertion",
-                                "name": "fields",
+                                "deprecated": true,
+                                "doc": "The type of resource that the policy applies to. This will most often be a data asset entity name, for\nexample 'dataset'. It is not strictly required because in the future we will want to support filtering a resource\nby domain, as well.",
+                                "name": "type",
                                 "type": [
                                     "null",
-                                    {
-                                        "items": "string",
-                                        "type": "array"
-                                    }
-                                ],
-                                "urn_is_array": true
+                                    "string"
+                                ]
                             },
                             {
                                 "default": null,
-                                "doc": "Standardized assertion operator",
-                                "name": "aggregation",
+                                "deprecated": true,
+                                "doc": "A specific set of resources to apply the policy to, e.g. asset urns",
+                                "name": "resources",
                                 "type": [
                                     "null",
                                     {
-                                        "doc": "The function that is applied to the aggregation input (schema, rows, column values) before evaluating an operator.",
-                                        "name": "AssertionStdAggregation",
-                                        "namespace": "com.linkedin.pegasus2avro.assertion",
-                                        "symbolDocs": {
-                                            "COLUMNS": "Assertion is applied on all columns.",
-                                            "COLUMN_COUNT": "Assertion is applied on number of columns.",
-                                            "IDENTITY": "Assertion is applied on individual column value.",
-                                            "MAX": "Assertion is applied on column std deviation",
-                                            "MEAN": "Assertion is applied on column mean",
-                                            "MEDIAN": "Assertion is applied on column median",
-                                            "MIN": "Assertion is applied on column min",
-                                            "NULL_COUNT": "Assertion is applied on number of null values in column",
-                                            "NULL_PROPORTION": "Assertion is applied on proportion of null values in column",
-                                            "ROW_COUNT": "Assertion is applied on number of rows.",
-                                            "STDDEV": "Assertion is applied on column std deviation",
-                                            "SUM": "Assertion is applied on column sum",
-                                            "UNIQUE_COUNT": "Assertion is applied on number of distinct values in column",
-                                            "UNIQUE_PROPOTION": "Assertion is applied on proportion of distinct values in column",
-                                            "_NATIVE_": "Other"
-                                        },
-                                        "symbols": [
-                                            "ROW_COUNT",
-                                            "COLUMNS",
-                                            "COLUMN_COUNT",
-                                            "IDENTITY",
-                                            "MEAN",
-                                            "MEDIAN",
-                                            "UNIQUE_COUNT",
-                                            "UNIQUE_PROPOTION",
-                                            "NULL_COUNT",
-                                            "NULL_PROPORTION",
-                                            "STDDEV",
-                                            "MIN",
-                                            "MAX",
-                                            "SUM",
-                                            "_NATIVE_"
-                                        ],
-                                        "type": "enum"
+                                        "items": "string",
+                                        "type": "array"
                                     }
                                 ]
                             },
                             {
-                                "doc": "Standardized assertion operator",
-                                "name": "operator",
-                                "type": {
-                                    "doc": "A boolean operator that is applied on the input to an assertion, after an aggregation function has been applied.",
-                                    "name": "AssertionStdOperator",
-                                    "namespace": "com.linkedin.pegasus2avro.assertion",
-                                    "symbolDocs": {
-                                        "BETWEEN": "Value being asserted is between min_value and max_value.  Requires 'minValue' & 'maxValue' parameters.",
-                                        "CONTAIN": "Value being asserted contains value. Requires 'value' parameter.",
-                                        "END_WITH": "Value being asserted ends with value. Requires 'value' parameter.",
-                                        "EQUAL_TO": "Value being asserted is equal to value. Requires 'value' parameter.",
-                                        "GREATER_THAN": "Value being asserted is greater than some value. Requires 'value' parameter.",
-                                        "GREATER_THAN_OR_EQUAL_TO": "Value being asserted is greater than or equal to some value. Requires 'value' parameter.",
-                                        "IN": "Value being asserted is one of the array values. Requires 'value' parameter.",
-                                        "LESS_THAN": "Value being asserted is less than a max value. Requires 'value' parameter.",
-                                        "LESS_THAN_OR_EQUAL_TO": "Value being asserted is less than or equal to some value. Requires 'value' parameter.",
-                                        "NOT_IN": "Value being asserted is not in one of the array values. Requires 'value' parameter.",
-                                        "NOT_NULL": "Value being asserted is not null. Requires no parameters.",
-                                        "REGEX_MATCH": "Value being asserted matches the regex value. Requires 'value' parameter.",
-                                        "START_WITH": "Value being asserted starts with value. Requires 'value' parameter.",
-                                        "_NATIVE_": "Other"
-                                    },
-                                    "symbols": [
-                                        "BETWEEN",
-                                        "LESS_THAN",
-                                        "LESS_THAN_OR_EQUAL_TO",
-                                        "GREATER_THAN",
-                                        "GREATER_THAN_OR_EQUAL_TO",
-                                        "EQUAL_TO",
-                                        "NOT_NULL",
-                                        "CONTAIN",
-                                        "END_WITH",
-                                        "START_WITH",
-                                        "REGEX_MATCH",
-                                        "IN",
-                                        "NOT_IN",
-                                        "_NATIVE_"
-                                    ],
-                                    "type": "enum"
-                                }
+                                "default": false,
+                                "deprecated": true,
+                                "doc": "Whether the policy should be applied to all assets matching the filter.",
+                                "name": "allResources",
+                                "type": "boolean"
                             },
                             {
                                 "default": null,
-                                "doc": "Standard parameters required for the assertion. e.g. min_value, max_value, value, columns",
-                                "name": "parameters",
+                                "doc": "Filter to apply privileges to",
+                                "name": "filter",
                                 "type": [
                                     "null",
                                     {
-                                        "doc": "Parameters for AssertionStdOperators.",
+                                        "doc": "The filter for specifying the resource or actor to apply privileges to",
                                         "fields": [
                                             {
-                                                "default": null,
-                                                "doc": "The value parameter of an assertion",
-                                                "name": "value",
-                                                "type": [
-                                                    "null",
-                                                    {
-                                                        "doc": "Single parameter for AssertionStdOperators.",
+                                                "doc": "A list of criteria to apply conjunctively (so all criteria must pass)",
+                                                "name": "criteria",
+                                                "type": {
+                                                    "items": {
+                                                        "doc": "A criterion for matching a field with given value",
                                                         "fields": [
                                                             {
-                                                                "doc": "The parameter value",
-                                                                "name": "value",
+                                                                "doc": "The name of the field that the criterion refers to",
+                                                                "name": "field",
                                                                 "type": "string"
                                                             },
                                                             {
-                                                                "doc": "The type of the parameter",
-                                                                "name": "type",
+                                                                "doc": "Values. Matches criterion if any one of the values matches condition (OR-relationship)",
+                                                                "name": "values",
                                                                 "type": {
-                                                                    "name": "AssertionStdParameterType",
-                                                                    "namespace": "com.linkedin.pegasus2avro.assertion",
+                                                                    "items": "string",
+                                                                    "type": "array"
+                                                                }
+                                                            },
+                                                            {
+                                                                "default": "EQUALS",
+                                                                "doc": "The condition for the criterion",
+                                                                "name": "condition",
+                                                                "type": {
+                                                                    "doc": "The matching condition in a filter criterion",
+                                                                    "name": "PolicyMatchCondition",
+                                                                    "namespace": "com.linkedin.pegasus2avro.policy",
+                                                                    "symbolDocs": {
+                                                                        "EQUALS": "Whether the field matches the value"
+                                                                    },
                                                                     "symbols": [
-                                                                        "STRING",
-                                                                        "NUMBER",
-                                                                        "LIST",
-                                                                        "SET",
-                                                                        "UNKNOWN"
+                                                                        "EQUALS"
                                                                     ],
                                                                     "type": "enum"
                                                                 }
                                                             }
                                                         ],
-                                                        "name": "AssertionStdParameter",
-                                                        "namespace": "com.linkedin.pegasus2avro.assertion",
+                                                        "name": "PolicyMatchCriterion",
+                                                        "namespace": "com.linkedin.pegasus2avro.policy",
                                                         "type": "record"
-                                                    }
-                                                ]
-                                            },
-                                            {
-                                                "default": null,
-                                                "doc": "The maxValue parameter of an assertion",
-                                                "name": "maxValue",
-                                                "type": [
-                                                    "null",
-                                                    "com.linkedin.pegasus2avro.assertion.AssertionStdParameter"
-                                                ]
-                                            },
-                                            {
-                                                "default": null,
-                                                "doc": "The minValue parameter of an assertion",
-                                                "name": "minValue",
-                                                "type": [
-                                                    "null",
-                                                    "com.linkedin.pegasus2avro.assertion.AssertionStdParameter"
-                                                ]
+                                                    },
+                                                    "type": "array"
+                                                }
                                             }
                                         ],
-                                        "name": "AssertionStdParameters",
-                                        "namespace": "com.linkedin.pegasus2avro.assertion",
+                                        "name": "PolicyMatchFilter",
+                                        "namespace": "com.linkedin.pegasus2avro.policy",
                                         "type": "record"
                                     }
                                 ]
-                            },
-                            {
-                                "default": null,
-                                "doc": "Native assertion type",
-                                "name": "nativeType",
-                                "type": [
-                                    "null",
-                                    "string"
-                                ]
-                            },
-                            {
-                                "default": null,
-                                "doc": "Native parameters required for the assertion.",
-                                "name": "nativeParameters",
-                                "type": [
-                                    "null",
-                                    {
-                                        "type": "map",
-                                        "values": "string"
-                                    }
-                                ]
-                            },
-                            {
-                                "default": null,
-                                "name": "logic",
-                                "type": [
-                                    "null",
-                                    "string"
-                                ]
                             }
                         ],
-                        "name": "DatasetAssertionInfo",
-                        "namespace": "com.linkedin.pegasus2avro.assertion",
+                        "name": "DataHubResourceFilter",
+                        "namespace": "com.linkedin.pegasus2avro.policy",
                         "type": "record"
                     }
                 ]
+            },
+            {
+                "doc": "The privileges that the policy grants.",
+                "name": "privileges",
+                "type": {
+                    "items": "string",
+                    "type": "array"
+                }
+            },
+            {
+                "doc": "The actors that the policy applies to.",
+                "name": "actors",
+                "type": {
+                    "doc": "Information used to filter DataHub actors.",
+                    "fields": [
+                        {
+                            "Urn": "Urn",
+                            "default": null,
+                            "doc": "A specific set of users to apply the policy to (disjunctive)",
+                            "name": "users",
+                            "type": [
+                                "null",
+                                {
+                                    "items": "string",
+                                    "type": "array"
+                                }
+                            ],
+                            "urn_is_array": true
+                        },
+                        {
+                            "Urn": "Urn",
+                            "default": null,
+                            "doc": "A specific set of groups to apply the policy to (disjunctive)",
+                            "name": "groups",
+                            "type": [
+                                "null",
+                                {
+                                    "items": "string",
+                                    "type": "array"
+                                }
+                            ],
+                            "urn_is_array": true
+                        },
+                        {
+                            "default": false,
+                            "doc": "Whether the filter should return true for owners of a particular resource.\nOnly applies to policies of type 'Metadata', which have a resource associated with them.",
+                            "name": "resourceOwners",
+                            "type": "boolean"
+                        },
+                        {
+                            "default": false,
+                            "doc": "Whether the filter should apply to all users.",
+                            "name": "allUsers",
+                            "type": "boolean"
+                        },
+                        {
+                            "default": false,
+                            "doc": "Whether the filter should apply to all groups.",
+                            "name": "allGroups",
+                            "type": "boolean"
+                        },
+                        {
+                            "Relationship": {
+                                "/*": {
+                                    "entityTypes": [
+                                        "dataHubRole"
+                                    ],
+                                    "name": "IsAssociatedWithRole"
+                                }
+                            },
+                            "Urn": "Urn",
+                            "default": null,
+                            "doc": "A specific set of roles to apply the policy to (disjunctive).",
+                            "name": "roles",
+                            "type": [
+                                "null",
+                                {
+                                    "items": "string",
+                                    "type": "array"
+                                }
+                            ],
+                            "urn_is_array": true
+                        }
+                    ],
+                    "name": "DataHubActorFilter",
+                    "namespace": "com.linkedin.pegasus2avro.policy",
+                    "type": "record"
+                }
+            },
+            {
+                "default": true,
+                "doc": "Whether the policy should be editable via the UI",
+                "name": "editable",
+                "type": "boolean"
+            },
+            {
+                "Searchable": {
+                    "fieldType": "DATETIME"
+                },
+                "default": null,
+                "doc": "Timestamp when the policy was last updated",
+                "name": "lastUpdatedTimestamp",
+                "type": [
+                    "null",
+                    "long"
+                ]
             }
         ],
-        "name": "AssertionInfo",
-        "namespace": "com.linkedin.pegasus2avro.assertion",
+        "name": "DataHubPolicyInfo",
+        "namespace": "com.linkedin.pegasus2avro.policy",
+        "type": "record"
+    },
+    {
+        "Aspect": {
+            "name": "dataHubRoleInfo"
+        },
+        "doc": "Information about a DataHub Role.",
+        "fields": [
+            {
+                "Searchable": {
+                    "fieldType": "TEXT_PARTIAL"
+                },
+                "doc": "Name of the Role",
+                "name": "name",
+                "type": "string"
+            },
+            {
+                "Searchable": {
+                    "fieldType": "TEXT"
+                },
+                "doc": "Description of the Role",
+                "name": "description",
+                "type": "string"
+            },
+            {
+                "default": false,
+                "doc": "Whether the role should be editable via the UI",
+                "name": "editable",
+                "type": "boolean"
+            }
+        ],
+        "name": "DataHubRoleInfo",
+        "namespace": "com.linkedin.pegasus2avro.policy",
         "type": "record"
     },
     {
         "Aspect": {
             "name": "dataHubStepStateProperties"
         },
         "doc": "The properties associated with a DataHub step state",
@@ -4395,98 +4197,100 @@
         ],
         "name": "DataHubStepStateProperties",
         "namespace": "com.linkedin.pegasus2avro.step",
         "type": "record"
     },
     {
         "Aspect": {
-            "name": "dataHubSecretValue"
+            "name": "dataPlatformInfo"
         },
-        "doc": "The value of a DataHub Secret",
+        "doc": "Information about a data platform",
         "fields": [
             {
                 "Searchable": {
+                    "boostScore": 10.0,
+                    "enableAutocomplete": false,
                     "fieldType": "TEXT_PARTIAL"
                 },
-                "doc": "The display name for the secret",
+                "doc": "Name of the data platform",
                 "name": "name",
-                "type": "string"
-            },
-            {
-                "doc": "The AES-encrypted value of the DataHub secret.",
-                "name": "value",
-                "type": "string"
-            },
-            {
-                "default": null,
-                "doc": "Description of the secret",
-                "name": "description",
-                "type": [
-                    "null",
-                    "string"
-                ]
-            },
-            {
-                "Searchable": {
-                    "/time": {
-                        "fieldName": "createdTime",
-                        "fieldType": "DATETIME"
+                "type": "string",
+                "validate": {
+                    "strlen": {
+                        "max": 15
                     }
-                },
-                "default": null,
-                "doc": "Created Audit stamp",
-                "name": "created",
-                "type": [
-                    "null",
-                    "com.linkedin.pegasus2avro.common.AuditStamp"
-                ]
-            }
-        ],
-        "name": "DataHubSecretValue",
-        "namespace": "com.linkedin.pegasus2avro.secret",
-        "type": "record"
-    },
-    {
-        "Aspect": {
-            "name": "tagProperties"
-        },
-        "doc": "Properties associated with a Tag",
-        "fields": [
+                }
+            },
             {
                 "Searchable": {
                     "boostScore": 10.0,
                     "enableAutocomplete": true,
                     "fieldType": "TEXT_PARTIAL"
                 },
-                "doc": "Display name of the tag",
-                "name": "name",
-                "type": "string"
-            },
-            {
-                "Searchable": {},
                 "default": null,
-                "doc": "Documentation of the tag",
-                "name": "description",
+                "doc": "The name that will be used for displaying a platform type.",
+                "name": "displayName",
                 "type": [
                     "null",
                     "string"
                 ]
             },
             {
+                "doc": "Platform type this data platform describes",
+                "name": "type",
+                "type": {
+                    "doc": "Platform types available at LinkedIn",
+                    "name": "PlatformType",
+                    "namespace": "com.linkedin.pegasus2avro.dataplatform",
+                    "symbolDocs": {
+                        "FILE_SYSTEM": "Value for a file system, e.g. hdfs",
+                        "KEY_VALUE_STORE": "Value for a key value store, e.g. espresso, voldemort",
+                        "MESSAGE_BROKER": "Value for a message broker, e.g. kafka",
+                        "OBJECT_STORE": "Value for an object store, e.g. ambry",
+                        "OLAP_DATASTORE": "Value for an OLAP datastore, e.g. pinot",
+                        "OTHERS": "Value for other platforms, e.g salesforce, dovetail",
+                        "QUERY_ENGINE": "Value for a query engine, e.g. presto",
+                        "RELATIONAL_DB": "Value for a relational database, e.g. oracle, mysql",
+                        "SEARCH_ENGINE": "Value for a search engine, e.g seas"
+                    },
+                    "symbols": [
+                        "FILE_SYSTEM",
+                        "KEY_VALUE_STORE",
+                        "MESSAGE_BROKER",
+                        "OBJECT_STORE",
+                        "OLAP_DATASTORE",
+                        "OTHERS",
+                        "QUERY_ENGINE",
+                        "RELATIONAL_DB",
+                        "SEARCH_ENGINE"
+                    ],
+                    "type": "enum"
+                }
+            },
+            {
+                "doc": "The delimiter in the dataset names on the data platform, e.g. '/' for HDFS and '.' for Oracle",
+                "name": "datasetNameDelimiter",
+                "type": "string"
+            },
+            {
                 "default": null,
-                "doc": "The color associated with the Tag in Hex. For example #FFFFFF.",
-                "name": "colorHex",
+                "doc": "The URL for a logo associated with the platform",
+                "java": {
+                    "class": "com.linkedin.pegasus2avro.common.url.Url",
+                    "coercerClass": "com.linkedin.pegasus2avro.common.url.UrlCoercer"
+                },
+                "name": "logoUrl",
                 "type": [
                     "null",
                     "string"
                 ]
             }
         ],
-        "name": "TagProperties",
-        "namespace": "com.linkedin.pegasus2avro.tag",
+        "name": "DataPlatformInfo",
+        "namespace": "com.linkedin.pegasus2avro.dataplatform",
         "type": "record"
     },
     {
         "Aspect": {
             "name": "dataHubExecutionRequestResult"
         },
         "doc": "The result of an execution request",
@@ -4671,210 +4475,112 @@
         ],
         "name": "ExecutionRequestSignal",
         "namespace": "com.linkedin.pegasus2avro.execution",
         "type": "record"
     },
     {
         "Aspect": {
-            "name": "dashboardInfo"
+            "name": "chartQuery"
         },
-        "doc": "Information about a dashboard",
+        "doc": "Information for chart query which is used for getting data of the chart",
         "fields": [
             {
-                "Searchable": {
-                    "/*": {
-                        "queryByDefault": true
-                    }
-                },
-                "default": {},
-                "doc": "Custom property bag.",
-                "name": "customProperties",
-                "type": {
-                    "type": "map",
-                    "values": "string"
-                }
-            },
-            {
-                "default": null,
-                "doc": "URL where the reference exist",
-                "java": {
-                    "class": "com.linkedin.pegasus2avro.common.url.Url",
-                    "coercerClass": "com.linkedin.pegasus2avro.common.url.UrlCoercer"
-                },
-                "name": "externalUrl",
-                "type": [
-                    "null",
-                    "string"
-                ]
-            },
-            {
-                "Searchable": {
-                    "boostScore": 10.0,
-                    "enableAutocomplete": true,
-                    "fieldType": "TEXT_PARTIAL"
-                },
-                "doc": "Title of the dashboard",
-                "name": "title",
+                "doc": "Raw query to build a chart from input datasets",
+                "name": "rawQuery",
                 "type": "string"
             },
             {
                 "Searchable": {
-                    "fieldType": "TEXT",
-                    "hasValuesFieldName": "hasDescription"
-                },
-                "doc": "Detailed description about the dashboard",
-                "name": "description",
-                "type": "string"
-            },
-            {
-                "Relationship": {
-                    "/*": {
-                        "entityTypes": [
-                            "chart"
-                        ],
-                        "isLineage": true,
-                        "name": "Contains"
-                    }
+                    "addToFilters": true,
+                    "fieldName": "queryType",
+                    "fieldType": "KEYWORD",
+                    "filterNameOverride": "Query Type"
                 },
-                "Urn": "ChartUrn",
-                "default": [],
-                "deprecated": true,
-                "doc": "Charts in a dashboard\nDeprecated! Use chartEdges instead.",
-                "name": "charts",
+                "doc": "Chart query type",
+                "name": "type",
                 "type": {
-                    "items": "string",
-                    "type": "array"
-                },
-                "urn_is_array": true
-            },
-            {
-                "Relationship": {
-                    "/*/destinationUrn": {
-                        "createdActor": "chartEdges/*/created/actor",
-                        "createdOn": "chartEdges/*/created/time",
-                        "entityTypes": [
-                            "chart"
-                        ],
-                        "isLineage": true,
-                        "name": "Contains",
-                        "properties": "chartEdges/*/properties",
-                        "updatedActor": "chartEdges/*/lastModified/actor",
-                        "updatedOn": "chartEdges/*/lastModified/time"
-                    }
-                },
-                "default": null,
-                "doc": "Charts in a dashboard",
-                "name": "chartEdges",
-                "type": [
-                    "null",
-                    {
-                        "items": "com.linkedin.pegasus2avro.common.Edge",
-                        "type": "array"
-                    }
-                ]
-            },
+                    "name": "ChartQueryType",
+                    "namespace": "com.linkedin.pegasus2avro.chart",
+                    "symbolDocs": {
+                        "LOOKML": "LookML queries",
+                        "SQL": "SQL type queries"
+                    },
+                    "symbols": [
+                        "LOOKML",
+                        "SQL"
+                    ],
+                    "type": "enum"
+                }
+            }
+        ],
+        "name": "ChartQuery",
+        "namespace": "com.linkedin.pegasus2avro.chart",
+        "type": "record"
+    },
+    {
+        "Aspect": {
+            "name": "editableChartProperties"
+        },
+        "doc": "Stores editable changes made to properties. This separates changes made from\ningestion pipelines and edits in the UI to avoid accidental overwrites of user-provided data by ingestion pipelines",
+        "fields": [
             {
-                "Relationship": {
-                    "/*": {
-                        "entityTypes": [
-                            "dataset"
-                        ],
-                        "isLineage": true,
-                        "name": "Consumes"
-                    }
-                },
-                "Urn": "Urn",
-                "default": [],
-                "deprecated": true,
-                "doc": "Datasets consumed by a dashboard\nDeprecated! Use datasetEdges instead.",
-                "name": "datasets",
-                "type": {
-                    "items": "string",
-                    "type": "array"
+                "default": {
+                    "actor": "urn:li:corpuser:unknown",
+                    "impersonator": null,
+                    "message": null,
+                    "time": 0
                 },
-                "urn_is_array": true
+                "doc": "An AuditStamp corresponding to the creation of this resource/association/sub-resource. A value of 0 for time indicates missing data.",
+                "name": "created",
+                "type": "com.linkedin.pegasus2avro.common.AuditStamp"
             },
             {
-                "Relationship": {
-                    "/*/destinationUrn": {
-                        "createdActor": "datasetEdges/*/created/actor",
-                        "createdOn": "datasetEdges/*/created/time",
-                        "entityTypes": [
-                            "dataset"
-                        ],
-                        "isLineage": true,
-                        "name": "Consumes",
-                        "properties": "datasetEdges/*/properties",
-                        "updatedActor": "datasetEdges/*/lastModified/actor",
-                        "updatedOn": "datasetEdges/*/lastModified/time"
-                    }
+                "default": {
+                    "actor": "urn:li:corpuser:unknown",
+                    "impersonator": null,
+                    "message": null,
+                    "time": 0
                 },
-                "default": null,
-                "doc": "Datasets consumed by a dashboard",
-                "name": "datasetEdges",
-                "type": [
-                    "null",
-                    {
-                        "items": "com.linkedin.pegasus2avro.common.Edge",
-                        "type": "array"
-                    }
-                ]
-            },
-            {
-                "doc": "Captures information about who created/last modified/deleted this dashboard and when",
+                "doc": "An AuditStamp corresponding to the last modification of this resource/association/sub-resource. If no modification has happened since creation, lastModified should be the same as created. A value of 0 for time indicates missing data.",
                 "name": "lastModified",
-                "type": "com.linkedin.pegasus2avro.common.ChangeAuditStamps"
+                "type": "com.linkedin.pegasus2avro.common.AuditStamp"
             },
             {
                 "default": null,
-                "doc": "URL for the dashboard. This could be used as an external link on DataHub to allow users access/view the dashboard",
-                "java": {
-                    "class": "com.linkedin.pegasus2avro.common.url.Url",
-                    "coercerClass": "com.linkedin.pegasus2avro.common.url.UrlCoercer"
-                },
-                "name": "dashboardUrl",
+                "doc": "An AuditStamp corresponding to the deletion of this resource/association/sub-resource. Logically, deleted MUST have a later timestamp than creation. It may or may not have the same time as lastModified depending upon the resource/association/sub-resource semantics.",
+                "name": "deleted",
                 "type": [
                     "null",
-                    "string"
+                    "com.linkedin.pegasus2avro.common.AuditStamp"
                 ]
             },
             {
                 "Searchable": {
-                    "addToFilters": true,
-                    "fieldType": "KEYWORD",
-                    "filterNameOverride": "Access Level"
+                    "fieldName": "editedDescription",
+                    "fieldType": "TEXT"
                 },
                 "default": null,
-                "doc": "Access level for the dashboard",
-                "name": "access",
-                "type": [
-                    "null",
-                    "com.linkedin.pegasus2avro.common.AccessLevel"
-                ]
-            },
-            {
-                "default": null,
-                "doc": "The time when this dashboard last refreshed",
-                "name": "lastRefreshed",
+                "doc": "Edited documentation of the chart ",
+                "name": "description",
                 "type": [
                     "null",
-                    "long"
+                    "string"
                 ]
             }
         ],
-        "name": "DashboardInfo",
-        "namespace": "com.linkedin.pegasus2avro.dashboard",
+        "name": "EditableChartProperties",
+        "namespace": "com.linkedin.pegasus2avro.chart",
         "type": "record"
     },
     {
         "Aspect": {
-            "name": "dashboardUsageStatistics",
+            "name": "chartUsageStatistics",
             "type": "timeseries"
         },
-        "doc": "Experimental (Subject to breaking change) -- Stats corresponding to dashboard's usage.\n\nIf this aspect represents the latest snapshot of the statistics about a Dashboard, the eventGranularity field should be null. \nIf this aspect represents a bucketed window of usage statistics (e.g. over a day), then the eventGranularity field should be set accordingly. ",
+        "doc": "Experimental (Subject to breaking change) -- Stats corresponding to chart's usage.\n\nIf this aspect represents the latest snapshot of the statistics about a Chart, the eventGranularity field should be null.\nIf this aspect represents a bucketed window of usage statistics (e.g. over a day), then the eventGranularity field should be set accordingly.",
         "fields": [
             {
                 "doc": "The event timestamp field as epoch at UTC in milli seconds.",
                 "name": "timestampMillis",
                 "type": "long"
             },
             {
@@ -4907,34 +4613,24 @@
                     "null",
                     "string"
                 ]
             },
             {
                 "TimeseriesField": {},
                 "default": null,
-                "doc": "The total number of times dashboard has been viewed",
+                "doc": "The total number of times chart has been viewed",
                 "name": "viewsCount",
                 "type": [
                     "null",
                     "int"
                 ]
             },
             {
                 "TimeseriesField": {},
                 "default": null,
-                "doc": "The total number of dashboard executions (refreshes / syncs) ",
-                "name": "executionsCount",
-                "type": [
-                    "null",
-                    "int"
-                ]
-            },
-            {
-                "TimeseriesField": {},
-                "default": null,
                 "doc": "Unique user count",
                 "name": "uniqueUserCount",
                 "type": [
                     "null",
                     "int"
                 ]
             },
@@ -4959,719 +4655,298 @@
                                     },
                                     "name": "user",
                                     "type": "string"
                                 },
                                 {
                                     "TimeseriesField": {},
                                     "default": null,
-                                    "doc": "The number of times the user has viewed the dashboard",
+                                    "doc": "The number of times the user has viewed the chart",
                                     "name": "viewsCount",
                                     "type": [
                                         "null",
                                         "int"
                                     ]
-                                },
-                                {
-                                    "TimeseriesField": {},
-                                    "default": null,
-                                    "doc": "The number of times the user has executed (refreshed) the dashboard",
-                                    "name": "executionsCount",
-                                    "type": [
-                                        "null",
-                                        "int"
-                                    ]
-                                },
-                                {
-                                    "TimeseriesField": {},
-                                    "default": null,
-                                    "doc": "Normalized numeric metric representing user's dashboard usage -- the number of times the user executed or viewed the dashboard. ",
-                                    "name": "usageCount",
-                                    "type": [
-                                        "null",
-                                        "int"
-                                    ]
-                                },
-                                {
-                                    "TimeseriesField": {},
-                                    "default": null,
-                                    "doc": "If user_email is set, we attempt to resolve the user's urn upon ingest",
-                                    "name": "userEmail",
-                                    "type": [
-                                        "null",
-                                        "string"
-                                    ]
                                 }
                             ],
-                            "name": "DashboardUserUsageCounts",
-                            "namespace": "com.linkedin.pegasus2avro.dashboard",
+                            "name": "ChartUserUsageCounts",
+                            "namespace": "com.linkedin.pegasus2avro.chart",
                             "type": "record"
                         },
                         "type": "array"
                     }
                 ]
-            },
-            {
-                "TimeseriesField": {},
-                "default": null,
-                "doc": "The total number of times that the dashboard has been favorited ",
-                "name": "favoritesCount",
-                "type": [
-                    "null",
-                    "int"
-                ]
-            },
-            {
-                "TimeseriesField": {},
-                "default": null,
-                "doc": "Last viewed at\n\nThis should not be set in cases where statistics are windowed. ",
-                "name": "lastViewedAt",
-                "type": [
-                    "null",
-                    "long"
-                ]
             }
         ],
-        "name": "DashboardUsageStatistics",
-        "namespace": "com.linkedin.pegasus2avro.dashboard",
+        "name": "ChartUsageStatistics",
+        "namespace": "com.linkedin.pegasus2avro.chart",
         "type": "record"
     },
     {
         "Aspect": {
-            "name": "editableDashboardProperties"
+            "name": "chartInfo"
         },
-        "doc": "Stores editable changes made to properties. This separates changes made from\ningestion pipelines and edits in the UI to avoid accidental overwrites of user-provided data by ingestion pipelines",
+        "doc": "Information about a chart",
         "fields": [
             {
-                "default": {
-                    "actor": "urn:li:corpuser:unknown",
-                    "impersonator": null,
-                    "message": null,
-                    "time": 0
-                },
-                "doc": "An AuditStamp corresponding to the creation of this resource/association/sub-resource. A value of 0 for time indicates missing data.",
-                "name": "created",
-                "type": "com.linkedin.pegasus2avro.common.AuditStamp"
-            },
-            {
-                "default": {
-                    "actor": "urn:li:corpuser:unknown",
-                    "impersonator": null,
-                    "message": null,
-                    "time": 0
+                "Searchable": {
+                    "/*": {
+                        "queryByDefault": true
+                    }
                 },
-                "doc": "An AuditStamp corresponding to the last modification of this resource/association/sub-resource. If no modification has happened since creation, lastModified should be the same as created. A value of 0 for time indicates missing data.",
-                "name": "lastModified",
-                "type": "com.linkedin.pegasus2avro.common.AuditStamp"
+                "default": {},
+                "doc": "Custom property bag.",
+                "name": "customProperties",
+                "type": {
+                    "type": "map",
+                    "values": "string"
+                }
             },
             {
                 "default": null,
-                "doc": "An AuditStamp corresponding to the deletion of this resource/association/sub-resource. Logically, deleted MUST have a later timestamp than creation. It may or may not have the same time as lastModified depending upon the resource/association/sub-resource semantics.",
-                "name": "deleted",
-                "type": [
-                    "null",
-                    "com.linkedin.pegasus2avro.common.AuditStamp"
-                ]
-            },
-            {
-                "Searchable": {
-                    "fieldName": "editedDescription",
-                    "fieldType": "TEXT"
+                "doc": "URL where the reference exist",
+                "java": {
+                    "class": "com.linkedin.pegasus2avro.common.url.Url",
+                    "coercerClass": "com.linkedin.pegasus2avro.common.url.UrlCoercer"
                 },
-                "default": null,
-                "doc": "Edited documentation of the dashboard",
-                "name": "description",
+                "name": "externalUrl",
                 "type": [
                     "null",
                     "string"
                 ]
-            }
-        ],
-        "name": "EditableDashboardProperties",
-        "namespace": "com.linkedin.pegasus2avro.dashboard",
-        "type": "record"
-    },
-    {
-        "Event": {
-            "name": "entityChangeEvent"
-        },
-        "doc": "Shared fields for all entity change events.",
-        "fields": [
-            {
-                "doc": "The type of the entity affected. Corresponds to the entity registry, e.g. 'dataset', 'chart', 'dashboard', etc.",
-                "name": "entityType",
-                "type": "string"
             },
             {
-                "Urn": "Urn",
-                "doc": "The urn of the entity which was affected.",
-                "java": {
-                    "class": "com.linkedin.pegasus2avro.common.urn.Urn"
+                "Searchable": {
+                    "enableAutocomplete": true,
+                    "fieldType": "TEXT_PARTIAL"
                 },
-                "name": "entityUrn",
-                "type": "string"
-            },
-            {
-                "doc": "The category type (TAG, GLOSSARY_TERM, OWNERSHIP, TECHNICAL_SCHEMA, etc). This is used to determine what the rest of the schema will look like.",
-                "name": "category",
+                "doc": "Title of the chart",
+                "name": "title",
                 "type": "string"
             },
             {
-                "doc": "The operation type. This is used to determine what the rest of the schema will look like.",
-                "name": "operation",
+                "Searchable": {},
+                "doc": "Detailed description about the chart",
+                "name": "description",
                 "type": "string"
             },
             {
-                "default": null,
-                "doc": "The urn of the entity which was affected.",
-                "name": "modifier",
-                "type": [
-                    "null",
-                    "string"
-                ]
-            },
-            {
-                "default": null,
-                "doc": "Arbitrary key-value parameters corresponding to the event.",
-                "name": "parameters",
-                "type": [
-                    "null",
-                    {
-                        "doc": "Arbitrary key-value parameters for an Entity Change Event. (any record).",
-                        "fields": [],
-                        "name": "Parameters",
-                        "namespace": "com.linkedin.pegasus2avro.platform.event.v1",
-                        "type": "record"
-                    }
-                ]
-            },
-            {
-                "doc": "Audit stamp of the operation",
-                "name": "auditStamp",
-                "type": "com.linkedin.pegasus2avro.common.AuditStamp"
-            },
-            {
-                "doc": "The version of the event type, incremented in integers.",
-                "name": "version",
-                "type": "int"
-            }
-        ],
-        "name": "EntityChangeEvent",
-        "namespace": "com.linkedin.pegasus2avro.platform.event.v1",
-        "type": "record"
-    },
-    {
-        "Aspect": {
-            "name": "editableDataJobProperties"
-        },
-        "doc": "Stores editable changes made to properties. This separates changes made from\ningestion pipelines and edits in the UI to avoid accidental overwrites of user-provided data by ingestion pipelines",
-        "fields": [
-            {
-                "default": {
-                    "actor": "urn:li:corpuser:unknown",
-                    "impersonator": null,
-                    "message": null,
-                    "time": 0
-                },
-                "doc": "An AuditStamp corresponding to the creation of this resource/association/sub-resource. A value of 0 for time indicates missing data.",
-                "name": "created",
-                "type": "com.linkedin.pegasus2avro.common.AuditStamp"
-            },
-            {
-                "default": {
-                    "actor": "urn:li:corpuser:unknown",
-                    "impersonator": null,
-                    "message": null,
-                    "time": 0
-                },
-                "doc": "An AuditStamp corresponding to the last modification of this resource/association/sub-resource. If no modification has happened since creation, lastModified should be the same as created. A value of 0 for time indicates missing data.",
+                "doc": "Captures information about who created/last modified/deleted this chart and when",
                 "name": "lastModified",
-                "type": "com.linkedin.pegasus2avro.common.AuditStamp"
+                "type": {
+                    "doc": "Data captured on a resource/association/sub-resource level giving insight into when that resource/association/sub-resource moved into various lifecycle stages, and who acted to move it into those lifecycle stages. The recommended best practice is to include this record in your record schema, and annotate its fields as @readOnly in your resource. See https://github.com/linkedin/rest.li/wiki/Validation-in-Rest.li#restli-validation-annotations",
+                    "fields": [
+                        {
+                            "default": {
+                                "actor": "urn:li:corpuser:unknown",
+                                "impersonator": null,
+                                "message": null,
+                                "time": 0
+                            },
+                            "doc": "An AuditStamp corresponding to the creation of this resource/association/sub-resource. A value of 0 for time indicates missing data.",
+                            "name": "created",
+                            "type": "com.linkedin.pegasus2avro.common.AuditStamp"
+                        },
+                        {
+                            "default": {
+                                "actor": "urn:li:corpuser:unknown",
+                                "impersonator": null,
+                                "message": null,
+                                "time": 0
+                            },
+                            "doc": "An AuditStamp corresponding to the last modification of this resource/association/sub-resource. If no modification has happened since creation, lastModified should be the same as created. A value of 0 for time indicates missing data.",
+                            "name": "lastModified",
+                            "type": "com.linkedin.pegasus2avro.common.AuditStamp"
+                        },
+                        {
+                            "default": null,
+                            "doc": "An AuditStamp corresponding to the deletion of this resource/association/sub-resource. Logically, deleted MUST have a later timestamp than creation. It may or may not have the same time as lastModified depending upon the resource/association/sub-resource semantics.",
+                            "name": "deleted",
+                            "type": [
+                                "null",
+                                "com.linkedin.pegasus2avro.common.AuditStamp"
+                            ]
+                        }
+                    ],
+                    "name": "ChangeAuditStamps",
+                    "namespace": "com.linkedin.pegasus2avro.common",
+                    "type": "record"
+                }
             },
             {
                 "default": null,
-                "doc": "An AuditStamp corresponding to the deletion of this resource/association/sub-resource. Logically, deleted MUST have a later timestamp than creation. It may or may not have the same time as lastModified depending upon the resource/association/sub-resource semantics.",
-                "name": "deleted",
-                "type": [
-                    "null",
-                    "com.linkedin.pegasus2avro.common.AuditStamp"
-                ]
-            },
-            {
-                "Searchable": {
-                    "fieldName": "editedDescription",
-                    "fieldType": "TEXT"
+                "doc": "URL for the chart. This could be used as an external link on DataHub to allow users access/view the chart",
+                "java": {
+                    "class": "com.linkedin.pegasus2avro.common.url.Url",
+                    "coercerClass": "com.linkedin.pegasus2avro.common.url.UrlCoercer"
                 },
-                "default": null,
-                "doc": "Edited documentation of the data job ",
-                "name": "description",
+                "name": "chartUrl",
                 "type": [
                     "null",
                     "string"
                 ]
-            }
-        ],
-        "name": "EditableDataJobProperties",
-        "namespace": "com.linkedin.pegasus2avro.datajob",
-        "type": "record"
-    },
-    {
-        "Aspect": {
-            "name": "dataJobInputOutput"
-        },
-        "doc": "Information about the inputs and outputs of a Data processing job",
-        "fields": [
-            {
-                "Relationship": {
-                    "/*": {
-                        "entityTypes": [
-                            "dataset"
-                        ],
-                        "isLineage": true,
-                        "name": "Consumes"
-                    }
-                },
-                "Searchable": {
-                    "/*": {
-                        "fieldName": "inputs",
-                        "fieldType": "URN",
-                        "numValuesFieldName": "numInputDatasets",
-                        "queryByDefault": false
-                    }
-                },
-                "Urn": "DatasetUrn",
-                "deprecated": true,
-                "doc": "Input datasets consumed by the data job during processing\nDeprecated! Use inputDatasetEdges instead.",
-                "name": "inputDatasets",
-                "type": {
-                    "items": "string",
-                    "type": "array"
-                },
-                "urn_is_array": true
             },
             {
                 "Relationship": {
-                    "/*/destinationUrn": {
-                        "createdActor": "inputDatasetEdges/*/created/actor",
-                        "createdOn": "inputDatasetEdges/*/created/time",
+                    "/*/string": {
                         "entityTypes": [
                             "dataset"
                         ],
                         "isLineage": true,
-                        "name": "Consumes",
-                        "properties": "inputDatasetEdges/*/properties",
-                        "updatedActor": "inputDatasetEdges/*/lastModified/actor",
-                        "updatedOn": "inputDatasetEdges/*/lastModified/time"
-                    }
-                },
-                "Searchable": {
-                    "/*/destinationUrn": {
-                        "fieldName": "inputDatasetEdges",
-                        "fieldType": "URN",
-                        "numValuesFieldName": "numInputDatasets",
-                        "queryByDefault": false
+                        "name": "Consumes"
                     }
                 },
                 "default": null,
-                "doc": "Input datasets consumed by the data job during processing",
-                "name": "inputDatasetEdges",
+                "deprecated": true,
+                "doc": "Data sources for the chart\nDeprecated! Use inputEdges instead.",
+                "name": "inputs",
                 "type": [
                     "null",
                     {
-                        "items": "com.linkedin.pegasus2avro.common.Edge",
+                        "items": [
+                            "string"
+                        ],
                         "type": "array"
                     }
                 ]
             },
             {
                 "Relationship": {
-                    "/*": {
-                        "entityTypes": [
-                            "dataset"
-                        ],
-                        "isLineage": true,
-                        "isUpstream": false,
-                        "name": "Produces"
-                    }
-                },
-                "Searchable": {
-                    "/*": {
-                        "fieldName": "outputs",
-                        "fieldType": "URN",
-                        "numValuesFieldName": "numOutputDatasets",
-                        "queryByDefault": false
-                    }
-                },
-                "Urn": "DatasetUrn",
-                "deprecated": true,
-                "doc": "Output datasets produced by the data job during processing\nDeprecated! Use outputDatasetEdges instead.",
-                "name": "outputDatasets",
-                "type": {
-                    "items": "string",
-                    "type": "array"
-                },
-                "urn_is_array": true
-            },
-            {
-                "Relationship": {
                     "/*/destinationUrn": {
-                        "createdActor": "outputDatasetEdges/*/created/actor",
-                        "createdOn": "outputDatasetEdges/*/created/time",
+                        "createdActor": "inputEdges/*/created/actor",
+                        "createdOn": "inputEdges/*/created/time",
                         "entityTypes": [
                             "dataset"
                         ],
                         "isLineage": true,
-                        "isUpstream": false,
-                        "name": "Produces",
-                        "properties": "outputDatasetEdges/*/properties",
-                        "updatedActor": "outputDatasetEdges/*/lastModified/actor",
-                        "updatedOn": "outputDatasetEdges/*/lastModified/time"
-                    }
-                },
-                "Searchable": {
-                    "/*/destinationUrn": {
-                        "fieldName": "outputDatasetEdges",
-                        "fieldType": "URN",
-                        "numValuesFieldName": "numOutputDatasets",
-                        "queryByDefault": false
+                        "name": "Consumes",
+                        "properties": "inputEdges/*/properties",
+                        "updatedActor": "inputEdges/*/lastModified/actor",
+                        "updatedOn": "inputEdges/*/lastModified/time"
                     }
                 },
                 "default": null,
-                "doc": "Output datasets produced by the data job during processing",
-                "name": "outputDatasetEdges",
+                "doc": "Data sources for the chart",
+                "name": "inputEdges",
                 "type": [
                     "null",
                     {
                         "items": "com.linkedin.pegasus2avro.common.Edge",
                         "type": "array"
                     }
                 ]
             },
             {
-                "Relationship": {
-                    "/*": {
-                        "entityTypes": [
-                            "dataJob"
-                        ],
-                        "isLineage": true,
-                        "name": "DownstreamOf"
-                    }
+                "Searchable": {
+                    "addToFilters": true,
+                    "fieldType": "KEYWORD",
+                    "filterNameOverride": "Chart Type"
                 },
-                "Urn": "DataJobUrn",
                 "default": null,
-                "deprecated": true,
-                "doc": "Input datajobs that this data job depends on\nDeprecated! Use inputDatajobEdges instead.",
-                "name": "inputDatajobs",
+                "doc": "Type of the chart",
+                "name": "type",
                 "type": [
                     "null",
                     {
-                        "items": "string",
-                        "type": "array"
-                    }
-                ],
-                "urn_is_array": true
-            },
-            {
-                "Relationship": {
-                    "/*/destinationUrn": {
-                        "createdActor": "inputDatajobEdges/*/created/actor",
-                        "createdOn": "inputDatajobEdges/*/created/time",
-                        "entityTypes": [
-                            "dataJob"
+                        "doc": "The various types of charts",
+                        "name": "ChartType",
+                        "namespace": "com.linkedin.pegasus2avro.chart",
+                        "symbolDocs": {
+                            "BAR": "Chart showing a Bar chart",
+                            "PIE": "Chart showing a Pie chart",
+                            "SCATTER": "Chart showing a Scatter plot",
+                            "TABLE": "Chart showing a table",
+                            "TEXT": "Chart showing Markdown formatted text"
+                        },
+                        "symbols": [
+                            "BAR",
+                            "PIE",
+                            "SCATTER",
+                            "TABLE",
+                            "TEXT",
+                            "LINE",
+                            "AREA",
+                            "HISTOGRAM",
+                            "BOX_PLOT",
+                            "WORD_CLOUD",
+                            "COHORT"
                         ],
-                        "isLineage": true,
-                        "name": "DownstreamOf",
-                        "properties": "inputDatajobEdges/*/properties",
-                        "updatedActor": "inputDatajobEdges/*/lastModified/actor",
-                        "updatedOn": "inputDatajobEdges/*/lastModified/time"
-                    }
-                },
-                "default": null,
-                "doc": "Input datajobs that this data job depends on",
-                "name": "inputDatajobEdges",
-                "type": [
-                    "null",
-                    {
-                        "items": "com.linkedin.pegasus2avro.common.Edge",
-                        "type": "array"
+                        "type": "enum"
                     }
                 ]
             },
             {
-                "Relationship": {
-                    "/*": {
-                        "entityTypes": [
-                            "schemaField"
-                        ],
-                        "name": "Consumes"
-                    }
-                },
                 "Searchable": {
-                    "/*": {
-                        "fieldName": "inputFields",
-                        "fieldType": "URN",
-                        "numValuesFieldName": "numInputFields",
-                        "queryByDefault": false
-                    }
+                    "addToFilters": true,
+                    "fieldType": "KEYWORD",
+                    "filterNameOverride": "Access Level"
                 },
-                "Urn": "Urn",
                 "default": null,
-                "doc": "Fields of the input datasets used by this job",
-                "name": "inputDatasetFields",
+                "doc": "Access level for the chart",
+                "name": "access",
                 "type": [
                     "null",
                     {
-                        "items": "string",
-                        "type": "array"
-                    }
-                ],
-                "urn_is_array": true
-            },
-            {
-                "Relationship": {
-                    "/*": {
-                        "entityTypes": [
-                            "schemaField"
+                        "doc": "The various access levels",
+                        "name": "AccessLevel",
+                        "namespace": "com.linkedin.pegasus2avro.common",
+                        "symbolDocs": {
+                            "PRIVATE": "Private availability to certain set of users",
+                            "PUBLIC": "Publicly available access level"
+                        },
+                        "symbols": [
+                            "PUBLIC",
+                            "PRIVATE"
                         ],
-                        "name": "Produces"
-                    }
-                },
-                "Searchable": {
-                    "/*": {
-                        "fieldName": "outputFields",
-                        "fieldType": "URN",
-                        "numValuesFieldName": "numOutputFields",
-                        "queryByDefault": false
-                    }
-                },
-                "Urn": "Urn",
-                "default": null,
-                "doc": "Fields of the output datasets this job writes to",
-                "name": "outputDatasetFields",
-                "type": [
-                    "null",
-                    {
-                        "items": "string",
-                        "type": "array"
+                        "type": "enum"
                     }
-                ],
-                "urn_is_array": true
+                ]
             },
             {
                 "default": null,
-                "doc": "Fine-grained column-level lineages",
-                "name": "fineGrainedLineages",
+                "doc": "The time when this chart last refreshed",
+                "name": "lastRefreshed",
                 "type": [
                     "null",
-                    {
-                        "items": {
-                            "doc": "A fine-grained lineage from upstream fields/datasets to downstream field(s)",
-                            "fields": [
-                                {
-                                    "doc": "The type of upstream entity",
-                                    "name": "upstreamType",
-                                    "type": {
-                                        "doc": "The type of upstream entity in a fine-grained lineage",
-                                        "name": "FineGrainedLineageUpstreamType",
-                                        "namespace": "com.linkedin.pegasus2avro.dataset",
-                                        "symbolDocs": {
-                                            "DATASET": " Indicates that this lineage is originating from upstream dataset(s)",
-                                            "FIELD_SET": " Indicates that this lineage is originating from upstream field(s)",
-                                            "NONE": " Indicates that there is no upstream lineage i.e. the downstream field is not a derived field"
-                                        },
-                                        "symbols": [
-                                            "FIELD_SET",
-                                            "DATASET",
-                                            "NONE"
-                                        ],
-                                        "type": "enum"
-                                    }
-                                },
-                                {
-                                    "Urn": "Urn",
-                                    "default": null,
-                                    "doc": "Upstream entities in the lineage",
-                                    "name": "upstreams",
-                                    "type": [
-                                        "null",
-                                        {
-                                            "items": "string",
-                                            "type": "array"
-                                        }
-                                    ],
-                                    "urn_is_array": true
-                                },
-                                {
-                                    "doc": "The type of downstream field(s)",
-                                    "name": "downstreamType",
-                                    "type": {
-                                        "doc": "The type of downstream field(s) in a fine-grained lineage",
-                                        "name": "FineGrainedLineageDownstreamType",
-                                        "namespace": "com.linkedin.pegasus2avro.dataset",
-                                        "symbolDocs": {
-                                            "FIELD": " Indicates that the lineage is for a single, specific, downstream field",
-                                            "FIELD_SET": " Indicates that the lineage is for a set of downstream fields"
-                                        },
-                                        "symbols": [
-                                            "FIELD",
-                                            "FIELD_SET"
-                                        ],
-                                        "type": "enum"
-                                    }
-                                },
-                                {
-                                    "Urn": "Urn",
-                                    "default": null,
-                                    "doc": "Downstream fields in the lineage",
-                                    "name": "downstreams",
-                                    "type": [
-                                        "null",
-                                        {
-                                            "items": "string",
-                                            "type": "array"
-                                        }
-                                    ],
-                                    "urn_is_array": true
-                                },
-                                {
-                                    "default": null,
-                                    "doc": "The transform operation applied to the upstream entities to produce the downstream field(s)",
-                                    "name": "transformOperation",
-                                    "type": [
-                                        "null",
-                                        "string"
-                                    ]
-                                },
-                                {
-                                    "default": 1.0,
-                                    "doc": "The confidence in this lineage between 0 (low confidence) and 1 (high confidence)",
-                                    "name": "confidenceScore",
-                                    "type": "float"
-                                }
-                            ],
-                            "name": "FineGrainedLineage",
-                            "namespace": "com.linkedin.pegasus2avro.dataset",
-                            "type": "record"
-                        },
-                        "type": "array"
-                    }
+                    "long"
                 ]
             }
         ],
-        "name": "DataJobInputOutput",
-        "namespace": "com.linkedin.pegasus2avro.datajob",
+        "name": "ChartInfo",
+        "namespace": "com.linkedin.pegasus2avro.chart",
         "type": "record"
     },
     {
         "Aspect": {
-            "name": "editableDataFlowProperties"
+            "name": "editableContainerProperties"
         },
-        "doc": "Stores editable changes made to properties. This separates changes made from\ningestion pipelines and edits in the UI to avoid accidental overwrites of user-provided data by ingestion pipelines",
+        "doc": "Editable information about an Asset Container as defined on the DataHub Platform",
         "fields": [
             {
-                "default": {
-                    "actor": "urn:li:corpuser:unknown",
-                    "impersonator": null,
-                    "message": null,
-                    "time": 0
-                },
-                "doc": "An AuditStamp corresponding to the creation of this resource/association/sub-resource. A value of 0 for time indicates missing data.",
-                "name": "created",
-                "type": "com.linkedin.pegasus2avro.common.AuditStamp"
-            },
-            {
-                "default": {
-                    "actor": "urn:li:corpuser:unknown",
-                    "impersonator": null,
-                    "message": null,
-                    "time": 0
-                },
-                "doc": "An AuditStamp corresponding to the last modification of this resource/association/sub-resource. If no modification has happened since creation, lastModified should be the same as created. A value of 0 for time indicates missing data.",
-                "name": "lastModified",
-                "type": "com.linkedin.pegasus2avro.common.AuditStamp"
-            },
-            {
-                "default": null,
-                "doc": "An AuditStamp corresponding to the deletion of this resource/association/sub-resource. Logically, deleted MUST have a later timestamp than creation. It may or may not have the same time as lastModified depending upon the resource/association/sub-resource semantics.",
-                "name": "deleted",
-                "type": [
-                    "null",
-                    "com.linkedin.pegasus2avro.common.AuditStamp"
-                ]
-            },
-            {
                 "Searchable": {
                     "fieldName": "editedDescription",
                     "fieldType": "TEXT"
                 },
                 "default": null,
-                "doc": "Edited documentation of the data flow",
+                "doc": "Description of the Asset Container as its received on the DataHub Platform",
                 "name": "description",
                 "type": [
                     "null",
                     "string"
                 ]
             }
         ],
-        "name": "EditableDataFlowProperties",
-        "namespace": "com.linkedin.pegasus2avro.datajob",
-        "type": "record"
-    },
-    {
-        "Aspect": {
-            "name": "versionInfo"
-        },
-        "doc": "Information about a Data processing job",
-        "fields": [
-            {
-                "Searchable": {
-                    "/*": {
-                        "queryByDefault": true
-                    }
-                },
-                "default": {},
-                "doc": "Custom property bag.",
-                "name": "customProperties",
-                "type": {
-                    "type": "map",
-                    "values": "string"
-                }
-            },
-            {
-                "default": null,
-                "doc": "URL where the reference exist",
-                "java": {
-                    "class": "com.linkedin.pegasus2avro.common.url.Url",
-                    "coercerClass": "com.linkedin.pegasus2avro.common.url.UrlCoercer"
-                },
-                "name": "externalUrl",
-                "type": [
-                    "null",
-                    "string"
-                ]
-            },
-            {
-                "doc": "The version which can indentify a job version like a commit hash or md5 hash",
-                "name": "version",
-                "type": "string"
-            },
-            {
-                "doc": "The type of the version like git hash or md5 hash",
-                "name": "versionType",
-                "type": "string"
-            }
-        ],
-        "name": "VersionInfo",
-        "namespace": "com.linkedin.pegasus2avro.datajob",
+        "name": "EditableContainerProperties",
+        "namespace": "com.linkedin.pegasus2avro.container",
         "type": "record"
     },
     {
         "Aspect": {
-            "name": "dataFlowInfo"
+            "name": "containerProperties"
         },
-        "doc": "Information about a Data processing flow",
+        "doc": "Information about a Asset Container as received from a 3rd party source system",
         "fields": [
             {
                 "Searchable": {
                     "/*": {
                         "queryByDefault": true
                     }
                 },
@@ -5698,39 +4973,40 @@
             },
             {
                 "Searchable": {
                     "boostScore": 10.0,
                     "enableAutocomplete": true,
                     "fieldType": "TEXT_PARTIAL"
                 },
-                "doc": "Flow name",
+                "doc": "Display name of the Asset Container",
                 "name": "name",
                 "type": "string"
             },
             {
                 "Searchable": {
-                    "fieldType": "TEXT",
-                    "hasValuesFieldName": "hasDescription"
+                    "boostScore": 10.0,
+                    "enableAutocomplete": true,
+                    "fieldType": "TEXT_PARTIAL"
                 },
                 "default": null,
-                "doc": "Flow description",
-                "name": "description",
+                "doc": "Fully-qualified name of the Container",
+                "name": "qualifiedName",
                 "type": [
                     "null",
                     "string"
                 ]
             },
             {
                 "Searchable": {
-                    "fieldType": "TEXT_PARTIAL",
-                    "queryByDefault": false
+                    "fieldType": "TEXT",
+                    "hasValuesFieldName": "hasDescription"
                 },
                 "default": null,
-                "doc": "Optional project/namespace associated with the flow",
-                "name": "project",
+                "doc": "Description of the Asset Container as it exists inside a source system",
+                "name": "description",
                 "type": [
                     "null",
                     "string"
                 ]
             },
             {
                 "Searchable": {
@@ -5740,40 +5016,15 @@
                     }
                 },
                 "default": null,
                 "doc": "A timestamp documenting when the asset was created in the source Data Platform (not on DataHub)",
                 "name": "created",
                 "type": [
                     "null",
-                    {
-                        "doc": "A standard event timestamp",
-                        "fields": [
-                            {
-                                "doc": "When did the event occur",
-                                "name": "time",
-                                "type": "long"
-                            },
-                            {
-                                "Urn": "Urn",
-                                "default": null,
-                                "doc": "Optional: The actor urn involved in the event.",
-                                "java": {
-                                    "class": "com.linkedin.pegasus2avro.common.urn.Urn"
-                                },
-                                "name": "actor",
-                                "type": [
-                                    "null",
-                                    "string"
-                                ]
-                            }
-                        ],
-                        "name": "TimeStamp",
-                        "namespace": "com.linkedin.pegasus2avro.common",
-                        "type": "record"
-                    }
+                    "com.linkedin.pegasus2avro.common.TimeStamp"
                 ]
             },
             {
                 "Searchable": {
                     "/time": {
                         "fieldName": "lastModifiedAt",
                         "fieldType": "DATETIME"
@@ -5784,601 +5035,664 @@
                 "name": "lastModified",
                 "type": [
                     "null",
                     "com.linkedin.pegasus2avro.common.TimeStamp"
                 ]
             }
         ],
-        "name": "DataFlowInfo",
-        "namespace": "com.linkedin.pegasus2avro.datajob",
+        "name": "ContainerProperties",
+        "namespace": "com.linkedin.pegasus2avro.container",
         "type": "record"
     },
     {
         "Aspect": {
-            "name": "dataJobInfo"
+            "name": "container"
         },
-        "doc": "Information about a Data processing job",
+        "doc": "Link from an asset to its parent container",
         "fields": [
             {
+                "Relationship": {
+                    "entityTypes": [
+                        "container"
+                    ],
+                    "name": "IsPartOf"
+                },
                 "Searchable": {
-                    "/*": {
-                        "queryByDefault": true
-                    }
+                    "addToFilters": true,
+                    "fieldName": "container",
+                    "fieldType": "URN",
+                    "filterNameOverride": "Container",
+                    "hasValuesFieldName": "hasContainer"
                 },
-                "default": {},
-                "doc": "Custom property bag.",
-                "name": "customProperties",
-                "type": {
-                    "type": "map",
-                    "values": "string"
-                }
-            },
-            {
-                "default": null,
-                "doc": "URL where the reference exist",
+                "Urn": "Urn",
+                "doc": "The parent container of an asset",
                 "java": {
-                    "class": "com.linkedin.pegasus2avro.common.url.Url",
-                    "coercerClass": "com.linkedin.pegasus2avro.common.url.UrlCoercer"
+                    "class": "com.linkedin.pegasus2avro.common.urn.Urn"
                 },
-                "name": "externalUrl",
-                "type": [
-                    "null",
-                    "string"
-                ]
-            },
+                "name": "container",
+                "type": "string"
+            }
+        ],
+        "name": "Container",
+        "namespace": "com.linkedin.pegasus2avro.container",
+        "type": "record"
+    },
+    {
+        "Aspect": {
+            "name": "glossaryNodeInfo"
+        },
+        "doc": "Properties associated with a GlossaryNode",
+        "fields": [
             {
-                "Searchable": {
-                    "boostScore": 10.0,
-                    "enableAutocomplete": true,
-                    "fieldType": "TEXT_PARTIAL"
-                },
-                "doc": "Job name",
-                "name": "name",
+                "Searchable": {},
+                "doc": "Definition of business node",
+                "name": "definition",
                 "type": "string"
             },
             {
+                "Relationship": {
+                    "entityTypes": [
+                        "glossaryNode"
+                    ],
+                    "name": "IsPartOf"
+                },
                 "Searchable": {
-                    "fieldType": "TEXT",
-                    "hasValuesFieldName": "hasDescription"
+                    "fieldName": "parentNode",
+                    "fieldType": "URN",
+                    "hasValuesFieldName": "hasParentNode"
                 },
+                "Urn": "GlossaryNodeUrn",
                 "default": null,
-                "doc": "Job description",
-                "name": "description",
-                "type": [
-                    "null",
-                    "string"
-                ]
-            },
-            {
-                "doc": "Datajob type\n*NOTE**: AzkabanJobType is deprecated. Please use strings instead.",
-                "name": "type",
-                "type": [
-                    {
-                        "doc": "The various types of support azkaban jobs",
-                        "name": "AzkabanJobType",
-                        "namespace": "com.linkedin.pegasus2avro.datajob.azkaban",
-                        "symbolDocs": {
-                            "COMMAND": "The command job type is one of the basic built-in types. It runs multiple UNIX commands using java processbuilder.\nUpon execution, Azkaban spawns off a process to run the command.",
-                            "GLUE": "Glue type is for running AWS Glue job transforms.",
-                            "HADOOP_JAVA": "Runs a java program with ability to access Hadoop cluster.\nhttps://azkaban.readthedocs.io/en/latest/jobTypes.html#java-job-type",
-                            "HADOOP_SHELL": "In large part, this is the same Command type. The difference is its ability to talk to a Hadoop cluster\nsecurely, via Hadoop tokens.",
-                            "HIVE": "Hive type is for running Hive jobs.",
-                            "PIG": "Pig type is for running Pig jobs.",
-                            "SQL": "SQL is for running Presto, mysql queries etc"
-                        },
-                        "symbols": [
-                            "COMMAND",
-                            "HADOOP_JAVA",
-                            "HADOOP_SHELL",
-                            "HIVE",
-                            "PIG",
-                            "SQL",
-                            "GLUE"
-                        ],
-                        "type": "enum"
-                    },
-                    "string"
-                ]
-            },
-            {
-                "Urn": "DataFlowUrn",
-                "default": null,
-                "doc": "DataFlow urn that this job is part of",
+                "doc": "Parent node of the glossary term",
                 "java": {
-                    "class": "com.linkedin.pegasus2avro.common.urn.DataFlowUrn"
+                    "class": "com.linkedin.pegasus2avro.common.urn.GlossaryNodeUrn"
                 },
-                "name": "flowUrn",
+                "name": "parentNode",
                 "type": [
                     "null",
                     "string"
                 ]
             },
             {
                 "Searchable": {
-                    "/time": {
-                        "fieldName": "createdAt",
-                        "fieldType": "DATETIME"
-                    }
+                    "boostScore": 10.0,
+                    "enableAutocomplete": true,
+                    "fieldName": "displayName",
+                    "fieldType": "TEXT_PARTIAL"
                 },
                 "default": null,
-                "doc": "A timestamp documenting when the asset was created in the source Data Platform (not on DataHub)",
-                "name": "created",
+                "doc": "Display name of the node",
+                "name": "name",
                 "type": [
                     "null",
-                    "com.linkedin.pegasus2avro.common.TimeStamp"
+                    "string"
                 ]
             },
             {
                 "Searchable": {
-                    "/time": {
-                        "fieldName": "lastModifiedAt",
-                        "fieldType": "DATETIME"
-                    }
+                    "fieldType": "TEXT_PARTIAL"
                 },
                 "default": null,
-                "doc": "A timestamp documenting when the asset was last modified in the source Data Platform (not on DataHub)",
-                "name": "lastModified",
-                "type": [
-                    "null",
-                    "com.linkedin.pegasus2avro.common.TimeStamp"
-                ]
-            },
-            {
-                "default": null,
-                "deprecated": "Use Data Process Instance model, instead",
-                "doc": "Status of the job - Deprecated for Data Process Instance model.",
-                "name": "status",
+                "doc": "Optional id for the GlossaryNode",
+                "name": "id",
                 "type": [
                     "null",
-                    {
-                        "doc": "Job statuses",
-                        "name": "JobStatus",
-                        "namespace": "com.linkedin.pegasus2avro.datajob",
-                        "symbolDocs": {
-                            "COMPLETED": "Jobs with successful completion.",
-                            "FAILED": "Jobs that have failed.",
-                            "IN_PROGRESS": "Jobs currently running.",
-                            "SKIPPED": "Jobs that have been skipped.",
-                            "STARTING": "Jobs being initialized.",
-                            "STOPPED": "Jobs that have stopped.",
-                            "STOPPING": "Jobs being stopped.",
-                            "UNKNOWN": "Jobs with unknown status (either unmappable or unavailable)"
-                        },
-                        "symbols": [
-                            "STARTING",
-                            "IN_PROGRESS",
-                            "STOPPING",
-                            "STOPPED",
-                            "COMPLETED",
-                            "FAILED",
-                            "UNKNOWN",
-                            "SKIPPED"
-                        ],
-                        "type": "enum"
-                    }
+                    "string"
                 ]
             }
         ],
-        "name": "DataJobInfo",
-        "namespace": "com.linkedin.pegasus2avro.datajob",
+        "name": "GlossaryNodeInfo",
+        "namespace": "com.linkedin.pegasus2avro.glossary",
         "type": "record"
     },
     {
         "Aspect": {
-            "name": "datahubIngestionRunSummary",
-            "type": "timeseries"
+            "name": "glossaryTermInfo"
         },
-        "doc": "Summary of a datahub ingestion run for a given platform.",
+        "doc": "Properties associated with a GlossaryTerm",
         "fields": [
             {
-                "doc": "The event timestamp field as epoch at UTC in milli seconds.",
-                "name": "timestampMillis",
-                "type": "long"
+                "Searchable": {
+                    "/*": {
+                        "queryByDefault": true
+                    }
+                },
+                "default": {},
+                "doc": "Custom property bag.",
+                "name": "customProperties",
+                "type": {
+                    "type": "map",
+                    "values": "string"
+                }
             },
             {
+                "Searchable": {
+                    "fieldType": "TEXT_PARTIAL"
+                },
                 "default": null,
-                "doc": "Granularity of the event if applicable",
-                "name": "eventGranularity",
+                "doc": "Optional id for the term",
+                "name": "id",
                 "type": [
                     "null",
-                    "com.linkedin.pegasus2avro.timeseries.TimeWindowSize"
+                    "string"
                 ]
             },
             {
-                "default": {
-                    "partition": "FULL_TABLE_SNAPSHOT",
-                    "timePartition": null,
-                    "type": "FULL_TABLE"
+                "Searchable": {
+                    "boostScore": 10.0,
+                    "enableAutocomplete": true,
+                    "fieldType": "TEXT_PARTIAL"
                 },
-                "doc": "The optional partition specification.",
-                "name": "partitionSpec",
-                "type": [
-                    "com.linkedin.pegasus2avro.timeseries.PartitionSpec",
-                    "null"
-                ]
-            },
-            {
                 "default": null,
-                "doc": "The optional messageId, if provided serves as a custom user-defined unique identifier for an aspect value.",
-                "name": "messageId",
+                "doc": "Display name of the term",
+                "name": "name",
                 "type": [
                     "null",
                     "string"
                 ]
             },
             {
-                "TimeseriesField": {},
-                "doc": "The name of the pipeline that ran ingestion, a stable unique user provided identifier.\n e.g. my_snowflake1-to-datahub.",
-                "name": "pipelineName",
-                "type": "string"
-            },
-            {
-                "TimeseriesField": {},
-                "doc": "The id of the instance against which the ingestion pipeline ran.\ne.g.: Bigquery project ids, MySQL hostnames etc.",
-                "name": "platformInstanceId",
-                "type": "string"
-            },
-            {
-                "TimeseriesField": {},
-                "doc": "The runId for this pipeline instance.",
-                "name": "runId",
+                "Searchable": {},
+                "doc": "Definition of business term.",
+                "name": "definition",
                 "type": "string"
             },
             {
-                "TimeseriesField": {},
-                "doc": "Run Status - Succeeded/Skipped/Failed etc.",
-                "name": "runStatus",
-                "type": "com.linkedin.pegasus2avro.datajob.JobStatus"
-            },
-            {
-                "default": null,
-                "doc": "The number of workunits written to sink.",
-                "name": "numWorkUnitsCommitted",
-                "type": [
-                    "null",
-                    "long"
-                ]
-            },
-            {
-                "default": null,
-                "doc": "The number of workunits that are produced.",
-                "name": "numWorkUnitsCreated",
-                "type": [
-                    "null",
-                    "long"
-                ]
-            },
-            {
+                "Relationship": {
+                    "entityTypes": [
+                        "glossaryNode"
+                    ],
+                    "name": "IsPartOf"
+                },
+                "Searchable": {
+                    "fieldName": "parentNode",
+                    "fieldType": "URN",
+                    "hasValuesFieldName": "hasParentNode"
+                },
+                "Urn": "GlossaryNodeUrn",
                 "default": null,
-                "doc": "The number of events produced (MCE + MCP).",
-                "name": "numEvents",
+                "doc": "Parent node of the glossary term",
+                "java": {
+                    "class": "com.linkedin.pegasus2avro.common.urn.GlossaryNodeUrn"
+                },
+                "name": "parentNode",
                 "type": [
                     "null",
-                    "long"
+                    "string"
                 ]
             },
             {
-                "default": null,
-                "doc": "The total number of entities produced (unique entity urns).",
-                "name": "numEntities",
-                "type": [
-                    "null",
-                    "long"
-                ]
+                "Searchable": {
+                    "fieldType": "KEYWORD"
+                },
+                "doc": "Source of the Business Term (INTERNAL or EXTERNAL) with default value as INTERNAL",
+                "name": "termSource",
+                "type": "string"
             },
             {
+                "Searchable": {
+                    "fieldType": "KEYWORD"
+                },
                 "default": null,
-                "doc": "The total number of aspects produced across all entities.",
-                "name": "numAspects",
+                "doc": "External Reference to the business-term",
+                "name": "sourceRef",
                 "type": [
                     "null",
-                    "long"
+                    "string"
                 ]
             },
             {
                 "default": null,
-                "doc": "Total number of source API calls.",
-                "name": "numSourceAPICalls",
+                "doc": "The abstracted URL such as https://spec.edmcouncil.org/fibo/ontology/FBC/FinancialInstruments/FinancialInstruments/CashInstrument.",
+                "java": {
+                    "class": "com.linkedin.pegasus2avro.common.url.Url",
+                    "coercerClass": "com.linkedin.pegasus2avro.common.url.UrlCoercer"
+                },
+                "name": "sourceUrl",
                 "type": [
                     "null",
-                    "long"
+                    "string"
                 ]
             },
             {
                 "default": null,
-                "doc": "Total latency across all source API calls.",
-                "name": "totalLatencySourceAPICalls",
+                "deprecated": true,
+                "doc": "Schema definition of the glossary term",
+                "name": "rawSchema",
                 "type": [
                     "null",
-                    "long"
+                    "string"
                 ]
-            },
+            }
+        ],
+        "name": "GlossaryTermInfo",
+        "namespace": "com.linkedin.pegasus2avro.glossary",
+        "type": "record"
+    },
+    {
+        "Aspect": {
+            "name": "glossaryRelatedTerms"
+        },
+        "doc": "Has A / Is A lineage information about a glossary Term reporting the lineage",
+        "fields": [
             {
+                "Relationship": {
+                    "/*": {
+                        "entityTypes": [
+                            "glossaryTerm"
+                        ],
+                        "name": "IsA"
+                    }
+                },
+                "Searchable": {
+                    "/*": {
+                        "boostScore": 2.0,
+                        "fieldName": "isRelatedTerms",
+                        "fieldType": "URN"
+                    }
+                },
+                "Urn": "GlossaryTermUrn",
                 "default": null,
-                "doc": "Total number of sink API calls.",
-                "name": "numSinkAPICalls",
+                "doc": "The relationship Is A with glossary term",
+                "name": "isRelatedTerms",
                 "type": [
                     "null",
-                    "long"
-                ]
+                    {
+                        "items": "string",
+                        "type": "array"
+                    }
+                ],
+                "urn_is_array": true
             },
             {
+                "Relationship": {
+                    "/*": {
+                        "entityTypes": [
+                            "glossaryTerm"
+                        ],
+                        "name": "HasA"
+                    }
+                },
+                "Searchable": {
+                    "/*": {
+                        "boostScore": 2.0,
+                        "fieldName": "hasRelatedTerms",
+                        "fieldType": "URN"
+                    }
+                },
+                "Urn": "GlossaryTermUrn",
                 "default": null,
-                "doc": "Total latency across all sink API calls.",
-                "name": "totalLatencySinkAPICalls",
+                "doc": "The relationship Has A with glossary term",
+                "name": "hasRelatedTerms",
                 "type": [
                     "null",
-                    "long"
-                ]
+                    {
+                        "items": "string",
+                        "type": "array"
+                    }
+                ],
+                "urn_is_array": true
             },
             {
+                "Relationship": {
+                    "/*": {
+                        "entityTypes": [
+                            "glossaryTerm"
+                        ],
+                        "name": "HasValue"
+                    }
+                },
+                "Searchable": {
+                    "/*": {
+                        "fieldName": "values",
+                        "fieldType": "URN"
+                    }
+                },
+                "Urn": "GlossaryTermUrn",
                 "default": null,
-                "doc": "Number of warnings generated.",
-                "name": "numWarnings",
+                "doc": "The relationship Has Value with glossary term.\nThese are fixed value a term has. For example a ColorEnum where RED, GREEN and YELLOW are fixed values.",
+                "name": "values",
                 "type": [
                     "null",
-                    "long"
-                ]
+                    {
+                        "items": "string",
+                        "type": "array"
+                    }
+                ],
+                "urn_is_array": true
             },
             {
+                "Relationship": {
+                    "/*": {
+                        "entityTypes": [
+                            "glossaryTerm"
+                        ],
+                        "name": "IsRelatedTo"
+                    }
+                },
+                "Searchable": {
+                    "/*": {
+                        "fieldName": "relatedTerms",
+                        "fieldType": "URN"
+                    }
+                },
+                "Urn": "GlossaryTermUrn",
                 "default": null,
-                "doc": "Number of errors generated.",
-                "name": "numErrors",
+                "doc": "The relationship isRelatedTo with glossary term",
+                "name": "relatedTerms",
                 "type": [
                     "null",
-                    "long"
-                ]
-            },
+                    {
+                        "items": "string",
+                        "type": "array"
+                    }
+                ],
+                "urn_is_array": true
+            }
+        ],
+        "name": "GlossaryRelatedTerms",
+        "namespace": "com.linkedin.pegasus2avro.glossary",
+        "type": "record"
+    },
+    {
+        "Aspect": {
+            "name": "tagProperties"
+        },
+        "doc": "Properties associated with a Tag",
+        "fields": [
             {
-                "default": null,
-                "doc": "Number of entities skipped.",
-                "name": "numEntitiesSkipped",
-                "type": [
-                    "null",
-                    "long"
-                ]
+                "Searchable": {
+                    "boostScore": 10.0,
+                    "enableAutocomplete": true,
+                    "fieldType": "TEXT_PARTIAL"
+                },
+                "doc": "Display name of the tag",
+                "name": "name",
+                "type": "string"
             },
             {
+                "Searchable": {},
                 "default": null,
-                "doc": "The non-sensitive key-value pairs of the yaml config used as json string.",
-                "name": "config",
+                "doc": "Documentation of the tag",
+                "name": "description",
                 "type": [
                     "null",
                     "string"
                 ]
             },
             {
                 "default": null,
-                "doc": "Custom value.",
-                "name": "custom_summary",
+                "doc": "The color associated with the Tag in Hex. For example #FFFFFF.",
+                "name": "colorHex",
                 "type": [
                     "null",
                     "string"
                 ]
+            }
+        ],
+        "name": "TagProperties",
+        "namespace": "com.linkedin.pegasus2avro.tag",
+        "type": "record"
+    },
+    {
+        "Aspect": {
+            "name": "querySubjects"
+        },
+        "doc": "Information about the subjects of a particular Query, i.e. the assets\nbeing queried.",
+        "fields": [
+            {
+                "doc": "One or more subjects of the query.\n\nIn single-asset queries (e.g. table select), this will contain the Table reference\nand optionally schema field references.\n\nIn multi-asset queries (e.g. table joins), this may contain multiple Table references\nand optionally schema field references.",
+                "name": "subjects",
+                "type": {
+                    "items": {
+                        "doc": "A single subject of a particular query.\nIn the future, we may evolve this model to include richer details\nabout the Query Subject in relation to the query.",
+                        "fields": [
+                            {
+                                "Relationship": {
+                                    "entityTypes": [
+                                        "dataset",
+                                        "schemaField"
+                                    ],
+                                    "name": "IsAssociatedWith"
+                                },
+                                "Searchable": {
+                                    "fieldName": "entities",
+                                    "fieldType": "URN"
+                                },
+                                "Urn": "Urn",
+                                "doc": "An entity which is the subject of a query.",
+                                "java": {
+                                    "class": "com.linkedin.pegasus2avro.common.urn.Urn"
+                                },
+                                "name": "entity",
+                                "type": "string"
+                            }
+                        ],
+                        "name": "QuerySubject",
+                        "namespace": "com.linkedin.pegasus2avro.query",
+                        "type": "record"
+                    },
+                    "type": "array"
+                }
+            }
+        ],
+        "name": "QuerySubjects",
+        "namespace": "com.linkedin.pegasus2avro.query",
+        "type": "record"
+    },
+    {
+        "Aspect": {
+            "name": "queryProperties"
+        },
+        "doc": "Information about a Query against one or more data assets (e.g. Tables or Views).",
+        "fields": [
+            {
+                "doc": "The Query Statement.",
+                "name": "statement",
+                "type": {
+                    "doc": "A query statement against one or more data assets.",
+                    "fields": [
+                        {
+                            "doc": "The query text",
+                            "name": "value",
+                            "type": "string"
+                        },
+                        {
+                            "default": "SQL",
+                            "doc": "The language of the Query, e.g. SQL.",
+                            "name": "language",
+                            "type": {
+                                "name": "QueryLanguage",
+                                "namespace": "com.linkedin.pegasus2avro.query",
+                                "symbolDocs": {
+                                    "SQL": "A SQL Query"
+                                },
+                                "symbols": [
+                                    "SQL"
+                                ],
+                                "type": "enum"
+                            }
+                        }
+                    ],
+                    "name": "QueryStatement",
+                    "namespace": "com.linkedin.pegasus2avro.query",
+                    "type": "record"
+                }
             },
             {
-                "TimeseriesField": {},
-                "default": null,
-                "doc": "The software version of this ingestion.",
-                "name": "softwareVersion",
-                "type": [
-                    "null",
-                    "string"
-                ]
+                "Searchable": {},
+                "doc": "The source of the Query",
+                "name": "source",
+                "type": {
+                    "name": "QuerySource",
+                    "namespace": "com.linkedin.pegasus2avro.query",
+                    "symbolDocs": {
+                        "MANUAL": "The query was entered manually by a user (via the UI)."
+                    },
+                    "symbols": [
+                        "MANUAL"
+                    ],
+                    "type": "enum"
+                }
             },
             {
+                "Searchable": {
+                    "boostScore": 10.0,
+                    "enableAutocomplete": true,
+                    "fieldType": "TEXT_PARTIAL"
+                },
                 "default": null,
-                "doc": "The hostname the ingestion pipeline ran on.",
-                "name": "systemHostName",
+                "doc": "Optional display name to identify the query.",
+                "name": "name",
                 "type": [
                     "null",
                     "string"
                 ]
             },
             {
-                "TimeseriesField": {},
                 "default": null,
-                "doc": "The os the ingestion pipeline ran on.",
-                "name": "operatingSystemName",
+                "doc": "The Query description.",
+                "name": "description",
                 "type": [
                     "null",
                     "string"
                 ]
             },
             {
-                "default": null,
-                "doc": "The number of processors on the host the ingestion pipeline ran on.",
-                "name": "numProcessors",
-                "type": [
-                    "null",
-                    "int"
-                ]
+                "Searchable": {
+                    "/actor": {
+                        "fieldName": "createdBy",
+                        "fieldType": "URN"
+                    },
+                    "/time": {
+                        "fieldName": "createdAt",
+                        "fieldType": "DATETIME"
+                    }
+                },
+                "doc": "Audit stamp capturing the time and actor who created the Query.",
+                "name": "created",
+                "type": "com.linkedin.pegasus2avro.common.AuditStamp"
             },
             {
-                "default": null,
-                "doc": "The total amount of memory on the host the ingestion pipeline ran on.",
-                "name": "totalMemory",
-                "type": [
-                    "null",
-                    "long"
-                ]
-            },
+                "Searchable": {
+                    "/actor": {
+                        "fieldName": "lastModifiedBy",
+                        "fieldType": "URN"
+                    },
+                    "/time": {
+                        "fieldName": "lastModifiedAt",
+                        "fieldType": "DATETIME"
+                    }
+                },
+                "doc": "Audit stamp capturing the time and actor who last modified the Query.",
+                "name": "lastModified",
+                "type": "com.linkedin.pegasus2avro.common.AuditStamp"
+            }
+        ],
+        "name": "QueryProperties",
+        "namespace": "com.linkedin.pegasus2avro.query",
+        "type": "record"
+    },
+    {
+        "Aspect": {
+            "name": "telemetryClientId"
+        },
+        "doc": "A simple wrapper around a String to persist the client ID for telemetry in DataHub's backend DB",
+        "fields": [
             {
-                "default": null,
-                "doc": "The available memory on the host the ingestion pipeline ran on.",
-                "name": "availableMemory",
-                "type": [
-                    "null",
-                    "long"
-                ]
+                "doc": "A string representing the telemetry client ID",
+                "name": "clientId",
+                "type": "string"
             }
         ],
-        "name": "DatahubIngestionRunSummary",
-        "namespace": "com.linkedin.pegasus2avro.datajob.datahub",
+        "name": "TelemetryClientId",
+        "namespace": "com.linkedin.pegasus2avro.telemetry",
         "type": "record"
     },
     {
         "Aspect": {
-            "name": "datahubIngestionCheckpoint",
-            "type": "timeseries"
+            "name": "domainProperties"
         },
-        "doc": "Checkpoint of a datahub ingestion run for a given job.",
+        "doc": "Information about a Domain",
         "fields": [
             {
-                "doc": "The event timestamp field as epoch at UTC in milli seconds.",
-                "name": "timestampMillis",
-                "type": "long"
+                "Searchable": {
+                    "boostScore": 10.0,
+                    "enableAutocomplete": true,
+                    "fieldType": "TEXT_PARTIAL"
+                },
+                "doc": "Display name of the Domain",
+                "name": "name",
+                "type": "string"
             },
             {
                 "default": null,
-                "doc": "Granularity of the event if applicable",
-                "name": "eventGranularity",
+                "doc": "Description of the Domain",
+                "name": "description",
                 "type": [
                     "null",
-                    "com.linkedin.pegasus2avro.timeseries.TimeWindowSize"
+                    "string"
                 ]
             },
             {
-                "default": {
-                    "partition": "FULL_TABLE_SNAPSHOT",
-                    "timePartition": null,
-                    "type": "FULL_TABLE"
+                "Searchable": {
+                    "/time": {
+                        "fieldName": "createdTime",
+                        "fieldType": "DATETIME"
+                    }
                 },
-                "doc": "The optional partition specification.",
-                "name": "partitionSpec",
-                "type": [
-                    "com.linkedin.pegasus2avro.timeseries.PartitionSpec",
-                    "null"
-                ]
-            },
-            {
                 "default": null,
-                "doc": "The optional messageId, if provided serves as a custom user-defined unique identifier for an aspect value.",
-                "name": "messageId",
+                "doc": "Created Audit stamp",
+                "name": "created",
                 "type": [
                     "null",
-                    "string"
+                    "com.linkedin.pegasus2avro.common.AuditStamp"
                 ]
-            },
-            {
-                "TimeseriesField": {},
-                "doc": "The name of the pipeline that ran ingestion, a stable unique user provided identifier.\n e.g. my_snowflake1-to-datahub.",
-                "name": "pipelineName",
-                "type": "string"
-            },
-            {
-                "TimeseriesField": {},
-                "doc": "The id of the instance against which the ingestion pipeline ran.\ne.g.: Bigquery project ids, MySQL hostnames etc.",
-                "name": "platformInstanceId",
-                "type": "string"
-            },
-            {
-                "doc": "Json-encoded string representation of the non-secret members of the config .",
-                "name": "config",
-                "type": "string"
-            },
-            {
-                "doc": "Opaque blob of the state representation.",
-                "name": "state",
-                "type": {
-                    "doc": "The checkpoint state object of a datahub ingestion run for a given job.",
-                    "fields": [
-                        {
-                            "doc": "The version of the state format.",
-                            "name": "formatVersion",
-                            "type": "string"
-                        },
-                        {
-                            "doc": "The serialization/deserialization protocol.",
-                            "name": "serde",
-                            "type": "string"
-                        },
-                        {
-                            "default": null,
-                            "doc": "Opaque blob of the state representation.",
-                            "name": "payload",
-                            "type": [
-                                "null",
-                                "bytes"
-                            ]
-                        }
-                    ],
-                    "name": "IngestionCheckpointState",
-                    "namespace": "com.linkedin.pegasus2avro.datajob.datahub",
-                    "type": "record"
-                }
-            },
-            {
-                "TimeseriesField": {},
-                "doc": "The run identifier of this job.",
-                "name": "runId",
-                "type": "string"
             }
         ],
-        "name": "DatahubIngestionCheckpoint",
-        "namespace": "com.linkedin.pegasus2avro.datajob.datahub",
+        "name": "DomainProperties",
+        "namespace": "com.linkedin.pegasus2avro.domain",
         "type": "record"
     },
     {
         "Aspect": {
-            "name": "dataHubRetentionConfig"
+            "name": "domains"
         },
+        "doc": "Links from an Asset to its Domains",
         "fields": [
             {
-                "name": "retention",
+                "Relationship": {
+                    "/*": {
+                        "entityTypes": [
+                            "domain"
+                        ],
+                        "name": "AssociatedWith"
+                    }
+                },
+                "Searchable": {
+                    "/*": {
+                        "addToFilters": true,
+                        "fieldName": "domains",
+                        "fieldType": "URN",
+                        "filterNameOverride": "Domain",
+                        "hasValuesFieldName": "hasDomain"
+                    }
+                },
+                "Urn": "Urn",
+                "doc": "The Domains attached to an Asset",
+                "name": "domains",
                 "type": {
-                    "doc": "Base class that encapsulates different retention policies.\nOnly one of the fields should be set",
-                    "fields": [
-                        {
-                            "default": null,
-                            "name": "version",
-                            "type": [
-                                "null",
-                                {
-                                    "doc": "Keep max N latest records",
-                                    "fields": [
-                                        {
-                                            "name": "maxVersions",
-                                            "type": "int"
-                                        }
-                                    ],
-                                    "name": "VersionBasedRetention",
-                                    "namespace": "com.linkedin.pegasus2avro.retention",
-                                    "type": "record"
-                                }
-                            ]
-                        },
-                        {
-                            "default": null,
-                            "name": "time",
-                            "type": [
-                                "null",
-                                {
-                                    "doc": "Keep records that are less than X seconds old",
-                                    "fields": [
-                                        {
-                                            "name": "maxAgeInSeconds",
-                                            "type": "int"
-                                        }
-                                    ],
-                                    "name": "TimeBasedRetention",
-                                    "namespace": "com.linkedin.pegasus2avro.retention",
-                                    "type": "record"
-                                }
-                            ]
-                        }
-                    ],
-                    "name": "Retention",
-                    "namespace": "com.linkedin.pegasus2avro.retention",
-                    "type": "record"
-                }
+                    "items": "string",
+                    "type": "array"
+                },
+                "urn_is_array": true
             }
         ],
-        "name": "DataHubRetentionConfig",
-        "namespace": "com.linkedin.pegasus2avro.retention",
+        "name": "Domains",
+        "namespace": "com.linkedin.pegasus2avro.domain",
         "type": "record"
     },
     {
         "Aspect": {
             "name": "editableSchemaMetadata"
         },
         "doc": "EditableSchemaMetadata stores editable changes made to schema metadata. This separates changes made from\ningestion pipelines and edits in the UI to avoid accidental overwrites of user-provided data by ingestion pipelines.",
@@ -6457,77 +5771,15 @@
                                     }
                                 },
                                 "default": null,
                                 "doc": "Tags associated with the field",
                                 "name": "globalTags",
                                 "type": [
                                     "null",
-                                    {
-                                        "Aspect": {
-                                            "name": "globalTags"
-                                        },
-                                        "doc": "Tag aspect used for applying tags to an entity",
-                                        "fields": [
-                                            {
-                                                "Relationship": {
-                                                    "/*/tag": {
-                                                        "entityTypes": [
-                                                            "tag"
-                                                        ],
-                                                        "name": "TaggedWith"
-                                                    }
-                                                },
-                                                "Searchable": {
-                                                    "/*/tag": {
-                                                        "addToFilters": true,
-                                                        "boostScore": 0.5,
-                                                        "fieldName": "tags",
-                                                        "fieldType": "URN",
-                                                        "filterNameOverride": "Tag",
-                                                        "hasValuesFieldName": "hasTags",
-                                                        "queryByDefault": true
-                                                    }
-                                                },
-                                                "doc": "Tags associated with a given entity",
-                                                "name": "tags",
-                                                "type": {
-                                                    "items": {
-                                                        "doc": "Properties of an applied tag. For now, just an Urn. In the future we can extend this with other properties, e.g.\npropagation parameters.",
-                                                        "fields": [
-                                                            {
-                                                                "Urn": "TagUrn",
-                                                                "doc": "Urn of the applied tag",
-                                                                "java": {
-                                                                    "class": "com.linkedin.pegasus2avro.common.urn.TagUrn"
-                                                                },
-                                                                "name": "tag",
-                                                                "type": "string"
-                                                            },
-                                                            {
-                                                                "default": null,
-                                                                "doc": "Additional context about the association",
-                                                                "name": "context",
-                                                                "type": [
-                                                                    "null",
-                                                                    "string"
-                                                                ]
-                                                            }
-                                                        ],
-                                                        "name": "TagAssociation",
-                                                        "namespace": "com.linkedin.pegasus2avro.common",
-                                                        "type": "record"
-                                                    },
-                                                    "type": "array"
-                                                }
-                                            }
-                                        ],
-                                        "name": "GlobalTags",
-                                        "namespace": "com.linkedin.pegasus2avro.common",
-                                        "type": "record"
-                                    }
+                                    "com.linkedin.pegasus2avro.common.GlobalTags"
                                 ]
                             },
                             {
                                 "Relationship": {
                                     "/terms/*/urn": {
                                         "entityTypes": [
                                             "glossaryTerm"
@@ -6543,76 +5795,15 @@
                                     }
                                 },
                                 "default": null,
                                 "doc": "Glossary terms associated with the field",
                                 "name": "glossaryTerms",
                                 "type": [
                                     "null",
-                                    {
-                                        "Aspect": {
-                                            "name": "glossaryTerms"
-                                        },
-                                        "doc": "Related business terms information",
-                                        "fields": [
-                                            {
-                                                "doc": "The related business terms",
-                                                "name": "terms",
-                                                "type": {
-                                                    "items": {
-                                                        "doc": "Properties of an applied glossary term.",
-                                                        "fields": [
-                                                            {
-                                                                "Relationship": {
-                                                                    "entityTypes": [
-                                                                        "glossaryTerm"
-                                                                    ],
-                                                                    "name": "TermedWith"
-                                                                },
-                                                                "Searchable": {
-                                                                    "addToFilters": true,
-                                                                    "fieldName": "glossaryTerms",
-                                                                    "fieldType": "URN",
-                                                                    "filterNameOverride": "Glossary Term",
-                                                                    "hasValuesFieldName": "hasGlossaryTerms"
-                                                                },
-                                                                "Urn": "GlossaryTermUrn",
-                                                                "doc": "Urn of the applied glossary term",
-                                                                "java": {
-                                                                    "class": "com.linkedin.pegasus2avro.common.urn.GlossaryTermUrn"
-                                                                },
-                                                                "name": "urn",
-                                                                "type": "string"
-                                                            },
-                                                            {
-                                                                "default": null,
-                                                                "doc": "Additional context about the association",
-                                                                "name": "context",
-                                                                "type": [
-                                                                    "null",
-                                                                    "string"
-                                                                ]
-                                                            }
-                                                        ],
-                                                        "name": "GlossaryTermAssociation",
-                                                        "namespace": "com.linkedin.pegasus2avro.common",
-                                                        "type": "record"
-                                                    },
-                                                    "type": "array"
-                                                }
-                                            },
-                                            {
-                                                "doc": "Audit stamp containing who reported the related business term",
-                                                "name": "auditStamp",
-                                                "type": "com.linkedin.pegasus2avro.common.AuditStamp"
-                                            }
-                                        ],
-                                        "name": "GlossaryTerms",
-                                        "namespace": "com.linkedin.pegasus2avro.common",
-                                        "type": "record"
-                                    }
+                                    "com.linkedin.pegasus2avro.common.GlossaryTerms"
                                 ]
                             }
                         ],
                         "name": "EditableSchemaFieldInfo",
                         "namespace": "com.linkedin.pegasus2avro.schema",
                         "type": "record"
                     },
@@ -6862,331 +6053,15 @@
                     }
                 ]
             },
             {
                 "doc": "Client provided a list of fields from document schema.",
                 "name": "fields",
                 "type": {
-                    "items": {
-                        "doc": "SchemaField to describe metadata related to dataset schema.",
-                        "fields": [
-                            {
-                                "Searchable": {
-                                    "boostScore": 5.0,
-                                    "fieldName": "fieldPaths",
-                                    "fieldType": "TEXT"
-                                },
-                                "doc": "Flattened name of the field. Field is computed from jsonPath field.",
-                                "name": "fieldPath",
-                                "type": "string"
-                            },
-                            {
-                                "Deprecated": true,
-                                "default": null,
-                                "doc": "Flattened name of a field in JSON Path notation.",
-                                "name": "jsonPath",
-                                "type": [
-                                    "null",
-                                    "string"
-                                ]
-                            },
-                            {
-                                "default": false,
-                                "doc": "Indicates if this field is optional or nullable",
-                                "name": "nullable",
-                                "type": "boolean"
-                            },
-                            {
-                                "Searchable": {
-                                    "boostScore": 0.1,
-                                    "fieldName": "fieldDescriptions",
-                                    "fieldType": "TEXT"
-                                },
-                                "default": null,
-                                "doc": "Description",
-                                "name": "description",
-                                "type": [
-                                    "null",
-                                    "string"
-                                ]
-                            },
-                            {
-                                "Searchable": {
-                                    "boostScore": 0.2,
-                                    "fieldName": "fieldLabels",
-                                    "fieldType": "TEXT"
-                                },
-                                "default": null,
-                                "doc": "Label of the field. Provides a more human-readable name for the field than field path. Some sources will\nprovide this metadata but not all sources have the concept of a label. If just one string is associated with\na field in a source, that is most likely a description.",
-                                "name": "label",
-                                "type": [
-                                    "null",
-                                    "string"
-                                ]
-                            },
-                            {
-                                "default": null,
-                                "doc": "An AuditStamp corresponding to the creation of this schema field.",
-                                "name": "created",
-                                "type": [
-                                    "null",
-                                    "com.linkedin.pegasus2avro.common.AuditStamp"
-                                ]
-                            },
-                            {
-                                "default": null,
-                                "doc": "An AuditStamp corresponding to the last modification of this schema field.",
-                                "name": "lastModified",
-                                "type": [
-                                    "null",
-                                    "com.linkedin.pegasus2avro.common.AuditStamp"
-                                ]
-                            },
-                            {
-                                "doc": "Platform independent field type of the field.",
-                                "name": "type",
-                                "type": {
-                                    "doc": "Schema field data types",
-                                    "fields": [
-                                        {
-                                            "doc": "Data platform specific types",
-                                            "name": "type",
-                                            "type": [
-                                                {
-                                                    "doc": "Boolean field type.",
-                                                    "fields": [],
-                                                    "name": "BooleanType",
-                                                    "namespace": "com.linkedin.pegasus2avro.schema",
-                                                    "type": "record"
-                                                },
-                                                {
-                                                    "doc": "Fixed field type.",
-                                                    "fields": [],
-                                                    "name": "FixedType",
-                                                    "namespace": "com.linkedin.pegasus2avro.schema",
-                                                    "type": "record"
-                                                },
-                                                {
-                                                    "doc": "String field type.",
-                                                    "fields": [],
-                                                    "name": "StringType",
-                                                    "namespace": "com.linkedin.pegasus2avro.schema",
-                                                    "type": "record"
-                                                },
-                                                {
-                                                    "doc": "Bytes field type.",
-                                                    "fields": [],
-                                                    "name": "BytesType",
-                                                    "namespace": "com.linkedin.pegasus2avro.schema",
-                                                    "type": "record"
-                                                },
-                                                {
-                                                    "doc": "Number data type: long, integer, short, etc..",
-                                                    "fields": [],
-                                                    "name": "NumberType",
-                                                    "namespace": "com.linkedin.pegasus2avro.schema",
-                                                    "type": "record"
-                                                },
-                                                {
-                                                    "doc": "Date field type.",
-                                                    "fields": [],
-                                                    "name": "DateType",
-                                                    "namespace": "com.linkedin.pegasus2avro.schema",
-                                                    "type": "record"
-                                                },
-                                                {
-                                                    "doc": "Time field type. This should also be used for datetimes.",
-                                                    "fields": [],
-                                                    "name": "TimeType",
-                                                    "namespace": "com.linkedin.pegasus2avro.schema",
-                                                    "type": "record"
-                                                },
-                                                {
-                                                    "doc": "Enum field type.",
-                                                    "fields": [],
-                                                    "name": "EnumType",
-                                                    "namespace": "com.linkedin.pegasus2avro.schema",
-                                                    "type": "record"
-                                                },
-                                                {
-                                                    "doc": "Null field type.",
-                                                    "fields": [],
-                                                    "name": "NullType",
-                                                    "namespace": "com.linkedin.pegasus2avro.schema",
-                                                    "type": "record"
-                                                },
-                                                {
-                                                    "doc": "Map field type.",
-                                                    "fields": [
-                                                        {
-                                                            "default": null,
-                                                            "doc": "Key type in a map",
-                                                            "name": "keyType",
-                                                            "type": [
-                                                                "null",
-                                                                "string"
-                                                            ]
-                                                        },
-                                                        {
-                                                            "default": null,
-                                                            "doc": "Type of the value in a map",
-                                                            "name": "valueType",
-                                                            "type": [
-                                                                "null",
-                                                                "string"
-                                                            ]
-                                                        }
-                                                    ],
-                                                    "name": "MapType",
-                                                    "namespace": "com.linkedin.pegasus2avro.schema",
-                                                    "type": "record"
-                                                },
-                                                {
-                                                    "doc": "Array field type.",
-                                                    "fields": [
-                                                        {
-                                                            "default": null,
-                                                            "doc": "List of types this array holds.",
-                                                            "name": "nestedType",
-                                                            "type": [
-                                                                "null",
-                                                                {
-                                                                    "items": "string",
-                                                                    "type": "array"
-                                                                }
-                                                            ]
-                                                        }
-                                                    ],
-                                                    "name": "ArrayType",
-                                                    "namespace": "com.linkedin.pegasus2avro.schema",
-                                                    "type": "record"
-                                                },
-                                                {
-                                                    "doc": "Union field type.",
-                                                    "fields": [
-                                                        {
-                                                            "default": null,
-                                                            "doc": "List of types in union type.",
-                                                            "name": "nestedTypes",
-                                                            "type": [
-                                                                "null",
-                                                                {
-                                                                    "items": "string",
-                                                                    "type": "array"
-                                                                }
-                                                            ]
-                                                        }
-                                                    ],
-                                                    "name": "UnionType",
-                                                    "namespace": "com.linkedin.pegasus2avro.schema",
-                                                    "type": "record"
-                                                },
-                                                {
-                                                    "doc": "Record field type.",
-                                                    "fields": [],
-                                                    "name": "RecordType",
-                                                    "namespace": "com.linkedin.pegasus2avro.schema",
-                                                    "type": "record"
-                                                }
-                                            ]
-                                        }
-                                    ],
-                                    "name": "SchemaFieldDataType",
-                                    "namespace": "com.linkedin.pegasus2avro.schema",
-                                    "type": "record"
-                                }
-                            },
-                            {
-                                "doc": "The native type of the field in the dataset's platform as declared by platform schema.",
-                                "name": "nativeDataType",
-                                "type": "string"
-                            },
-                            {
-                                "default": false,
-                                "doc": "There are use cases when a field in type B references type A. A field in A references field of type B. In such cases, we will mark the first field as recursive.",
-                                "name": "recursive",
-                                "type": "boolean"
-                            },
-                            {
-                                "Relationship": {
-                                    "/tags/*/tag": {
-                                        "entityTypes": [
-                                            "tag"
-                                        ],
-                                        "name": "SchemaFieldTaggedWith"
-                                    }
-                                },
-                                "Searchable": {
-                                    "/tags/*/tag": {
-                                        "boostScore": 0.5,
-                                        "fieldName": "fieldTags",
-                                        "fieldType": "URN"
-                                    }
-                                },
-                                "default": null,
-                                "doc": "Tags associated with the field",
-                                "name": "globalTags",
-                                "type": [
-                                    "null",
-                                    "com.linkedin.pegasus2avro.common.GlobalTags"
-                                ]
-                            },
-                            {
-                                "Relationship": {
-                                    "/terms/*/urn": {
-                                        "entityTypes": [
-                                            "glossaryTerm"
-                                        ],
-                                        "name": "SchemaFieldWithGlossaryTerm"
-                                    }
-                                },
-                                "Searchable": {
-                                    "/terms/*/urn": {
-                                        "boostScore": 0.5,
-                                        "fieldName": "fieldGlossaryTerms",
-                                        "fieldType": "URN"
-                                    }
-                                },
-                                "default": null,
-                                "doc": "Glossary terms associated with the field",
-                                "name": "glossaryTerms",
-                                "type": [
-                                    "null",
-                                    "com.linkedin.pegasus2avro.common.GlossaryTerms"
-                                ]
-                            },
-                            {
-                                "default": false,
-                                "doc": "For schema fields that are part of complex keys, set this field to true\nWe do this to easily distinguish between value and key fields",
-                                "name": "isPartOfKey",
-                                "type": "boolean"
-                            },
-                            {
-                                "default": null,
-                                "doc": "For Datasets which are partitioned, this determines the partitioning key.",
-                                "name": "isPartitioningKey",
-                                "type": [
-                                    "null",
-                                    "boolean"
-                                ]
-                            },
-                            {
-                                "default": null,
-                                "doc": "For schema fields that have other properties that are not modeled explicitly,\nuse this field to serialize those properties into a JSON string",
-                                "name": "jsonProps",
-                                "type": [
-                                    "null",
-                                    "string"
-                                ]
-                            }
-                        ],
-                        "name": "SchemaField",
-                        "namespace": "com.linkedin.pegasus2avro.schema",
-                        "type": "record"
-                    },
+                    "items": "com.linkedin.pegasus2avro.schema.SchemaField",
                     "type": "array"
                 }
             },
             {
                 "default": null,
                 "doc": "Client provided list of fields that define primary keys to access record. Field order defines hierarchical espresso keys. Empty lists indicates absence of primary key access patter. Value is a SchemaField@fieldPath.",
                 "name": "primaryKeys",
@@ -7337,120 +6212,14 @@
         ],
         "name": "SchemaMetadata",
         "namespace": "com.linkedin.pegasus2avro.schema",
         "type": "record"
     },
     {
         "Aspect": {
-            "name": "dataPlatformInfo"
-        },
-        "doc": "Information about a data platform",
-        "fields": [
-            {
-                "Searchable": {
-                    "boostScore": 10.0,
-                    "enableAutocomplete": false,
-                    "fieldType": "TEXT_PARTIAL"
-                },
-                "doc": "Name of the data platform",
-                "name": "name",
-                "type": "string",
-                "validate": {
-                    "strlen": {
-                        "max": 15
-                    }
-                }
-            },
-            {
-                "Searchable": {
-                    "boostScore": 10.0,
-                    "enableAutocomplete": true,
-                    "fieldType": "TEXT_PARTIAL"
-                },
-                "default": null,
-                "doc": "The name that will be used for displaying a platform type.",
-                "name": "displayName",
-                "type": [
-                    "null",
-                    "string"
-                ]
-            },
-            {
-                "doc": "Platform type this data platform describes",
-                "name": "type",
-                "type": {
-                    "doc": "Platform types available at LinkedIn",
-                    "name": "PlatformType",
-                    "namespace": "com.linkedin.pegasus2avro.dataplatform",
-                    "symbolDocs": {
-                        "FILE_SYSTEM": "Value for a file system, e.g. hdfs",
-                        "KEY_VALUE_STORE": "Value for a key value store, e.g. espresso, voldemort",
-                        "MESSAGE_BROKER": "Value for a message broker, e.g. kafka",
-                        "OBJECT_STORE": "Value for an object store, e.g. ambry",
-                        "OLAP_DATASTORE": "Value for an OLAP datastore, e.g. pinot",
-                        "OTHERS": "Value for other platforms, e.g salesforce, dovetail",
-                        "QUERY_ENGINE": "Value for a query engine, e.g. presto",
-                        "RELATIONAL_DB": "Value for a relational database, e.g. oracle, mysql",
-                        "SEARCH_ENGINE": "Value for a search engine, e.g seas"
-                    },
-                    "symbols": [
-                        "FILE_SYSTEM",
-                        "KEY_VALUE_STORE",
-                        "MESSAGE_BROKER",
-                        "OBJECT_STORE",
-                        "OLAP_DATASTORE",
-                        "OTHERS",
-                        "QUERY_ENGINE",
-                        "RELATIONAL_DB",
-                        "SEARCH_ENGINE"
-                    ],
-                    "type": "enum"
-                }
-            },
-            {
-                "doc": "The delimiter in the dataset names on the data platform, e.g. '/' for HDFS and '.' for Oracle",
-                "name": "datasetNameDelimiter",
-                "type": "string"
-            },
-            {
-                "default": null,
-                "doc": "The URL for a logo associated with the platform",
-                "java": {
-                    "class": "com.linkedin.pegasus2avro.common.url.Url",
-                    "coercerClass": "com.linkedin.pegasus2avro.common.url.UrlCoercer"
-                },
-                "name": "logoUrl",
-                "type": [
-                    "null",
-                    "string"
-                ]
-            }
-        ],
-        "name": "DataPlatformInfo",
-        "namespace": "com.linkedin.pegasus2avro.dataplatform",
-        "type": "record"
-    },
-    {
-        "Aspect": {
-            "name": "telemetryClientId"
-        },
-        "doc": "A simple wrapper around a String to persist the client ID for telemetry in DataHub's backend DB",
-        "fields": [
-            {
-                "doc": "A string representing the telemetry client ID",
-                "name": "clientId",
-                "type": "string"
-            }
-        ],
-        "name": "TelemetryClientId",
-        "namespace": "com.linkedin.pegasus2avro.telemetry",
-        "type": "record"
-    },
-    {
-        "Aspect": {
             "name": "dataHubIngestionSourceInfo"
         },
         "doc": "Info about a DataHub ingestion source",
         "fields": [
             {
                 "Searchable": {
                     "fieldType": "TEXT_PARTIAL"
@@ -7548,707 +6317,43 @@
             }
         ],
         "name": "DataHubIngestionSourceInfo",
         "namespace": "com.linkedin.pegasus2avro.ingestion",
         "type": "record"
     },
     {
-        "doc": "Usage data for a given resource, rolled up into a bucket.",
-        "fields": [
-            {
-                "doc": " Bucket start time in milliseconds ",
-                "name": "bucket",
-                "type": "long"
-            },
-            {
-                "doc": " Bucket duration ",
-                "name": "duration",
-                "type": {
-                    "doc": "Enum to define the length of a bucket when doing aggregations",
-                    "name": "WindowDuration",
-                    "namespace": "com.linkedin.pegasus2avro.common",
-                    "symbols": [
-                        "YEAR",
-                        "MONTH",
-                        "WEEK",
-                        "DAY",
-                        "HOUR"
-                    ],
-                    "type": "enum"
-                }
-            },
-            {
-                "Urn": "Urn",
-                "doc": " Resource associated with these usage stats ",
-                "java": {
-                    "class": "com.linkedin.pegasus2avro.common.urn.Urn"
-                },
-                "name": "resource",
-                "type": "string"
-            },
-            {
-                "doc": " Metrics associated with this bucket ",
-                "name": "metrics",
-                "type": {
-                    "doc": "Metrics for usage data for a given resource and bucket. Not all fields\nmake sense for all buckets, so every field is optional.",
-                    "fields": [
-                        {
-                            "default": null,
-                            "doc": " Unique user count ",
-                            "name": "uniqueUserCount",
-                            "type": [
-                                "null",
-                                "int"
-                            ]
-                        },
-                        {
-                            "default": null,
-                            "doc": " Users within this bucket, with frequency counts ",
-                            "name": "users",
-                            "type": [
-                                "null",
-                                {
-                                    "items": {
-                                        "doc": " Records a single user's usage counts for a given resource ",
-                                        "fields": [
-                                            {
-                                                "Urn": "Urn",
-                                                "default": null,
-                                                "java": {
-                                                    "class": "com.linkedin.pegasus2avro.common.urn.Urn"
-                                                },
-                                                "name": "user",
-                                                "type": [
-                                                    "null",
-                                                    "string"
-                                                ]
-                                            },
-                                            {
-                                                "name": "count",
-                                                "type": "int"
-                                            },
-                                            {
-                                                "default": null,
-                                                "doc": " If user_email is set, we attempt to resolve the user's urn upon ingest ",
-                                                "name": "userEmail",
-                                                "type": [
-                                                    "null",
-                                                    "string"
-                                                ]
-                                            }
-                                        ],
-                                        "name": "UserUsageCounts",
-                                        "namespace": "com.linkedin.pegasus2avro.usage",
-                                        "type": "record"
-                                    },
-                                    "type": "array"
-                                }
-                            ]
-                        },
-                        {
-                            "default": null,
-                            "doc": " Total SQL query count ",
-                            "name": "totalSqlQueries",
-                            "type": [
-                                "null",
-                                "int"
-                            ]
-                        },
-                        {
-                            "default": null,
-                            "doc": " Frequent SQL queries; mostly makes sense for datasets in SQL databases ",
-                            "name": "topSqlQueries",
-                            "type": [
-                                "null",
-                                {
-                                    "items": "string",
-                                    "type": "array"
-                                }
-                            ]
-                        },
-                        {
-                            "default": null,
-                            "doc": " Field-level usage stats ",
-                            "name": "fields",
-                            "type": [
-                                "null",
-                                {
-                                    "items": {
-                                        "doc": " Records field-level usage counts for a given resource ",
-                                        "fields": [
-                                            {
-                                                "name": "fieldName",
-                                                "type": "string"
-                                            },
-                                            {
-                                                "name": "count",
-                                                "type": "int"
-                                            }
-                                        ],
-                                        "name": "FieldUsageCounts",
-                                        "namespace": "com.linkedin.pegasus2avro.usage",
-                                        "type": "record"
-                                    },
-                                    "type": "array"
-                                }
-                            ]
-                        }
-                    ],
-                    "name": "UsageAggregationMetrics",
-                    "namespace": "com.linkedin.pegasus2avro.usage",
-                    "type": "record"
-                }
-            }
-        ],
-        "name": "UsageAggregation",
-        "namespace": "com.linkedin.pegasus2avro.usage",
-        "type": "record"
-    },
-    {
-        "Aspect": {
-            "name": "glossaryTermInfo"
-        },
-        "doc": "Properties associated with a GlossaryTerm",
-        "fields": [
-            {
-                "Searchable": {
-                    "/*": {
-                        "queryByDefault": true
-                    }
-                },
-                "default": {},
-                "doc": "Custom property bag.",
-                "name": "customProperties",
-                "type": {
-                    "type": "map",
-                    "values": "string"
-                }
-            },
-            {
-                "Searchable": {
-                    "fieldType": "TEXT_PARTIAL"
-                },
-                "default": null,
-                "doc": "Optional id for the term",
-                "name": "id",
-                "type": [
-                    "null",
-                    "string"
-                ]
-            },
-            {
-                "Searchable": {
-                    "boostScore": 10.0,
-                    "enableAutocomplete": true,
-                    "fieldType": "TEXT_PARTIAL"
-                },
-                "default": null,
-                "doc": "Display name of the term",
-                "name": "name",
-                "type": [
-                    "null",
-                    "string"
-                ]
-            },
-            {
-                "Searchable": {},
-                "doc": "Definition of business term.",
-                "name": "definition",
-                "type": "string"
-            },
-            {
-                "Relationship": {
-                    "entityTypes": [
-                        "glossaryNode"
-                    ],
-                    "name": "IsPartOf"
-                },
-                "Searchable": {
-                    "fieldName": "parentNode",
-                    "fieldType": "URN",
-                    "hasValuesFieldName": "hasParentNode"
-                },
-                "Urn": "GlossaryNodeUrn",
-                "default": null,
-                "doc": "Parent node of the glossary term",
-                "java": {
-                    "class": "com.linkedin.pegasus2avro.common.urn.GlossaryNodeUrn"
-                },
-                "name": "parentNode",
-                "type": [
-                    "null",
-                    "string"
-                ]
-            },
-            {
-                "Searchable": {
-                    "fieldType": "KEYWORD"
-                },
-                "doc": "Source of the Business Term (INTERNAL or EXTERNAL) with default value as INTERNAL",
-                "name": "termSource",
-                "type": "string"
-            },
-            {
-                "Searchable": {
-                    "fieldType": "KEYWORD"
-                },
-                "default": null,
-                "doc": "External Reference to the business-term",
-                "name": "sourceRef",
-                "type": [
-                    "null",
-                    "string"
-                ]
-            },
-            {
-                "default": null,
-                "doc": "The abstracted URL such as https://spec.edmcouncil.org/fibo/ontology/FBC/FinancialInstruments/FinancialInstruments/CashInstrument.",
-                "java": {
-                    "class": "com.linkedin.pegasus2avro.common.url.Url",
-                    "coercerClass": "com.linkedin.pegasus2avro.common.url.UrlCoercer"
-                },
-                "name": "sourceUrl",
-                "type": [
-                    "null",
-                    "string"
-                ]
-            },
-            {
-                "default": null,
-                "deprecated": true,
-                "doc": "Schema definition of the glossary term",
-                "name": "rawSchema",
-                "type": [
-                    "null",
-                    "string"
-                ]
-            }
-        ],
-        "name": "GlossaryTermInfo",
-        "namespace": "com.linkedin.pegasus2avro.glossary",
-        "type": "record"
-    },
-    {
         "Aspect": {
-            "name": "glossaryRelatedTerms"
+            "name": "viewProperties"
         },
-        "doc": "Has A / Is A lineage information about a glossary Term reporting the lineage",
+        "doc": "Details about a View. \ne.g. Gets activated when subTypes is view",
         "fields": [
             {
-                "Relationship": {
-                    "/*": {
-                        "entityTypes": [
-                            "glossaryTerm"
-                        ],
-                        "name": "IsA"
-                    }
-                },
-                "Searchable": {
-                    "/*": {
-                        "boostScore": 2.0,
-                        "fieldName": "isRelatedTerms",
-                        "fieldType": "URN"
-                    }
-                },
-                "Urn": "GlossaryTermUrn",
-                "default": null,
-                "doc": "The relationship Is A with glossary term",
-                "name": "isRelatedTerms",
-                "type": [
-                    "null",
-                    {
-                        "items": "string",
-                        "type": "array"
-                    }
-                ],
-                "urn_is_array": true
-            },
-            {
-                "Relationship": {
-                    "/*": {
-                        "entityTypes": [
-                            "glossaryTerm"
-                        ],
-                        "name": "HasA"
-                    }
-                },
-                "Searchable": {
-                    "/*": {
-                        "boostScore": 2.0,
-                        "fieldName": "hasRelatedTerms",
-                        "fieldType": "URN"
-                    }
-                },
-                "Urn": "GlossaryTermUrn",
-                "default": null,
-                "doc": "The relationship Has A with glossary term",
-                "name": "hasRelatedTerms",
-                "type": [
-                    "null",
-                    {
-                        "items": "string",
-                        "type": "array"
-                    }
-                ],
-                "urn_is_array": true
-            },
-            {
-                "Relationship": {
-                    "/*": {
-                        "entityTypes": [
-                            "glossaryTerm"
-                        ],
-                        "name": "HasValue"
-                    }
-                },
                 "Searchable": {
-                    "/*": {
-                        "fieldName": "values",
-                        "fieldType": "URN"
+                    "fieldType": "BOOLEAN",
+                    "weightsPerFieldValue": {
+                        "true": 0.5
                     }
                 },
-                "Urn": "GlossaryTermUrn",
-                "default": null,
-                "doc": "The relationship Has Value with glossary term.\nThese are fixed value a term has. For example a ColorEnum where RED, GREEN and YELLOW are fixed values.",
-                "name": "values",
-                "type": [
-                    "null",
-                    {
-                        "items": "string",
-                        "type": "array"
-                    }
-                ],
-                "urn_is_array": true
+                "doc": "Whether the view is materialized",
+                "name": "materialized",
+                "type": "boolean"
             },
             {
-                "Relationship": {
-                    "/*": {
-                        "entityTypes": [
-                            "glossaryTerm"
-                        ],
-                        "name": "IsRelatedTo"
-                    }
-                },
-                "Searchable": {
-                    "/*": {
-                        "fieldName": "relatedTerms",
-                        "fieldType": "URN"
-                    }
-                },
-                "Urn": "GlossaryTermUrn",
-                "default": null,
-                "doc": "The relationship isRelatedTo with glossary term",
-                "name": "relatedTerms",
-                "type": [
-                    "null",
-                    {
-                        "items": "string",
-                        "type": "array"
-                    }
-                ],
-                "urn_is_array": true
-            }
-        ],
-        "name": "GlossaryRelatedTerms",
-        "namespace": "com.linkedin.pegasus2avro.glossary",
-        "type": "record"
-    },
-    {
-        "Aspect": {
-            "name": "glossaryNodeInfo"
-        },
-        "doc": "Properties associated with a GlossaryNode",
-        "fields": [
-            {
-                "Searchable": {},
-                "doc": "Definition of business node",
-                "name": "definition",
+                "doc": "The view logic",
+                "name": "viewLogic",
                 "type": "string"
             },
             {
-                "Relationship": {
-                    "entityTypes": [
-                        "glossaryNode"
-                    ],
-                    "name": "IsPartOf"
-                },
-                "Searchable": {
-                    "fieldName": "parentNode",
-                    "fieldType": "URN",
-                    "hasValuesFieldName": "hasParentNode"
-                },
-                "Urn": "GlossaryNodeUrn",
-                "default": null,
-                "doc": "Parent node of the glossary term",
-                "java": {
-                    "class": "com.linkedin.pegasus2avro.common.urn.GlossaryNodeUrn"
-                },
-                "name": "parentNode",
-                "type": [
-                    "null",
-                    "string"
-                ]
-            },
-            {
-                "Searchable": {
-                    "boostScore": 10.0,
-                    "enableAutocomplete": true,
-                    "fieldName": "displayName",
-                    "fieldType": "TEXT_PARTIAL"
-                },
-                "default": null,
-                "doc": "Display name of the node",
-                "name": "name",
-                "type": [
-                    "null",
-                    "string"
-                ]
-            },
-            {
-                "Searchable": {
-                    "fieldType": "TEXT_PARTIAL"
-                },
-                "default": null,
-                "doc": "Optional id for the GlossaryNode",
-                "name": "id",
-                "type": [
-                    "null",
-                    "string"
-                ]
-            }
-        ],
-        "name": "GlossaryNodeInfo",
-        "namespace": "com.linkedin.pegasus2avro.glossary",
-        "type": "record"
-    },
-    {
-        "Aspect": {
-            "name": "domains"
-        },
-        "doc": "Links from an Asset to its Domains",
-        "fields": [
-            {
-                "Relationship": {
-                    "/*": {
-                        "entityTypes": [
-                            "domain"
-                        ],
-                        "name": "AssociatedWith"
-                    }
-                },
-                "Searchable": {
-                    "/*": {
-                        "addToFilters": true,
-                        "fieldName": "domains",
-                        "fieldType": "URN",
-                        "filterNameOverride": "Domain",
-                        "hasValuesFieldName": "hasDomain"
-                    }
-                },
-                "Urn": "Urn",
-                "doc": "The Domains attached to an Asset",
-                "name": "domains",
-                "type": {
-                    "items": "string",
-                    "type": "array"
-                },
-                "urn_is_array": true
-            }
-        ],
-        "name": "Domains",
-        "namespace": "com.linkedin.pegasus2avro.domain",
-        "type": "record"
-    },
-    {
-        "Aspect": {
-            "name": "domainProperties"
-        },
-        "doc": "Information about a Domain",
-        "fields": [
-            {
-                "Searchable": {
-                    "boostScore": 10.0,
-                    "enableAutocomplete": true,
-                    "fieldType": "TEXT_PARTIAL"
-                },
-                "doc": "Display name of the Domain",
-                "name": "name",
+                "doc": "The view logic language / dialect",
+                "name": "viewLanguage",
                 "type": "string"
-            },
-            {
-                "default": null,
-                "doc": "Description of the Domain",
-                "name": "description",
-                "type": [
-                    "null",
-                    "string"
-                ]
-            },
-            {
-                "Searchable": {
-                    "/time": {
-                        "fieldName": "createdTime",
-                        "fieldType": "DATETIME"
-                    }
-                },
-                "default": null,
-                "doc": "Created Audit stamp",
-                "name": "created",
-                "type": [
-                    "null",
-                    "com.linkedin.pegasus2avro.common.AuditStamp"
-                ]
-            }
-        ],
-        "name": "DomainProperties",
-        "namespace": "com.linkedin.pegasus2avro.domain",
-        "type": "record"
-    },
-    {
-        "Aspect": {
-            "name": "postInfo"
-        },
-        "doc": "Information about a DataHub Post.",
-        "fields": [
-            {
-                "doc": "Type of the Post.",
-                "name": "type",
-                "type": {
-                    "doc": "Enum defining types of Posts.",
-                    "name": "PostType",
-                    "namespace": "com.linkedin.pegasus2avro.post",
-                    "symbolDocs": {
-                        "HOME_PAGE_ANNOUNCEMENT": "The Post is an Home Page announcement."
-                    },
-                    "symbols": [
-                        "HOME_PAGE_ANNOUNCEMENT"
-                    ],
-                    "type": "enum"
-                }
-            },
-            {
-                "doc": "Content stored in the post.",
-                "name": "content",
-                "type": {
-                    "doc": "Content stored inside a Post.",
-                    "fields": [
-                        {
-                            "Searchable": {
-                                "fieldType": "TEXT_PARTIAL"
-                            },
-                            "doc": "Title of the post.",
-                            "name": "title",
-                            "type": "string"
-                        },
-                        {
-                            "doc": "Type of content held in the post.",
-                            "name": "type",
-                            "type": {
-                                "doc": "Enum defining the type of content held in a Post.",
-                                "name": "PostContentType",
-                                "namespace": "com.linkedin.pegasus2avro.post",
-                                "symbolDocs": {
-                                    "LINK": "Link content",
-                                    "TEXT": "Text content"
-                                },
-                                "symbols": [
-                                    "TEXT",
-                                    "LINK"
-                                ],
-                                "type": "enum"
-                            }
-                        },
-                        {
-                            "default": null,
-                            "doc": "Optional description of the post.",
-                            "name": "description",
-                            "type": [
-                                "null",
-                                "string"
-                            ]
-                        },
-                        {
-                            "default": null,
-                            "doc": "Optional link that the post is associated with.",
-                            "java": {
-                                "class": "com.linkedin.pegasus2avro.common.url.Url",
-                                "coercerClass": "com.linkedin.pegasus2avro.common.url.UrlCoercer"
-                            },
-                            "name": "link",
-                            "type": [
-                                "null",
-                                "string"
-                            ]
-                        },
-                        {
-                            "default": null,
-                            "doc": "Optional media that the post is storing",
-                            "name": "media",
-                            "type": [
-                                "null",
-                                {
-                                    "doc": "Carries information about which roles a user is assigned to.",
-                                    "fields": [
-                                        {
-                                            "doc": "Type of content the Media is storing, e.g. image, video, etc.",
-                                            "name": "type",
-                                            "type": {
-                                                "doc": "Enum defining the type of content a Media object holds.",
-                                                "name": "MediaType",
-                                                "namespace": "com.linkedin.pegasus2avro.common",
-                                                "symbolDocs": {
-                                                    "IMAGE": "The Media holds an image."
-                                                },
-                                                "symbols": [
-                                                    "IMAGE"
-                                                ],
-                                                "type": "enum"
-                                            }
-                                        },
-                                        {
-                                            "doc": "Where the media content is stored.",
-                                            "java": {
-                                                "class": "com.linkedin.pegasus2avro.common.url.Url",
-                                                "coercerClass": "com.linkedin.pegasus2avro.common.url.UrlCoercer"
-                                            },
-                                            "name": "location",
-                                            "type": "string"
-                                        }
-                                    ],
-                                    "name": "Media",
-                                    "namespace": "com.linkedin.pegasus2avro.common",
-                                    "type": "record"
-                                }
-                            ]
-                        }
-                    ],
-                    "name": "PostContent",
-                    "namespace": "com.linkedin.pegasus2avro.post",
-                    "type": "record"
-                }
-            },
-            {
-                "Searchable": {
-                    "fieldType": "COUNT"
-                },
-                "doc": "The time at which the post was initially created",
-                "name": "created",
-                "type": "long"
-            },
-            {
-                "Searchable": {
-                    "fieldType": "COUNT"
-                },
-                "doc": "The time at which the post was last modified",
-                "name": "lastModified",
-                "type": "long"
             }
         ],
-        "name": "PostInfo",
-        "namespace": "com.linkedin.pegasus2avro.post",
+        "name": "ViewProperties",
+        "namespace": "com.linkedin.pegasus2avro.dataset",
         "type": "record"
     },
     {
         "Aspect": {
             "name": "datasetDeprecation"
         },
         "Deprecated": true,
@@ -8295,64 +6400,95 @@
         ],
         "name": "DatasetDeprecation",
         "namespace": "com.linkedin.pegasus2avro.dataset",
         "type": "record"
     },
     {
         "Aspect": {
-            "name": "editableDatasetProperties"
+            "name": "datasetUpstreamLineage"
         },
-        "doc": "EditableDatasetProperties stores editable changes made to dataset properties. This separates changes made from\ningestion pipelines and edits in the UI to avoid accidental overwrites of user-provided data by ingestion pipelines",
+        "deprecated": "use UpstreamLineage.fineGrainedLineages instead",
+        "doc": "Fine Grained upstream lineage for fields in a dataset",
         "fields": [
             {
-                "default": {
-                    "actor": "urn:li:corpuser:unknown",
-                    "impersonator": null,
-                    "message": null,
-                    "time": 0
-                },
-                "doc": "An AuditStamp corresponding to the creation of this resource/association/sub-resource. A value of 0 for time indicates missing data.",
-                "name": "created",
-                "type": "com.linkedin.pegasus2avro.common.AuditStamp"
-            },
-            {
-                "default": {
-                    "actor": "urn:li:corpuser:unknown",
-                    "impersonator": null,
-                    "message": null,
-                    "time": 0
-                },
-                "doc": "An AuditStamp corresponding to the last modification of this resource/association/sub-resource. If no modification has happened since creation, lastModified should be the same as created. A value of 0 for time indicates missing data.",
-                "name": "lastModified",
-                "type": "com.linkedin.pegasus2avro.common.AuditStamp"
-            },
-            {
-                "default": null,
-                "doc": "An AuditStamp corresponding to the deletion of this resource/association/sub-resource. Logically, deleted MUST have a later timestamp than creation. It may or may not have the same time as lastModified depending upon the resource/association/sub-resource semantics.",
-                "name": "deleted",
-                "type": [
-                    "null",
-                    "com.linkedin.pegasus2avro.common.AuditStamp"
-                ]
-            },
-            {
-                "Searchable": {
-                    "fieldName": "editedDescription",
-                    "fieldType": "TEXT"
-                },
-                "default": null,
-                "doc": "Documentation of the dataset",
-                "name": "description",
-                "type": [
-                    "null",
-                    "string"
-                ]
+                "doc": "Upstream to downstream field level lineage mappings",
+                "name": "fieldMappings",
+                "type": {
+                    "items": {
+                        "deprecated": "use FineGrainedLineage instead",
+                        "doc": "Representation of mapping between fields in source dataset to the field in destination dataset",
+                        "fields": [
+                            {
+                                "doc": "Audit stamp containing who reported the field mapping and when",
+                                "name": "created",
+                                "type": "com.linkedin.pegasus2avro.common.AuditStamp"
+                            },
+                            {
+                                "doc": "Transfomration function between the fields involved",
+                                "name": "transformation",
+                                "type": [
+                                    {
+                                        "doc": "Type of the transformation involved in generating destination fields from source fields.",
+                                        "name": "TransformationType",
+                                        "namespace": "com.linkedin.pegasus2avro.common.fieldtransformer",
+                                        "symbolDocs": {
+                                            "BLACKBOX": "Field transformation expressed as unknown black box function.",
+                                            "IDENTITY": "Field transformation expressed as Identity function."
+                                        },
+                                        "symbols": [
+                                            "BLACKBOX",
+                                            "IDENTITY"
+                                        ],
+                                        "type": "enum"
+                                    },
+                                    {
+                                        "doc": "Field transformation expressed in UDF",
+                                        "fields": [
+                                            {
+                                                "doc": "A UDF mentioning how the source fields got transformed to destination field. This is the FQCN(Fully Qualified Class Name) of the udf.",
+                                                "name": "udf",
+                                                "type": "string"
+                                            }
+                                        ],
+                                        "name": "UDFTransformer",
+                                        "namespace": "com.linkedin.pegasus2avro.common.fieldtransformer",
+                                        "type": "record"
+                                    }
+                                ]
+                            },
+                            {
+                                "doc": "Source fields from which the fine grained lineage is derived",
+                                "name": "sourceFields",
+                                "type": {
+                                    "items": [
+                                        "string"
+                                    ],
+                                    "type": "array"
+                                }
+                            },
+                            {
+                                "Urn": "DatasetFieldUrn",
+                                "deprecated": "use SchemaFieldPath and represent as generic Urn instead",
+                                "doc": "Destination field which is derived from source fields",
+                                "java": {
+                                    "class": "com.linkedin.pegasus2avro.common.urn.DatasetFieldUrn"
+                                },
+                                "name": "destinationField",
+                                "type": "string"
+                            }
+                        ],
+                        "name": "DatasetFieldMapping",
+                        "namespace": "com.linkedin.pegasus2avro.dataset",
+                        "type": "record"
+                    },
+                    "type": "array"
+                }
             }
         ],
-        "name": "EditableDatasetProperties",
+        "name": "DatasetUpstreamLineage",
         "namespace": "com.linkedin.pegasus2avro.dataset",
         "type": "record"
     },
     {
         "Aspect": {
             "name": "datasetUsageStatistics",
             "type": "timeseries"
@@ -8511,14 +6647,147 @@
         ],
         "name": "DatasetUsageStatistics",
         "namespace": "com.linkedin.pegasus2avro.dataset",
         "type": "record"
     },
     {
         "Aspect": {
+            "name": "datasetProperties"
+        },
+        "doc": "Properties associated with a Dataset",
+        "fields": [
+            {
+                "Searchable": {
+                    "/*": {
+                        "queryByDefault": true
+                    }
+                },
+                "default": {},
+                "doc": "Custom property bag.",
+                "name": "customProperties",
+                "type": {
+                    "type": "map",
+                    "values": "string"
+                }
+            },
+            {
+                "default": null,
+                "doc": "URL where the reference exist",
+                "java": {
+                    "class": "com.linkedin.pegasus2avro.common.url.Url",
+                    "coercerClass": "com.linkedin.pegasus2avro.common.url.UrlCoercer"
+                },
+                "name": "externalUrl",
+                "type": [
+                    "null",
+                    "string"
+                ]
+            },
+            {
+                "Searchable": {
+                    "boostScore": 10.0,
+                    "enableAutocomplete": true,
+                    "fieldType": "TEXT_PARTIAL"
+                },
+                "default": null,
+                "doc": "Display name of the Dataset",
+                "name": "name",
+                "type": [
+                    "null",
+                    "string"
+                ]
+            },
+            {
+                "Searchable": {
+                    "addToFilters": false,
+                    "boostScore": 10.0,
+                    "enableAutocomplete": true,
+                    "fieldType": "TEXT"
+                },
+                "default": null,
+                "doc": "Fully-qualified name of the Dataset",
+                "name": "qualifiedName",
+                "type": [
+                    "null",
+                    "string"
+                ]
+            },
+            {
+                "Searchable": {
+                    "fieldType": "TEXT",
+                    "hasValuesFieldName": "hasDescription"
+                },
+                "default": null,
+                "doc": "Documentation of the dataset",
+                "name": "description",
+                "type": [
+                    "null",
+                    "string"
+                ]
+            },
+            {
+                "default": null,
+                "deprecated": "Use ExternalReference.externalUrl field instead.",
+                "doc": "The abstracted URI such as hdfs:///data/tracking/PageViewEvent, file:///dir/file_name. Uri should not include any environment specific properties. Some datasets might not have a standardized uri, which makes this field optional (i.e. kafka topic).",
+                "java": {
+                    "class": "java.net.URI"
+                },
+                "name": "uri",
+                "type": [
+                    "null",
+                    "string"
+                ]
+            },
+            {
+                "Searchable": {
+                    "/time": {
+                        "fieldName": "createdAt",
+                        "fieldType": "DATETIME"
+                    }
+                },
+                "default": null,
+                "doc": "A timestamp documenting when the asset was created in the source Data Platform (not on DataHub)",
+                "name": "created",
+                "type": [
+                    "null",
+                    "com.linkedin.pegasus2avro.common.TimeStamp"
+                ]
+            },
+            {
+                "Searchable": {
+                    "/time": {
+                        "fieldName": "lastModifiedAt",
+                        "fieldType": "DATETIME"
+                    }
+                },
+                "default": null,
+                "doc": "A timestamp documenting when the asset was last modified in the source Data Platform (not on DataHub)",
+                "name": "lastModified",
+                "type": [
+                    "null",
+                    "com.linkedin.pegasus2avro.common.TimeStamp"
+                ]
+            },
+            {
+                "default": [],
+                "deprecated": "Use GlobalTags aspect instead.",
+                "doc": "[Legacy] Unstructured tags for the dataset. Structured tags can be applied via the `GlobalTags` aspect.\nThis is now deprecated.",
+                "name": "tags",
+                "type": {
+                    "items": "string",
+                    "type": "array"
+                }
+            }
+        ],
+        "name": "DatasetProperties",
+        "namespace": "com.linkedin.pegasus2avro.dataset",
+        "type": "record"
+    },
+    {
+        "Aspect": {
             "name": "upstreamLineage"
         },
         "doc": "Upstream lineage of a dataset",
         "fields": [
             {
                 "doc": "List of upstream dataset lineage information",
                 "name": "upstreams",
@@ -8887,34 +7156,778 @@
                         },
                         "type": "array"
                     }
                 ]
             },
             {
                 "Searchable": {
-                    "fieldType": "COUNT"
+                    "fieldType": "COUNT"
+                },
+                "default": null,
+                "doc": "Storage size in bytes",
+                "name": "sizeInBytes",
+                "type": [
+                    "null",
+                    "long"
+                ]
+            }
+        ],
+        "name": "DatasetProfile",
+        "namespace": "com.linkedin.pegasus2avro.dataset",
+        "type": "record"
+    },
+    {
+        "Aspect": {
+            "name": "editableDatasetProperties"
+        },
+        "doc": "EditableDatasetProperties stores editable changes made to dataset properties. This separates changes made from\ningestion pipelines and edits in the UI to avoid accidental overwrites of user-provided data by ingestion pipelines",
+        "fields": [
+            {
+                "default": {
+                    "actor": "urn:li:corpuser:unknown",
+                    "impersonator": null,
+                    "message": null,
+                    "time": 0
+                },
+                "doc": "An AuditStamp corresponding to the creation of this resource/association/sub-resource. A value of 0 for time indicates missing data.",
+                "name": "created",
+                "type": "com.linkedin.pegasus2avro.common.AuditStamp"
+            },
+            {
+                "default": {
+                    "actor": "urn:li:corpuser:unknown",
+                    "impersonator": null,
+                    "message": null,
+                    "time": 0
+                },
+                "doc": "An AuditStamp corresponding to the last modification of this resource/association/sub-resource. If no modification has happened since creation, lastModified should be the same as created. A value of 0 for time indicates missing data.",
+                "name": "lastModified",
+                "type": "com.linkedin.pegasus2avro.common.AuditStamp"
+            },
+            {
+                "default": null,
+                "doc": "An AuditStamp corresponding to the deletion of this resource/association/sub-resource. Logically, deleted MUST have a later timestamp than creation. It may or may not have the same time as lastModified depending upon the resource/association/sub-resource semantics.",
+                "name": "deleted",
+                "type": [
+                    "null",
+                    "com.linkedin.pegasus2avro.common.AuditStamp"
+                ]
+            },
+            {
+                "Searchable": {
+                    "fieldName": "editedDescription",
+                    "fieldType": "TEXT"
+                },
+                "default": null,
+                "doc": "Documentation of the dataset",
+                "name": "description",
+                "type": [
+                    "null",
+                    "string"
+                ]
+            }
+        ],
+        "name": "EditableDatasetProperties",
+        "namespace": "com.linkedin.pegasus2avro.dataset",
+        "type": "record"
+    },
+    {
+        "Aspect": {
+            "name": "editableDashboardProperties"
+        },
+        "doc": "Stores editable changes made to properties. This separates changes made from\ningestion pipelines and edits in the UI to avoid accidental overwrites of user-provided data by ingestion pipelines",
+        "fields": [
+            {
+                "default": {
+                    "actor": "urn:li:corpuser:unknown",
+                    "impersonator": null,
+                    "message": null,
+                    "time": 0
+                },
+                "doc": "An AuditStamp corresponding to the creation of this resource/association/sub-resource. A value of 0 for time indicates missing data.",
+                "name": "created",
+                "type": "com.linkedin.pegasus2avro.common.AuditStamp"
+            },
+            {
+                "default": {
+                    "actor": "urn:li:corpuser:unknown",
+                    "impersonator": null,
+                    "message": null,
+                    "time": 0
+                },
+                "doc": "An AuditStamp corresponding to the last modification of this resource/association/sub-resource. If no modification has happened since creation, lastModified should be the same as created. A value of 0 for time indicates missing data.",
+                "name": "lastModified",
+                "type": "com.linkedin.pegasus2avro.common.AuditStamp"
+            },
+            {
+                "default": null,
+                "doc": "An AuditStamp corresponding to the deletion of this resource/association/sub-resource. Logically, deleted MUST have a later timestamp than creation. It may or may not have the same time as lastModified depending upon the resource/association/sub-resource semantics.",
+                "name": "deleted",
+                "type": [
+                    "null",
+                    "com.linkedin.pegasus2avro.common.AuditStamp"
+                ]
+            },
+            {
+                "Searchable": {
+                    "fieldName": "editedDescription",
+                    "fieldType": "TEXT"
+                },
+                "default": null,
+                "doc": "Edited documentation of the dashboard",
+                "name": "description",
+                "type": [
+                    "null",
+                    "string"
+                ]
+            }
+        ],
+        "name": "EditableDashboardProperties",
+        "namespace": "com.linkedin.pegasus2avro.dashboard",
+        "type": "record"
+    },
+    {
+        "Aspect": {
+            "name": "dashboardUsageStatistics",
+            "type": "timeseries"
+        },
+        "doc": "Experimental (Subject to breaking change) -- Stats corresponding to dashboard's usage.\n\nIf this aspect represents the latest snapshot of the statistics about a Dashboard, the eventGranularity field should be null. \nIf this aspect represents a bucketed window of usage statistics (e.g. over a day), then the eventGranularity field should be set accordingly. ",
+        "fields": [
+            {
+                "doc": "The event timestamp field as epoch at UTC in milli seconds.",
+                "name": "timestampMillis",
+                "type": "long"
+            },
+            {
+                "default": null,
+                "doc": "Granularity of the event if applicable",
+                "name": "eventGranularity",
+                "type": [
+                    "null",
+                    "com.linkedin.pegasus2avro.timeseries.TimeWindowSize"
+                ]
+            },
+            {
+                "default": {
+                    "partition": "FULL_TABLE_SNAPSHOT",
+                    "timePartition": null,
+                    "type": "FULL_TABLE"
+                },
+                "doc": "The optional partition specification.",
+                "name": "partitionSpec",
+                "type": [
+                    "com.linkedin.pegasus2avro.timeseries.PartitionSpec",
+                    "null"
+                ]
+            },
+            {
+                "default": null,
+                "doc": "The optional messageId, if provided serves as a custom user-defined unique identifier for an aspect value.",
+                "name": "messageId",
+                "type": [
+                    "null",
+                    "string"
+                ]
+            },
+            {
+                "TimeseriesField": {},
+                "default": null,
+                "doc": "The total number of times dashboard has been viewed",
+                "name": "viewsCount",
+                "type": [
+                    "null",
+                    "int"
+                ]
+            },
+            {
+                "TimeseriesField": {},
+                "default": null,
+                "doc": "The total number of dashboard executions (refreshes / syncs) ",
+                "name": "executionsCount",
+                "type": [
+                    "null",
+                    "int"
+                ]
+            },
+            {
+                "TimeseriesField": {},
+                "default": null,
+                "doc": "Unique user count",
+                "name": "uniqueUserCount",
+                "type": [
+                    "null",
+                    "int"
+                ]
+            },
+            {
+                "TimeseriesFieldCollection": {
+                    "key": "user"
+                },
+                "default": null,
+                "doc": "Users within this bucket, with frequency counts",
+                "name": "userCounts",
+                "type": [
+                    "null",
+                    {
+                        "items": {
+                            "doc": "Records a single user's usage counts for a given resource",
+                            "fields": [
+                                {
+                                    "Urn": "Urn",
+                                    "doc": "The unique id of the user.",
+                                    "java": {
+                                        "class": "com.linkedin.pegasus2avro.common.urn.Urn"
+                                    },
+                                    "name": "user",
+                                    "type": "string"
+                                },
+                                {
+                                    "TimeseriesField": {},
+                                    "default": null,
+                                    "doc": "The number of times the user has viewed the dashboard",
+                                    "name": "viewsCount",
+                                    "type": [
+                                        "null",
+                                        "int"
+                                    ]
+                                },
+                                {
+                                    "TimeseriesField": {},
+                                    "default": null,
+                                    "doc": "The number of times the user has executed (refreshed) the dashboard",
+                                    "name": "executionsCount",
+                                    "type": [
+                                        "null",
+                                        "int"
+                                    ]
+                                },
+                                {
+                                    "TimeseriesField": {},
+                                    "default": null,
+                                    "doc": "Normalized numeric metric representing user's dashboard usage -- the number of times the user executed or viewed the dashboard. ",
+                                    "name": "usageCount",
+                                    "type": [
+                                        "null",
+                                        "int"
+                                    ]
+                                },
+                                {
+                                    "TimeseriesField": {},
+                                    "default": null,
+                                    "doc": "If user_email is set, we attempt to resolve the user's urn upon ingest",
+                                    "name": "userEmail",
+                                    "type": [
+                                        "null",
+                                        "string"
+                                    ]
+                                }
+                            ],
+                            "name": "DashboardUserUsageCounts",
+                            "namespace": "com.linkedin.pegasus2avro.dashboard",
+                            "type": "record"
+                        },
+                        "type": "array"
+                    }
+                ]
+            },
+            {
+                "TimeseriesField": {},
+                "default": null,
+                "doc": "The total number of times that the dashboard has been favorited ",
+                "name": "favoritesCount",
+                "type": [
+                    "null",
+                    "int"
+                ]
+            },
+            {
+                "TimeseriesField": {},
+                "default": null,
+                "doc": "Last viewed at\n\nThis should not be set in cases where statistics are windowed. ",
+                "name": "lastViewedAt",
+                "type": [
+                    "null",
+                    "long"
+                ]
+            }
+        ],
+        "name": "DashboardUsageStatistics",
+        "namespace": "com.linkedin.pegasus2avro.dashboard",
+        "type": "record"
+    },
+    {
+        "Aspect": {
+            "name": "dashboardInfo"
+        },
+        "doc": "Information about a dashboard",
+        "fields": [
+            {
+                "Searchable": {
+                    "/*": {
+                        "queryByDefault": true
+                    }
+                },
+                "default": {},
+                "doc": "Custom property bag.",
+                "name": "customProperties",
+                "type": {
+                    "type": "map",
+                    "values": "string"
+                }
+            },
+            {
+                "default": null,
+                "doc": "URL where the reference exist",
+                "java": {
+                    "class": "com.linkedin.pegasus2avro.common.url.Url",
+                    "coercerClass": "com.linkedin.pegasus2avro.common.url.UrlCoercer"
+                },
+                "name": "externalUrl",
+                "type": [
+                    "null",
+                    "string"
+                ]
+            },
+            {
+                "Searchable": {
+                    "boostScore": 10.0,
+                    "enableAutocomplete": true,
+                    "fieldType": "TEXT_PARTIAL"
+                },
+                "doc": "Title of the dashboard",
+                "name": "title",
+                "type": "string"
+            },
+            {
+                "Searchable": {
+                    "fieldType": "TEXT",
+                    "hasValuesFieldName": "hasDescription"
+                },
+                "doc": "Detailed description about the dashboard",
+                "name": "description",
+                "type": "string"
+            },
+            {
+                "Relationship": {
+                    "/*": {
+                        "entityTypes": [
+                            "chart"
+                        ],
+                        "isLineage": true,
+                        "name": "Contains"
+                    }
+                },
+                "Urn": "ChartUrn",
+                "default": [],
+                "deprecated": true,
+                "doc": "Charts in a dashboard\nDeprecated! Use chartEdges instead.",
+                "name": "charts",
+                "type": {
+                    "items": "string",
+                    "type": "array"
+                },
+                "urn_is_array": true
+            },
+            {
+                "Relationship": {
+                    "/*/destinationUrn": {
+                        "createdActor": "chartEdges/*/created/actor",
+                        "createdOn": "chartEdges/*/created/time",
+                        "entityTypes": [
+                            "chart"
+                        ],
+                        "isLineage": true,
+                        "name": "Contains",
+                        "properties": "chartEdges/*/properties",
+                        "updatedActor": "chartEdges/*/lastModified/actor",
+                        "updatedOn": "chartEdges/*/lastModified/time"
+                    }
+                },
+                "default": null,
+                "doc": "Charts in a dashboard",
+                "name": "chartEdges",
+                "type": [
+                    "null",
+                    {
+                        "items": "com.linkedin.pegasus2avro.common.Edge",
+                        "type": "array"
+                    }
+                ]
+            },
+            {
+                "Relationship": {
+                    "/*": {
+                        "entityTypes": [
+                            "dataset"
+                        ],
+                        "isLineage": true,
+                        "name": "Consumes"
+                    }
+                },
+                "Urn": "Urn",
+                "default": [],
+                "deprecated": true,
+                "doc": "Datasets consumed by a dashboard\nDeprecated! Use datasetEdges instead.",
+                "name": "datasets",
+                "type": {
+                    "items": "string",
+                    "type": "array"
+                },
+                "urn_is_array": true
+            },
+            {
+                "Relationship": {
+                    "/*/destinationUrn": {
+                        "createdActor": "datasetEdges/*/created/actor",
+                        "createdOn": "datasetEdges/*/created/time",
+                        "entityTypes": [
+                            "dataset"
+                        ],
+                        "isLineage": true,
+                        "name": "Consumes",
+                        "properties": "datasetEdges/*/properties",
+                        "updatedActor": "datasetEdges/*/lastModified/actor",
+                        "updatedOn": "datasetEdges/*/lastModified/time"
+                    }
+                },
+                "default": null,
+                "doc": "Datasets consumed by a dashboard",
+                "name": "datasetEdges",
+                "type": [
+                    "null",
+                    {
+                        "items": "com.linkedin.pegasus2avro.common.Edge",
+                        "type": "array"
+                    }
+                ]
+            },
+            {
+                "doc": "Captures information about who created/last modified/deleted this dashboard and when",
+                "name": "lastModified",
+                "type": "com.linkedin.pegasus2avro.common.ChangeAuditStamps"
+            },
+            {
+                "default": null,
+                "doc": "URL for the dashboard. This could be used as an external link on DataHub to allow users access/view the dashboard",
+                "java": {
+                    "class": "com.linkedin.pegasus2avro.common.url.Url",
+                    "coercerClass": "com.linkedin.pegasus2avro.common.url.UrlCoercer"
+                },
+                "name": "dashboardUrl",
+                "type": [
+                    "null",
+                    "string"
+                ]
+            },
+            {
+                "Searchable": {
+                    "addToFilters": true,
+                    "fieldType": "KEYWORD",
+                    "filterNameOverride": "Access Level"
+                },
+                "default": null,
+                "doc": "Access level for the dashboard",
+                "name": "access",
+                "type": [
+                    "null",
+                    "com.linkedin.pegasus2avro.common.AccessLevel"
+                ]
+            },
+            {
+                "default": null,
+                "doc": "The time when this dashboard last refreshed",
+                "name": "lastRefreshed",
+                "type": [
+                    "null",
+                    "long"
+                ]
+            }
+        ],
+        "name": "DashboardInfo",
+        "namespace": "com.linkedin.pegasus2avro.dashboard",
+        "type": "record"
+    },
+    {
+        "Aspect": {
+            "name": "dataHubRetentionConfig"
+        },
+        "fields": [
+            {
+                "name": "retention",
+                "type": {
+                    "doc": "Base class that encapsulates different retention policies.\nOnly one of the fields should be set",
+                    "fields": [
+                        {
+                            "default": null,
+                            "name": "version",
+                            "type": [
+                                "null",
+                                {
+                                    "doc": "Keep max N latest records",
+                                    "fields": [
+                                        {
+                                            "name": "maxVersions",
+                                            "type": "int"
+                                        }
+                                    ],
+                                    "name": "VersionBasedRetention",
+                                    "namespace": "com.linkedin.pegasus2avro.retention",
+                                    "type": "record"
+                                }
+                            ]
+                        },
+                        {
+                            "default": null,
+                            "name": "time",
+                            "type": [
+                                "null",
+                                {
+                                    "doc": "Keep records that are less than X seconds old",
+                                    "fields": [
+                                        {
+                                            "name": "maxAgeInSeconds",
+                                            "type": "int"
+                                        }
+                                    ],
+                                    "name": "TimeBasedRetention",
+                                    "namespace": "com.linkedin.pegasus2avro.retention",
+                                    "type": "record"
+                                }
+                            ]
+                        }
+                    ],
+                    "name": "Retention",
+                    "namespace": "com.linkedin.pegasus2avro.retention",
+                    "type": "record"
+                }
+            }
+        ],
+        "name": "DataHubRetentionConfig",
+        "namespace": "com.linkedin.pegasus2avro.retention",
+        "type": "record"
+    },
+    {
+        "Aspect": {
+            "name": "corpUserStatus"
+        },
+        "doc": "The status of the user, e.g. provisioned, active, suspended, etc.",
+        "fields": [
+            {
+                "Searchable": {
+                    "fieldType": "KEYWORD"
+                },
+                "doc": "Status of the user, e.g. PROVISIONED / ACTIVE / SUSPENDED",
+                "name": "status",
+                "type": "string"
+            },
+            {
+                "doc": "Audit stamp containing who last modified the status and when.",
+                "name": "lastModified",
+                "type": "com.linkedin.pegasus2avro.common.AuditStamp"
+            }
+        ],
+        "name": "CorpUserStatus",
+        "namespace": "com.linkedin.pegasus2avro.identity",
+        "type": "record"
+    },
+    {
+        "Aspect": {
+            "EntityUrns": [
+                "com.linkedin.pegasus2avro.common.CorpuserUrn"
+            ],
+            "name": "corpUserCredentials"
+        },
+        "doc": "Corp user credentials",
+        "fields": [
+            {
+                "doc": "Salt used to hash password",
+                "name": "salt",
+                "type": "string"
+            },
+            {
+                "doc": "Hashed password generated by concatenating salt and password, then hashing",
+                "name": "hashedPassword",
+                "type": "string"
+            },
+            {
+                "default": null,
+                "doc": "Optional token needed to reset a user's password. Can only be set by the admin.",
+                "name": "passwordResetToken",
+                "type": [
+                    "null",
+                    "string"
+                ]
+            },
+            {
+                "default": null,
+                "doc": "When the password reset token expires.",
+                "name": "passwordResetTokenExpirationTimeMillis",
+                "type": [
+                    "null",
+                    "long"
+                ]
+            }
+        ],
+        "name": "CorpUserCredentials",
+        "namespace": "com.linkedin.pegasus2avro.identity",
+        "type": "record"
+    },
+    {
+        "Aspect": {
+            "EntityUrns": [
+                "com.linkedin.pegasus2avro.common.CorpuserUrn"
+            ],
+            "name": "corpUserEditableInfo"
+        },
+        "doc": "Linkedin corp user information that can be edited from UI",
+        "fields": [
+            {
+                "default": null,
+                "doc": "About me section of the user",
+                "name": "aboutMe",
+                "type": [
+                    "null",
+                    "string"
+                ]
+            },
+            {
+                "Searchable": {
+                    "/*": {
+                        "fieldType": "TEXT"
+                    }
+                },
+                "default": [],
+                "doc": "Teams that the user belongs to e.g. Metadata",
+                "name": "teams",
+                "type": {
+                    "items": "string",
+                    "type": "array"
+                }
+            },
+            {
+                "Searchable": {
+                    "/*": {
+                        "fieldType": "TEXT"
+                    }
+                },
+                "default": [],
+                "doc": "Skills that the user possesses e.g. Machine Learning",
+                "name": "skills",
+                "type": {
+                    "items": "string",
+                    "type": "array"
+                }
+            },
+            {
+                "default": "https://raw.githubusercontent.com/datahub-project/datahub/master/datahub-web-react/src/images/default_avatar.png",
+                "doc": "A URL which points to a picture which user wants to set as a profile photo",
+                "java": {
+                    "class": "com.linkedin.pegasus2avro.common.url.Url",
+                    "coercerClass": "com.linkedin.pegasus2avro.common.url.UrlCoercer"
+                },
+                "name": "pictureLink",
+                "type": "string"
+            },
+            {
+                "Searchable": {
+                    "boostScore": 10.0,
+                    "fieldType": "TEXT_PARTIAL",
+                    "queryByDefault": true
+                },
+                "default": null,
+                "doc": "DataHub-native display name",
+                "name": "displayName",
+                "type": [
+                    "null",
+                    "string"
+                ]
+            },
+            {
+                "default": null,
+                "doc": "DataHub-native Title, e.g. 'Software Engineer'",
+                "name": "title",
+                "type": [
+                    "null",
+                    "string"
+                ]
+            },
+            {
+                "default": null,
+                "doc": "Slack handle for the user",
+                "name": "slack",
+                "type": [
+                    "null",
+                    "string"
+                ]
+            },
+            {
+                "default": null,
+                "doc": "Phone number to contact the user",
+                "name": "phone",
+                "type": [
+                    "null",
+                    "string"
+                ]
+            },
+            {
+                "default": null,
+                "doc": "Email address to contact the user",
+                "name": "email",
+                "type": [
+                    "null",
+                    "string"
+                ]
+            }
+        ],
+        "name": "CorpUserEditableInfo",
+        "namespace": "com.linkedin.pegasus2avro.identity",
+        "type": "record"
+    },
+    {
+        "Aspect": {
+            "name": "inviteToken"
+        },
+        "doc": "Aspect used to store invite tokens.",
+        "fields": [
+            {
+                "doc": "The encrypted invite token.",
+                "name": "token",
+                "type": "string"
+            },
+            {
+                "Searchable": {
+                    "fieldName": "role",
+                    "fieldType": "KEYWORD",
+                    "hasValuesFieldName": "hasRole"
                 },
+                "Urn": "Urn",
                 "default": null,
-                "doc": "Storage size in bytes",
-                "name": "sizeInBytes",
+                "doc": "The role that this invite token may be associated with",
+                "java": {
+                    "class": "com.linkedin.pegasus2avro.common.urn.Urn"
+                },
+                "name": "role",
                 "type": [
                     "null",
-                    "long"
+                    "string"
                 ]
             }
         ],
-        "name": "DatasetProfile",
-        "namespace": "com.linkedin.pegasus2avro.dataset",
+        "name": "InviteToken",
+        "namespace": "com.linkedin.pegasus2avro.identity",
         "type": "record"
     },
     {
         "Aspect": {
-            "name": "datasetProperties"
+            "EntityUrns": [
+                "com.linkedin.pegasus2avro.common.CorpuserUrn"
+            ],
+            "name": "corpUserInfo"
         },
-        "doc": "Properties associated with a Dataset",
+        "doc": "Linkedin corp user information",
         "fields": [
             {
                 "Searchable": {
                     "/*": {
                         "queryByDefault": true
                     }
                 },
@@ -8923,250 +7936,614 @@
                 "name": "customProperties",
                 "type": {
                     "type": "map",
                     "values": "string"
                 }
             },
             {
-                "default": null,
-                "doc": "URL where the reference exist",
-                "java": {
-                    "class": "com.linkedin.pegasus2avro.common.url.Url",
-                    "coercerClass": "com.linkedin.pegasus2avro.common.url.UrlCoercer"
+                "Searchable": {
+                    "fieldType": "BOOLEAN",
+                    "weightsPerFieldValue": {
+                        "true": 2.0
+                    }
                 },
-                "name": "externalUrl",
-                "type": [
-                    "null",
-                    "string"
-                ]
+                "doc": "Deprecated! Use CorpUserStatus instead. Whether the corpUser is active, ref: https://iwww.corp.linkedin.com/wiki/cf/display/GTSD/Accessing+Active+Directory+via+LDAP+tools",
+                "name": "active",
+                "type": "boolean"
             },
             {
                 "Searchable": {
                     "boostScore": 10.0,
                     "enableAutocomplete": true,
-                    "fieldType": "TEXT_PARTIAL"
+                    "fieldType": "TEXT_PARTIAL",
+                    "queryByDefault": true
                 },
                 "default": null,
-                "doc": "Display name of the Dataset",
-                "name": "name",
+                "doc": "displayName of this user ,  e.g.  Hang Zhang(DataHQ)",
+                "name": "displayName",
                 "type": [
                     "null",
                     "string"
                 ]
             },
             {
                 "Searchable": {
-                    "addToFilters": false,
-                    "boostScore": 10.0,
-                    "enableAutocomplete": true,
-                    "fieldType": "TEXT"
+                    "fieldType": "KEYWORD",
+                    "queryByDefault": true
                 },
                 "default": null,
-                "doc": "Fully-qualified name of the Dataset",
-                "name": "qualifiedName",
+                "doc": "email address of this user",
+                "name": "email",
                 "type": [
                     "null",
                     "string"
                 ]
             },
             {
                 "Searchable": {
-                    "fieldType": "TEXT",
-                    "hasValuesFieldName": "hasDescription"
+                    "fieldType": "KEYWORD",
+                    "queryByDefault": true
                 },
                 "default": null,
-                "doc": "Documentation of the dataset",
-                "name": "description",
+                "doc": "title of this user",
+                "name": "title",
                 "type": [
                     "null",
                     "string"
                 ]
             },
             {
+                "Relationship": {
+                    "entityTypes": [
+                        "corpuser"
+                    ],
+                    "name": "ReportsTo"
+                },
+                "Searchable": {
+                    "fieldName": "managerLdap",
+                    "fieldType": "URN",
+                    "queryByDefault": true
+                },
+                "Urn": "CorpuserUrn",
                 "default": null,
-                "deprecated": "Use ExternalReference.externalUrl field instead.",
-                "doc": "The abstracted URI such as hdfs:///data/tracking/PageViewEvent, file:///dir/file_name. Uri should not include any environment specific properties. Some datasets might not have a standardized uri, which makes this field optional (i.e. kafka topic).",
+                "doc": "direct manager of this user",
                 "java": {
-                    "class": "java.net.URI"
+                    "class": "com.linkedin.pegasus2avro.common.urn.CorpuserUrn"
                 },
-                "name": "uri",
+                "name": "managerUrn",
                 "type": [
                     "null",
                     "string"
                 ]
             },
             {
-                "Searchable": {
-                    "/time": {
-                        "fieldName": "createdAt",
-                        "fieldType": "DATETIME"
-                    }
-                },
                 "default": null,
-                "doc": "A timestamp documenting when the asset was created in the source Data Platform (not on DataHub)",
-                "name": "created",
+                "doc": "department id this user belong to",
+                "name": "departmentId",
                 "type": [
                     "null",
-                    "com.linkedin.pegasus2avro.common.TimeStamp"
+                    "long"
+                ]
+            },
+            {
+                "default": null,
+                "doc": "department name this user belong to",
+                "name": "departmentName",
+                "type": [
+                    "null",
+                    "string"
+                ]
+            },
+            {
+                "default": null,
+                "doc": "first name of this user",
+                "name": "firstName",
+                "type": [
+                    "null",
+                    "string"
+                ]
+            },
+            {
+                "default": null,
+                "doc": "last name of this user",
+                "name": "lastName",
+                "type": [
+                    "null",
+                    "string"
                 ]
             },
             {
                 "Searchable": {
-                    "/time": {
-                        "fieldName": "lastModifiedAt",
-                        "fieldType": "DATETIME"
-                    }
+                    "boostScore": 10.0,
+                    "enableAutocomplete": true,
+                    "fieldType": "TEXT_PARTIAL",
+                    "queryByDefault": true
                 },
                 "default": null,
-                "doc": "A timestamp documenting when the asset was last modified in the source Data Platform (not on DataHub)",
-                "name": "lastModified",
+                "doc": "Common name of this user, format is firstName + lastName (split by a whitespace)",
+                "name": "fullName",
                 "type": [
                     "null",
-                    "com.linkedin.pegasus2avro.common.TimeStamp"
+                    "string"
                 ]
             },
             {
-                "default": [],
-                "deprecated": "Use GlobalTags aspect instead.",
-                "doc": "[Legacy] Unstructured tags for the dataset. Structured tags can be applied via the `GlobalTags` aspect.\nThis is now deprecated.",
-                "name": "tags",
+                "default": null,
+                "doc": "two uppercase letters country code. e.g.  US",
+                "name": "countryCode",
+                "type": [
+                    "null",
+                    "string"
+                ]
+            }
+        ],
+        "name": "CorpUserInfo",
+        "namespace": "com.linkedin.pegasus2avro.identity",
+        "type": "record"
+    },
+    {
+        "Aspect": {
+            "name": "roleMembership"
+        },
+        "doc": "Carries information about which roles a user is assigned to.",
+        "fields": [
+            {
+                "Relationship": {
+                    "/*": {
+                        "entityTypes": [
+                            "dataHubRole"
+                        ],
+                        "name": "IsMemberOfRole"
+                    }
+                },
+                "Urn": "Urn",
+                "name": "roles",
                 "type": {
                     "items": "string",
                     "type": "array"
-                }
+                },
+                "urn_is_array": true
             }
         ],
-        "name": "DatasetProperties",
-        "namespace": "com.linkedin.pegasus2avro.dataset",
+        "name": "RoleMembership",
+        "namespace": "com.linkedin.pegasus2avro.identity",
         "type": "record"
     },
     {
         "Aspect": {
-            "name": "datasetUpstreamLineage"
+            "name": "groupMembership"
         },
-        "deprecated": "use UpstreamLineage.fineGrainedLineages instead",
-        "doc": "Fine Grained upstream lineage for fields in a dataset",
+        "doc": "Carries information about the CorpGroups a user is in.",
         "fields": [
             {
-                "doc": "Upstream to downstream field level lineage mappings",
-                "name": "fieldMappings",
+                "Relationship": {
+                    "/*": {
+                        "entityTypes": [
+                            "corpGroup"
+                        ],
+                        "name": "IsMemberOfGroup"
+                    }
+                },
+                "Urn": "Urn",
+                "name": "groups",
                 "type": {
-                    "items": {
-                        "deprecated": "use FineGrainedLineage instead",
-                        "doc": "Representation of mapping between fields in source dataset to the field in destination dataset",
+                    "items": "string",
+                    "type": "array"
+                },
+                "urn_is_array": true
+            }
+        ],
+        "name": "GroupMembership",
+        "namespace": "com.linkedin.pegasus2avro.identity",
+        "type": "record"
+    },
+    {
+        "Aspect": {
+            "name": "corpUserSettings"
+        },
+        "doc": "Settings that a user can customize through the datahub ui",
+        "fields": [
+            {
+                "doc": "Settings for a user around the appearance of their DataHub U",
+                "name": "appearance",
+                "type": {
+                    "doc": "Settings for a user around the appearance of their DataHub UI",
+                    "fields": [
+                        {
+                            "default": null,
+                            "doc": "Flag whether the user should see a homepage with only datasets, charts and dashboards. Intended for users\nwho have less operational use cases for the datahub tool.",
+                            "name": "showSimplifiedHomepage",
+                            "type": [
+                                "null",
+                                "boolean"
+                            ]
+                        }
+                    ],
+                    "name": "CorpUserAppearanceSettings",
+                    "namespace": "com.linkedin.pegasus2avro.identity",
+                    "type": "record"
+                }
+            },
+            {
+                "default": null,
+                "doc": "User preferences for the Views feature.",
+                "name": "views",
+                "type": [
+                    "null",
+                    {
+                        "doc": "Settings related to the 'Views' feature.",
                         "fields": [
                             {
-                                "doc": "Audit stamp containing who reported the field mapping and when",
-                                "name": "created",
-                                "type": "com.linkedin.pegasus2avro.common.AuditStamp"
-                            },
-                            {
-                                "doc": "Transfomration function between the fields involved",
-                                "name": "transformation",
-                                "type": [
-                                    {
-                                        "doc": "Type of the transformation involved in generating destination fields from source fields.",
-                                        "name": "TransformationType",
-                                        "namespace": "com.linkedin.pegasus2avro.common.fieldtransformer",
-                                        "symbolDocs": {
-                                            "BLACKBOX": "Field transformation expressed as unknown black box function.",
-                                            "IDENTITY": "Field transformation expressed as Identity function."
-                                        },
-                                        "symbols": [
-                                            "BLACKBOX",
-                                            "IDENTITY"
-                                        ],
-                                        "type": "enum"
-                                    },
-                                    {
-                                        "doc": "Field transformation expressed in UDF",
-                                        "fields": [
-                                            {
-                                                "doc": "A UDF mentioning how the source fields got transformed to destination field. This is the FQCN(Fully Qualified Class Name) of the udf.",
-                                                "name": "udf",
-                                                "type": "string"
-                                            }
-                                        ],
-                                        "name": "UDFTransformer",
-                                        "namespace": "com.linkedin.pegasus2avro.common.fieldtransformer",
-                                        "type": "record"
-                                    }
-                                ]
-                            },
-                            {
-                                "doc": "Source fields from which the fine grained lineage is derived",
-                                "name": "sourceFields",
-                                "type": {
-                                    "items": [
-                                        "string"
-                                    ],
-                                    "type": "array"
-                                }
-                            },
-                            {
-                                "Urn": "DatasetFieldUrn",
-                                "deprecated": "use SchemaFieldPath and represent as generic Urn instead",
-                                "doc": "Destination field which is derived from source fields",
+                                "Urn": "Urn",
+                                "default": null,
+                                "doc": "The default View which is selected for the user.\nIf none is chosen, then this value will be left blank.",
                                 "java": {
-                                    "class": "com.linkedin.pegasus2avro.common.urn.DatasetFieldUrn"
+                                    "class": "com.linkedin.pegasus2avro.common.urn.Urn"
                                 },
-                                "name": "destinationField",
-                                "type": "string"
+                                "name": "defaultView",
+                                "type": [
+                                    "null",
+                                    "string"
+                                ]
                             }
                         ],
-                        "name": "DatasetFieldMapping",
-                        "namespace": "com.linkedin.pegasus2avro.dataset",
+                        "name": "CorpUserViewsSettings",
+                        "namespace": "com.linkedin.pegasus2avro.identity",
                         "type": "record"
-                    },
+                    }
+                ]
+            }
+        ],
+        "name": "CorpUserSettings",
+        "namespace": "com.linkedin.pegasus2avro.identity",
+        "type": "record"
+    },
+    {
+        "Aspect": {
+            "name": "corpGroupEditableInfo"
+        },
+        "doc": "Group information that can be edited from UI",
+        "fields": [
+            {
+                "Searchable": {
+                    "fieldName": "editedDescription",
+                    "fieldType": "TEXT"
+                },
+                "default": null,
+                "doc": "A description of the group",
+                "name": "description",
+                "type": [
+                    "null",
+                    "string"
+                ]
+            },
+            {
+                "default": "https://raw.githubusercontent.com/datahub-project/datahub/master/datahub-web-react/src/images/default_avatar.png",
+                "doc": "A URL which points to a picture which user wants to set as the photo for the group",
+                "java": {
+                    "class": "com.linkedin.pegasus2avro.common.url.Url",
+                    "coercerClass": "com.linkedin.pegasus2avro.common.url.UrlCoercer"
+                },
+                "name": "pictureLink",
+                "type": "string"
+            },
+            {
+                "default": null,
+                "doc": "Slack channel for the group",
+                "name": "slack",
+                "type": [
+                    "null",
+                    "string"
+                ]
+            },
+            {
+                "default": null,
+                "doc": "Email address to contact the group",
+                "name": "email",
+                "type": [
+                    "null",
+                    "string"
+                ]
+            }
+        ],
+        "name": "CorpGroupEditableInfo",
+        "namespace": "com.linkedin.pegasus2avro.identity",
+        "type": "record"
+    },
+    {
+        "Aspect": {
+            "name": "nativeGroupMembership"
+        },
+        "doc": "Carries information about the native CorpGroups a user is in.",
+        "fields": [
+            {
+                "Relationship": {
+                    "/*": {
+                        "entityTypes": [
+                            "corpGroup"
+                        ],
+                        "name": "IsMemberOfNativeGroup"
+                    }
+                },
+                "Urn": "Urn",
+                "name": "nativeGroups",
+                "type": {
+                    "items": "string",
                     "type": "array"
-                }
+                },
+                "urn_is_array": true
             }
         ],
-        "name": "DatasetUpstreamLineage",
-        "namespace": "com.linkedin.pegasus2avro.dataset",
+        "name": "NativeGroupMembership",
+        "namespace": "com.linkedin.pegasus2avro.identity",
         "type": "record"
     },
     {
         "Aspect": {
-            "name": "viewProperties"
+            "EntityUrns": [
+                "com.linkedin.pegasus2avro.common.CorpGroupUrn"
+            ],
+            "name": "corpGroupInfo"
         },
-        "doc": "Details about a View. \ne.g. Gets activated when subTypes is view",
+        "doc": "Information about a Corp Group ingested from a third party source",
         "fields": [
             {
                 "Searchable": {
-                    "fieldType": "BOOLEAN",
-                    "weightsPerFieldValue": {
-                        "true": 0.5
+                    "boostScore": 10.0,
+                    "enableAutocomplete": true,
+                    "fieldType": "TEXT_PARTIAL",
+                    "queryByDefault": true
+                },
+                "default": null,
+                "doc": "The name of the group.",
+                "name": "displayName",
+                "type": [
+                    "null",
+                    "string"
+                ]
+            },
+            {
+                "default": null,
+                "doc": "email of this group",
+                "name": "email",
+                "type": [
+                    "null",
+                    "string"
+                ]
+            },
+            {
+                "Relationship": {
+                    "/*": {
+                        "entityTypes": [
+                            "corpuser"
+                        ],
+                        "name": "OwnedBy"
                     }
                 },
-                "doc": "Whether the view is materialized",
-                "name": "materialized",
-                "type": "boolean"
+                "Urn": "CorpuserUrn",
+                "deprecated": true,
+                "doc": "owners of this group\nDeprecated! Replaced by Ownership aspect.",
+                "name": "admins",
+                "type": {
+                    "items": "string",
+                    "type": "array"
+                },
+                "urn_is_array": true
             },
             {
-                "doc": "The view logic",
-                "name": "viewLogic",
+                "Relationship": {
+                    "/*": {
+                        "entityTypes": [
+                            "corpuser"
+                        ],
+                        "name": "IsPartOf"
+                    }
+                },
+                "Urn": "CorpuserUrn",
+                "deprecated": true,
+                "doc": "List of ldap urn in this group.\nDeprecated! Replaced by GroupMembership aspect.",
+                "name": "members",
+                "type": {
+                    "items": "string",
+                    "type": "array"
+                },
+                "urn_is_array": true
+            },
+            {
+                "Relationship": {
+                    "/*": {
+                        "entityTypes": [
+                            "corpGroup"
+                        ],
+                        "name": "IsPartOf"
+                    }
+                },
+                "Urn": "CorpGroupUrn",
+                "deprecated": true,
+                "doc": "List of groups in this group.\nDeprecated! This field is unused.",
+                "name": "groups",
+                "type": {
+                    "items": "string",
+                    "type": "array"
+                },
+                "urn_is_array": true
+            },
+            {
+                "Searchable": {
+                    "fieldType": "TEXT_PARTIAL"
+                },
+                "default": null,
+                "doc": "A description of the group.",
+                "name": "description",
+                "type": [
+                    "null",
+                    "string"
+                ]
+            },
+            {
+                "default": null,
+                "doc": "Slack channel for the group",
+                "name": "slack",
+                "type": [
+                    "null",
+                    "string"
+                ]
+            },
+            {
+                "Searchable": {
+                    "/time": {
+                        "fieldName": "createdTime",
+                        "fieldType": "DATETIME"
+                    }
+                },
+                "default": null,
+                "doc": "Created Audit stamp",
+                "name": "created",
+                "type": [
+                    "null",
+                    "com.linkedin.pegasus2avro.common.AuditStamp"
+                ]
+            }
+        ],
+        "name": "CorpGroupInfo",
+        "namespace": "com.linkedin.pegasus2avro.identity",
+        "type": "record"
+    },
+    {
+        "Aspect": {
+            "name": "dataHubAccessTokenInfo"
+        },
+        "doc": "Information about a DataHub Access Token",
+        "fields": [
+            {
+                "Searchable": {
+                    "fieldType": "TEXT_PARTIAL"
+                },
+                "doc": "User defined name for the access token if defined.",
+                "name": "name",
                 "type": "string"
             },
             {
-                "doc": "The view logic language / dialect",
-                "name": "viewLanguage",
+                "Searchable": {
+                    "fieldType": "URN"
+                },
+                "Urn": "Urn",
+                "doc": "Urn of the actor to which this access token belongs to.",
+                "java": {
+                    "class": "com.linkedin.pegasus2avro.common.urn.Urn"
+                },
+                "name": "actorUrn",
+                "type": "string"
+            },
+            {
+                "Searchable": {
+                    "fieldType": "URN"
+                },
+                "Urn": "Urn",
+                "doc": "Urn of the actor which created this access token.",
+                "java": {
+                    "class": "com.linkedin.pegasus2avro.common.urn.Urn"
+                },
+                "name": "ownerUrn",
                 "type": "string"
+            },
+            {
+                "Searchable": {
+                    "fieldType": "COUNT",
+                    "queryByDefault": false
+                },
+                "doc": "When the token was created.",
+                "name": "createdAt",
+                "type": "long"
+            },
+            {
+                "Searchable": {
+                    "fieldType": "COUNT",
+                    "queryByDefault": false
+                },
+                "default": null,
+                "doc": "When the token expires.",
+                "name": "expiresAt",
+                "type": [
+                    "null",
+                    "long"
+                ]
+            },
+            {
+                "default": null,
+                "doc": "Description of the token if defined.",
+                "name": "description",
+                "type": [
+                    "null",
+                    "string"
+                ]
             }
         ],
-        "name": "ViewProperties",
-        "namespace": "com.linkedin.pegasus2avro.dataset",
+        "name": "DataHubAccessTokenInfo",
+        "namespace": "com.linkedin.pegasus2avro.access.token",
         "type": "record"
     },
     {
-        "doc": "Kafka event for proposing a metadata change for an entity. A corresponding MetadataAuditEvent is emitted when the change is accepted and committed, otherwise a FailedMetadataChangeEvent will be emitted instead.",
+        "doc": "A DataHub Platform Event.",
+        "fields": [
+            {
+                "doc": "Header information stored with the event.",
+                "name": "header",
+                "type": {
+                    "doc": "A header included with each DataHub platform event.",
+                    "fields": [
+                        {
+                            "doc": "The event timestamp field as epoch at UTC in milli seconds.",
+                            "name": "timestampMillis",
+                            "type": "long"
+                        }
+                    ],
+                    "name": "PlatformEventHeader",
+                    "namespace": "com.linkedin.pegasus2avro.mxe",
+                    "type": "record"
+                }
+            },
+            {
+                "doc": "The name of the event, e.g. the type of event. For example, 'notificationRequestEvent', 'entityChangeEvent'",
+                "name": "name",
+                "type": "string"
+            },
+            {
+                "doc": "The event payload.",
+                "name": "payload",
+                "type": {
+                    "doc": "Generic payload record structure for serializing a Platform Event.",
+                    "fields": [
+                        {
+                            "doc": "The value of the event, serialized as bytes.",
+                            "name": "value",
+                            "type": "bytes"
+                        },
+                        {
+                            "doc": "The content type, which represents the fashion in which the event was serialized.\nThe only type currently supported is application/json.",
+                            "name": "contentType",
+                            "type": "string"
+                        }
+                    ],
+                    "name": "GenericPayload",
+                    "namespace": "com.linkedin.pegasus2avro.mxe",
+                    "type": "record"
+                }
+            }
+        ],
+        "name": "PlatformEvent",
+        "namespace": "com.linkedin.pegasus2avro.mxe",
+        "type": "record"
+    },
+    {
+        "doc": "Kafka event for capturing update made to an entity's metadata.",
         "fields": [
             {
                 "default": null,
-                "doc": "Kafka audit header. See go/kafkaauditheader for more info.",
+                "doc": "Kafka audit header. Currently remains unused in the open source.",
                 "name": "auditHeader",
                 "type": [
                     "null",
                     {
                         "doc": "This header records information about the context of an event as it is emitted into kafka and is intended to be used by the kafka audit application.  For more information see go/kafkaauditheader",
                         "fields": [
                             {
@@ -9246,14 +8623,210 @@
                         "name": "KafkaAuditHeader",
                         "namespace": "com.linkedin.events",
                         "type": "record"
                     }
                 ]
             },
             {
+                "doc": "Type of the entity being written to",
+                "name": "entityType",
+                "type": "string"
+            },
+            {
+                "Urn": "Urn",
+                "default": null,
+                "doc": "Urn of the entity being written",
+                "java": {
+                    "class": "com.linkedin.pegasus2avro.common.urn.Urn"
+                },
+                "name": "entityUrn",
+                "type": [
+                    "null",
+                    "string"
+                ]
+            },
+            {
+                "default": null,
+                "doc": "Key aspect of the entity being written",
+                "name": "entityKeyAspect",
+                "type": [
+                    "null",
+                    {
+                        "doc": "Generic record structure for serializing an Aspect",
+                        "fields": [
+                            {
+                                "doc": "The value of the aspect, serialized as bytes.",
+                                "name": "value",
+                                "type": "bytes"
+                            },
+                            {
+                                "doc": "The content type, which represents the fashion in which the aspect was serialized.\nThe only type currently supported is application/json.",
+                                "name": "contentType",
+                                "type": "string"
+                            }
+                        ],
+                        "name": "GenericAspect",
+                        "namespace": "com.linkedin.pegasus2avro.mxe",
+                        "type": "record"
+                    }
+                ]
+            },
+            {
+                "doc": "Type of change being proposed",
+                "name": "changeType",
+                "type": {
+                    "doc": "Descriptor for a change action",
+                    "name": "ChangeType",
+                    "namespace": "com.linkedin.pegasus2avro.events.metadata",
+                    "symbolDocs": {
+                        "CREATE": "NOT SUPPORTED YET\ninsert if not exists. otherwise fail",
+                        "DELETE": "NOT SUPPORTED YET\ndelete action",
+                        "PATCH": "NOT SUPPORTED YET\npatch the changes instead of full replace",
+                        "RESTATE": "Restate an aspect, eg. in a index refresh.",
+                        "UPDATE": "NOT SUPPORTED YET\nupdate if exists. otherwise fail",
+                        "UPSERT": "insert if not exists. otherwise update"
+                    },
+                    "symbols": [
+                        "UPSERT",
+                        "CREATE",
+                        "UPDATE",
+                        "DELETE",
+                        "PATCH",
+                        "RESTATE"
+                    ],
+                    "type": "enum"
+                }
+            },
+            {
+                "default": null,
+                "doc": "Aspect of the entity being written to\nNot filling this out implies that the writer wants to affect the entire entity\nNote: This is only valid for CREATE, UPSERT, and DELETE operations.",
+                "name": "aspectName",
+                "type": [
+                    "null",
+                    "string"
+                ]
+            },
+            {
+                "default": null,
+                "doc": "The value of the new aspect.",
+                "name": "aspect",
+                "type": [
+                    "null",
+                    "com.linkedin.pegasus2avro.mxe.GenericAspect"
+                ]
+            },
+            {
+                "default": null,
+                "doc": "A string->string map of custom properties that one might want to attach to an event",
+                "name": "systemMetadata",
+                "type": [
+                    "null",
+                    {
+                        "doc": "Metadata associated with each metadata change that is processed by the system",
+                        "fields": [
+                            {
+                                "default": 0,
+                                "doc": "The timestamp the metadata was observed at",
+                                "name": "lastObserved",
+                                "type": [
+                                    "long",
+                                    "null"
+                                ]
+                            },
+                            {
+                                "default": "no-run-id-provided",
+                                "doc": "The run id that produced the metadata. Populated in case of batch-ingestion.",
+                                "name": "runId",
+                                "type": [
+                                    "string",
+                                    "null"
+                                ]
+                            },
+                            {
+                                "default": null,
+                                "doc": "The model registry name that was used to process this event",
+                                "name": "registryName",
+                                "type": [
+                                    "null",
+                                    "string"
+                                ]
+                            },
+                            {
+                                "default": null,
+                                "doc": "The model registry version that was used to process this event",
+                                "name": "registryVersion",
+                                "type": [
+                                    "null",
+                                    "string"
+                                ]
+                            },
+                            {
+                                "default": null,
+                                "doc": "Additional properties",
+                                "name": "properties",
+                                "type": [
+                                    "null",
+                                    {
+                                        "type": "map",
+                                        "values": "string"
+                                    }
+                                ]
+                            }
+                        ],
+                        "name": "SystemMetadata",
+                        "namespace": "com.linkedin.pegasus2avro.mxe",
+                        "type": "record"
+                    }
+                ]
+            },
+            {
+                "default": null,
+                "doc": "The previous value of the aspect that has changed.",
+                "name": "previousAspectValue",
+                "type": [
+                    "null",
+                    "com.linkedin.pegasus2avro.mxe.GenericAspect"
+                ]
+            },
+            {
+                "default": null,
+                "doc": "The previous value of the system metadata field that has changed.",
+                "name": "previousSystemMetadata",
+                "type": [
+                    "null",
+                    "com.linkedin.pegasus2avro.mxe.SystemMetadata"
+                ]
+            },
+            {
+                "default": null,
+                "doc": "An audit stamp detailing who and when the aspect was changed by. Required for all intents and purposes.",
+                "name": "created",
+                "type": [
+                    "null",
+                    "com.linkedin.pegasus2avro.common.AuditStamp"
+                ]
+            }
+        ],
+        "name": "MetadataChangeLog",
+        "namespace": "com.linkedin.pegasus2avro.mxe",
+        "type": "record"
+    },
+    {
+        "doc": "Kafka event for proposing a metadata change for an entity. A corresponding MetadataAuditEvent is emitted when the change is accepted and committed, otherwise a FailedMetadataChangeEvent will be emitted instead.",
+        "fields": [
+            {
+                "default": null,
+                "doc": "Kafka audit header. See go/kafkaauditheader for more info.",
+                "name": "auditHeader",
+                "type": [
+                    "null",
+                    "com.linkedin.events.KafkaAuditHeader"
+                ]
+            },
+            {
                 "doc": "Snapshot of the proposed metadata change. Include only the aspects affected by the change in the snapshot.",
                 "name": "proposedSnapshot",
                 "type": [
                     {
                         "Entity": {
                             "keyAspect": "chartKey",
                             "name": "chart"
@@ -9299,307 +8872,21 @@
                                             "name": "ChartKey",
                                             "namespace": "com.linkedin.pegasus2avro.metadata.key",
                                             "type": "record"
                                         },
                                         "com.linkedin.pegasus2avro.chart.ChartInfo",
                                         "com.linkedin.pegasus2avro.chart.ChartQuery",
                                         "com.linkedin.pegasus2avro.chart.EditableChartProperties",
-                                        {
-                                            "Aspect": {
-                                                "name": "ownership"
-                                            },
-                                            "doc": "Ownership information of an entity.",
-                                            "fields": [
-                                                {
-                                                    "doc": "List of owners of the entity.",
-                                                    "name": "owners",
-                                                    "type": {
-                                                        "items": {
-                                                            "doc": "Ownership information",
-                                                            "fields": [
-                                                                {
-                                                                    "Relationship": {
-                                                                        "entityTypes": [
-                                                                            "corpuser",
-                                                                            "corpGroup"
-                                                                        ],
-                                                                        "name": "OwnedBy"
-                                                                    },
-                                                                    "Searchable": {
-                                                                        "addToFilters": true,
-                                                                        "fieldName": "owners",
-                                                                        "fieldType": "URN",
-                                                                        "filterNameOverride": "Owned By",
-                                                                        "hasValuesFieldName": "hasOwners",
-                                                                        "queryByDefault": false
-                                                                    },
-                                                                    "Urn": "Urn",
-                                                                    "doc": "Owner URN, e.g. urn:li:corpuser:ldap, urn:li:corpGroup:group_name, and urn:li:multiProduct:mp_name\n(Caveat: only corpuser is currently supported in the frontend.)",
-                                                                    "java": {
-                                                                        "class": "com.linkedin.pegasus2avro.common.urn.Urn"
-                                                                    },
-                                                                    "name": "owner",
-                                                                    "type": "string"
-                                                                },
-                                                                {
-                                                                    "doc": "The type of the ownership",
-                                                                    "name": "type",
-                                                                    "type": {
-                                                                        "deprecatedSymbols": {
-                                                                            "CONSUMER": true,
-                                                                            "DATAOWNER": true,
-                                                                            "DELEGATE": true,
-                                                                            "DEVELOPER": true,
-                                                                            "PRODUCER": true,
-                                                                            "STAKEHOLDER": true
-                                                                        },
-                                                                        "doc": "Asset owner types",
-                                                                        "name": "OwnershipType",
-                                                                        "namespace": "com.linkedin.pegasus2avro.common",
-                                                                        "symbolDocs": {
-                                                                            "BUSINESS_OWNER": "A person or group who is responsible for logical, or business related, aspects of the asset.",
-                                                                            "CONSUMER": "A person, group, or service that consumes the data\nDeprecated! Use TECHNICAL_OWNER or BUSINESS_OWNER instead.",
-                                                                            "DATAOWNER": "A person or group that is owning the data\nDeprecated! Use TECHNICAL_OWNER instead.",
-                                                                            "DATA_STEWARD": "A steward, expert, or delegate responsible for the asset.",
-                                                                            "DELEGATE": "A person or a group that overseas the operation, e.g. a DBA or SRE.\nDeprecated! Use TECHNICAL_OWNER instead.",
-                                                                            "DEVELOPER": "A person or group that is in charge of developing the code\nDeprecated! Use TECHNICAL_OWNER instead.",
-                                                                            "NONE": "No specific type associated to the owner.",
-                                                                            "PRODUCER": "A person, group, or service that produces/generates the data\nDeprecated! Use TECHNICAL_OWNER instead.",
-                                                                            "STAKEHOLDER": "A person or a group that has direct business interest\nDeprecated! Use TECHNICAL_OWNER, BUSINESS_OWNER, or STEWARD instead.",
-                                                                            "TECHNICAL_OWNER": "person or group who is responsible for technical aspects of the asset."
-                                                                        },
-                                                                        "symbols": [
-                                                                            "TECHNICAL_OWNER",
-                                                                            "BUSINESS_OWNER",
-                                                                            "DATA_STEWARD",
-                                                                            "NONE",
-                                                                            "DEVELOPER",
-                                                                            "DATAOWNER",
-                                                                            "DELEGATE",
-                                                                            "PRODUCER",
-                                                                            "CONSUMER",
-                                                                            "STAKEHOLDER"
-                                                                        ],
-                                                                        "type": "enum"
-                                                                    }
-                                                                },
-                                                                {
-                                                                    "default": null,
-                                                                    "doc": "Source information for the ownership",
-                                                                    "name": "source",
-                                                                    "type": [
-                                                                        "null",
-                                                                        {
-                                                                            "doc": "Source/provider of the ownership information",
-                                                                            "fields": [
-                                                                                {
-                                                                                    "doc": "The type of the source",
-                                                                                    "name": "type",
-                                                                                    "type": {
-                                                                                        "name": "OwnershipSourceType",
-                                                                                        "namespace": "com.linkedin.pegasus2avro.common",
-                                                                                        "symbolDocs": {
-                                                                                            "AUDIT": "Auditing system or audit logs",
-                                                                                            "DATABASE": "Database, e.g. GRANTS table",
-                                                                                            "FILE_SYSTEM": "File system, e.g. file/directory owner",
-                                                                                            "ISSUE_TRACKING_SYSTEM": "Issue tracking system, e.g. Jira",
-                                                                                            "MANUAL": "Manually provided by a user",
-                                                                                            "OTHER": "Other sources",
-                                                                                            "SERVICE": "Other ownership-like service, e.g. Nuage, ACL service etc",
-                                                                                            "SOURCE_CONTROL": "SCM system, e.g. GIT, SVN"
-                                                                                        },
-                                                                                        "symbols": [
-                                                                                            "AUDIT",
-                                                                                            "DATABASE",
-                                                                                            "FILE_SYSTEM",
-                                                                                            "ISSUE_TRACKING_SYSTEM",
-                                                                                            "MANUAL",
-                                                                                            "SERVICE",
-                                                                                            "SOURCE_CONTROL",
-                                                                                            "OTHER"
-                                                                                        ],
-                                                                                        "type": "enum"
-                                                                                    }
-                                                                                },
-                                                                                {
-                                                                                    "default": null,
-                                                                                    "doc": "A reference URL for the source",
-                                                                                    "name": "url",
-                                                                                    "type": [
-                                                                                        "null",
-                                                                                        "string"
-                                                                                    ]
-                                                                                }
-                                                                            ],
-                                                                            "name": "OwnershipSource",
-                                                                            "namespace": "com.linkedin.pegasus2avro.common",
-                                                                            "type": "record"
-                                                                        }
-                                                                    ]
-                                                                }
-                                                            ],
-                                                            "name": "Owner",
-                                                            "namespace": "com.linkedin.pegasus2avro.common",
-                                                            "type": "record"
-                                                        },
-                                                        "type": "array"
-                                                    }
-                                                },
-                                                {
-                                                    "default": {
-                                                        "actor": "urn:li:corpuser:unknown",
-                                                        "impersonator": null,
-                                                        "message": null,
-                                                        "time": 0
-                                                    },
-                                                    "doc": "Audit stamp containing who last modified the record and when. A value of 0 in the time field indicates missing data.",
-                                                    "name": "lastModified",
-                                                    "type": "com.linkedin.pegasus2avro.common.AuditStamp"
-                                                }
-                                            ],
-                                            "name": "Ownership",
-                                            "namespace": "com.linkedin.pegasus2avro.common",
-                                            "type": "record"
-                                        },
-                                        {
-                                            "Aspect": {
-                                                "name": "status"
-                                            },
-                                            "doc": "The lifecycle status metadata of an entity, e.g. dataset, metric, feature, etc.\nThis aspect is used to represent soft deletes conventionally.",
-                                            "fields": [
-                                                {
-                                                    "Searchable": {
-                                                        "fieldType": "BOOLEAN"
-                                                    },
-                                                    "default": false,
-                                                    "doc": "Whether the entity has been removed (soft-deleted).",
-                                                    "name": "removed",
-                                                    "type": "boolean"
-                                                }
-                                            ],
-                                            "name": "Status",
-                                            "namespace": "com.linkedin.pegasus2avro.common",
-                                            "type": "record"
-                                        },
+                                        "com.linkedin.pegasus2avro.common.Ownership",
+                                        "com.linkedin.pegasus2avro.common.Status",
                                         "com.linkedin.pegasus2avro.common.GlobalTags",
-                                        {
-                                            "Aspect": {
-                                                "name": "browsePaths"
-                                            },
-                                            "doc": "Shared aspect containing Browse Paths to be indexed for an entity.",
-                                            "fields": [
-                                                {
-                                                    "Searchable": {
-                                                        "/*": {
-                                                            "fieldName": "browsePaths",
-                                                            "fieldType": "BROWSE_PATH"
-                                                        }
-                                                    },
-                                                    "doc": "A list of valid browse paths for the entity.\n\nBrowse paths are expected to be forward slash-separated strings. For example: 'prod/snowflake/datasetName'",
-                                                    "name": "paths",
-                                                    "type": {
-                                                        "items": "string",
-                                                        "type": "array"
-                                                    }
-                                                }
-                                            ],
-                                            "name": "BrowsePaths",
-                                            "namespace": "com.linkedin.pegasus2avro.common",
-                                            "type": "record"
-                                        },
+                                        "com.linkedin.pegasus2avro.common.BrowsePaths",
                                         "com.linkedin.pegasus2avro.common.GlossaryTerms",
-                                        {
-                                            "Aspect": {
-                                                "name": "institutionalMemory"
-                                            },
-                                            "doc": "Institutional memory of an entity. This is a way to link to relevant documentation and provide description of the documentation. Institutional or tribal knowledge is very important for users to leverage the entity.",
-                                            "fields": [
-                                                {
-                                                    "doc": "List of records that represent institutional memory of an entity. Each record consists of a link, description, creator and timestamps associated with that record.",
-                                                    "name": "elements",
-                                                    "type": {
-                                                        "items": {
-                                                            "doc": "Metadata corresponding to a record of institutional memory.",
-                                                            "fields": [
-                                                                {
-                                                                    "doc": "Link to an engineering design document or a wiki page.",
-                                                                    "java": {
-                                                                        "class": "com.linkedin.pegasus2avro.common.url.Url",
-                                                                        "coercerClass": "com.linkedin.pegasus2avro.common.url.UrlCoercer"
-                                                                    },
-                                                                    "name": "url",
-                                                                    "type": "string"
-                                                                },
-                                                                {
-                                                                    "doc": "Description of the link.",
-                                                                    "name": "description",
-                                                                    "type": "string"
-                                                                },
-                                                                {
-                                                                    "doc": "Audit stamp associated with creation of this record",
-                                                                    "name": "createStamp",
-                                                                    "type": "com.linkedin.pegasus2avro.common.AuditStamp"
-                                                                }
-                                                            ],
-                                                            "name": "InstitutionalMemoryMetadata",
-                                                            "namespace": "com.linkedin.pegasus2avro.common",
-                                                            "type": "record"
-                                                        },
-                                                        "type": "array"
-                                                    }
-                                                }
-                                            ],
-                                            "name": "InstitutionalMemory",
-                                            "namespace": "com.linkedin.pegasus2avro.common",
-                                            "type": "record"
-                                        },
-                                        {
-                                            "Aspect": {
-                                                "name": "dataPlatformInstance"
-                                            },
-                                            "doc": "The specific instance of the data platform that this entity belongs to",
-                                            "fields": [
-                                                {
-                                                    "Searchable": {
-                                                        "addToFilters": true,
-                                                        "fieldType": "URN",
-                                                        "filterNameOverride": "Platform"
-                                                    },
-                                                    "Urn": "Urn",
-                                                    "doc": "Data Platform",
-                                                    "java": {
-                                                        "class": "com.linkedin.pegasus2avro.common.urn.Urn"
-                                                    },
-                                                    "name": "platform",
-                                                    "type": "string"
-                                                },
-                                                {
-                                                    "Searchable": {
-                                                        "addToFilters": true,
-                                                        "fieldName": "platformInstance",
-                                                        "fieldType": "URN",
-                                                        "filterNameOverride": "Platform Instance"
-                                                    },
-                                                    "Urn": "Urn",
-                                                    "default": null,
-                                                    "doc": "Instance of the data platform (e.g. db instance)",
-                                                    "java": {
-                                                        "class": "com.linkedin.pegasus2avro.common.urn.Urn"
-                                                    },
-                                                    "name": "instance",
-                                                    "type": [
-                                                        "null",
-                                                        "string"
-                                                    ]
-                                                }
-                                            ],
-                                            "name": "DataPlatformInstance",
-                                            "namespace": "com.linkedin.pegasus2avro.common",
-                                            "type": "record"
-                                        }
+                                        "com.linkedin.pegasus2avro.common.InstitutionalMemory",
+                                        "com.linkedin.pegasus2avro.common.DataPlatformInstance"
                                     ],
                                     "type": "array"
                                 }
                             }
                         ],
                         "name": "ChartSnapshot",
                         "namespace": "com.linkedin.pegasus2avro.metadata.snapshot",
@@ -10116,15 +9403,87 @@
                                                 }
                                             ],
                                             "name": "DataProcessKey",
                                             "namespace": "com.linkedin.pegasus2avro.metadata.key",
                                             "type": "record"
                                         },
                                         "com.linkedin.pegasus2avro.common.Ownership",
-                                        "com.linkedin.pegasus2avro.dataprocess.DataProcessInfo",
+                                        {
+                                            "Aspect": {
+                                                "name": "dataProcessInfo"
+                                            },
+                                            "doc": "The inputs and outputs of this data process",
+                                            "fields": [
+                                                {
+                                                    "Relationship": {
+                                                        "/*": {
+                                                            "entityTypes": [
+                                                                "dataset"
+                                                            ],
+                                                            "isLineage": true,
+                                                            "name": "Consumes"
+                                                        }
+                                                    },
+                                                    "Searchable": {
+                                                        "/*": {
+                                                            "fieldName": "inputs",
+                                                            "fieldType": "URN",
+                                                            "numValuesFieldName": "numInputDatasets",
+                                                            "queryByDefault": false
+                                                        }
+                                                    },
+                                                    "Urn": "DatasetUrn",
+                                                    "default": null,
+                                                    "doc": "the inputs of the data process",
+                                                    "name": "inputs",
+                                                    "type": [
+                                                        "null",
+                                                        {
+                                                            "items": "string",
+                                                            "type": "array"
+                                                        }
+                                                    ],
+                                                    "urn_is_array": true
+                                                },
+                                                {
+                                                    "Relationship": {
+                                                        "/*": {
+                                                            "entityTypes": [
+                                                                "dataset"
+                                                            ],
+                                                            "isLineage": true,
+                                                            "name": "Consumes"
+                                                        }
+                                                    },
+                                                    "Searchable": {
+                                                        "/*": {
+                                                            "fieldName": "outputs",
+                                                            "fieldType": "URN",
+                                                            "numValuesFieldName": "numOutputDatasets",
+                                                            "queryByDefault": false
+                                                        }
+                                                    },
+                                                    "Urn": "DatasetUrn",
+                                                    "default": null,
+                                                    "doc": "the outputs of the data process",
+                                                    "name": "outputs",
+                                                    "type": [
+                                                        "null",
+                                                        {
+                                                            "items": "string",
+                                                            "type": "array"
+                                                        }
+                                                    ],
+                                                    "urn_is_array": true
+                                                }
+                                            ],
+                                            "name": "DataProcessInfo",
+                                            "namespace": "com.linkedin.pegasus2avro.dataprocess",
+                                            "type": "record"
+                                        },
                                         "com.linkedin.pegasus2avro.common.Status"
                                     ],
                                     "type": "array"
                                 }
                             }
                         ],
                         "name": "DataProcessSnapshot",
@@ -10249,123 +9608,16 @@
                                         "com.linkedin.pegasus2avro.ml.metadata.TrainingData",
                                         "com.linkedin.pegasus2avro.ml.metadata.QuantitativeAnalyses",
                                         "com.linkedin.pegasus2avro.ml.metadata.EthicalConsiderations",
                                         "com.linkedin.pegasus2avro.ml.metadata.CaveatsAndRecommendations",
                                         "com.linkedin.pegasus2avro.common.InstitutionalMemory",
                                         "com.linkedin.pegasus2avro.ml.metadata.SourceCode",
                                         "com.linkedin.pegasus2avro.common.Status",
-                                        {
-                                            "Aspect": {
-                                                "name": "cost"
-                                            },
-                                            "fields": [
-                                                {
-                                                    "name": "costType",
-                                                    "type": {
-                                                        "doc": "Type of Cost Code",
-                                                        "name": "CostType",
-                                                        "namespace": "com.linkedin.pegasus2avro.common",
-                                                        "symbolDocs": {
-                                                            "ORG_COST_TYPE": "Org Cost Type to which the Cost of this entity should be attributed to"
-                                                        },
-                                                        "symbols": [
-                                                            "ORG_COST_TYPE"
-                                                        ],
-                                                        "type": "enum"
-                                                    }
-                                                },
-                                                {
-                                                    "name": "cost",
-                                                    "type": {
-                                                        "fields": [
-                                                            {
-                                                                "default": null,
-                                                                "name": "costId",
-                                                                "type": [
-                                                                    "null",
-                                                                    "double"
-                                                                ]
-                                                            },
-                                                            {
-                                                                "default": null,
-                                                                "name": "costCode",
-                                                                "type": [
-                                                                    "null",
-                                                                    "string"
-                                                                ]
-                                                            },
-                                                            {
-                                                                "doc": "Contains the name of the field that has its value set.",
-                                                                "name": "fieldDiscriminator",
-                                                                "type": {
-                                                                    "name": "CostCostDiscriminator",
-                                                                    "namespace": "com.linkedin.pegasus2avro.common",
-                                                                    "symbols": [
-                                                                        "costId",
-                                                                        "costCode"
-                                                                    ],
-                                                                    "type": "enum"
-                                                                }
-                                                            }
-                                                        ],
-                                                        "name": "CostCost",
-                                                        "namespace": "com.linkedin.pegasus2avro.common",
-                                                        "type": "record"
-                                                    }
-                                                }
-                                            ],
-                                            "name": "Cost",
-                                            "namespace": "com.linkedin.pegasus2avro.common",
-                                            "type": "record"
-                                        },
-                                        {
-                                            "Aspect": {
-                                                "name": "deprecation"
-                                            },
-                                            "doc": "Deprecation status of an entity",
-                                            "fields": [
-                                                {
-                                                    "Searchable": {
-                                                        "fieldType": "BOOLEAN",
-                                                        "weightsPerFieldValue": {
-                                                            "true": 0.5
-                                                        }
-                                                    },
-                                                    "doc": "Whether the entity is deprecated.",
-                                                    "name": "deprecated",
-                                                    "type": "boolean"
-                                                },
-                                                {
-                                                    "default": null,
-                                                    "doc": "The time user plan to decommission this entity.",
-                                                    "name": "decommissionTime",
-                                                    "type": [
-                                                        "null",
-                                                        "long"
-                                                    ]
-                                                },
-                                                {
-                                                    "doc": "Additional information about the entity deprecation plan, such as the wiki, doc, RB.",
-                                                    "name": "note",
-                                                    "type": "string"
-                                                },
-                                                {
-                                                    "Urn": "Urn",
-                                                    "doc": "The user URN which will be credited for modifying this deprecation content.",
-                                                    "java": {
-                                                        "class": "com.linkedin.pegasus2avro.common.urn.Urn"
-                                                    },
-                                                    "name": "actor",
-                                                    "type": "string"
-                                                }
-                                            ],
-                                            "name": "Deprecation",
-                                            "namespace": "com.linkedin.pegasus2avro.common",
-                                            "type": "record"
-                                        },
+                                        "com.linkedin.pegasus2avro.common.Cost",
+                                        "com.linkedin.pegasus2avro.common.Deprecation",
                                         "com.linkedin.pegasus2avro.common.BrowsePaths",
                                         "com.linkedin.pegasus2avro.common.GlobalTags",
                                         "com.linkedin.pegasus2avro.common.DataPlatformInstance"
                                     ],
                                     "type": "array"
                                 }
                             }
@@ -10925,264 +10177,15 @@
                                                     "type": "string"
                                                 }
                                             ],
                                             "name": "DataHubPolicyKey",
                                             "namespace": "com.linkedin.pegasus2avro.metadata.key",
                                             "type": "record"
                                         },
-                                        {
-                                            "Aspect": {
-                                                "name": "dataHubPolicyInfo"
-                                            },
-                                            "doc": "Information about a DataHub (UI) access policy.",
-                                            "fields": [
-                                                {
-                                                    "Searchable": {
-                                                        "fieldType": "TEXT_PARTIAL"
-                                                    },
-                                                    "doc": "Display name of the Policy",
-                                                    "name": "displayName",
-                                                    "type": "string"
-                                                },
-                                                {
-                                                    "Searchable": {
-                                                        "fieldType": "TEXT"
-                                                    },
-                                                    "doc": "Description of the Policy",
-                                                    "name": "description",
-                                                    "type": "string"
-                                                },
-                                                {
-                                                    "doc": "The type of policy",
-                                                    "name": "type",
-                                                    "type": "string"
-                                                },
-                                                {
-                                                    "doc": "The state of policy, ACTIVE or INACTIVE",
-                                                    "name": "state",
-                                                    "type": "string"
-                                                },
-                                                {
-                                                    "default": null,
-                                                    "doc": "The resource that the policy applies to. Not required for some 'Platform' privileges.",
-                                                    "name": "resources",
-                                                    "type": [
-                                                        "null",
-                                                        {
-                                                            "doc": "Information used to filter DataHub resource.",
-                                                            "fields": [
-                                                                {
-                                                                    "default": null,
-                                                                    "deprecated": true,
-                                                                    "doc": "The type of resource that the policy applies to. This will most often be a data asset entity name, for\nexample 'dataset'. It is not strictly required because in the future we will want to support filtering a resource\nby domain, as well.",
-                                                                    "name": "type",
-                                                                    "type": [
-                                                                        "null",
-                                                                        "string"
-                                                                    ]
-                                                                },
-                                                                {
-                                                                    "default": null,
-                                                                    "deprecated": true,
-                                                                    "doc": "A specific set of resources to apply the policy to, e.g. asset urns",
-                                                                    "name": "resources",
-                                                                    "type": [
-                                                                        "null",
-                                                                        {
-                                                                            "items": "string",
-                                                                            "type": "array"
-                                                                        }
-                                                                    ]
-                                                                },
-                                                                {
-                                                                    "default": false,
-                                                                    "deprecated": true,
-                                                                    "doc": "Whether the policy should be applied to all assets matching the filter.",
-                                                                    "name": "allResources",
-                                                                    "type": "boolean"
-                                                                },
-                                                                {
-                                                                    "default": null,
-                                                                    "doc": "Filter to apply privileges to",
-                                                                    "name": "filter",
-                                                                    "type": [
-                                                                        "null",
-                                                                        {
-                                                                            "doc": "The filter for specifying the resource or actor to apply privileges to",
-                                                                            "fields": [
-                                                                                {
-                                                                                    "doc": "A list of criteria to apply conjunctively (so all criteria must pass)",
-                                                                                    "name": "criteria",
-                                                                                    "type": {
-                                                                                        "items": {
-                                                                                            "doc": "A criterion for matching a field with given value",
-                                                                                            "fields": [
-                                                                                                {
-                                                                                                    "doc": "The name of the field that the criterion refers to",
-                                                                                                    "name": "field",
-                                                                                                    "type": "string"
-                                                                                                },
-                                                                                                {
-                                                                                                    "doc": "Values. Matches criterion if any one of the values matches condition (OR-relationship)",
-                                                                                                    "name": "values",
-                                                                                                    "type": {
-                                                                                                        "items": "string",
-                                                                                                        "type": "array"
-                                                                                                    }
-                                                                                                },
-                                                                                                {
-                                                                                                    "default": "EQUALS",
-                                                                                                    "doc": "The condition for the criterion",
-                                                                                                    "name": "condition",
-                                                                                                    "type": {
-                                                                                                        "doc": "The matching condition in a filter criterion",
-                                                                                                        "name": "PolicyMatchCondition",
-                                                                                                        "namespace": "com.linkedin.pegasus2avro.policy",
-                                                                                                        "symbolDocs": {
-                                                                                                            "EQUALS": "Whether the field matches the value"
-                                                                                                        },
-                                                                                                        "symbols": [
-                                                                                                            "EQUALS"
-                                                                                                        ],
-                                                                                                        "type": "enum"
-                                                                                                    }
-                                                                                                }
-                                                                                            ],
-                                                                                            "name": "PolicyMatchCriterion",
-                                                                                            "namespace": "com.linkedin.pegasus2avro.policy",
-                                                                                            "type": "record"
-                                                                                        },
-                                                                                        "type": "array"
-                                                                                    }
-                                                                                }
-                                                                            ],
-                                                                            "name": "PolicyMatchFilter",
-                                                                            "namespace": "com.linkedin.pegasus2avro.policy",
-                                                                            "type": "record"
-                                                                        }
-                                                                    ]
-                                                                }
-                                                            ],
-                                                            "name": "DataHubResourceFilter",
-                                                            "namespace": "com.linkedin.pegasus2avro.policy",
-                                                            "type": "record"
-                                                        }
-                                                    ]
-                                                },
-                                                {
-                                                    "doc": "The privileges that the policy grants.",
-                                                    "name": "privileges",
-                                                    "type": {
-                                                        "items": "string",
-                                                        "type": "array"
-                                                    }
-                                                },
-                                                {
-                                                    "doc": "The actors that the policy applies to.",
-                                                    "name": "actors",
-                                                    "type": {
-                                                        "doc": "Information used to filter DataHub actors.",
-                                                        "fields": [
-                                                            {
-                                                                "Urn": "Urn",
-                                                                "default": null,
-                                                                "doc": "A specific set of users to apply the policy to (disjunctive)",
-                                                                "name": "users",
-                                                                "type": [
-                                                                    "null",
-                                                                    {
-                                                                        "items": "string",
-                                                                        "type": "array"
-                                                                    }
-                                                                ],
-                                                                "urn_is_array": true
-                                                            },
-                                                            {
-                                                                "Urn": "Urn",
-                                                                "default": null,
-                                                                "doc": "A specific set of groups to apply the policy to (disjunctive)",
-                                                                "name": "groups",
-                                                                "type": [
-                                                                    "null",
-                                                                    {
-                                                                        "items": "string",
-                                                                        "type": "array"
-                                                                    }
-                                                                ],
-                                                                "urn_is_array": true
-                                                            },
-                                                            {
-                                                                "default": false,
-                                                                "doc": "Whether the filter should return true for owners of a particular resource.\nOnly applies to policies of type 'Metadata', which have a resource associated with them.",
-                                                                "name": "resourceOwners",
-                                                                "type": "boolean"
-                                                            },
-                                                            {
-                                                                "default": false,
-                                                                "doc": "Whether the filter should apply to all users.",
-                                                                "name": "allUsers",
-                                                                "type": "boolean"
-                                                            },
-                                                            {
-                                                                "default": false,
-                                                                "doc": "Whether the filter should apply to all groups.",
-                                                                "name": "allGroups",
-                                                                "type": "boolean"
-                                                            },
-                                                            {
-                                                                "Relationship": {
-                                                                    "/*": {
-                                                                        "entityTypes": [
-                                                                            "dataHubRole"
-                                                                        ],
-                                                                        "name": "IsAssociatedWithRole"
-                                                                    }
-                                                                },
-                                                                "Urn": "Urn",
-                                                                "default": null,
-                                                                "doc": "A specific set of roles to apply the policy to (disjunctive).",
-                                                                "name": "roles",
-                                                                "type": [
-                                                                    "null",
-                                                                    {
-                                                                        "items": "string",
-                                                                        "type": "array"
-                                                                    }
-                                                                ],
-                                                                "urn_is_array": true
-                                                            }
-                                                        ],
-                                                        "name": "DataHubActorFilter",
-                                                        "namespace": "com.linkedin.pegasus2avro.policy",
-                                                        "type": "record"
-                                                    }
-                                                },
-                                                {
-                                                    "default": true,
-                                                    "doc": "Whether the policy should be editable via the UI",
-                                                    "name": "editable",
-                                                    "type": "boolean"
-                                                },
-                                                {
-                                                    "Searchable": {
-                                                        "fieldType": "DATETIME"
-                                                    },
-                                                    "default": null,
-                                                    "doc": "Timestamp when the policy was last updated",
-                                                    "name": "lastUpdatedTimestamp",
-                                                    "type": [
-                                                        "null",
-                                                        "long"
-                                                    ]
-                                                }
-                                            ],
-                                            "name": "DataHubPolicyInfo",
-                                            "namespace": "com.linkedin.pegasus2avro.policy",
-                                            "type": "record"
-                                        }
+                                        "com.linkedin.pegasus2avro.policy.DataHubPolicyInfo"
                                     ],
                                     "type": "array"
                                 }
                             }
                         ],
                         "name": "DataHubPolicySnapshot",
                         "namespace": "com.linkedin.pegasus2avro.metadata.snapshot",
@@ -11313,70 +10316,15 @@
             },
             {
                 "default": null,
                 "doc": "Metadata around how the snapshot was ingested",
                 "name": "systemMetadata",
                 "type": [
                     "null",
-                    {
-                        "doc": "Metadata associated with each metadata change that is processed by the system",
-                        "fields": [
-                            {
-                                "default": 0,
-                                "doc": "The timestamp the metadata was observed at",
-                                "name": "lastObserved",
-                                "type": [
-                                    "long",
-                                    "null"
-                                ]
-                            },
-                            {
-                                "default": "no-run-id-provided",
-                                "doc": "The run id that produced the metadata. Populated in case of batch-ingestion.",
-                                "name": "runId",
-                                "type": [
-                                    "string",
-                                    "null"
-                                ]
-                            },
-                            {
-                                "default": null,
-                                "doc": "The model registry name that was used to process this event",
-                                "name": "registryName",
-                                "type": [
-                                    "null",
-                                    "string"
-                                ]
-                            },
-                            {
-                                "default": null,
-                                "doc": "The model registry version that was used to process this event",
-                                "name": "registryVersion",
-                                "type": [
-                                    "null",
-                                    "string"
-                                ]
-                            },
-                            {
-                                "default": null,
-                                "doc": "Additional properties",
-                                "name": "properties",
-                                "type": [
-                                    "null",
-                                    {
-                                        "type": "map",
-                                        "values": "string"
-                                    }
-                                ]
-                            }
-                        ],
-                        "name": "SystemMetadata",
-                        "namespace": "com.linkedin.pegasus2avro.mxe",
-                        "type": "record"
-                    }
+                    "com.linkedin.pegasus2avro.mxe.SystemMetadata"
                 ]
             }
         ],
         "name": "MetadataChangeEvent",
         "namespace": "com.linkedin.pegasus2avro.mxe",
         "type": "record"
     },
@@ -11412,59 +10360,21 @@
             },
             {
                 "default": null,
                 "doc": "Key aspect of the entity being written",
                 "name": "entityKeyAspect",
                 "type": [
                     "null",
-                    {
-                        "doc": "Generic record structure for serializing an Aspect",
-                        "fields": [
-                            {
-                                "doc": "The value of the aspect, serialized as bytes.",
-                                "name": "value",
-                                "type": "bytes"
-                            },
-                            {
-                                "doc": "The content type, which represents the fashion in which the aspect was serialized.\nThe only type currently supported is application/json.",
-                                "name": "contentType",
-                                "type": "string"
-                            }
-                        ],
-                        "name": "GenericAspect",
-                        "namespace": "com.linkedin.pegasus2avro.mxe",
-                        "type": "record"
-                    }
+                    "com.linkedin.pegasus2avro.mxe.GenericAspect"
                 ]
             },
             {
                 "doc": "Type of change being proposed",
                 "name": "changeType",
-                "type": {
-                    "doc": "Descriptor for a change action",
-                    "name": "ChangeType",
-                    "namespace": "com.linkedin.pegasus2avro.events.metadata",
-                    "symbolDocs": {
-                        "CREATE": "NOT SUPPORTED YET\ninsert if not exists. otherwise fail",
-                        "DELETE": "NOT SUPPORTED YET\ndelete action",
-                        "PATCH": "NOT SUPPORTED YET\npatch the changes instead of full replace",
-                        "RESTATE": "Restate an aspect, eg. in a index refresh.",
-                        "UPDATE": "NOT SUPPORTED YET\nupdate if exists. otherwise fail",
-                        "UPSERT": "insert if not exists. otherwise update"
-                    },
-                    "symbols": [
-                        "UPSERT",
-                        "CREATE",
-                        "UPDATE",
-                        "DELETE",
-                        "PATCH",
-                        "RESTATE"
-                    ],
-                    "type": "enum"
-                }
+                "type": "com.linkedin.pegasus2avro.events.metadata.ChangeType"
             },
             {
                 "default": null,
                 "doc": "Aspect of the entity being written to\nNot filling this out implies that the writer wants to affect the entire entity\nNote: This is only valid for CREATE, UPSERT, and DELETE operations.",
                 "name": "aspectName",
                 "type": [
                     "null",
@@ -11491,230 +10401,396 @@
             }
         ],
         "name": "MetadataChangeProposal",
         "namespace": "com.linkedin.pegasus2avro.mxe",
         "type": "record"
     },
     {
-        "doc": "Kafka event for capturing update made to an entity's metadata.",
+        "Aspect": {
+            "name": "dataProcessInstanceRunEvent",
+            "type": "timeseries"
+        },
+        "doc": "An event representing the current status of data process run.\nDataProcessRunEvent should be used for reporting the status of a dataProcess' run.",
         "fields": [
             {
+                "doc": "The event timestamp field as epoch at UTC in milli seconds.",
+                "name": "timestampMillis",
+                "type": "long"
+            },
+            {
                 "default": null,
-                "doc": "Kafka audit header. Currently remains unused in the open source.",
-                "name": "auditHeader",
+                "doc": "Granularity of the event if applicable",
+                "name": "eventGranularity",
                 "type": [
                     "null",
-                    "com.linkedin.events.KafkaAuditHeader"
+                    "com.linkedin.pegasus2avro.timeseries.TimeWindowSize"
                 ]
             },
             {
-                "doc": "Type of the entity being written to",
-                "name": "entityType",
-                "type": "string"
+                "default": {
+                    "partition": "FULL_TABLE_SNAPSHOT",
+                    "timePartition": null,
+                    "type": "FULL_TABLE"
+                },
+                "doc": "The optional partition specification.",
+                "name": "partitionSpec",
+                "type": [
+                    "com.linkedin.pegasus2avro.timeseries.PartitionSpec",
+                    "null"
+                ]
             },
             {
-                "Urn": "Urn",
                 "default": null,
-                "doc": "Urn of the entity being written",
-                "java": {
-                    "class": "com.linkedin.pegasus2avro.common.urn.Urn"
-                },
-                "name": "entityUrn",
+                "doc": "The optional messageId, if provided serves as a custom user-defined unique identifier for an aspect value.",
+                "name": "messageId",
                 "type": [
                     "null",
                     "string"
                 ]
             },
             {
                 "default": null,
-                "doc": "Key aspect of the entity being written",
-                "name": "entityKeyAspect",
+                "doc": "URL where the reference exist",
+                "java": {
+                    "class": "com.linkedin.pegasus2avro.common.url.Url",
+                    "coercerClass": "com.linkedin.pegasus2avro.common.url.UrlCoercer"
+                },
+                "name": "externalUrl",
                 "type": [
                     "null",
-                    "com.linkedin.pegasus2avro.mxe.GenericAspect"
+                    "string"
                 ]
             },
             {
-                "doc": "Type of change being proposed",
-                "name": "changeType",
-                "type": "com.linkedin.pegasus2avro.events.metadata.ChangeType"
+                "TimeseriesField": {},
+                "name": "status",
+                "type": {
+                    "name": "DataProcessRunStatus",
+                    "namespace": "com.linkedin.pegasus2avro.dataprocess",
+                    "symbolDocs": {
+                        "STARTED": "The status where the Data processing run is in."
+                    },
+                    "symbols": [
+                        "STARTED",
+                        "COMPLETE"
+                    ],
+                    "type": "enum"
+                }
             },
             {
                 "default": null,
-                "doc": "Aspect of the entity being written to\nNot filling this out implies that the writer wants to affect the entire entity\nNote: This is only valid for CREATE, UPSERT, and DELETE operations.",
-                "name": "aspectName",
+                "doc": "Return the try number that this Instance Run is in",
+                "name": "attempt",
                 "type": [
                     "null",
-                    "string"
+                    "int"
                 ]
             },
             {
+                "TimeseriesField": {},
                 "default": null,
-                "doc": "The value of the new aspect.",
-                "name": "aspect",
+                "doc": "The final result of the Data Processing run.",
+                "name": "result",
                 "type": [
                     "null",
-                    "com.linkedin.pegasus2avro.mxe.GenericAspect"
+                    {
+                        "fields": [
+                            {
+                                "doc": " The final result, e.g. SUCCESS, FAILURE, SKIPPED, or UP_FOR_RETRY.",
+                                "name": "type",
+                                "type": {
+                                    "name": "RunResultType",
+                                    "namespace": "com.linkedin.pegasus2avro.dataprocess",
+                                    "symbolDocs": {
+                                        "FAILURE": " The Run Failed",
+                                        "SKIPPED": " The Run Skipped",
+                                        "SUCCESS": " The Run Succeeded",
+                                        "UP_FOR_RETRY": " The Run Failed and will Retry"
+                                    },
+                                    "symbols": [
+                                        "SUCCESS",
+                                        "FAILURE",
+                                        "SKIPPED",
+                                        "UP_FOR_RETRY"
+                                    ],
+                                    "type": "enum"
+                                }
+                            },
+                            {
+                                "doc": "It identifies the system where the native result comes from like Airflow, Azkaban, etc..",
+                                "name": "nativeResultType",
+                                "type": "string"
+                            }
+                        ],
+                        "name": "DataProcessInstanceRunResult",
+                        "namespace": "com.linkedin.pegasus2avro.dataprocess",
+                        "type": "record"
+                    }
                 ]
+            }
+        ],
+        "name": "DataProcessInstanceRunEvent",
+        "namespace": "com.linkedin.pegasus2avro.dataprocess",
+        "type": "record"
+    },
+    {
+        "Aspect": {
+            "name": "dataProcessInstanceInput"
+        },
+        "doc": "Information about the inputs datasets of a Data process",
+        "fields": [
+            {
+                "Relationship": {
+                    "/*": {
+                        "entityTypes": [
+                            "dataset"
+                        ],
+                        "name": "Consumes"
+                    }
+                },
+                "Searchable": {
+                    "/*": {
+                        "addToFilters": true,
+                        "fieldName": "inputs",
+                        "fieldType": "URN",
+                        "numValuesFieldName": "numInputs",
+                        "queryByDefault": false
+                    }
+                },
+                "Urn": "Urn",
+                "doc": "Input datasets to be consumed",
+                "name": "inputs",
+                "type": {
+                    "items": "string",
+                    "type": "array"
+                },
+                "urn_is_array": true
+            }
+        ],
+        "name": "DataProcessInstanceInput",
+        "namespace": "com.linkedin.pegasus2avro.dataprocess",
+        "type": "record"
+    },
+    {
+        "Aspect": {
+            "name": "dataProcessInstanceProperties"
+        },
+        "doc": "The inputs and outputs of this data process",
+        "fields": [
+            {
+                "Searchable": {
+                    "/*": {
+                        "queryByDefault": true
+                    }
+                },
+                "default": {},
+                "doc": "Custom property bag.",
+                "name": "customProperties",
+                "type": {
+                    "type": "map",
+                    "values": "string"
+                }
             },
             {
                 "default": null,
-                "doc": "A string->string map of custom properties that one might want to attach to an event",
-                "name": "systemMetadata",
+                "doc": "URL where the reference exist",
+                "java": {
+                    "class": "com.linkedin.pegasus2avro.common.url.Url",
+                    "coercerClass": "com.linkedin.pegasus2avro.common.url.UrlCoercer"
+                },
+                "name": "externalUrl",
                 "type": [
                     "null",
-                    "com.linkedin.pegasus2avro.mxe.SystemMetadata"
+                    "string"
                 ]
             },
             {
-                "default": null,
-                "doc": "The previous value of the aspect that has changed.",
-                "name": "previousAspectValue",
-                "type": [
-                    "null",
-                    "com.linkedin.pegasus2avro.mxe.GenericAspect"
-                ]
+                "Searchable": {
+                    "boostScore": 10.0,
+                    "enableAutocomplete": true,
+                    "fieldType": "TEXT_PARTIAL"
+                },
+                "doc": "Process name",
+                "name": "name",
+                "type": "string"
             },
             {
+                "Searchable": {
+                    "addToFilters": true,
+                    "fieldType": "KEYWORD",
+                    "filterNameOverride": "Process Type"
+                },
                 "default": null,
-                "doc": "The previous value of the system metadata field that has changed.",
-                "name": "previousSystemMetadata",
+                "doc": "Process type",
+                "name": "type",
                 "type": [
                     "null",
-                    "com.linkedin.pegasus2avro.mxe.SystemMetadata"
+                    {
+                        "name": "DataProcessType",
+                        "namespace": "com.linkedin.pegasus2avro.dataprocess",
+                        "symbols": [
+                            "BATCH_SCHEDULED",
+                            "BATCH_AD_HOC",
+                            "STREAMING"
+                        ],
+                        "type": "enum"
+                    }
                 ]
             },
             {
-                "default": null,
-                "doc": "An audit stamp detailing who and when the aspect was changed by. Required for all intents and purposes.",
+                "Searchable": {
+                    "/time": {
+                        "fieldName": "created",
+                        "fieldType": "COUNT",
+                        "queryByDefault": false
+                    }
+                },
+                "doc": "Audit stamp containing who reported the lineage and when",
                 "name": "created",
-                "type": [
-                    "null",
-                    "com.linkedin.pegasus2avro.common.AuditStamp"
-                ]
+                "type": "com.linkedin.pegasus2avro.common.AuditStamp"
             }
         ],
-        "name": "MetadataChangeLog",
-        "namespace": "com.linkedin.pegasus2avro.mxe",
+        "name": "DataProcessInstanceProperties",
+        "namespace": "com.linkedin.pegasus2avro.dataprocess",
         "type": "record"
     },
     {
-        "doc": "A DataHub Platform Event.",
+        "Aspect": {
+            "name": "dataProcessInstanceOutput"
+        },
+        "doc": "Information about the outputs of a Data process",
         "fields": [
             {
-                "doc": "Header information stored with the event.",
-                "name": "header",
-                "type": {
-                    "doc": "A header included with each DataHub platform event.",
-                    "fields": [
-                        {
-                            "doc": "The event timestamp field as epoch at UTC in milli seconds.",
-                            "name": "timestampMillis",
-                            "type": "long"
-                        }
-                    ],
-                    "name": "PlatformEventHeader",
-                    "namespace": "com.linkedin.pegasus2avro.mxe",
-                    "type": "record"
-                }
-            },
-            {
-                "doc": "The name of the event, e.g. the type of event. For example, 'notificationRequestEvent', 'entityChangeEvent'",
-                "name": "name",
-                "type": "string"
-            },
-            {
-                "doc": "The event payload.",
-                "name": "payload",
+                "Relationship": {
+                    "/*": {
+                        "entityTypes": [
+                            "dataset"
+                        ],
+                        "name": "Produces"
+                    }
+                },
+                "Searchable": {
+                    "/*": {
+                        "addToFilters": true,
+                        "fieldName": "outputs",
+                        "fieldType": "URN",
+                        "numValuesFieldName": "numOutputs",
+                        "queryByDefault": false
+                    }
+                },
+                "Urn": "Urn",
+                "doc": "Output datasets to be produced",
+                "name": "outputs",
                 "type": {
-                    "doc": "Generic payload record structure for serializing a Platform Event.",
-                    "fields": [
-                        {
-                            "doc": "The value of the event, serialized as bytes.",
-                            "name": "value",
-                            "type": "bytes"
-                        },
-                        {
-                            "doc": "The content type, which represents the fashion in which the event was serialized.\nThe only type currently supported is application/json.",
-                            "name": "contentType",
-                            "type": "string"
-                        }
-                    ],
-                    "name": "GenericPayload",
-                    "namespace": "com.linkedin.pegasus2avro.mxe",
-                    "type": "record"
-                }
+                    "items": "string",
+                    "type": "array"
+                },
+                "urn_is_array": true
             }
         ],
-        "name": "PlatformEvent",
-        "namespace": "com.linkedin.pegasus2avro.mxe",
+        "name": "DataProcessInstanceOutput",
+        "namespace": "com.linkedin.pegasus2avro.dataprocess",
         "type": "record"
     },
+    "com.linkedin.pegasus2avro.dataprocess.DataProcessInfo",
     {
         "Aspect": {
-            "name": "editableContainerProperties"
+            "name": "dataProcessInstanceRelationships"
         },
-        "doc": "Editable information about an Asset Container as defined on the DataHub Platform",
+        "doc": "Information about Data process relationships",
         "fields": [
             {
+                "Relationship": {
+                    "entityTypes": [
+                        "dataJob",
+                        "dataFlow"
+                    ],
+                    "name": "InstanceOf"
+                },
                 "Searchable": {
-                    "fieldName": "editedDescription",
-                    "fieldType": "TEXT"
+                    "/*": {
+                        "fieldName": "parentTemplate",
+                        "fieldType": "URN",
+                        "queryByDefault": false
+                    }
                 },
+                "Urn": "Urn",
                 "default": null,
-                "doc": "Description of the Asset Container as its received on the DataHub Platform",
-                "name": "description",
+                "doc": "The parent entity whose run instance it is",
+                "java": {
+                    "class": "com.linkedin.pegasus2avro.common.urn.Urn"
+                },
+                "name": "parentTemplate",
                 "type": [
                     "null",
                     "string"
                 ]
-            }
-        ],
-        "name": "EditableContainerProperties",
-        "namespace": "com.linkedin.pegasus2avro.container",
-        "type": "record"
-    },
-    {
-        "Aspect": {
-            "name": "container"
-        },
-        "doc": "Link from an asset to its parent container",
-        "fields": [
+            },
             {
                 "Relationship": {
                     "entityTypes": [
-                        "container"
+                        "dataProcessInstance"
                     ],
-                    "name": "IsPartOf"
+                    "name": "ChildOf"
                 },
                 "Searchable": {
-                    "addToFilters": true,
-                    "fieldName": "container",
-                    "fieldType": "URN",
-                    "filterNameOverride": "Container",
-                    "hasValuesFieldName": "hasContainer"
+                    "/*": {
+                        "fieldName": "parentInstance",
+                        "fieldType": "URN",
+                        "queryByDefault": false
+                    }
                 },
                 "Urn": "Urn",
-                "doc": "The parent container of an asset",
+                "default": null,
+                "doc": "The parent DataProcessInstance where it belongs to.\nIf it is a Airflow Task then it should belong to an Airflow Dag run as well\nwhich will be another DataProcessInstance",
                 "java": {
                     "class": "com.linkedin.pegasus2avro.common.urn.Urn"
                 },
-                "name": "container",
-                "type": "string"
+                "name": "parentInstance",
+                "type": [
+                    "null",
+                    "string"
+                ]
+            },
+            {
+                "Relationship": {
+                    "/*": {
+                        "entityTypes": [
+                            "dataProcessInstance"
+                        ],
+                        "name": "UpstreamOf"
+                    }
+                },
+                "Searchable": {
+                    "/*": {
+                        "fieldName": "upstream",
+                        "fieldType": "URN",
+                        "numValuesFieldName": "numUpstreams",
+                        "queryByDefault": false
+                    }
+                },
+                "Urn": "Urn",
+                "doc": "Input DataProcessInstance which triggered this dataprocess instance",
+                "name": "upstreamInstances",
+                "type": {
+                    "items": "string",
+                    "type": "array"
+                },
+                "urn_is_array": true
             }
         ],
-        "name": "Container",
-        "namespace": "com.linkedin.pegasus2avro.container",
+        "name": "DataProcessInstanceRelationships",
+        "namespace": "com.linkedin.pegasus2avro.dataprocess",
         "type": "record"
     },
     {
         "Aspect": {
-            "name": "containerProperties"
+            "name": "assertionInfo"
         },
-        "doc": "Information about a Asset Container as received from a 3rd party source system",
+        "doc": "Information about an assertion",
         "fields": [
             {
                 "Searchable": {
                     "/*": {
                         "queryByDefault": true
                     }
                 },
@@ -11736,487 +10812,1409 @@
                 "name": "externalUrl",
                 "type": [
                     "null",
                     "string"
                 ]
             },
             {
-                "Searchable": {
-                    "boostScore": 10.0,
-                    "enableAutocomplete": true,
-                    "fieldType": "TEXT_PARTIAL"
-                },
-                "doc": "Display name of the Asset Container",
-                "name": "name",
-                "type": "string"
+                "doc": "Type of assertion. Assertion types can evolve to span Datasets, Flows (Pipelines), Models, Features etc.",
+                "name": "type",
+                "type": {
+                    "name": "AssertionType",
+                    "namespace": "com.linkedin.pegasus2avro.assertion",
+                    "symbols": [
+                        "DATASET"
+                    ],
+                    "type": "enum"
+                }
             },
             {
-                "Searchable": {
-                    "boostScore": 10.0,
-                    "enableAutocomplete": true,
-                    "fieldType": "TEXT_PARTIAL"
-                },
                 "default": null,
-                "doc": "Fully-qualified name of the Container",
-                "name": "qualifiedName",
+                "doc": "Dataset Assertion information when type is DATASET",
+                "name": "datasetAssertion",
                 "type": [
                     "null",
-                    "string"
+                    {
+                        "doc": "Attributes that are applicable to single-Dataset Assertions",
+                        "fields": [
+                            {
+                                "Relationship": {
+                                    "entityTypes": [
+                                        "dataset"
+                                    ],
+                                    "name": "Asserts"
+                                },
+                                "Urn": "Urn",
+                                "doc": "The dataset targeted by this assertion.",
+                                "java": {
+                                    "class": "com.linkedin.pegasus2avro.common.urn.Urn"
+                                },
+                                "name": "dataset",
+                                "type": "string"
+                            },
+                            {
+                                "doc": "Scope of the Assertion. What part of the dataset does this assertion apply to?",
+                                "name": "scope",
+                                "type": {
+                                    "name": "DatasetAssertionScope",
+                                    "namespace": "com.linkedin.pegasus2avro.assertion",
+                                    "symbolDocs": {
+                                        "DATASET_COLUMN": "This assertion applies to dataset columns",
+                                        "DATASET_ROWS": "This assertion applies to entire rows of the dataset",
+                                        "DATASET_SCHEMA": "This assertion applies to the schema of the dataset",
+                                        "UNKNOWN": "The scope of the assertion is unknown"
+                                    },
+                                    "symbols": [
+                                        "DATASET_COLUMN",
+                                        "DATASET_ROWS",
+                                        "DATASET_SCHEMA",
+                                        "UNKNOWN"
+                                    ],
+                                    "type": "enum"
+                                }
+                            },
+                            {
+                                "Relationship": {
+                                    "/*": {
+                                        "entityTypes": [
+                                            "schemaField"
+                                        ],
+                                        "name": "Asserts"
+                                    }
+                                },
+                                "Urn": "Urn",
+                                "default": null,
+                                "doc": "One or more dataset schema fields that are targeted by this assertion",
+                                "name": "fields",
+                                "type": [
+                                    "null",
+                                    {
+                                        "items": "string",
+                                        "type": "array"
+                                    }
+                                ],
+                                "urn_is_array": true
+                            },
+                            {
+                                "default": null,
+                                "doc": "Standardized assertion operator",
+                                "name": "aggregation",
+                                "type": [
+                                    "null",
+                                    {
+                                        "doc": "The function that is applied to the aggregation input (schema, rows, column values) before evaluating an operator.",
+                                        "name": "AssertionStdAggregation",
+                                        "namespace": "com.linkedin.pegasus2avro.assertion",
+                                        "symbolDocs": {
+                                            "COLUMNS": "Assertion is applied on all columns.",
+                                            "COLUMN_COUNT": "Assertion is applied on number of columns.",
+                                            "IDENTITY": "Assertion is applied on individual column value.",
+                                            "MAX": "Assertion is applied on column std deviation",
+                                            "MEAN": "Assertion is applied on column mean",
+                                            "MEDIAN": "Assertion is applied on column median",
+                                            "MIN": "Assertion is applied on column min",
+                                            "NULL_COUNT": "Assertion is applied on number of null values in column",
+                                            "NULL_PROPORTION": "Assertion is applied on proportion of null values in column",
+                                            "ROW_COUNT": "Assertion is applied on number of rows.",
+                                            "STDDEV": "Assertion is applied on column std deviation",
+                                            "SUM": "Assertion is applied on column sum",
+                                            "UNIQUE_COUNT": "Assertion is applied on number of distinct values in column",
+                                            "UNIQUE_PROPOTION": "Assertion is applied on proportion of distinct values in column",
+                                            "_NATIVE_": "Other"
+                                        },
+                                        "symbols": [
+                                            "ROW_COUNT",
+                                            "COLUMNS",
+                                            "COLUMN_COUNT",
+                                            "IDENTITY",
+                                            "MEAN",
+                                            "MEDIAN",
+                                            "UNIQUE_COUNT",
+                                            "UNIQUE_PROPOTION",
+                                            "NULL_COUNT",
+                                            "NULL_PROPORTION",
+                                            "STDDEV",
+                                            "MIN",
+                                            "MAX",
+                                            "SUM",
+                                            "_NATIVE_"
+                                        ],
+                                        "type": "enum"
+                                    }
+                                ]
+                            },
+                            {
+                                "doc": "Standardized assertion operator",
+                                "name": "operator",
+                                "type": {
+                                    "doc": "A boolean operator that is applied on the input to an assertion, after an aggregation function has been applied.",
+                                    "name": "AssertionStdOperator",
+                                    "namespace": "com.linkedin.pegasus2avro.assertion",
+                                    "symbolDocs": {
+                                        "BETWEEN": "Value being asserted is between min_value and max_value.  Requires 'minValue' & 'maxValue' parameters.",
+                                        "CONTAIN": "Value being asserted contains value. Requires 'value' parameter.",
+                                        "END_WITH": "Value being asserted ends with value. Requires 'value' parameter.",
+                                        "EQUAL_TO": "Value being asserted is equal to value. Requires 'value' parameter.",
+                                        "GREATER_THAN": "Value being asserted is greater than some value. Requires 'value' parameter.",
+                                        "GREATER_THAN_OR_EQUAL_TO": "Value being asserted is greater than or equal to some value. Requires 'value' parameter.",
+                                        "IN": "Value being asserted is one of the array values. Requires 'value' parameter.",
+                                        "LESS_THAN": "Value being asserted is less than a max value. Requires 'value' parameter.",
+                                        "LESS_THAN_OR_EQUAL_TO": "Value being asserted is less than or equal to some value. Requires 'value' parameter.",
+                                        "NOT_IN": "Value being asserted is not in one of the array values. Requires 'value' parameter.",
+                                        "NOT_NULL": "Value being asserted is not null. Requires no parameters.",
+                                        "REGEX_MATCH": "Value being asserted matches the regex value. Requires 'value' parameter.",
+                                        "START_WITH": "Value being asserted starts with value. Requires 'value' parameter.",
+                                        "_NATIVE_": "Other"
+                                    },
+                                    "symbols": [
+                                        "BETWEEN",
+                                        "LESS_THAN",
+                                        "LESS_THAN_OR_EQUAL_TO",
+                                        "GREATER_THAN",
+                                        "GREATER_THAN_OR_EQUAL_TO",
+                                        "EQUAL_TO",
+                                        "NOT_NULL",
+                                        "CONTAIN",
+                                        "END_WITH",
+                                        "START_WITH",
+                                        "REGEX_MATCH",
+                                        "IN",
+                                        "NOT_IN",
+                                        "_NATIVE_"
+                                    ],
+                                    "type": "enum"
+                                }
+                            },
+                            {
+                                "default": null,
+                                "doc": "Standard parameters required for the assertion. e.g. min_value, max_value, value, columns",
+                                "name": "parameters",
+                                "type": [
+                                    "null",
+                                    {
+                                        "doc": "Parameters for AssertionStdOperators.",
+                                        "fields": [
+                                            {
+                                                "default": null,
+                                                "doc": "The value parameter of an assertion",
+                                                "name": "value",
+                                                "type": [
+                                                    "null",
+                                                    {
+                                                        "doc": "Single parameter for AssertionStdOperators.",
+                                                        "fields": [
+                                                            {
+                                                                "doc": "The parameter value",
+                                                                "name": "value",
+                                                                "type": "string"
+                                                            },
+                                                            {
+                                                                "doc": "The type of the parameter",
+                                                                "name": "type",
+                                                                "type": {
+                                                                    "name": "AssertionStdParameterType",
+                                                                    "namespace": "com.linkedin.pegasus2avro.assertion",
+                                                                    "symbols": [
+                                                                        "STRING",
+                                                                        "NUMBER",
+                                                                        "LIST",
+                                                                        "SET",
+                                                                        "UNKNOWN"
+                                                                    ],
+                                                                    "type": "enum"
+                                                                }
+                                                            }
+                                                        ],
+                                                        "name": "AssertionStdParameter",
+                                                        "namespace": "com.linkedin.pegasus2avro.assertion",
+                                                        "type": "record"
+                                                    }
+                                                ]
+                                            },
+                                            {
+                                                "default": null,
+                                                "doc": "The maxValue parameter of an assertion",
+                                                "name": "maxValue",
+                                                "type": [
+                                                    "null",
+                                                    "com.linkedin.pegasus2avro.assertion.AssertionStdParameter"
+                                                ]
+                                            },
+                                            {
+                                                "default": null,
+                                                "doc": "The minValue parameter of an assertion",
+                                                "name": "minValue",
+                                                "type": [
+                                                    "null",
+                                                    "com.linkedin.pegasus2avro.assertion.AssertionStdParameter"
+                                                ]
+                                            }
+                                        ],
+                                        "name": "AssertionStdParameters",
+                                        "namespace": "com.linkedin.pegasus2avro.assertion",
+                                        "type": "record"
+                                    }
+                                ]
+                            },
+                            {
+                                "default": null,
+                                "doc": "Native assertion type",
+                                "name": "nativeType",
+                                "type": [
+                                    "null",
+                                    "string"
+                                ]
+                            },
+                            {
+                                "default": null,
+                                "doc": "Native parameters required for the assertion.",
+                                "name": "nativeParameters",
+                                "type": [
+                                    "null",
+                                    {
+                                        "type": "map",
+                                        "values": "string"
+                                    }
+                                ]
+                            },
+                            {
+                                "default": null,
+                                "name": "logic",
+                                "type": [
+                                    "null",
+                                    "string"
+                                ]
+                            }
+                        ],
+                        "name": "DatasetAssertionInfo",
+                        "namespace": "com.linkedin.pegasus2avro.assertion",
+                        "type": "record"
+                    }
                 ]
+            }
+        ],
+        "name": "AssertionInfo",
+        "namespace": "com.linkedin.pegasus2avro.assertion",
+        "type": "record"
+    },
+    {
+        "Aspect": {
+            "name": "assertionRunEvent",
+            "type": "timeseries"
+        },
+        "doc": "An event representing the current status of evaluating an assertion on a batch.\nAssertionRunEvent should be used for reporting the status of a run as an assertion evaluation progresses.",
+        "fields": [
+            {
+                "doc": "The event timestamp field as epoch at UTC in milli seconds.",
+                "name": "timestampMillis",
+                "type": "long"
             },
             {
-                "Searchable": {
-                    "fieldType": "TEXT",
-                    "hasValuesFieldName": "hasDescription"
+                "default": null,
+                "doc": "Granularity of the event if applicable",
+                "name": "eventGranularity",
+                "type": [
+                    "null",
+                    "com.linkedin.pegasus2avro.timeseries.TimeWindowSize"
+                ]
+            },
+            {
+                "default": {
+                    "partition": "FULL_TABLE_SNAPSHOT",
+                    "timePartition": null,
+                    "type": "FULL_TABLE"
                 },
+                "doc": "The optional partition specification.",
+                "name": "partitionSpec",
+                "type": [
+                    "com.linkedin.pegasus2avro.timeseries.PartitionSpec",
+                    "null"
+                ]
+            },
+            {
                 "default": null,
-                "doc": "Description of the Asset Container as it exists inside a source system",
-                "name": "description",
+                "doc": "The optional messageId, if provided serves as a custom user-defined unique identifier for an aspect value.",
+                "name": "messageId",
                 "type": [
                     "null",
                     "string"
                 ]
             },
             {
-                "Searchable": {
-                    "/time": {
-                        "fieldName": "createdAt",
-                        "fieldType": "DATETIME"
-                    }
+                "doc": " Native (platform-specific) identifier for this run",
+                "name": "runId",
+                "type": "string"
+            },
+            {
+                "TimeseriesField": {},
+                "Urn": "Urn",
+                "java": {
+                    "class": "com.linkedin.pegasus2avro.common.urn.Urn"
                 },
+                "name": "assertionUrn",
+                "type": "string"
+            },
+            {
+                "TimeseriesField": {},
+                "Urn": "Urn",
+                "java": {
+                    "class": "com.linkedin.pegasus2avro.common.urn.Urn"
+                },
+                "name": "asserteeUrn",
+                "type": "string"
+            },
+            {
                 "default": null,
-                "doc": "A timestamp documenting when the asset was created in the source Data Platform (not on DataHub)",
-                "name": "created",
+                "doc": "Specification of the batch which this run is evaluating",
+                "name": "batchSpec",
                 "type": [
                     "null",
-                    "com.linkedin.pegasus2avro.common.TimeStamp"
+                    {
+                        "doc": "A batch on which certain operations, e.g. data quality evaluation, is done.",
+                        "fields": [
+                            {
+                                "Searchable": {
+                                    "/*": {
+                                        "queryByDefault": true
+                                    }
+                                },
+                                "default": {},
+                                "doc": "Custom property bag.",
+                                "name": "customProperties",
+                                "type": {
+                                    "type": "map",
+                                    "values": "string"
+                                }
+                            },
+                            {
+                                "default": null,
+                                "doc": "The native identifier as specified by the system operating on the batch.",
+                                "name": "nativeBatchId",
+                                "type": [
+                                    "null",
+                                    "string"
+                                ]
+                            },
+                            {
+                                "default": null,
+                                "doc": "A query that identifies a batch of data",
+                                "name": "query",
+                                "type": [
+                                    "null",
+                                    "string"
+                                ]
+                            },
+                            {
+                                "default": null,
+                                "doc": "Any limit to the number of rows in the batch, if applied",
+                                "name": "limit",
+                                "type": [
+                                    "null",
+                                    "int"
+                                ]
+                            }
+                        ],
+                        "name": "BatchSpec",
+                        "namespace": "com.linkedin.pegasus2avro.assertion",
+                        "type": "record"
+                    }
                 ]
             },
             {
-                "Searchable": {
-                    "/time": {
-                        "fieldName": "lastModifiedAt",
-                        "fieldType": "DATETIME"
+                "TimeseriesField": {},
+                "doc": "The status of the assertion run as per this timeseries event.",
+                "name": "status",
+                "type": {
+                    "name": "AssertionRunStatus",
+                    "namespace": "com.linkedin.pegasus2avro.assertion",
+                    "symbolDocs": {
+                        "COMPLETE": "The Assertion Run has completed"
+                    },
+                    "symbols": [
+                        "COMPLETE"
+                    ],
+                    "type": "enum"
+                }
+            },
+            {
+                "default": null,
+                "doc": "Results of assertion, present if the status is COMPLETE",
+                "name": "result",
+                "type": [
+                    "null",
+                    {
+                        "doc": "The result of running an assertion",
+                        "fields": [
+                            {
+                                "TimeseriesField": {},
+                                "doc": " The final result, e.g. either SUCCESS or FAILURE.",
+                                "name": "type",
+                                "type": {
+                                    "name": "AssertionResultType",
+                                    "namespace": "com.linkedin.pegasus2avro.assertion",
+                                    "symbolDocs": {
+                                        "FAILURE": " The Assertion Failed",
+                                        "SUCCESS": " The Assertion Succeeded"
+                                    },
+                                    "symbols": [
+                                        "SUCCESS",
+                                        "FAILURE"
+                                    ],
+                                    "type": "enum"
+                                }
+                            },
+                            {
+                                "default": null,
+                                "doc": "Number of rows for evaluated batch",
+                                "name": "rowCount",
+                                "type": [
+                                    "null",
+                                    "long"
+                                ]
+                            },
+                            {
+                                "default": null,
+                                "doc": "Number of rows with missing value for evaluated batch",
+                                "name": "missingCount",
+                                "type": [
+                                    "null",
+                                    "long"
+                                ]
+                            },
+                            {
+                                "default": null,
+                                "doc": "Number of rows with unexpected value for evaluated batch",
+                                "name": "unexpectedCount",
+                                "type": [
+                                    "null",
+                                    "long"
+                                ]
+                            },
+                            {
+                                "default": null,
+                                "doc": "Observed aggregate value for evaluated batch",
+                                "name": "actualAggValue",
+                                "type": [
+                                    "null",
+                                    "float"
+                                ]
+                            },
+                            {
+                                "default": null,
+                                "doc": "Other results of evaluation",
+                                "name": "nativeResults",
+                                "type": [
+                                    "null",
+                                    {
+                                        "type": "map",
+                                        "values": "string"
+                                    }
+                                ]
+                            },
+                            {
+                                "default": null,
+                                "doc": "URL where full results are available",
+                                "name": "externalUrl",
+                                "type": [
+                                    "null",
+                                    "string"
+                                ]
+                            }
+                        ],
+                        "name": "AssertionResult",
+                        "namespace": "com.linkedin.pegasus2avro.assertion",
+                        "type": "record"
                     }
-                },
+                ]
+            },
+            {
                 "default": null,
-                "doc": "A timestamp documenting when the asset was last modified in the source Data Platform (not on DataHub)",
-                "name": "lastModified",
+                "doc": "Runtime parameters of evaluation",
+                "name": "runtimeContext",
                 "type": [
                     "null",
-                    "com.linkedin.pegasus2avro.common.TimeStamp"
+                    {
+                        "type": "map",
+                        "values": "string"
+                    }
                 ]
             }
         ],
-        "name": "ContainerProperties",
-        "namespace": "com.linkedin.pegasus2avro.container",
+        "name": "AssertionRunEvent",
+        "namespace": "com.linkedin.pegasus2avro.assertion",
         "type": "record"
     },
     {
-        "Aspect": {
-            "name": "testInfo"
+        "Event": {
+            "name": "entityChangeEvent"
         },
-        "doc": "Information about a DataHub Test",
+        "doc": "Shared fields for all entity change events.",
         "fields": [
             {
-                "Searchable": {
-                    "fieldType": "TEXT_PARTIAL"
-                },
-                "doc": "The name of the test",
-                "name": "name",
+                "doc": "The type of the entity affected. Corresponds to the entity registry, e.g. 'dataset', 'chart', 'dashboard', etc.",
+                "name": "entityType",
                 "type": "string"
             },
             {
-                "Searchable": {
-                    "fieldType": "KEYWORD"
+                "Urn": "Urn",
+                "doc": "The urn of the entity which was affected.",
+                "java": {
+                    "class": "com.linkedin.pegasus2avro.common.urn.Urn"
                 },
-                "doc": "Category of the test",
+                "name": "entityUrn",
+                "type": "string"
+            },
+            {
+                "doc": "The category type (TAG, GLOSSARY_TERM, OWNERSHIP, TECHNICAL_SCHEMA, etc). This is used to determine what the rest of the schema will look like.",
                 "name": "category",
                 "type": "string"
             },
             {
-                "Searchable": {
-                    "fieldType": "TEXT"
-                },
+                "doc": "The operation type. This is used to determine what the rest of the schema will look like.",
+                "name": "operation",
+                "type": "string"
+            },
+            {
                 "default": null,
-                "doc": "Description of the test",
-                "name": "description",
+                "doc": "The urn of the entity which was affected.",
+                "name": "modifier",
                 "type": [
                     "null",
                     "string"
                 ]
             },
             {
-                "doc": "Configuration for the Test",
-                "name": "definition",
-                "type": {
-                    "fields": [
-                        {
-                            "doc": "The Test Definition Type",
-                            "name": "type",
-                            "type": {
-                                "name": "TestDefinitionType",
-                                "namespace": "com.linkedin.pegasus2avro.test",
-                                "symbolDocs": {
-                                    "JSON": "JSON / YAML test def"
-                                },
-                                "symbols": [
-                                    "JSON"
-                                ],
-                                "type": "enum"
-                            }
-                        },
-                        {
-                            "default": null,
-                            "doc": "JSON format configuration for the test",
-                            "name": "json",
-                            "type": [
-                                "null",
-                                "string"
-                            ]
-                        }
-                    ],
-                    "name": "TestDefinition",
-                    "namespace": "com.linkedin.pegasus2avro.test",
-                    "type": "record"
-                }
+                "default": null,
+                "doc": "Arbitrary key-value parameters corresponding to the event.",
+                "name": "parameters",
+                "type": [
+                    "null",
+                    {
+                        "doc": "Arbitrary key-value parameters for an Entity Change Event. (any record).",
+                        "fields": [],
+                        "name": "Parameters",
+                        "namespace": "com.linkedin.pegasus2avro.platform.event.v1",
+                        "type": "record"
+                    }
+                ]
+            },
+            {
+                "doc": "Audit stamp of the operation",
+                "name": "auditStamp",
+                "type": "com.linkedin.pegasus2avro.common.AuditStamp"
+            },
+            {
+                "doc": "The version of the event type, incremented in integers.",
+                "name": "version",
+                "type": "int"
             }
         ],
-        "name": "TestInfo",
-        "namespace": "com.linkedin.pegasus2avro.test",
+        "name": "EntityChangeEvent",
+        "namespace": "com.linkedin.pegasus2avro.platform.event.v1",
         "type": "record"
     },
     {
         "Aspect": {
-            "name": "testResults"
+            "name": "notebookContent"
         },
-        "doc": "Information about a Test Result",
+        "doc": "Content in a Notebook\nNote: This is IN BETA version",
         "fields": [
             {
-                "Relationship": {
-                    "/*/test": {
-                        "entityTypes": [
-                            "test"
-                        ],
-                        "name": "IsFailing"
-                    }
-                },
-                "Searchable": {
-                    "/*/test": {
-                        "fieldName": "failingTests",
-                        "fieldType": "URN",
-                        "hasValuesFieldName": "hasFailingTests"
-                    }
-                },
-                "doc": "Results that are failing",
-                "name": "failing",
+                "default": [],
+                "doc": "The content of a Notebook which is composed by a list of NotebookCell",
+                "name": "cells",
                 "type": {
                     "items": {
-                        "doc": "Information about a Test Result",
+                        "doc": "A record of all supported cells for a Notebook. Only one type of cell will be non-null.",
                         "fields": [
                             {
-                                "Urn": "Urn",
-                                "doc": "The urn of the test",
-                                "java": {
-                                    "class": "com.linkedin.pegasus2avro.common.urn.Urn"
-                                },
-                                "name": "test",
-                                "type": "string"
+                                "default": null,
+                                "doc": "The text cell content. The will be non-null only when all other cell field is null.",
+                                "name": "textCell",
+                                "type": [
+                                    "null",
+                                    {
+                                        "doc": "Text cell in a Notebook, which will present content in text format",
+                                        "fields": [
+                                            {
+                                                "default": null,
+                                                "doc": "Title of the cell",
+                                                "name": "cellTitle",
+                                                "type": [
+                                                    "null",
+                                                    "string"
+                                                ]
+                                            },
+                                            {
+                                                "doc": "Unique id for the cell. This id should be globally unique for a Notebook tool even when there are multiple deployments of it. As an example, Notebook URL could be used here for QueryBook such as 'querybook.com/notebook/773/?cellId=1234'",
+                                                "name": "cellId",
+                                                "type": "string"
+                                            },
+                                            {
+                                                "doc": "Captures information about who created/last modified/deleted this Notebook cell and when",
+                                                "name": "changeAuditStamps",
+                                                "type": "com.linkedin.pegasus2avro.common.ChangeAuditStamps"
+                                            },
+                                            {
+                                                "doc": "The actual text in a TextCell in a Notebook",
+                                                "name": "text",
+                                                "type": "string"
+                                            }
+                                        ],
+                                        "name": "TextCell",
+                                        "namespace": "com.linkedin.pegasus2avro.notebook",
+                                        "type": "record"
+                                    }
+                                ]
                             },
                             {
-                                "doc": "The type of the result",
+                                "default": null,
+                                "doc": "The query cell content. The will be non-null only when all other cell field is null.",
+                                "name": "queryCell",
+                                "type": [
+                                    "null",
+                                    {
+                                        "doc": "Query cell in a Notebook, which will present content in query format",
+                                        "fields": [
+                                            {
+                                                "default": null,
+                                                "doc": "Title of the cell",
+                                                "name": "cellTitle",
+                                                "type": [
+                                                    "null",
+                                                    "string"
+                                                ]
+                                            },
+                                            {
+                                                "doc": "Unique id for the cell. This id should be globally unique for a Notebook tool even when there are multiple deployments of it. As an example, Notebook URL could be used here for QueryBook such as 'querybook.com/notebook/773/?cellId=1234'",
+                                                "name": "cellId",
+                                                "type": "string"
+                                            },
+                                            {
+                                                "doc": "Captures information about who created/last modified/deleted this Notebook cell and when",
+                                                "name": "changeAuditStamps",
+                                                "type": "com.linkedin.pegasus2avro.common.ChangeAuditStamps"
+                                            },
+                                            {
+                                                "doc": "Raw query to explain some specific logic in a Notebook",
+                                                "name": "rawQuery",
+                                                "type": "string"
+                                            },
+                                            {
+                                                "default": null,
+                                                "doc": "Captures information about who last executed this query cell and when",
+                                                "name": "lastExecuted",
+                                                "type": [
+                                                    "null",
+                                                    "com.linkedin.pegasus2avro.common.AuditStamp"
+                                                ]
+                                            }
+                                        ],
+                                        "name": "QueryCell",
+                                        "namespace": "com.linkedin.pegasus2avro.notebook",
+                                        "type": "record"
+                                    }
+                                ]
+                            },
+                            {
+                                "default": null,
+                                "doc": "The chart cell content. The will be non-null only when all other cell field is null.",
+                                "name": "chartCell",
+                                "type": [
+                                    "null",
+                                    {
+                                        "doc": "Chart cell in a notebook, which will present content in chart format",
+                                        "fields": [
+                                            {
+                                                "default": null,
+                                                "doc": "Title of the cell",
+                                                "name": "cellTitle",
+                                                "type": [
+                                                    "null",
+                                                    "string"
+                                                ]
+                                            },
+                                            {
+                                                "doc": "Unique id for the cell. This id should be globally unique for a Notebook tool even when there are multiple deployments of it. As an example, Notebook URL could be used here for QueryBook such as 'querybook.com/notebook/773/?cellId=1234'",
+                                                "name": "cellId",
+                                                "type": "string"
+                                            },
+                                            {
+                                                "doc": "Captures information about who created/last modified/deleted this Notebook cell and when",
+                                                "name": "changeAuditStamps",
+                                                "type": "com.linkedin.pegasus2avro.common.ChangeAuditStamps"
+                                            }
+                                        ],
+                                        "name": "ChartCell",
+                                        "namespace": "com.linkedin.pegasus2avro.notebook",
+                                        "type": "record"
+                                    }
+                                ]
+                            },
+                            {
+                                "doc": "The type of this Notebook cell",
                                 "name": "type",
                                 "type": {
-                                    "name": "TestResultType",
-                                    "namespace": "com.linkedin.pegasus2avro.test",
+                                    "doc": "Type of Notebook Cell",
+                                    "name": "NotebookCellType",
+                                    "namespace": "com.linkedin.pegasus2avro.notebook",
                                     "symbolDocs": {
-                                        "FAILURE": " The Test Failed",
-                                        "SUCCESS": " The Test Succeeded"
+                                        "CHART_CELL": "CHART Notebook cell type. The cell content is chart only.",
+                                        "QUERY_CELL": "QUERY Notebook cell type. The cell context is query only.",
+                                        "TEXT_CELL": "TEXT Notebook cell type. The cell context is text only."
                                     },
                                     "symbols": [
-                                        "SUCCESS",
-                                        "FAILURE"
+                                        "TEXT_CELL",
+                                        "QUERY_CELL",
+                                        "CHART_CELL"
                                     ],
                                     "type": "enum"
                                 }
                             }
                         ],
-                        "name": "TestResult",
-                        "namespace": "com.linkedin.pegasus2avro.test",
+                        "name": "NotebookCell",
+                        "namespace": "com.linkedin.pegasus2avro.notebook",
                         "type": "record"
                     },
                     "type": "array"
                 }
-            },
+            }
+        ],
+        "name": "NotebookContent",
+        "namespace": "com.linkedin.pegasus2avro.notebook",
+        "type": "record"
+    },
+    {
+        "Aspect": {
+            "name": "notebookInfo"
+        },
+        "doc": "Information about a Notebook\nNote: This is IN BETA version",
+        "fields": [
             {
-                "Relationship": {
-                    "/*/test": {
-                        "entityTypes": [
-                            "test"
-                        ],
-                        "name": "IsPassing"
-                    }
-                },
                 "Searchable": {
-                    "/*/test": {
-                        "fieldName": "passingTests",
-                        "fieldType": "URN",
-                        "hasValuesFieldName": "hasPassingTests"
+                    "/*": {
+                        "queryByDefault": true
                     }
                 },
-                "doc": "Results that are passing",
-                "name": "passing",
+                "default": {},
+                "doc": "Custom property bag.",
+                "name": "customProperties",
                 "type": {
-                    "items": "com.linkedin.pegasus2avro.test.TestResult",
-                    "type": "array"
+                    "type": "map",
+                    "values": "string"
                 }
+            },
+            {
+                "default": null,
+                "doc": "URL where the reference exist",
+                "java": {
+                    "class": "com.linkedin.pegasus2avro.common.url.Url",
+                    "coercerClass": "com.linkedin.pegasus2avro.common.url.UrlCoercer"
+                },
+                "name": "externalUrl",
+                "type": [
+                    "null",
+                    "string"
+                ]
+            },
+            {
+                "Searchable": {
+                    "boostScore": 10.0,
+                    "enableAutocomplete": true,
+                    "fieldType": "TEXT_PARTIAL"
+                },
+                "doc": "Title of the Notebook",
+                "name": "title",
+                "type": "string"
+            },
+            {
+                "Searchable": {
+                    "fieldType": "TEXT",
+                    "hasValuesFieldName": "hasDescription"
+                },
+                "default": null,
+                "doc": "Detailed description about the Notebook",
+                "name": "description",
+                "type": [
+                    "null",
+                    "string"
+                ]
+            },
+            {
+                "doc": "Captures information about who created/last modified/deleted this Notebook and when",
+                "name": "changeAuditStamps",
+                "type": "com.linkedin.pegasus2avro.common.ChangeAuditStamps"
             }
         ],
-        "name": "TestResults",
-        "namespace": "com.linkedin.pegasus2avro.test",
+        "name": "NotebookInfo",
+        "namespace": "com.linkedin.pegasus2avro.notebook",
         "type": "record"
     },
     {
         "Aspect": {
-            "name": "querySubjects"
+            "name": "editableNotebookProperties"
         },
-        "doc": "Information about the subjects of a particular Query, i.e. the assets\nbeing queried.",
+        "doc": "Stores editable changes made to properties. This separates changes made from\ningestion pipelines and edits in the UI to avoid accidental overwrites of user-provided data by ingestion pipelines\nNote: This is IN BETA version",
         "fields": [
             {
-                "doc": "One or more subjects of the query.\n\nIn single-asset queries (e.g. table select), this will contain the Table reference\nand optionally schema field references.\n\nIn multi-asset queries (e.g. table joins), this may contain multiple Table references\nand optionally schema field references.",
-                "name": "subjects",
+                "default": {
+                    "actor": "urn:li:corpuser:unknown",
+                    "impersonator": null,
+                    "message": null,
+                    "time": 0
+                },
+                "doc": "An AuditStamp corresponding to the creation of this resource/association/sub-resource. A value of 0 for time indicates missing data.",
+                "name": "created",
+                "type": "com.linkedin.pegasus2avro.common.AuditStamp"
+            },
+            {
+                "default": {
+                    "actor": "urn:li:corpuser:unknown",
+                    "impersonator": null,
+                    "message": null,
+                    "time": 0
+                },
+                "doc": "An AuditStamp corresponding to the last modification of this resource/association/sub-resource. If no modification has happened since creation, lastModified should be the same as created. A value of 0 for time indicates missing data.",
+                "name": "lastModified",
+                "type": "com.linkedin.pegasus2avro.common.AuditStamp"
+            },
+            {
+                "default": null,
+                "doc": "An AuditStamp corresponding to the deletion of this resource/association/sub-resource. Logically, deleted MUST have a later timestamp than creation. It may or may not have the same time as lastModified depending upon the resource/association/sub-resource semantics.",
+                "name": "deleted",
+                "type": [
+                    "null",
+                    "com.linkedin.pegasus2avro.common.AuditStamp"
+                ]
+            },
+            {
+                "Searchable": {
+                    "fieldName": "editedDescription",
+                    "fieldType": "TEXT"
+                },
+                "default": null,
+                "doc": "Edited documentation of the Notebook",
+                "name": "description",
+                "type": [
+                    "null",
+                    "string"
+                ]
+            }
+        ],
+        "name": "EditableNotebookProperties",
+        "namespace": "com.linkedin.pegasus2avro.notebook",
+        "type": "record"
+    },
+    {
+        "doc": "Usage data for a given resource, rolled up into a bucket.",
+        "fields": [
+            {
+                "doc": " Bucket start time in milliseconds ",
+                "name": "bucket",
+                "type": "long"
+            },
+            {
+                "doc": " Bucket duration ",
+                "name": "duration",
                 "type": {
-                    "items": {
-                        "doc": "A single subject of a particular query.\nIn the future, we may evolve this model to include richer details\nabout the Query Subject in relation to the query.",
-                        "fields": [
-                            {
-                                "Relationship": {
-                                    "entityTypes": [
-                                        "dataset",
-                                        "schemaField"
-                                    ],
-                                    "name": "IsAssociatedWith"
-                                },
-                                "Searchable": {
-                                    "fieldName": "entities",
-                                    "fieldType": "URN"
-                                },
-                                "Urn": "Urn",
-                                "doc": "An entity which is the subject of a query.",
-                                "java": {
-                                    "class": "com.linkedin.pegasus2avro.common.urn.Urn"
-                                },
-                                "name": "entity",
-                                "type": "string"
-                            }
-                        ],
-                        "name": "QuerySubject",
-                        "namespace": "com.linkedin.pegasus2avro.query",
-                        "type": "record"
-                    },
-                    "type": "array"
+                    "doc": "Enum to define the length of a bucket when doing aggregations",
+                    "name": "WindowDuration",
+                    "namespace": "com.linkedin.pegasus2avro.common",
+                    "symbols": [
+                        "YEAR",
+                        "MONTH",
+                        "WEEK",
+                        "DAY",
+                        "HOUR"
+                    ],
+                    "type": "enum"
+                }
+            },
+            {
+                "Urn": "Urn",
+                "doc": " Resource associated with these usage stats ",
+                "java": {
+                    "class": "com.linkedin.pegasus2avro.common.urn.Urn"
+                },
+                "name": "resource",
+                "type": "string"
+            },
+            {
+                "doc": " Metrics associated with this bucket ",
+                "name": "metrics",
+                "type": {
+                    "doc": "Metrics for usage data for a given resource and bucket. Not all fields\nmake sense for all buckets, so every field is optional.",
+                    "fields": [
+                        {
+                            "default": null,
+                            "doc": " Unique user count ",
+                            "name": "uniqueUserCount",
+                            "type": [
+                                "null",
+                                "int"
+                            ]
+                        },
+                        {
+                            "default": null,
+                            "doc": " Users within this bucket, with frequency counts ",
+                            "name": "users",
+                            "type": [
+                                "null",
+                                {
+                                    "items": {
+                                        "doc": " Records a single user's usage counts for a given resource ",
+                                        "fields": [
+                                            {
+                                                "Urn": "Urn",
+                                                "default": null,
+                                                "java": {
+                                                    "class": "com.linkedin.pegasus2avro.common.urn.Urn"
+                                                },
+                                                "name": "user",
+                                                "type": [
+                                                    "null",
+                                                    "string"
+                                                ]
+                                            },
+                                            {
+                                                "name": "count",
+                                                "type": "int"
+                                            },
+                                            {
+                                                "default": null,
+                                                "doc": " If user_email is set, we attempt to resolve the user's urn upon ingest ",
+                                                "name": "userEmail",
+                                                "type": [
+                                                    "null",
+                                                    "string"
+                                                ]
+                                            }
+                                        ],
+                                        "name": "UserUsageCounts",
+                                        "namespace": "com.linkedin.pegasus2avro.usage",
+                                        "type": "record"
+                                    },
+                                    "type": "array"
+                                }
+                            ]
+                        },
+                        {
+                            "default": null,
+                            "doc": " Total SQL query count ",
+                            "name": "totalSqlQueries",
+                            "type": [
+                                "null",
+                                "int"
+                            ]
+                        },
+                        {
+                            "default": null,
+                            "doc": " Frequent SQL queries; mostly makes sense for datasets in SQL databases ",
+                            "name": "topSqlQueries",
+                            "type": [
+                                "null",
+                                {
+                                    "items": "string",
+                                    "type": "array"
+                                }
+                            ]
+                        },
+                        {
+                            "default": null,
+                            "doc": " Field-level usage stats ",
+                            "name": "fields",
+                            "type": [
+                                "null",
+                                {
+                                    "items": {
+                                        "doc": " Records field-level usage counts for a given resource ",
+                                        "fields": [
+                                            {
+                                                "name": "fieldName",
+                                                "type": "string"
+                                            },
+                                            {
+                                                "name": "count",
+                                                "type": "int"
+                                            }
+                                        ],
+                                        "name": "FieldUsageCounts",
+                                        "namespace": "com.linkedin.pegasus2avro.usage",
+                                        "type": "record"
+                                    },
+                                    "type": "array"
+                                }
+                            ]
+                        }
+                    ],
+                    "name": "UsageAggregationMetrics",
+                    "namespace": "com.linkedin.pegasus2avro.usage",
+                    "type": "record"
                 }
             }
         ],
-        "name": "QuerySubjects",
-        "namespace": "com.linkedin.pegasus2avro.query",
+        "name": "UsageAggregation",
+        "namespace": "com.linkedin.pegasus2avro.usage",
         "type": "record"
     },
     {
         "Aspect": {
-            "name": "queryProperties"
+            "name": "postInfo"
         },
-        "doc": "Information about a Query against one or more data assets (e.g. Tables or Views).",
+        "doc": "Information about a DataHub Post.",
         "fields": [
             {
-                "doc": "The Query Statement.",
-                "name": "statement",
+                "doc": "Type of the Post.",
+                "name": "type",
                 "type": {
-                    "doc": "A query statement against one or more data assets.",
+                    "doc": "Enum defining types of Posts.",
+                    "name": "PostType",
+                    "namespace": "com.linkedin.pegasus2avro.post",
+                    "symbolDocs": {
+                        "HOME_PAGE_ANNOUNCEMENT": "The Post is an Home Page announcement."
+                    },
+                    "symbols": [
+                        "HOME_PAGE_ANNOUNCEMENT"
+                    ],
+                    "type": "enum"
+                }
+            },
+            {
+                "doc": "Content stored in the post.",
+                "name": "content",
+                "type": {
+                    "doc": "Content stored inside a Post.",
                     "fields": [
                         {
-                            "doc": "The query text",
-                            "name": "value",
+                            "Searchable": {
+                                "fieldType": "TEXT_PARTIAL"
+                            },
+                            "doc": "Title of the post.",
+                            "name": "title",
                             "type": "string"
                         },
                         {
-                            "default": "SQL",
-                            "doc": "The language of the Query, e.g. SQL.",
-                            "name": "language",
+                            "doc": "Type of content held in the post.",
+                            "name": "type",
                             "type": {
-                                "name": "QueryLanguage",
-                                "namespace": "com.linkedin.pegasus2avro.query",
+                                "doc": "Enum defining the type of content held in a Post.",
+                                "name": "PostContentType",
+                                "namespace": "com.linkedin.pegasus2avro.post",
                                 "symbolDocs": {
-                                    "SQL": "A SQL Query"
+                                    "LINK": "Link content",
+                                    "TEXT": "Text content"
                                 },
                                 "symbols": [
-                                    "SQL"
+                                    "TEXT",
+                                    "LINK"
                                 ],
                                 "type": "enum"
                             }
+                        },
+                        {
+                            "default": null,
+                            "doc": "Optional description of the post.",
+                            "name": "description",
+                            "type": [
+                                "null",
+                                "string"
+                            ]
+                        },
+                        {
+                            "default": null,
+                            "doc": "Optional link that the post is associated with.",
+                            "java": {
+                                "class": "com.linkedin.pegasus2avro.common.url.Url",
+                                "coercerClass": "com.linkedin.pegasus2avro.common.url.UrlCoercer"
+                            },
+                            "name": "link",
+                            "type": [
+                                "null",
+                                "string"
+                            ]
+                        },
+                        {
+                            "default": null,
+                            "doc": "Optional media that the post is storing",
+                            "name": "media",
+                            "type": [
+                                "null",
+                                {
+                                    "doc": "Carries information about which roles a user is assigned to.",
+                                    "fields": [
+                                        {
+                                            "doc": "Type of content the Media is storing, e.g. image, video, etc.",
+                                            "name": "type",
+                                            "type": {
+                                                "doc": "Enum defining the type of content a Media object holds.",
+                                                "name": "MediaType",
+                                                "namespace": "com.linkedin.pegasus2avro.common",
+                                                "symbolDocs": {
+                                                    "IMAGE": "The Media holds an image."
+                                                },
+                                                "symbols": [
+                                                    "IMAGE"
+                                                ],
+                                                "type": "enum"
+                                            }
+                                        },
+                                        {
+                                            "doc": "Where the media content is stored.",
+                                            "java": {
+                                                "class": "com.linkedin.pegasus2avro.common.url.Url",
+                                                "coercerClass": "com.linkedin.pegasus2avro.common.url.UrlCoercer"
+                                            },
+                                            "name": "location",
+                                            "type": "string"
+                                        }
+                                    ],
+                                    "name": "Media",
+                                    "namespace": "com.linkedin.pegasus2avro.common",
+                                    "type": "record"
+                                }
+                            ]
                         }
                     ],
-                    "name": "QueryStatement",
-                    "namespace": "com.linkedin.pegasus2avro.query",
+                    "name": "PostContent",
+                    "namespace": "com.linkedin.pegasus2avro.post",
                     "type": "record"
                 }
             },
             {
-                "Searchable": {},
-                "doc": "The source of the Query",
-                "name": "source",
-                "type": {
-                    "name": "QuerySource",
-                    "namespace": "com.linkedin.pegasus2avro.query",
-                    "symbolDocs": {
-                        "MANUAL": "The query was entered manually by a user (via the UI)."
-                    },
-                    "symbols": [
-                        "MANUAL"
-                    ],
-                    "type": "enum"
-                }
-            },
-            {
-                "Searchable": {
-                    "boostScore": 10.0,
-                    "enableAutocomplete": true,
-                    "fieldType": "TEXT_PARTIAL"
-                },
-                "default": null,
-                "doc": "Optional display name to identify the query.",
-                "name": "name",
-                "type": [
-                    "null",
-                    "string"
-                ]
-            },
-            {
-                "default": null,
-                "doc": "The Query description.",
-                "name": "description",
-                "type": [
-                    "null",
-                    "string"
-                ]
-            },
-            {
                 "Searchable": {
-                    "/actor": {
-                        "fieldName": "createdBy",
-                        "fieldType": "URN"
-                    },
-                    "/time": {
-                        "fieldName": "createdAt",
-                        "fieldType": "DATETIME"
-                    }
+                    "fieldType": "COUNT"
                 },
-                "doc": "Audit stamp capturing the time and actor who created the Query.",
+                "doc": "The time at which the post was initially created",
                 "name": "created",
-                "type": "com.linkedin.pegasus2avro.common.AuditStamp"
+                "type": "long"
             },
             {
                 "Searchable": {
-                    "/actor": {
-                        "fieldName": "lastModifiedBy",
-                        "fieldType": "URN"
-                    },
-                    "/time": {
-                        "fieldName": "lastModifiedAt",
-                        "fieldType": "DATETIME"
-                    }
+                    "fieldType": "COUNT"
                 },
-                "doc": "Audit stamp capturing the time and actor who last modified the Query.",
+                "doc": "The time at which the post was last modified",
                 "name": "lastModified",
-                "type": "com.linkedin.pegasus2avro.common.AuditStamp"
+                "type": "long"
             }
         ],
-        "name": "QueryProperties",
-        "namespace": "com.linkedin.pegasus2avro.query",
+        "name": "PostInfo",
+        "namespace": "com.linkedin.pegasus2avro.post",
         "type": "record"
     },
-    "com.linkedin.pegasus2avro.policy.DataHubPolicyInfo",
     {
         "Aspect": {
-            "name": "dataHubRoleInfo"
+            "name": "dataHubUpgradeResult"
         },
-        "doc": "Information about a DataHub Role.",
+        "doc": "Information collected when a DataHubUpgrade successfully finishes",
         "fields": [
             {
-                "Searchable": {
-                    "fieldType": "TEXT_PARTIAL"
-                },
-                "doc": "Name of the Role",
-                "name": "name",
-                "type": "string"
-            },
-            {
-                "Searchable": {
-                    "fieldType": "TEXT"
-                },
-                "doc": "Description of the Role",
-                "name": "description",
-                "type": "string"
+                "doc": "Timestamp when we started this DataHubUpgrade",
+                "name": "timestampMs",
+                "type": "long"
             },
             {
-                "default": false,
-                "doc": "Whether the role should be editable via the UI",
-                "name": "editable",
-                "type": "boolean"
+                "default": null,
+                "doc": "Result map to place helpful information about this upgrade job",
+                "name": "result",
+                "type": [
+                    "null",
+                    {
+                        "type": "map",
+                        "values": "string"
+                    }
+                ]
             }
         ],
-        "name": "DataHubRoleInfo",
-        "namespace": "com.linkedin.pegasus2avro.policy",
+        "name": "DataHubUpgradeResult",
+        "namespace": "com.linkedin.pegasus2avro.upgrade",
         "type": "record"
     },
-    "com.linkedin.pegasus2avro.metadata.key.DashboardKey",
     {
         "Aspect": {
-            "entityAspects": [
-                "globalSettingsInfo"
-            ],
-            "entityCategory": "internal",
-            "entityDoc": "Global settings for an the platform",
-            "keyForEntity": "globalSettings",
-            "name": "globalSettingsKey"
+            "name": "dataHubUpgradeRequest"
         },
-        "doc": "Key for a Global Settings",
+        "doc": "Information collected when kicking off a DataHubUpgrade",
         "fields": [
             {
-                "doc": "Id for the settings. There should be only 1 global settings urn: urn:li:globalSettings:0",
-                "name": "id",
+                "doc": "Timestamp when we started this DataHubUpgrade",
+                "name": "timestampMs",
+                "type": "long"
+            },
+            {
+                "doc": "Version of this upgrade",
+                "name": "version",
                 "type": "string"
             }
         ],
-        "name": "GlobalSettingsKey",
-        "namespace": "com.linkedin.pegasus2avro.metadata.key",
+        "name": "DataHubUpgradeRequest",
+        "namespace": "com.linkedin.pegasus2avro.upgrade",
         "type": "record"
     },
     {
+        "doc": "The filter for finding a record or a collection of records",
+        "fields": [
+            {
+                "default": null,
+                "doc": "A list of disjunctive criterion for the filter. (or operation to combine filters)",
+                "name": "or",
+                "type": [
+                    "null",
+                    {
+                        "items": {
+                            "doc": "A list of criterion and'd together.",
+                            "fields": [
+                                {
+                                    "doc": "A list of and criteria the filter applies to the query",
+                                    "name": "and",
+                                    "type": {
+                                        "items": {
+                                            "doc": "A criterion for matching a field with given value",
+                                            "fields": [
+                                                {
+                                                    "doc": "The name of the field that the criterion refers to",
+                                                    "name": "field",
+                                                    "type": "string"
+                                                },
+                                                {
+                                                    "doc": "The value of the intended field",
+                                                    "name": "value",
+                                                    "type": "string"
+                                                },
+                                                {
+                                                    "default": [],
+                                                    "doc": "Values. one of which the intended field should match\nNote, if values is set, the above \"value\" field will be ignored",
+                                                    "name": "values",
+                                                    "type": {
+                                                        "items": "string",
+                                                        "type": "array"
+                                                    }
+                                                },
+                                                {
+                                                    "default": "EQUAL",
+                                                    "doc": "The condition for the criterion, e.g. EQUAL, START_WITH",
+                                                    "name": "condition",
+                                                    "type": {
+                                                        "doc": "The matching condition in a filter criterion",
+                                                        "name": "Condition",
+                                                        "namespace": "com.linkedin.pegasus2avro.metadata.query.filter",
+                                                        "symbolDocs": {
+                                                            "CONTAIN": "Represent the relation: String field contains value, e.g. name contains Profile",
+                                                            "END_WITH": "Represent the relation: String field ends with value, e.g. name ends with Event",
+                                                            "EQUAL": "Represent the relation: field = value, e.g. platform = hdfs",
+                                                            "GREATER_THAN": "Represent the relation greater than, e.g. ownerCount > 5",
+                                                            "GREATER_THAN_OR_EQUAL_TO": "Represent the relation greater than or equal to, e.g. ownerCount >= 5",
+                                                            "IN": "Represent the relation: String field is one of the array values to, e.g. name in [\"Profile\", \"Event\"]",
+                                                            "IS_NULL": "Represent the relation: field is null, e.g. platform is null",
+                                                            "LESS_THAN": "Represent the relation less than, e.g. ownerCount < 3",
+                                                            "LESS_THAN_OR_EQUAL_TO": "Represent the relation less than or equal to, e.g. ownerCount <= 3",
+                                                            "START_WITH": "Represent the relation: String field starts with value, e.g. name starts with PageView"
+                                                        },
+                                                        "symbols": [
+                                                            "CONTAIN",
+                                                            "END_WITH",
+                                                            "EQUAL",
+                                                            "IS_NULL",
+                                                            "GREATER_THAN",
+                                                            "GREATER_THAN_OR_EQUAL_TO",
+                                                            "IN",
+                                                            "LESS_THAN",
+                                                            "LESS_THAN_OR_EQUAL_TO",
+                                                            "START_WITH"
+                                                        ],
+                                                        "type": "enum"
+                                                    }
+                                                },
+                                                {
+                                                    "default": false,
+                                                    "doc": "Whether the condition should be negated",
+                                                    "name": "negated",
+                                                    "type": "boolean"
+                                                }
+                                            ],
+                                            "name": "Criterion",
+                                            "namespace": "com.linkedin.pegasus2avro.metadata.query.filter",
+                                            "type": "record"
+                                        },
+                                        "type": "array"
+                                    }
+                                }
+                            ],
+                            "name": "ConjunctiveCriterion",
+                            "namespace": "com.linkedin.pegasus2avro.metadata.query.filter",
+                            "type": "record"
+                        },
+                        "type": "array"
+                    }
+                ]
+            },
+            {
+                "default": null,
+                "doc": "Deprecated! A list of conjunctive criterion for the filter. If \"or\" field is provided, then this field is ignored.",
+                "name": "criteria",
+                "type": [
+                    "null",
+                    {
+                        "items": "com.linkedin.pegasus2avro.metadata.query.filter.Criterion",
+                        "type": "array"
+                    }
+                ]
+            }
+        ],
+        "name": "Filter",
+        "namespace": "com.linkedin.pegasus2avro.metadata.query.filter",
+        "type": "record"
+    },
+    "com.linkedin.pegasus2avro.metadata.key.MLFeatureTableKey",
+    {
         "Aspect": {
             "entityAspects": [
-                "dataHubSecretValue"
+                "containerProperties",
+                "editableContainerProperties",
+                "dataPlatformInstance",
+                "subTypes",
+                "ownership",
+                "container",
+                "globalTags",
+                "glossaryTerms",
+                "institutionalMemory",
+                "browsePaths",
+                "status",
+                "domains"
             ],
-            "entityCategory": "internal",
-            "keyForEntity": "dataHubSecret",
-            "name": "dataHubSecretKey"
+            "entityCategory": "_unset_",
+            "entityDoc": "A container of related data assets.",
+            "keyForEntity": "container",
+            "name": "containerKey"
         },
-        "doc": "Key for a DataHub Secret",
+        "doc": "Key for an Asset Container",
         "fields": [
             {
-                "doc": "A unique id for the Secret",
-                "name": "id",
-                "type": "string"
+                "default": null,
+                "doc": "Unique guid for container",
+                "name": "guid",
+                "type": [
+                    "null",
+                    "string"
+                ]
             }
         ],
-        "name": "DataHubSecretKey",
+        "name": "ContainerKey",
         "namespace": "com.linkedin.pegasus2avro.metadata.key",
         "type": "record"
     },
-    "com.linkedin.pegasus2avro.metadata.key.MLFeatureTableKey",
+    "com.linkedin.pegasus2avro.metadata.key.DataHubRetentionKey",
+    "com.linkedin.pegasus2avro.metadata.key.DataJobKey",
+    "com.linkedin.pegasus2avro.metadata.key.MLModelDeploymentKey",
+    "com.linkedin.pegasus2avro.metadata.key.SchemaFieldKey",
+    "com.linkedin.pegasus2avro.metadata.key.DataProcessKey",
+    "com.linkedin.pegasus2avro.metadata.key.CorpGroupKey",
+    "com.linkedin.pegasus2avro.metadata.key.MLPrimaryKeyKey",
+    "com.linkedin.pegasus2avro.metadata.key.DataFlowKey",
+    "com.linkedin.pegasus2avro.metadata.key.DashboardKey",
+    "com.linkedin.pegasus2avro.metadata.key.MLModelGroupKey",
     {
         "Aspect": {
             "entityAspects": [
                 "telemetryClientId"
             ],
             "entityCategory": "internal",
             "keyForEntity": "telemetry",
@@ -12230,312 +12228,338 @@
                 "type": "string"
             }
         ],
         "name": "TelemetryKey",
         "namespace": "com.linkedin.pegasus2avro.metadata.key",
         "type": "record"
     },
+    "com.linkedin.pegasus2avro.metadata.key.GlossaryTermKey",
+    "com.linkedin.pegasus2avro.metadata.key.GlossaryNodeKey",
     {
         "Aspect": {
             "entityAspects": [
-                "dataHubAccessTokenInfo"
+                "dataProcessInstanceInput",
+                "dataProcessInstanceOutput",
+                "dataProcessInstanceProperties",
+                "dataProcessInstanceRelationships",
+                "dataProcessInstanceRunEvent"
             ],
-            "entityCategory": "internal",
-            "keyForEntity": "dataHubAccessToken",
-            "name": "dataHubAccessTokenKey"
+            "entityCategory": "_unset_",
+            "entityDoc": "DataProcessInstance represents an instance of a datajob/jobflow run",
+            "keyForEntity": "dataProcessInstance",
+            "name": "dataProcessInstanceKey"
         },
-        "doc": "Key for a DataHub Access Token",
+        "doc": "Key for an Asset DataProcessInstance",
         "fields": [
             {
-                "doc": "Access token's SHA-256 hashed JWT signature",
+                "doc": "A unique id for the DataProcessInstance . Should be separate from the name used for displaying a DataProcessInstance.",
                 "name": "id",
                 "type": "string"
             }
         ],
-        "name": "DataHubAccessTokenKey",
+        "name": "DataProcessInstanceKey",
         "namespace": "com.linkedin.pegasus2avro.metadata.key",
         "type": "record"
     },
-    "com.linkedin.pegasus2avro.metadata.key.DataHubPolicyKey",
     {
         "Aspect": {
             "entityAspects": [
-                "testInfo"
+                "dataHubRoleInfo"
             ],
             "entityCategory": "core",
-            "entityDoc": "A DataHub test",
-            "keyForEntity": "test",
-            "name": "testKey"
+            "keyForEntity": "dataHubRole",
+            "name": "dataHubRoleKey"
         },
-        "doc": "Key for a Test",
+        "doc": "Key for a DataHub Role",
         "fields": [
             {
-                "doc": "Unique id for the test",
+                "doc": "A unique id for the DataHub role record. Generated on the server side at role creation time.",
                 "name": "id",
                 "type": "string"
             }
         ],
-        "name": "TestKey",
+        "name": "DataHubRoleKey",
         "namespace": "com.linkedin.pegasus2avro.metadata.key",
         "type": "record"
     },
+    "com.linkedin.pegasus2avro.metadata.key.MLModelKey",
     {
         "Aspect": {
             "entityAspects": [
-                "dataHubIngestionSourceInfo"
+                "dataHubViewInfo"
             ],
-            "entityCategory": "internal",
-            "keyForEntity": "dataHubIngestionSource",
-            "name": "dataHubIngestionSourceKey"
+            "entityCategory": "core",
+            "keyForEntity": "dataHubView",
+            "name": "dataHubViewKey"
         },
-        "doc": "Key for a DataHub ingestion source",
+        "doc": "Key for a DataHub View",
         "fields": [
             {
-                "doc": "A unique id for the Ingestion Source, either generated or provided",
+                "doc": "A unique id for the View",
                 "name": "id",
                 "type": "string"
             }
         ],
-        "name": "DataHubIngestionSourceKey",
+        "name": "DataHubViewKey",
         "namespace": "com.linkedin.pegasus2avro.metadata.key",
         "type": "record"
     },
     {
         "Aspect": {
             "entityAspects": [
-                "assertionInfo",
-                "dataPlatformInstance",
-                "assertionRunEvent",
+                "queryProperties",
+                "querySubjects",
                 "status"
             ],
             "entityCategory": "core",
-            "entityDoc": "Assertion represents a data quality rule applied on one or more dataset.",
-            "keyForEntity": "assertion",
-            "name": "assertionKey"
+            "keyForEntity": "query",
+            "name": "queryKey"
         },
-        "doc": "Key for a Assertion",
+        "doc": "Key for a Query",
         "fields": [
             {
-                "doc": "Unique id for the assertion.",
-                "name": "assertionId",
+                "doc": "A unique id for the Query.",
+                "name": "id",
                 "type": "string"
             }
         ],
-        "name": "AssertionKey",
+        "name": "QueryKey",
         "namespace": "com.linkedin.pegasus2avro.metadata.key",
         "type": "record"
     },
+    "com.linkedin.pegasus2avro.metadata.key.CorpUserKey",
     {
         "Aspect": {
             "entityAspects": [
-                "postInfo"
+                "dataPlatformInstanceProperties",
+                "ownership",
+                "globalTags",
+                "institutionalMemory",
+                "deprecation",
+                "status"
             ],
-            "entityCategory": "core",
-            "keyForEntity": "post",
-            "name": "postKey"
+            "entityCategory": "internal",
+            "keyForEntity": "dataPlatformInstance",
+            "name": "dataPlatformInstanceKey"
         },
-        "doc": "Key for a Post.",
+        "doc": "Key for a Dataset",
         "fields": [
             {
-                "doc": "A unique id for the DataHub Post record. Generated on the server side at Post creation time.",
-                "name": "id",
+                "Urn": "Urn",
+                "doc": "Data platform urn associated with the instance",
+                "java": {
+                    "class": "com.linkedin.pegasus2avro.common.urn.Urn"
+                },
+                "name": "platform",
+                "type": "string"
+            },
+            {
+                "doc": "Unique instance id",
+                "name": "instance",
                 "type": "string"
             }
         ],
-        "name": "PostKey",
+        "name": "DataPlatformInstanceKey",
         "namespace": "com.linkedin.pegasus2avro.metadata.key",
         "type": "record"
     },
-    "com.linkedin.pegasus2avro.metadata.key.MLFeatureKey",
-    "com.linkedin.pegasus2avro.metadata.key.TagKey",
     {
         "Aspect": {
             "entityAspects": [
-                "domainProperties",
+                "notebookInfo",
+                "notebookContent",
+                "editableNotebookProperties",
+                "ownership",
+                "status",
+                "globalTags",
+                "glossaryTerms",
+                "browsePaths",
                 "institutionalMemory",
-                "ownership"
+                "domains",
+                "subTypes",
+                "dataPlatformInstance"
             ],
             "entityCategory": "_unset_",
-            "entityDoc": "A data domain within an organization.",
-            "keyForEntity": "domain",
-            "name": "domainKey"
+            "entityDoc": "Notebook represents a combination of query, text, chart and etc. This is in BETA version",
+            "keyForEntity": "notebook",
+            "name": "notebookKey"
         },
-        "doc": "Key for an Asset Domain",
+        "doc": "Key for a Notebook",
         "fields": [
             {
-                "doc": "A unique id for the domain. Should be separate from the name used for displaying a Domain.",
-                "name": "id",
+                "doc": "The name of the Notebook tool such as QueryBook, etc.",
+                "name": "notebookTool",
+                "type": "string"
+            },
+            {
+                "doc": "Unique id for the Notebook. This id should be globally unique for a Notebook tool even when there are multiple deployments of it. As an example, Notebook URL could be used here for QueryBook such as 'querybook.com/notebook/773'",
+                "name": "notebookId",
                 "type": "string"
             }
         ],
-        "name": "DomainKey",
+        "name": "NotebookKey",
         "namespace": "com.linkedin.pegasus2avro.metadata.key",
         "type": "record"
     },
+    "com.linkedin.pegasus2avro.metadata.key.MLFeatureKey",
+    "com.linkedin.pegasus2avro.metadata.key.ChartKey",
     {
         "Aspect": {
             "entityAspects": [
-                "dataHubViewInfo"
+                "assertionInfo",
+                "dataPlatformInstance",
+                "assertionRunEvent",
+                "status"
             ],
             "entityCategory": "core",
-            "keyForEntity": "dataHubView",
-            "name": "dataHubViewKey"
+            "entityDoc": "Assertion represents a data quality rule applied on one or more dataset.",
+            "keyForEntity": "assertion",
+            "name": "assertionKey"
         },
-        "doc": "Key for a DataHub View",
+        "doc": "Key for a Assertion",
         "fields": [
             {
-                "doc": "A unique id for the View",
+                "doc": "Unique id for the assertion.",
+                "name": "assertionId",
+                "type": "string"
+            }
+        ],
+        "name": "AssertionKey",
+        "namespace": "com.linkedin.pegasus2avro.metadata.key",
+        "type": "record"
+    },
+    {
+        "Aspect": {
+            "entityAspects": [
+                "dataHubSecretValue"
+            ],
+            "entityCategory": "internal",
+            "keyForEntity": "dataHubSecret",
+            "name": "dataHubSecretKey"
+        },
+        "doc": "Key for a DataHub Secret",
+        "fields": [
+            {
+                "doc": "A unique id for the Secret",
                 "name": "id",
                 "type": "string"
             }
         ],
-        "name": "DataHubViewKey",
+        "name": "DataHubSecretKey",
         "namespace": "com.linkedin.pegasus2avro.metadata.key",
         "type": "record"
     },
-    "com.linkedin.pegasus2avro.metadata.key.MLPrimaryKeyKey",
+    "com.linkedin.pegasus2avro.metadata.key.DataHubPolicyKey",
     {
         "Aspect": {
             "entityAspects": [
-                "dataHubStepStateProperties"
+                "testInfo"
             ],
             "entityCategory": "core",
-            "keyForEntity": "dataHubStepState",
-            "name": "dataHubStepStateKey"
+            "entityDoc": "A DataHub test",
+            "keyForEntity": "test",
+            "name": "testKey"
         },
-        "doc": "Key for a DataHub Step State",
+        "doc": "Key for a Test",
         "fields": [
             {
-                "doc": "A unique id for the state",
+                "doc": "Unique id for the test",
                 "name": "id",
                 "type": "string"
             }
         ],
-        "name": "DataHubStepStateKey",
+        "name": "TestKey",
         "namespace": "com.linkedin.pegasus2avro.metadata.key",
         "type": "record"
     },
     {
         "Aspect": {
             "entityAspects": [
-                "dataHubUpgradeRequest",
-                "dataHubUpgradeResult"
+                "dataHubAccessTokenInfo"
             ],
             "entityCategory": "internal",
-            "keyForEntity": "dataHubUpgrade",
-            "name": "dataHubUpgradeKey"
+            "keyForEntity": "dataHubAccessToken",
+            "name": "dataHubAccessTokenKey"
         },
-        "doc": "Key for a DataHubUpgrade",
+        "doc": "Key for a DataHub Access Token",
         "fields": [
             {
+                "doc": "Access token's SHA-256 hashed JWT signature",
                 "name": "id",
                 "type": "string"
             }
         ],
-        "name": "DataHubUpgradeKey",
+        "name": "DataHubAccessTokenKey",
         "namespace": "com.linkedin.pegasus2avro.metadata.key",
         "type": "record"
     },
-    "com.linkedin.pegasus2avro.metadata.key.GlossaryNodeKey",
-    "com.linkedin.pegasus2avro.metadata.key.MLModelDeploymentKey",
     {
         "Aspect": {
             "entityAspects": [
-                "dataHubRoleInfo"
+                "dataHubUpgradeRequest",
+                "dataHubUpgradeResult"
             ],
-            "entityCategory": "core",
-            "keyForEntity": "dataHubRole",
-            "name": "dataHubRoleKey"
+            "entityCategory": "internal",
+            "keyForEntity": "dataHubUpgrade",
+            "name": "dataHubUpgradeKey"
         },
-        "doc": "Key for a DataHub Role",
+        "doc": "Key for a DataHubUpgrade",
         "fields": [
             {
-                "doc": "A unique id for the DataHub role record. Generated on the server side at role creation time.",
                 "name": "id",
                 "type": "string"
             }
         ],
-        "name": "DataHubRoleKey",
+        "name": "DataHubUpgradeKey",
         "namespace": "com.linkedin.pegasus2avro.metadata.key",
         "type": "record"
     },
     "com.linkedin.pegasus2avro.metadata.key.DataPlatformKey",
     {
         "Aspect": {
             "entityAspects": [
-                "containerProperties",
-                "editableContainerProperties",
-                "dataPlatformInstance",
-                "subTypes",
-                "ownership",
-                "container",
-                "globalTags",
-                "glossaryTerms",
-                "institutionalMemory",
-                "browsePaths",
-                "status",
-                "domains"
+                "inviteToken"
             ],
-            "entityCategory": "_unset_",
-            "entityDoc": "A container of related data assets.",
-            "keyForEntity": "container",
-            "name": "containerKey"
+            "entityCategory": "core",
+            "keyForEntity": "inviteToken",
+            "name": "inviteTokenKey"
         },
-        "doc": "Key for an Asset Container",
+        "doc": "Key for an InviteToken.",
         "fields": [
             {
-                "default": null,
-                "doc": "Unique guid for container",
-                "name": "guid",
-                "type": [
-                    "null",
-                    "string"
-                ]
+                "doc": "A unique id for the invite token.",
+                "name": "id",
+                "type": "string"
             }
         ],
-        "name": "ContainerKey",
+        "name": "InviteTokenKey",
         "namespace": "com.linkedin.pegasus2avro.metadata.key",
         "type": "record"
     },
     {
         "Aspect": {
             "entityAspects": [
-                "dataPlatformInstanceProperties",
-                "ownership",
-                "globalTags",
-                "institutionalMemory",
-                "deprecation",
-                "status"
+                "postInfo"
             ],
-            "entityCategory": "internal",
-            "keyForEntity": "dataPlatformInstance",
-            "name": "dataPlatformInstanceKey"
+            "entityCategory": "core",
+            "keyForEntity": "post",
+            "name": "postKey"
         },
-        "doc": "Key for a Dataset",
+        "doc": "Key for a Post.",
         "fields": [
             {
-                "Urn": "Urn",
-                "doc": "Data platform urn associated with the instance",
-                "java": {
-                    "class": "com.linkedin.pegasus2avro.common.urn.Urn"
-                },
-                "name": "platform",
-                "type": "string"
-            },
-            {
-                "doc": "Unique instance id",
-                "name": "instance",
+                "doc": "A unique id for the DataHub Post record. Generated on the server side at Post creation time.",
+                "name": "id",
                 "type": "string"
             }
         ],
-        "name": "DataPlatformInstanceKey",
+        "name": "PostKey",
         "namespace": "com.linkedin.pegasus2avro.metadata.key",
         "type": "record"
     },
-    "com.linkedin.pegasus2avro.metadata.key.DataJobKey",
     {
         "Aspect": {
             "entityAspects": [
                 "dataHubExecutionRequestInput",
                 "dataHubExecutionRequestSignal",
                 "dataHubExecutionRequestResult"
             ],
@@ -12551,536 +12575,512 @@
                 "type": "string"
             }
         ],
         "name": "ExecutionRequestKey",
         "namespace": "com.linkedin.pegasus2avro.metadata.key",
         "type": "record"
     },
-    "com.linkedin.pegasus2avro.metadata.key.DataProcessKey",
-    "com.linkedin.pegasus2avro.metadata.key.CorpUserKey",
     {
         "Aspect": {
             "entityAspects": [
-                "notebookInfo",
-                "notebookContent",
-                "editableNotebookProperties",
-                "ownership",
-                "status",
-                "globalTags",
-                "glossaryTerms",
-                "browsePaths",
-                "institutionalMemory",
-                "domains",
-                "subTypes",
-                "dataPlatformInstance"
+                "dataHubIngestionSourceInfo"
             ],
-            "entityCategory": "_unset_",
-            "entityDoc": "Notebook represents a combination of query, text, chart and etc. This is in BETA version",
-            "keyForEntity": "notebook",
-            "name": "notebookKey"
+            "entityCategory": "internal",
+            "keyForEntity": "dataHubIngestionSource",
+            "name": "dataHubIngestionSourceKey"
         },
-        "doc": "Key for a Notebook",
+        "doc": "Key for a DataHub ingestion source",
         "fields": [
             {
-                "doc": "The name of the Notebook tool such as QueryBook, etc.",
-                "name": "notebookTool",
-                "type": "string"
-            },
-            {
-                "doc": "Unique id for the Notebook. This id should be globally unique for a Notebook tool even when there are multiple deployments of it. As an example, Notebook URL could be used here for QueryBook such as 'querybook.com/notebook/773'",
-                "name": "notebookId",
+                "doc": "A unique id for the Ingestion Source, either generated or provided",
+                "name": "id",
                 "type": "string"
             }
         ],
-        "name": "NotebookKey",
+        "name": "DataHubIngestionSourceKey",
         "namespace": "com.linkedin.pegasus2avro.metadata.key",
         "type": "record"
     },
-    "com.linkedin.pegasus2avro.metadata.key.SchemaFieldKey",
-    "com.linkedin.pegasus2avro.metadata.key.MLModelGroupKey",
     {
         "Aspect": {
             "entityAspects": [
-                "dataProcessInstanceInput",
-                "dataProcessInstanceOutput",
-                "dataProcessInstanceProperties",
-                "dataProcessInstanceRelationships",
-                "dataProcessInstanceRunEvent"
+                "domainProperties",
+                "institutionalMemory",
+                "ownership"
             ],
             "entityCategory": "_unset_",
-            "entityDoc": "DataProcessInstance represents an instance of a datajob/jobflow run",
-            "keyForEntity": "dataProcessInstance",
-            "name": "dataProcessInstanceKey"
+            "entityDoc": "A data domain within an organization.",
+            "keyForEntity": "domain",
+            "name": "domainKey"
         },
-        "doc": "Key for an Asset DataProcessInstance",
+        "doc": "Key for an Asset Domain",
         "fields": [
             {
-                "doc": "A unique id for the DataProcessInstance . Should be separate from the name used for displaying a DataProcessInstance.",
+                "doc": "A unique id for the domain. Should be separate from the name used for displaying a Domain.",
                 "name": "id",
                 "type": "string"
             }
         ],
-        "name": "DataProcessInstanceKey",
+        "name": "DomainKey",
         "namespace": "com.linkedin.pegasus2avro.metadata.key",
         "type": "record"
     },
+    "com.linkedin.pegasus2avro.metadata.key.DatasetKey",
     {
         "Aspect": {
             "entityAspects": [
-                "queryProperties",
-                "querySubjects",
-                "status"
+                "dataHubStepStateProperties"
             ],
             "entityCategory": "core",
-            "keyForEntity": "query",
-            "name": "queryKey"
+            "keyForEntity": "dataHubStepState",
+            "name": "dataHubStepStateKey"
         },
-        "doc": "Key for a Query",
+        "doc": "Key for a DataHub Step State",
         "fields": [
             {
-                "doc": "A unique id for the Query.",
+                "doc": "A unique id for the state",
                 "name": "id",
                 "type": "string"
             }
         ],
-        "name": "QueryKey",
+        "name": "DataHubStepStateKey",
         "namespace": "com.linkedin.pegasus2avro.metadata.key",
         "type": "record"
     },
-    "com.linkedin.pegasus2avro.metadata.key.MLModelKey",
-    "com.linkedin.pegasus2avro.metadata.key.GlossaryTermKey",
-    "com.linkedin.pegasus2avro.metadata.key.DatasetKey",
     {
         "Aspect": {
             "entityAspects": [
-                "inviteToken"
+                "globalSettingsInfo"
             ],
-            "entityCategory": "core",
-            "keyForEntity": "inviteToken",
-            "name": "inviteTokenKey"
+            "entityCategory": "internal",
+            "entityDoc": "Global settings for an the platform",
+            "keyForEntity": "globalSettings",
+            "name": "globalSettingsKey"
         },
-        "doc": "Key for an InviteToken.",
+        "doc": "Key for a Global Settings",
         "fields": [
             {
-                "doc": "A unique id for the invite token.",
+                "doc": "Id for the settings. There should be only 1 global settings urn: urn:li:globalSettings:0",
                 "name": "id",
                 "type": "string"
             }
         ],
-        "name": "InviteTokenKey",
+        "name": "GlobalSettingsKey",
         "namespace": "com.linkedin.pegasus2avro.metadata.key",
         "type": "record"
     },
-    "com.linkedin.pegasus2avro.metadata.key.CorpGroupKey",
-    "com.linkedin.pegasus2avro.metadata.key.DataHubRetentionKey",
-    "com.linkedin.pegasus2avro.metadata.key.DataFlowKey",
-    "com.linkedin.pegasus2avro.metadata.key.ChartKey",
-    "com.linkedin.pegasus2avro.metadata.query.filter.Filter",
-    "com.linkedin.pegasus2avro.common.GlossaryTerms",
+    "com.linkedin.pegasus2avro.metadata.key.TagKey",
     {
         "Aspect": {
-            "name": "embed"
+            "name": "globalSettingsInfo"
         },
-        "doc": "Information regarding rendering an embed for an asset.",
+        "doc": "DataHub Global platform settings. Careful - these should not be modified by the outside world!",
         "fields": [
             {
                 "default": null,
-                "doc": "An embed URL to be rendered inside of an iframe.",
-                "name": "renderUrl",
+                "doc": "Settings related to the Views Feature",
+                "name": "views",
                 "type": [
                     "null",
-                    "string"
+                    {
+                        "doc": "Settings for DataHub Views feature.",
+                        "fields": [
+                            {
+                                "Urn": "Urn",
+                                "default": null,
+                                "doc": "The default View for the instance, or organization.",
+                                "java": {
+                                    "class": "com.linkedin.pegasus2avro.common.urn.Urn"
+                                },
+                                "name": "defaultView",
+                                "type": [
+                                    "null",
+                                    "string"
+                                ]
+                            }
+                        ],
+                        "name": "GlobalViewsSettings",
+                        "namespace": "com.linkedin.pegasus2avro.settings.global",
+                        "type": "record"
+                    }
                 ]
             }
         ],
-        "name": "Embed",
-        "namespace": "com.linkedin.pegasus2avro.common",
+        "name": "GlobalSettingsInfo",
+        "namespace": "com.linkedin.pegasus2avro.settings.global",
         "type": "record"
     },
-    "com.linkedin.pegasus2avro.common.DataPlatformInstance",
     {
         "Aspect": {
-            "name": "inputFields"
+            "name": "testResults"
         },
-        "doc": "Information about the fields a chart or dashboard references",
+        "doc": "Information about a Test Result",
         "fields": [
             {
-                "doc": "List of fields being referenced",
-                "name": "fields",
+                "Relationship": {
+                    "/*/test": {
+                        "entityTypes": [
+                            "test"
+                        ],
+                        "name": "IsFailing"
+                    }
+                },
+                "Searchable": {
+                    "/*/test": {
+                        "fieldName": "failingTests",
+                        "fieldType": "URN",
+                        "hasValuesFieldName": "hasFailingTests"
+                    }
+                },
+                "doc": "Results that are failing",
+                "name": "failing",
                 "type": {
                     "items": {
-                        "doc": "Information about a field a chart or dashboard references",
+                        "doc": "Information about a Test Result",
                         "fields": [
                             {
-                                "Relationship": {
-                                    "entityTypes": [
-                                        "schemaField"
-                                    ],
-                                    "name": "consumesField"
-                                },
                                 "Urn": "Urn",
-                                "doc": "Urn of the schema being referenced for lineage purposes",
+                                "doc": "The urn of the test",
                                 "java": {
                                     "class": "com.linkedin.pegasus2avro.common.urn.Urn"
                                 },
-                                "name": "schemaFieldUrn",
+                                "name": "test",
                                 "type": "string"
                             },
                             {
-                                "default": null,
-                                "doc": "Copied version of the referenced schema field object for indexing purposes",
-                                "name": "schemaField",
-                                "type": [
-                                    "null",
-                                    "com.linkedin.pegasus2avro.schema.SchemaField"
-                                ]
+                                "doc": "The type of the result",
+                                "name": "type",
+                                "type": {
+                                    "name": "TestResultType",
+                                    "namespace": "com.linkedin.pegasus2avro.test",
+                                    "symbolDocs": {
+                                        "FAILURE": " The Test Failed",
+                                        "SUCCESS": " The Test Succeeded"
+                                    },
+                                    "symbols": [
+                                        "SUCCESS",
+                                        "FAILURE"
+                                    ],
+                                    "type": "enum"
+                                }
                             }
                         ],
-                        "name": "InputField",
-                        "namespace": "com.linkedin.pegasus2avro.common",
+                        "name": "TestResult",
+                        "namespace": "com.linkedin.pegasus2avro.test",
                         "type": "record"
                     },
                     "type": "array"
                 }
-            }
-        ],
-        "name": "InputFields",
-        "namespace": "com.linkedin.pegasus2avro.common",
-        "type": "record"
-    },
-    "com.linkedin.pegasus2avro.common.InstitutionalMemory",
-    "com.linkedin.pegasus2avro.common.Ownership",
-    {
-        "Aspect": {
-            "name": "subTypes"
-        },
-        "doc": "Sub Types. Use this aspect to specialize a generic Entity\ne.g. Making a Dataset also be a View or also be a LookerExplore",
-        "fields": [
+            },
             {
+                "Relationship": {
+                    "/*/test": {
+                        "entityTypes": [
+                            "test"
+                        ],
+                        "name": "IsPassing"
+                    }
+                },
                 "Searchable": {
-                    "/*": {
-                        "addToFilters": true,
-                        "fieldType": "KEYWORD",
-                        "filterNameOverride": "Sub Type",
-                        "queryByDefault": true
+                    "/*/test": {
+                        "fieldName": "passingTests",
+                        "fieldType": "URN",
+                        "hasValuesFieldName": "hasPassingTests"
                     }
                 },
-                "doc": "The names of the specific types.",
-                "name": "typeNames",
+                "doc": "Results that are passing",
+                "name": "passing",
                 "type": {
-                    "items": "string",
+                    "items": "com.linkedin.pegasus2avro.test.TestResult",
                     "type": "array"
                 }
             }
         ],
-        "name": "SubTypes",
-        "namespace": "com.linkedin.pegasus2avro.common",
+        "name": "TestResults",
+        "namespace": "com.linkedin.pegasus2avro.test",
         "type": "record"
     },
     {
         "Aspect": {
-            "name": "origin"
+            "name": "testInfo"
         },
-        "doc": "Carries information about where an entity originated from.",
+        "doc": "Information about a DataHub Test",
         "fields": [
             {
-                "doc": "Where an entity originated from. Either NATIVE or EXTERNAL.",
-                "name": "type",
-                "type": {
-                    "doc": "Enum to define where an entity originated from.",
-                    "name": "OriginType",
-                    "namespace": "com.linkedin.pegasus2avro.common",
-                    "symbolDocs": {
-                        "EXTERNAL": "The entity is external to DataHub.",
-                        "NATIVE": "The entity is native to DataHub."
-                    },
-                    "symbols": [
-                        "NATIVE",
-                        "EXTERNAL"
-                    ],
-                    "type": "enum"
-                }
+                "Searchable": {
+                    "fieldType": "TEXT_PARTIAL"
+                },
+                "doc": "The name of the test",
+                "name": "name",
+                "type": "string"
+            },
+            {
+                "Searchable": {
+                    "fieldType": "KEYWORD"
+                },
+                "doc": "Category of the test",
+                "name": "category",
+                "type": "string"
             },
             {
+                "Searchable": {
+                    "fieldType": "TEXT"
+                },
                 "default": null,
-                "doc": "Only populated if type is EXTERNAL. The externalType of the entity, such as the name of the identity provider.",
-                "name": "externalType",
+                "doc": "Description of the test",
+                "name": "description",
                 "type": [
                     "null",
                     "string"
                 ]
+            },
+            {
+                "doc": "Configuration for the Test",
+                "name": "definition",
+                "type": {
+                    "fields": [
+                        {
+                            "doc": "The Test Definition Type",
+                            "name": "type",
+                            "type": {
+                                "name": "TestDefinitionType",
+                                "namespace": "com.linkedin.pegasus2avro.test",
+                                "symbolDocs": {
+                                    "JSON": "JSON / YAML test def"
+                                },
+                                "symbols": [
+                                    "JSON"
+                                ],
+                                "type": "enum"
+                            }
+                        },
+                        {
+                            "default": null,
+                            "doc": "JSON format configuration for the test",
+                            "name": "json",
+                            "type": [
+                                "null",
+                                "string"
+                            ]
+                        }
+                    ],
+                    "name": "TestDefinition",
+                    "namespace": "com.linkedin.pegasus2avro.test",
+                    "type": "record"
+                }
             }
         ],
-        "name": "Origin",
-        "namespace": "com.linkedin.pegasus2avro.common",
+        "name": "TestInfo",
+        "namespace": "com.linkedin.pegasus2avro.test",
         "type": "record"
     },
-    "com.linkedin.pegasus2avro.common.GlobalTags",
-    "com.linkedin.pegasus2avro.common.Status",
     {
         "Aspect": {
-            "name": "operation",
-            "type": "timeseries"
+            "name": "dataPlatformInstanceProperties"
         },
-        "doc": "Operational info for an entity.",
+        "doc": "Properties associated with a Data Platform Instance",
         "fields": [
             {
-                "doc": "The event timestamp field as epoch at UTC in milli seconds.",
-                "name": "timestampMillis",
-                "type": "long"
+                "Searchable": {
+                    "/*": {
+                        "queryByDefault": true
+                    }
+                },
+                "default": {},
+                "doc": "Custom property bag.",
+                "name": "customProperties",
+                "type": {
+                    "type": "map",
+                    "values": "string"
+                }
             },
             {
                 "default": null,
-                "doc": "Granularity of the event if applicable",
-                "name": "eventGranularity",
+                "doc": "URL where the reference exist",
+                "java": {
+                    "class": "com.linkedin.pegasus2avro.common.url.Url",
+                    "coercerClass": "com.linkedin.pegasus2avro.common.url.UrlCoercer"
+                },
+                "name": "externalUrl",
                 "type": [
                     "null",
-                    "com.linkedin.pegasus2avro.timeseries.TimeWindowSize"
+                    "string"
                 ]
             },
             {
-                "default": {
-                    "partition": "FULL_TABLE_SNAPSHOT",
-                    "timePartition": null,
-                    "type": "FULL_TABLE"
+                "Searchable": {
+                    "boostScore": 10.0,
+                    "enableAutocomplete": true,
+                    "fieldType": "TEXT_PARTIAL"
                 },
-                "doc": "The optional partition specification.",
-                "name": "partitionSpec",
+                "default": null,
+                "doc": "Display name of the Data Platform Instance",
+                "name": "name",
                 "type": [
-                    "com.linkedin.pegasus2avro.timeseries.PartitionSpec",
-                    "null"
+                    "null",
+                    "string"
                 ]
             },
             {
+                "Searchable": {
+                    "fieldType": "TEXT",
+                    "hasValuesFieldName": "hasDescription"
+                },
                 "default": null,
-                "doc": "The optional messageId, if provided serves as a custom user-defined unique identifier for an aspect value.",
-                "name": "messageId",
+                "doc": "Documentation of the Data Platform Instance",
+                "name": "description",
                 "type": [
                     "null",
                     "string"
                 ]
+            }
+        ],
+        "name": "DataPlatformInstanceProperties",
+        "namespace": "com.linkedin.pegasus2avro.dataplatforminstance",
+        "type": "record"
+    },
+    {
+        "Aspect": {
+            "name": "dataHubViewInfo"
+        },
+        "doc": "Information about a DataHub View. -- TODO: Understand whether an entity type filter is required.",
+        "fields": [
+            {
+                "Searchable": {
+                    "fieldType": "TEXT_PARTIAL"
+                },
+                "doc": "The name of the View",
+                "name": "name",
+                "type": "string"
             },
             {
-                "TimeseriesField": {},
-                "Urn": "Urn",
                 "default": null,
-                "doc": "Actor who issued this operation.",
-                "java": {
-                    "class": "com.linkedin.pegasus2avro.common.urn.Urn"
-                },
-                "name": "actor",
+                "doc": "Description of the view",
+                "name": "description",
                 "type": [
                     "null",
                     "string"
                 ]
             },
             {
-                "TimeseriesField": {},
-                "doc": "Operation type of change.",
-                "name": "operationType",
+                "Searchable": {},
+                "doc": "The type of View",
+                "name": "type",
                 "type": {
-                    "doc": "Enum to define the operation type when an entity changes.",
-                    "name": "OperationType",
-                    "namespace": "com.linkedin.pegasus2avro.common",
+                    "name": "DataHubViewType",
+                    "namespace": "com.linkedin.pegasus2avro.view",
                     "symbolDocs": {
-                        "ALTER": "Asset was altered",
-                        "CREATE": "Asset was created",
-                        "CUSTOM": "Custom asset operation",
-                        "DELETE": "Rows were deleted",
-                        "DROP": "Asset was dropped",
-                        "INSERT": "Rows were inserted",
-                        "UPDATE": "Rows were updated"
+                        "GLOBAL": "A global view, which all users can see and use.",
+                        "PERSONAL": "A view private for a specific person."
                     },
                     "symbols": [
-                        "INSERT",
-                        "UPDATE",
-                        "DELETE",
-                        "CREATE",
-                        "ALTER",
-                        "DROP",
-                        "CUSTOM",
-                        "UNKNOWN"
+                        "PERSONAL",
+                        "GLOBAL"
                     ],
                     "type": "enum"
                 }
             },
             {
-                "TimeseriesField": {},
-                "default": null,
-                "doc": "A custom type of operation. Required if operationType is CUSTOM.",
-                "name": "customOperationType",
-                "type": [
-                    "null",
-                    "string"
-                ]
-            },
-            {
-                "TimeseriesField": {},
-                "default": null,
-                "doc": "How many rows were affected by this operation.",
-                "name": "numAffectedRows",
-                "type": [
-                    "null",
-                    "long"
-                ]
-            },
-            {
-                "TimeseriesFieldCollection": {
-                    "key": "datasetName"
-                },
-                "Urn": "Urn",
-                "default": null,
-                "doc": "Which other datasets were affected by this operation.",
-                "name": "affectedDatasets",
-                "type": [
-                    "null",
-                    {
-                        "items": "string",
-                        "type": "array"
-                    }
-                ],
-                "urn_is_array": true
-            },
-            {
-                "TimeseriesField": {},
-                "default": null,
-                "doc": "Source Type",
-                "name": "sourceType",
-                "type": [
-                    "null",
-                    {
-                        "doc": "The source of an operation",
-                        "name": "OperationSourceType",
-                        "namespace": "com.linkedin.pegasus2avro.common",
-                        "symbolDocs": {
-                            "DATA_PLATFORM": "Rows were updated",
-                            "DATA_PROCESS": "Provided by a Data Process"
+                "doc": "The view itself",
+                "name": "definition",
+                "type": {
+                    "doc": "A View definition.",
+                    "fields": [
+                        {
+                            "doc": "The Entity Types in the scope of the View.",
+                            "name": "entityTypes",
+                            "type": {
+                                "items": "string",
+                                "type": "array"
+                            }
                         },
-                        "symbols": [
-                            "DATA_PROCESS",
-                            "DATA_PLATFORM"
-                        ],
-                        "type": "enum"
-                    }
-                ]
+                        {
+                            "doc": "The filter criteria, which represents the view itself",
+                            "name": "filter",
+                            "type": "com.linkedin.pegasus2avro.metadata.query.filter.Filter"
+                        }
+                    ],
+                    "name": "DataHubViewDefinition",
+                    "namespace": "com.linkedin.pegasus2avro.view",
+                    "type": "record"
+                }
             },
             {
-                "default": null,
-                "doc": "Custom properties",
-                "name": "customProperties",
-                "type": [
-                    "null",
-                    {
-                        "type": "map",
-                        "values": "string"
+                "Searchable": {
+                    "/actor": {
+                        "fieldName": "createdBy",
+                        "fieldType": "URN"
+                    },
+                    "/time": {
+                        "fieldName": "createdAt",
+                        "fieldType": "DATETIME"
                     }
-                ]
+                },
+                "doc": "Audit stamp capturing the time and actor who created the View.",
+                "name": "created",
+                "type": "com.linkedin.pegasus2avro.common.AuditStamp"
             },
             {
                 "Searchable": {
-                    "fieldName": "lastOperationTime",
-                    "fieldType": "DATETIME"
+                    "/time": {
+                        "fieldName": "lastModifiedAt",
+                        "fieldType": "DATETIME"
+                    }
                 },
-                "TimeseriesField": {},
-                "doc": "The time at which the operation occurred. Would be better named 'operationTime'",
-                "name": "lastUpdatedTimestamp",
-                "type": "long"
+                "doc": "Audit stamp capturing the time and actor who last modified the View.",
+                "name": "lastModified",
+                "type": "com.linkedin.pegasus2avro.common.AuditStamp"
             }
         ],
-        "name": "Operation",
-        "namespace": "com.linkedin.pegasus2avro.common",
+        "name": "DataHubViewInfo",
+        "namespace": "com.linkedin.pegasus2avro.view",
         "type": "record"
     },
     {
         "Aspect": {
-            "name": "siblings"
+            "name": "dataHubSecretValue"
         },
-        "doc": "Siblings information of an entity.",
+        "doc": "The value of a DataHub Secret",
         "fields": [
             {
-                "Relationship": {
-                    "/*": {
-                        "entityTypes": [
-                            "dataset"
-                        ],
-                        "name": "SiblingOf"
-                    }
-                },
                 "Searchable": {
-                    "/*": {
-                        "fieldName": "siblings",
-                        "fieldType": "URN",
-                        "queryByDefault": false
-                    }
-                },
-                "Urn": "Urn",
-                "doc": "List of sibling entities",
-                "name": "siblings",
-                "type": {
-                    "items": "string",
-                    "type": "array"
+                    "fieldType": "TEXT_PARTIAL"
                 },
-                "urn_is_array": true
+                "doc": "The display name for the secret",
+                "name": "name",
+                "type": "string"
             },
             {
-                "doc": "If this is the leader entity of the set of siblings",
-                "name": "primary",
-                "type": "boolean"
-            }
-        ],
-        "name": "Siblings",
-        "namespace": "com.linkedin.pegasus2avro.common",
-        "type": "record"
-    },
-    "com.linkedin.pegasus2avro.common.BrowsePaths",
-    "com.linkedin.pegasus2avro.common.Deprecation",
-    "com.linkedin.pegasus2avro.common.Cost",
-    {
-        "Aspect": {
-            "name": "dataHubUpgradeResult"
-        },
-        "doc": "Information collected when a DataHubUpgrade successfully finishes",
-        "fields": [
-            {
-                "doc": "Timestamp when we started this DataHubUpgrade",
-                "name": "timestampMs",
-                "type": "long"
+                "doc": "The AES-encrypted value of the DataHub secret.",
+                "name": "value",
+                "type": "string"
             },
             {
                 "default": null,
-                "doc": "Result map to place helpful information about this upgrade job",
-                "name": "result",
+                "doc": "Description of the secret",
+                "name": "description",
                 "type": [
                     "null",
-                    {
-                        "type": "map",
-                        "values": "string"
-                    }
+                    "string"
                 ]
-            }
-        ],
-        "name": "DataHubUpgradeResult",
-        "namespace": "com.linkedin.pegasus2avro.upgrade",
-        "type": "record"
-    },
-    {
-        "Aspect": {
-            "name": "dataHubUpgradeRequest"
-        },
-        "doc": "Information collected when kicking off a DataHubUpgrade",
-        "fields": [
-            {
-                "doc": "Timestamp when we started this DataHubUpgrade",
-                "name": "timestampMs",
-                "type": "long"
             },
             {
-                "doc": "Version of this upgrade",
-                "name": "version",
-                "type": "string"
+                "Searchable": {
+                    "/time": {
+                        "fieldName": "createdTime",
+                        "fieldType": "DATETIME"
+                    }
+                },
+                "default": null,
+                "doc": "Created Audit stamp",
+                "name": "created",
+                "type": [
+                    "null",
+                    "com.linkedin.pegasus2avro.common.AuditStamp"
+                ]
             }
         ],
-        "name": "DataHubUpgradeRequest",
-        "namespace": "com.linkedin.pegasus2avro.upgrade",
+        "name": "DataHubSecretValue",
+        "namespace": "com.linkedin.pegasus2avro.secret",
         "type": "record"
     }
 ]
```

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/schema_classes.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/schema_classes.py`

 * *Files 14% similar despite different names*

```diff
@@ -25,32 +25,32 @@
 import decimal
 import datetime
 import six
 from avrogen.dict_wrapper import DictWrapper
 from avrogen import avrojson
 from avro.schema import RecordSchema, make_avsc_object
 from avro import schema as avro_schema
-from typing import ClassVar, List, Dict, Union, Optional, Type
+from typing import List, Dict, Union, Optional
 
 
 def __read_file(file_name):
     with open(file_name, "r") as f:
         return f.read()
         
 
 def __get_names_and_schema(json_str):
     names = avro_schema.Names()
     schema = make_avsc_object(json.loads(json_str), names)
     return names, schema
 
 
-_SCHEMA_JSON_STR = __read_file(os.path.join(os.path.dirname(__file__), "schema.avsc"))
+SCHEMA_JSON_STR = __read_file(os.path.join(os.path.dirname(__file__), "schema.avsc"))
 
 
-__NAMES, _SCHEMA = __get_names_and_schema(_SCHEMA_JSON_STR)
+__NAMES, SCHEMA = __get_names_and_schema(SCHEMA_JSON_STR)
 __SCHEMAS: Dict[str, RecordSchema] = {}
 
 class _Aspect(DictWrapper):
     ASPECT_NAME: ClassVar[str] = None  # type: ignore
     ASPECT_TYPE: ClassVar[str] = "default"
     ASPECT_INFO: ClassVar[dict] = None  # type: ignore
 
@@ -69,16 +69,16 @@
 
     @classmethod
     def get_aspect_info(cls) -> dict:
         return cls.ASPECT_INFO
 
 
 
-def get_schema_type(fullname: str) -> RecordSchema:
-    return __SCHEMAS[fullname]
+def get_schema_type(fullname):
+    return __SCHEMAS.get(fullname)
     
     
 __SCHEMAS = dict((n.fullname.lstrip("."), n) for n in six.itervalues(__NAMES.names))
 
 class KafkaAuditHeaderClass(DictWrapper):
     """This header records information about the context of an event as it is emitted into kafka and is intended to be used by the kafka audit application.  For more information see go/kafkaauditheader"""
     
@@ -100,102 +100,117 @@
         self.instance = instance
         self.appName = appName
         self.messageId = messageId
         self.auditVersion = auditVersion
         self.fabricUrn = fabricUrn
         self.clusterConnectionString = clusterConnectionString
     
+    @classmethod
+    def construct_with_defaults(cls) -> "KafkaAuditHeaderClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.time = int()
         self.server = str()
         self.instance = self.RECORD_SCHEMA.fields_dict["instance"].default
         self.appName = str()
         self.messageId = bytes()
         self.auditVersion = self.RECORD_SCHEMA.fields_dict["auditVersion"].default
         self.fabricUrn = self.RECORD_SCHEMA.fields_dict["fabricUrn"].default
         self.clusterConnectionString = self.RECORD_SCHEMA.fields_dict["clusterConnectionString"].default
     
     
     @property
     def time(self) -> int:
-        """The time at which the event was emitted into kafka."""
+        """Getter: The time at which the event was emitted into kafka."""
         return self._inner_dict.get('time')  # type: ignore
     
     @time.setter
     def time(self, value: int) -> None:
+        """Setter: The time at which the event was emitted into kafka."""
         self._inner_dict['time'] = value
     
     
     @property
     def server(self) -> str:
-        """The fully qualified name of the host from which the event is being emitted."""
+        """Getter: The fully qualified name of the host from which the event is being emitted."""
         return self._inner_dict.get('server')  # type: ignore
     
     @server.setter
     def server(self, value: str) -> None:
+        """Setter: The fully qualified name of the host from which the event is being emitted."""
         self._inner_dict['server'] = value
     
     
     @property
     def instance(self) -> Union[None, str]:
-        """The instance on the server from which the event is being emitted. e.g. i001"""
+        """Getter: The instance on the server from which the event is being emitted. e.g. i001"""
         return self._inner_dict.get('instance')  # type: ignore
     
     @instance.setter
     def instance(self, value: Union[None, str]) -> None:
+        """Setter: The instance on the server from which the event is being emitted. e.g. i001"""
         self._inner_dict['instance'] = value
     
     
     @property
     def appName(self) -> str:
-        """The name of the application from which the event is being emitted. see go/appname"""
+        """Getter: The name of the application from which the event is being emitted. see go/appname"""
         return self._inner_dict.get('appName')  # type: ignore
     
     @appName.setter
     def appName(self, value: str) -> None:
+        """Setter: The name of the application from which the event is being emitted. see go/appname"""
         self._inner_dict['appName'] = value
     
     
     @property
     def messageId(self) -> bytes:
-        """A unique identifier for the message"""
+        """Getter: A unique identifier for the message"""
         return self._inner_dict.get('messageId')  # type: ignore
     
     @messageId.setter
     def messageId(self, value: bytes) -> None:
+        """Setter: A unique identifier for the message"""
         self._inner_dict['messageId'] = value
     
     
     @property
     def auditVersion(self) -> Union[None, int]:
-        """The version that is being used for auditing. In version 0, the audit trail buckets events into 10 minute audit windows based on the EventHeader timestamp. In version 1, the audit trail buckets events as follows: if the schema has an outer KafkaAuditHeader, use the outer audit header timestamp for bucketing; else if the EventHeader has an inner KafkaAuditHeader use that inner audit header's timestamp for bucketing"""
+        """Getter: The version that is being used for auditing. In version 0, the audit trail buckets events into 10 minute audit windows based on the EventHeader timestamp. In version 1, the audit trail buckets events as follows: if the schema has an outer KafkaAuditHeader, use the outer audit header timestamp for bucketing; else if the EventHeader has an inner KafkaAuditHeader use that inner audit header's timestamp for bucketing"""
         return self._inner_dict.get('auditVersion')  # type: ignore
     
     @auditVersion.setter
     def auditVersion(self, value: Union[None, int]) -> None:
+        """Setter: The version that is being used for auditing. In version 0, the audit trail buckets events into 10 minute audit windows based on the EventHeader timestamp. In version 1, the audit trail buckets events as follows: if the schema has an outer KafkaAuditHeader, use the outer audit header timestamp for bucketing; else if the EventHeader has an inner KafkaAuditHeader use that inner audit header's timestamp for bucketing"""
         self._inner_dict['auditVersion'] = value
     
     
     @property
     def fabricUrn(self) -> Union[None, str]:
-        """The fabricUrn of the host from which the event is being emitted. Fabric Urn in the format of urn:li:fabric:{fabric_name}. See go/fabric."""
+        """Getter: The fabricUrn of the host from which the event is being emitted. Fabric Urn in the format of urn:li:fabric:{fabric_name}. See go/fabric."""
         return self._inner_dict.get('fabricUrn')  # type: ignore
     
     @fabricUrn.setter
     def fabricUrn(self, value: Union[None, str]) -> None:
+        """Setter: The fabricUrn of the host from which the event is being emitted. Fabric Urn in the format of urn:li:fabric:{fabric_name}. See go/fabric."""
         self._inner_dict['fabricUrn'] = value
     
     
     @property
     def clusterConnectionString(self) -> Union[None, str]:
-        """This is a String that the client uses to establish some kind of connection with the Kafka cluster. The exact format of it depends on specific versions of clients and brokers. This information could potentially identify the fabric and cluster with which the client is producing to or consuming from."""
+        """Getter: This is a String that the client uses to establish some kind of connection with the Kafka cluster. The exact format of it depends on specific versions of clients and brokers. This information could potentially identify the fabric and cluster with which the client is producing to or consuming from."""
         return self._inner_dict.get('clusterConnectionString')  # type: ignore
     
     @clusterConnectionString.setter
     def clusterConnectionString(self, value: Union[None, str]) -> None:
+        """Setter: This is a String that the client uses to establish some kind of connection with the Kafka cluster. The exact format of it depends on specific versions of clients and brokers. This information could potentially identify the fabric and cluster with which the client is producing to or consuming from."""
         self._inner_dict['clusterConnectionString'] = value
     
     
 class DataHubAccessTokenInfoClass(_Aspect):
     """Information about a DataHub Access Token"""
 
 
@@ -216,80 +231,93 @@
         self.name = name
         self.actorUrn = actorUrn
         self.ownerUrn = ownerUrn
         self.createdAt = createdAt
         self.expiresAt = expiresAt
         self.description = description
     
+    @classmethod
+    def construct_with_defaults(cls) -> "DataHubAccessTokenInfoClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.name = str()
         self.actorUrn = str()
         self.ownerUrn = str()
         self.createdAt = int()
         self.expiresAt = self.RECORD_SCHEMA.fields_dict["expiresAt"].default
         self.description = self.RECORD_SCHEMA.fields_dict["description"].default
     
     
     @property
     def name(self) -> str:
-        """User defined name for the access token if defined."""
+        """Getter: User defined name for the access token if defined."""
         return self._inner_dict.get('name')  # type: ignore
     
     @name.setter
     def name(self, value: str) -> None:
+        """Setter: User defined name for the access token if defined."""
         self._inner_dict['name'] = value
     
     
     @property
     def actorUrn(self) -> str:
-        """Urn of the actor to which this access token belongs to."""
+        """Getter: Urn of the actor to which this access token belongs to."""
         return self._inner_dict.get('actorUrn')  # type: ignore
     
     @actorUrn.setter
     def actorUrn(self, value: str) -> None:
+        """Setter: Urn of the actor to which this access token belongs to."""
         self._inner_dict['actorUrn'] = value
     
     
     @property
     def ownerUrn(self) -> str:
-        """Urn of the actor which created this access token."""
+        """Getter: Urn of the actor which created this access token."""
         return self._inner_dict.get('ownerUrn')  # type: ignore
     
     @ownerUrn.setter
     def ownerUrn(self, value: str) -> None:
+        """Setter: Urn of the actor which created this access token."""
         self._inner_dict['ownerUrn'] = value
     
     
     @property
     def createdAt(self) -> int:
-        """When the token was created."""
+        """Getter: When the token was created."""
         return self._inner_dict.get('createdAt')  # type: ignore
     
     @createdAt.setter
     def createdAt(self, value: int) -> None:
+        """Setter: When the token was created."""
         self._inner_dict['createdAt'] = value
     
     
     @property
     def expiresAt(self) -> Union[None, int]:
-        """When the token expires."""
+        """Getter: When the token expires."""
         return self._inner_dict.get('expiresAt')  # type: ignore
     
     @expiresAt.setter
     def expiresAt(self, value: Union[None, int]) -> None:
+        """Setter: When the token expires."""
         self._inner_dict['expiresAt'] = value
     
     
     @property
     def description(self) -> Union[None, str]:
-        """Description of the token if defined."""
+        """Getter: Description of the token if defined."""
         return self._inner_dict.get('description')  # type: ignore
     
     @description.setter
     def description(self, value: Union[None, str]) -> None:
+        """Setter: Description of the token if defined."""
         self._inner_dict['description'] = value
     
     
 class AssertionInfoClass(_Aspect):
     """Information about an assertion"""
 
 
@@ -310,58 +338,69 @@
             self.customProperties = dict()
         else:
             self.customProperties = customProperties
         self.externalUrl = externalUrl
         self.type = type
         self.datasetAssertion = datasetAssertion
     
+    @classmethod
+    def construct_with_defaults(cls) -> "AssertionInfoClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.customProperties = dict()
         self.externalUrl = self.RECORD_SCHEMA.fields_dict["externalUrl"].default
         self.type = AssertionTypeClass.DATASET
         self.datasetAssertion = self.RECORD_SCHEMA.fields_dict["datasetAssertion"].default
     
     
     @property
     def customProperties(self) -> Dict[str, str]:
-        """Custom property bag."""
+        """Getter: Custom property bag."""
         return self._inner_dict.get('customProperties')  # type: ignore
     
     @customProperties.setter
     def customProperties(self, value: Dict[str, str]) -> None:
+        """Setter: Custom property bag."""
         self._inner_dict['customProperties'] = value
     
     
     @property
     def externalUrl(self) -> Union[None, str]:
-        """URL where the reference exist"""
+        """Getter: URL where the reference exist"""
         return self._inner_dict.get('externalUrl')  # type: ignore
     
     @externalUrl.setter
     def externalUrl(self, value: Union[None, str]) -> None:
+        """Setter: URL where the reference exist"""
         self._inner_dict['externalUrl'] = value
     
     
     @property
     def type(self) -> Union[str, "AssertionTypeClass"]:
-        """Type of assertion. Assertion types can evolve to span Datasets, Flows (Pipelines), Models, Features etc."""
+        """Getter: Type of assertion. Assertion types can evolve to span Datasets, Flows (Pipelines), Models, Features etc."""
         return self._inner_dict.get('type')  # type: ignore
     
     @type.setter
     def type(self, value: Union[str, "AssertionTypeClass"]) -> None:
+        """Setter: Type of assertion. Assertion types can evolve to span Datasets, Flows (Pipelines), Models, Features etc."""
         self._inner_dict['type'] = value
     
     
     @property
     def datasetAssertion(self) -> Union[None, "DatasetAssertionInfoClass"]:
-        """Dataset Assertion information when type is DATASET"""
+        """Getter: Dataset Assertion information when type is DATASET"""
         return self._inner_dict.get('datasetAssertion')  # type: ignore
     
     @datasetAssertion.setter
     def datasetAssertion(self, value: Union[None, "DatasetAssertionInfoClass"]) -> None:
+        """Setter: Dataset Assertion information when type is DATASET"""
         self._inner_dict['datasetAssertion'] = value
     
     
 class AssertionResultClass(DictWrapper):
     """The result of running an assertion"""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.assertion.AssertionResult")
@@ -380,91 +419,105 @@
         self.rowCount = rowCount
         self.missingCount = missingCount
         self.unexpectedCount = unexpectedCount
         self.actualAggValue = actualAggValue
         self.nativeResults = nativeResults
         self.externalUrl = externalUrl
     
+    @classmethod
+    def construct_with_defaults(cls) -> "AssertionResultClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.type = AssertionResultTypeClass.SUCCESS
         self.rowCount = self.RECORD_SCHEMA.fields_dict["rowCount"].default
         self.missingCount = self.RECORD_SCHEMA.fields_dict["missingCount"].default
         self.unexpectedCount = self.RECORD_SCHEMA.fields_dict["unexpectedCount"].default
         self.actualAggValue = self.RECORD_SCHEMA.fields_dict["actualAggValue"].default
         self.nativeResults = self.RECORD_SCHEMA.fields_dict["nativeResults"].default
         self.externalUrl = self.RECORD_SCHEMA.fields_dict["externalUrl"].default
     
     
     @property
     def type(self) -> Union[str, "AssertionResultTypeClass"]:
-        """ The final result, e.g. either SUCCESS or FAILURE."""
+        """Getter:  The final result, e.g. either SUCCESS or FAILURE."""
         return self._inner_dict.get('type')  # type: ignore
     
     @type.setter
     def type(self, value: Union[str, "AssertionResultTypeClass"]) -> None:
+        """Setter:  The final result, e.g. either SUCCESS or FAILURE."""
         self._inner_dict['type'] = value
     
     
     @property
     def rowCount(self) -> Union[None, int]:
-        """Number of rows for evaluated batch"""
+        """Getter: Number of rows for evaluated batch"""
         return self._inner_dict.get('rowCount')  # type: ignore
     
     @rowCount.setter
     def rowCount(self, value: Union[None, int]) -> None:
+        """Setter: Number of rows for evaluated batch"""
         self._inner_dict['rowCount'] = value
     
     
     @property
     def missingCount(self) -> Union[None, int]:
-        """Number of rows with missing value for evaluated batch"""
+        """Getter: Number of rows with missing value for evaluated batch"""
         return self._inner_dict.get('missingCount')  # type: ignore
     
     @missingCount.setter
     def missingCount(self, value: Union[None, int]) -> None:
+        """Setter: Number of rows with missing value for evaluated batch"""
         self._inner_dict['missingCount'] = value
     
     
     @property
     def unexpectedCount(self) -> Union[None, int]:
-        """Number of rows with unexpected value for evaluated batch"""
+        """Getter: Number of rows with unexpected value for evaluated batch"""
         return self._inner_dict.get('unexpectedCount')  # type: ignore
     
     @unexpectedCount.setter
     def unexpectedCount(self, value: Union[None, int]) -> None:
+        """Setter: Number of rows with unexpected value for evaluated batch"""
         self._inner_dict['unexpectedCount'] = value
     
     
     @property
     def actualAggValue(self) -> Union[None, float]:
-        """Observed aggregate value for evaluated batch"""
+        """Getter: Observed aggregate value for evaluated batch"""
         return self._inner_dict.get('actualAggValue')  # type: ignore
     
     @actualAggValue.setter
     def actualAggValue(self, value: Union[None, float]) -> None:
+        """Setter: Observed aggregate value for evaluated batch"""
         self._inner_dict['actualAggValue'] = value
     
     
     @property
     def nativeResults(self) -> Union[None, Dict[str, str]]:
-        """Other results of evaluation"""
+        """Getter: Other results of evaluation"""
         return self._inner_dict.get('nativeResults')  # type: ignore
     
     @nativeResults.setter
     def nativeResults(self, value: Union[None, Dict[str, str]]) -> None:
+        """Setter: Other results of evaluation"""
         self._inner_dict['nativeResults'] = value
     
     
     @property
     def externalUrl(self) -> Union[None, str]:
-        """URL where full results are available"""
+        """Getter: URL where full results are available"""
         return self._inner_dict.get('externalUrl')  # type: ignore
     
     @externalUrl.setter
     def externalUrl(self, value: Union[None, str]) -> None:
+        """Setter: URL where full results are available"""
         self._inner_dict['externalUrl'] = value
     
     
 class AssertionResultTypeClass(object):
     # No docs available.
     
     
@@ -512,14 +565,21 @@
         self.assertionUrn = assertionUrn
         self.asserteeUrn = asserteeUrn
         self.batchSpec = batchSpec
         self.status = status
         self.result = result
         self.runtimeContext = runtimeContext
     
+    @classmethod
+    def construct_with_defaults(cls) -> "AssertionRunEventClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.timestampMillis = int()
         self.eventGranularity = self.RECORD_SCHEMA.fields_dict["eventGranularity"].default
         self.partitionSpec = _json_converter.from_json_object(self.RECORD_SCHEMA.fields_dict["partitionSpec"].default, writers_schema=self.RECORD_SCHEMA.fields_dict["partitionSpec"].type)
         self.messageId = self.RECORD_SCHEMA.fields_dict["messageId"].default
         self.runId = str()
         self.assertionUrn = str()
@@ -528,119 +588,130 @@
         self.status = AssertionRunStatusClass.COMPLETE
         self.result = self.RECORD_SCHEMA.fields_dict["result"].default
         self.runtimeContext = self.RECORD_SCHEMA.fields_dict["runtimeContext"].default
     
     
     @property
     def timestampMillis(self) -> int:
-        """The event timestamp field as epoch at UTC in milli seconds."""
+        """Getter: The event timestamp field as epoch at UTC in milli seconds."""
         return self._inner_dict.get('timestampMillis')  # type: ignore
     
     @timestampMillis.setter
     def timestampMillis(self, value: int) -> None:
+        """Setter: The event timestamp field as epoch at UTC in milli seconds."""
         self._inner_dict['timestampMillis'] = value
     
     
     @property
     def eventGranularity(self) -> Union[None, "TimeWindowSizeClass"]:
-        """Granularity of the event if applicable"""
+        """Getter: Granularity of the event if applicable"""
         return self._inner_dict.get('eventGranularity')  # type: ignore
     
     @eventGranularity.setter
     def eventGranularity(self, value: Union[None, "TimeWindowSizeClass"]) -> None:
+        """Setter: Granularity of the event if applicable"""
         self._inner_dict['eventGranularity'] = value
     
     
     @property
     def partitionSpec(self) -> Union["PartitionSpecClass", None]:
-        """The optional partition specification."""
+        """Getter: The optional partition specification."""
         return self._inner_dict.get('partitionSpec')  # type: ignore
     
     @partitionSpec.setter
     def partitionSpec(self, value: Union["PartitionSpecClass", None]) -> None:
+        """Setter: The optional partition specification."""
         self._inner_dict['partitionSpec'] = value
     
     
     @property
     def messageId(self) -> Union[None, str]:
-        """The optional messageId, if provided serves as a custom user-defined unique identifier for an aspect value."""
+        """Getter: The optional messageId, if provided serves as a custom user-defined unique identifier for an aspect value."""
         return self._inner_dict.get('messageId')  # type: ignore
     
     @messageId.setter
     def messageId(self, value: Union[None, str]) -> None:
+        """Setter: The optional messageId, if provided serves as a custom user-defined unique identifier for an aspect value."""
         self._inner_dict['messageId'] = value
     
     
     @property
     def runId(self) -> str:
-        """ Native (platform-specific) identifier for this run"""
+        """Getter:  Native (platform-specific) identifier for this run"""
         return self._inner_dict.get('runId')  # type: ignore
     
     @runId.setter
     def runId(self, value: str) -> None:
+        """Setter:  Native (platform-specific) identifier for this run"""
         self._inner_dict['runId'] = value
     
     
     @property
     def assertionUrn(self) -> str:
         # No docs available.
         return self._inner_dict.get('assertionUrn')  # type: ignore
     
     @assertionUrn.setter
     def assertionUrn(self, value: str) -> None:
+        # No docs available.
         self._inner_dict['assertionUrn'] = value
     
     
     @property
     def asserteeUrn(self) -> str:
         # No docs available.
         return self._inner_dict.get('asserteeUrn')  # type: ignore
     
     @asserteeUrn.setter
     def asserteeUrn(self, value: str) -> None:
+        # No docs available.
         self._inner_dict['asserteeUrn'] = value
     
     
     @property
     def batchSpec(self) -> Union[None, "BatchSpecClass"]:
-        """Specification of the batch which this run is evaluating"""
+        """Getter: Specification of the batch which this run is evaluating"""
         return self._inner_dict.get('batchSpec')  # type: ignore
     
     @batchSpec.setter
     def batchSpec(self, value: Union[None, "BatchSpecClass"]) -> None:
+        """Setter: Specification of the batch which this run is evaluating"""
         self._inner_dict['batchSpec'] = value
     
     
     @property
     def status(self) -> Union[str, "AssertionRunStatusClass"]:
-        """The status of the assertion run as per this timeseries event."""
+        """Getter: The status of the assertion run as per this timeseries event."""
         return self._inner_dict.get('status')  # type: ignore
     
     @status.setter
     def status(self, value: Union[str, "AssertionRunStatusClass"]) -> None:
+        """Setter: The status of the assertion run as per this timeseries event."""
         self._inner_dict['status'] = value
     
     
     @property
     def result(self) -> Union[None, "AssertionResultClass"]:
-        """Results of assertion, present if the status is COMPLETE"""
+        """Getter: Results of assertion, present if the status is COMPLETE"""
         return self._inner_dict.get('result')  # type: ignore
     
     @result.setter
     def result(self, value: Union[None, "AssertionResultClass"]) -> None:
+        """Setter: Results of assertion, present if the status is COMPLETE"""
         self._inner_dict['result'] = value
     
     
     @property
     def runtimeContext(self) -> Union[None, Dict[str, str]]:
-        """Runtime parameters of evaluation"""
+        """Getter: Runtime parameters of evaluation"""
         return self._inner_dict.get('runtimeContext')  # type: ignore
     
     @runtimeContext.setter
     def runtimeContext(self, value: Union[None, Dict[str, str]]) -> None:
+        """Setter: Runtime parameters of evaluation"""
         self._inner_dict['runtimeContext'] = value
     
     
 class AssertionRunStatusClass(object):
     # No docs available.
     
     
@@ -754,36 +825,45 @@
         type: Union[str, "AssertionStdParameterTypeClass"],
     ):
         super().__init__()
         
         self.value = value
         self.type = type
     
+    @classmethod
+    def construct_with_defaults(cls) -> "AssertionStdParameterClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.value = str()
         self.type = AssertionStdParameterTypeClass.STRING
     
     
     @property
     def value(self) -> str:
-        """The parameter value"""
+        """Getter: The parameter value"""
         return self._inner_dict.get('value')  # type: ignore
     
     @value.setter
     def value(self, value: str) -> None:
+        """Setter: The parameter value"""
         self._inner_dict['value'] = value
     
     
     @property
     def type(self) -> Union[str, "AssertionStdParameterTypeClass"]:
-        """The type of the parameter"""
+        """Getter: The type of the parameter"""
         return self._inner_dict.get('type')  # type: ignore
     
     @type.setter
     def type(self, value: Union[str, "AssertionStdParameterTypeClass"]) -> None:
+        """Setter: The type of the parameter"""
         self._inner_dict['type'] = value
     
     
 class AssertionStdParameterTypeClass(object):
     # No docs available.
     
     STRING = "STRING"
@@ -804,47 +884,57 @@
     ):
         super().__init__()
         
         self.value = value
         self.maxValue = maxValue
         self.minValue = minValue
     
+    @classmethod
+    def construct_with_defaults(cls) -> "AssertionStdParametersClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.value = self.RECORD_SCHEMA.fields_dict["value"].default
         self.maxValue = self.RECORD_SCHEMA.fields_dict["maxValue"].default
         self.minValue = self.RECORD_SCHEMA.fields_dict["minValue"].default
     
     
     @property
     def value(self) -> Union[None, "AssertionStdParameterClass"]:
-        """The value parameter of an assertion"""
+        """Getter: The value parameter of an assertion"""
         return self._inner_dict.get('value')  # type: ignore
     
     @value.setter
     def value(self, value: Union[None, "AssertionStdParameterClass"]) -> None:
+        """Setter: The value parameter of an assertion"""
         self._inner_dict['value'] = value
     
     
     @property
     def maxValue(self) -> Union[None, "AssertionStdParameterClass"]:
-        """The maxValue parameter of an assertion"""
+        """Getter: The maxValue parameter of an assertion"""
         return self._inner_dict.get('maxValue')  # type: ignore
     
     @maxValue.setter
     def maxValue(self, value: Union[None, "AssertionStdParameterClass"]) -> None:
+        """Setter: The maxValue parameter of an assertion"""
         self._inner_dict['maxValue'] = value
     
     
     @property
     def minValue(self) -> Union[None, "AssertionStdParameterClass"]:
-        """The minValue parameter of an assertion"""
+        """Getter: The minValue parameter of an assertion"""
         return self._inner_dict.get('minValue')  # type: ignore
     
     @minValue.setter
     def minValue(self, value: Union[None, "AssertionStdParameterClass"]) -> None:
+        """Setter: The minValue parameter of an assertion"""
         self._inner_dict['minValue'] = value
     
     
 class AssertionTypeClass(object):
     # No docs available.
     
     DATASET = "DATASET"
@@ -867,58 +957,69 @@
             self.customProperties = dict()
         else:
             self.customProperties = customProperties
         self.nativeBatchId = nativeBatchId
         self.query = query
         self.limit = limit
     
+    @classmethod
+    def construct_with_defaults(cls) -> "BatchSpecClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.customProperties = dict()
         self.nativeBatchId = self.RECORD_SCHEMA.fields_dict["nativeBatchId"].default
         self.query = self.RECORD_SCHEMA.fields_dict["query"].default
         self.limit = self.RECORD_SCHEMA.fields_dict["limit"].default
     
     
     @property
     def customProperties(self) -> Dict[str, str]:
-        """Custom property bag."""
+        """Getter: Custom property bag."""
         return self._inner_dict.get('customProperties')  # type: ignore
     
     @customProperties.setter
     def customProperties(self, value: Dict[str, str]) -> None:
+        """Setter: Custom property bag."""
         self._inner_dict['customProperties'] = value
     
     
     @property
     def nativeBatchId(self) -> Union[None, str]:
-        """The native identifier as specified by the system operating on the batch."""
+        """Getter: The native identifier as specified by the system operating on the batch."""
         return self._inner_dict.get('nativeBatchId')  # type: ignore
     
     @nativeBatchId.setter
     def nativeBatchId(self, value: Union[None, str]) -> None:
+        """Setter: The native identifier as specified by the system operating on the batch."""
         self._inner_dict['nativeBatchId'] = value
     
     
     @property
     def query(self) -> Union[None, str]:
-        """A query that identifies a batch of data"""
+        """Getter: A query that identifies a batch of data"""
         return self._inner_dict.get('query')  # type: ignore
     
     @query.setter
     def query(self, value: Union[None, str]) -> None:
+        """Setter: A query that identifies a batch of data"""
         self._inner_dict['query'] = value
     
     
     @property
     def limit(self) -> Union[None, int]:
-        """Any limit to the number of rows in the batch, if applied"""
+        """Getter: Any limit to the number of rows in the batch, if applied"""
         return self._inner_dict.get('limit')  # type: ignore
     
     @limit.setter
     def limit(self, value: Union[None, int]) -> None:
+        """Setter: Any limit to the number of rows in the batch, if applied"""
         self._inner_dict['limit'] = value
     
     
 class DatasetAssertionInfoClass(DictWrapper):
     """Attributes that are applicable to single-Dataset Assertions"""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.assertion.DatasetAssertionInfo")
@@ -941,113 +1042,129 @@
         self.aggregation = aggregation
         self.operator = operator
         self.parameters = parameters
         self.nativeType = nativeType
         self.nativeParameters = nativeParameters
         self.logic = logic
     
+    @classmethod
+    def construct_with_defaults(cls) -> "DatasetAssertionInfoClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.dataset = str()
         self.scope = DatasetAssertionScopeClass.DATASET_COLUMN
         self.fields = self.RECORD_SCHEMA.fields_dict["fields"].default
         self.aggregation = self.RECORD_SCHEMA.fields_dict["aggregation"].default
         self.operator = AssertionStdOperatorClass.BETWEEN
         self.parameters = self.RECORD_SCHEMA.fields_dict["parameters"].default
         self.nativeType = self.RECORD_SCHEMA.fields_dict["nativeType"].default
         self.nativeParameters = self.RECORD_SCHEMA.fields_dict["nativeParameters"].default
         self.logic = self.RECORD_SCHEMA.fields_dict["logic"].default
     
     
     @property
     def dataset(self) -> str:
-        """The dataset targeted by this assertion."""
+        """Getter: The dataset targeted by this assertion."""
         return self._inner_dict.get('dataset')  # type: ignore
     
     @dataset.setter
     def dataset(self, value: str) -> None:
+        """Setter: The dataset targeted by this assertion."""
         self._inner_dict['dataset'] = value
     
     
     @property
     def scope(self) -> Union[str, "DatasetAssertionScopeClass"]:
-        """Scope of the Assertion. What part of the dataset does this assertion apply to?"""
+        """Getter: Scope of the Assertion. What part of the dataset does this assertion apply to?"""
         return self._inner_dict.get('scope')  # type: ignore
     
     @scope.setter
     def scope(self, value: Union[str, "DatasetAssertionScopeClass"]) -> None:
+        """Setter: Scope of the Assertion. What part of the dataset does this assertion apply to?"""
         self._inner_dict['scope'] = value
     
     
     @property
     def fields(self) -> Union[None, List[str]]:
-        """One or more dataset schema fields that are targeted by this assertion"""
+        """Getter: One or more dataset schema fields that are targeted by this assertion"""
         return self._inner_dict.get('fields')  # type: ignore
     
     @fields.setter
     def fields(self, value: Union[None, List[str]]) -> None:
+        """Setter: One or more dataset schema fields that are targeted by this assertion"""
         self._inner_dict['fields'] = value
     
     
     @property
     def aggregation(self) -> Union[None, Union[str, "AssertionStdAggregationClass"]]:
-        """Standardized assertion operator"""
+        """Getter: Standardized assertion operator"""
         return self._inner_dict.get('aggregation')  # type: ignore
     
     @aggregation.setter
     def aggregation(self, value: Union[None, Union[str, "AssertionStdAggregationClass"]]) -> None:
+        """Setter: Standardized assertion operator"""
         self._inner_dict['aggregation'] = value
     
     
     @property
     def operator(self) -> Union[str, "AssertionStdOperatorClass"]:
-        """Standardized assertion operator"""
+        """Getter: Standardized assertion operator"""
         return self._inner_dict.get('operator')  # type: ignore
     
     @operator.setter
     def operator(self, value: Union[str, "AssertionStdOperatorClass"]) -> None:
+        """Setter: Standardized assertion operator"""
         self._inner_dict['operator'] = value
     
     
     @property
     def parameters(self) -> Union[None, "AssertionStdParametersClass"]:
-        """Standard parameters required for the assertion. e.g. min_value, max_value, value, columns"""
+        """Getter: Standard parameters required for the assertion. e.g. min_value, max_value, value, columns"""
         return self._inner_dict.get('parameters')  # type: ignore
     
     @parameters.setter
     def parameters(self, value: Union[None, "AssertionStdParametersClass"]) -> None:
+        """Setter: Standard parameters required for the assertion. e.g. min_value, max_value, value, columns"""
         self._inner_dict['parameters'] = value
     
     
     @property
     def nativeType(self) -> Union[None, str]:
-        """Native assertion type"""
+        """Getter: Native assertion type"""
         return self._inner_dict.get('nativeType')  # type: ignore
     
     @nativeType.setter
     def nativeType(self, value: Union[None, str]) -> None:
+        """Setter: Native assertion type"""
         self._inner_dict['nativeType'] = value
     
     
     @property
     def nativeParameters(self) -> Union[None, Dict[str, str]]:
-        """Native parameters required for the assertion."""
+        """Getter: Native parameters required for the assertion."""
         return self._inner_dict.get('nativeParameters')  # type: ignore
     
     @nativeParameters.setter
     def nativeParameters(self, value: Union[None, Dict[str, str]]) -> None:
+        """Setter: Native parameters required for the assertion."""
         self._inner_dict['nativeParameters'] = value
     
     
     @property
     def logic(self) -> Union[None, str]:
         # No docs available.
         return self._inner_dict.get('logic')  # type: ignore
     
     @logic.setter
     def logic(self, value: Union[None, str]) -> None:
+        # No docs available.
         self._inner_dict['logic'] = value
     
     
 class DatasetAssertionScopeClass(object):
     # No docs available.
     
     
@@ -1099,136 +1216,155 @@
         self.chartUrl = chartUrl
         self.inputs = inputs
         self.inputEdges = inputEdges
         self.type = type
         self.access = access
         self.lastRefreshed = lastRefreshed
     
+    @classmethod
+    def construct_with_defaults(cls) -> "ChartInfoClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.customProperties = dict()
         self.externalUrl = self.RECORD_SCHEMA.fields_dict["externalUrl"].default
         self.title = str()
         self.description = str()
-        self.lastModified = ChangeAuditStampsClass._construct_with_defaults()
+        self.lastModified = ChangeAuditStampsClass.construct_with_defaults()
         self.chartUrl = self.RECORD_SCHEMA.fields_dict["chartUrl"].default
         self.inputs = self.RECORD_SCHEMA.fields_dict["inputs"].default
         self.inputEdges = self.RECORD_SCHEMA.fields_dict["inputEdges"].default
         self.type = self.RECORD_SCHEMA.fields_dict["type"].default
         self.access = self.RECORD_SCHEMA.fields_dict["access"].default
         self.lastRefreshed = self.RECORD_SCHEMA.fields_dict["lastRefreshed"].default
     
     
     @property
     def customProperties(self) -> Dict[str, str]:
-        """Custom property bag."""
+        """Getter: Custom property bag."""
         return self._inner_dict.get('customProperties')  # type: ignore
     
     @customProperties.setter
     def customProperties(self, value: Dict[str, str]) -> None:
+        """Setter: Custom property bag."""
         self._inner_dict['customProperties'] = value
     
     
     @property
     def externalUrl(self) -> Union[None, str]:
-        """URL where the reference exist"""
+        """Getter: URL where the reference exist"""
         return self._inner_dict.get('externalUrl')  # type: ignore
     
     @externalUrl.setter
     def externalUrl(self, value: Union[None, str]) -> None:
+        """Setter: URL where the reference exist"""
         self._inner_dict['externalUrl'] = value
     
     
     @property
     def title(self) -> str:
-        """Title of the chart"""
+        """Getter: Title of the chart"""
         return self._inner_dict.get('title')  # type: ignore
     
     @title.setter
     def title(self, value: str) -> None:
+        """Setter: Title of the chart"""
         self._inner_dict['title'] = value
     
     
     @property
     def description(self) -> str:
-        """Detailed description about the chart"""
+        """Getter: Detailed description about the chart"""
         return self._inner_dict.get('description')  # type: ignore
     
     @description.setter
     def description(self, value: str) -> None:
+        """Setter: Detailed description about the chart"""
         self._inner_dict['description'] = value
     
     
     @property
     def lastModified(self) -> "ChangeAuditStampsClass":
-        """Captures information about who created/last modified/deleted this chart and when"""
+        """Getter: Captures information about who created/last modified/deleted this chart and when"""
         return self._inner_dict.get('lastModified')  # type: ignore
     
     @lastModified.setter
     def lastModified(self, value: "ChangeAuditStampsClass") -> None:
+        """Setter: Captures information about who created/last modified/deleted this chart and when"""
         self._inner_dict['lastModified'] = value
     
     
     @property
     def chartUrl(self) -> Union[None, str]:
-        """URL for the chart. This could be used as an external link on DataHub to allow users access/view the chart"""
+        """Getter: URL for the chart. This could be used as an external link on DataHub to allow users access/view the chart"""
         return self._inner_dict.get('chartUrl')  # type: ignore
     
     @chartUrl.setter
     def chartUrl(self, value: Union[None, str]) -> None:
+        """Setter: URL for the chart. This could be used as an external link on DataHub to allow users access/view the chart"""
         self._inner_dict['chartUrl'] = value
     
     
     @property
     def inputs(self) -> Union[None, List[str]]:
-        """Data sources for the chart
+        """Getter: Data sources for the chart
     Deprecated! Use inputEdges instead."""
         return self._inner_dict.get('inputs')  # type: ignore
     
     @inputs.setter
     def inputs(self, value: Union[None, List[str]]) -> None:
+        """Setter: Data sources for the chart
+    Deprecated! Use inputEdges instead."""
         self._inner_dict['inputs'] = value
     
     
     @property
     def inputEdges(self) -> Union[None, List["EdgeClass"]]:
-        """Data sources for the chart"""
+        """Getter: Data sources for the chart"""
         return self._inner_dict.get('inputEdges')  # type: ignore
     
     @inputEdges.setter
     def inputEdges(self, value: Union[None, List["EdgeClass"]]) -> None:
+        """Setter: Data sources for the chart"""
         self._inner_dict['inputEdges'] = value
     
     
     @property
     def type(self) -> Union[None, Union[str, "ChartTypeClass"]]:
-        """Type of the chart"""
+        """Getter: Type of the chart"""
         return self._inner_dict.get('type')  # type: ignore
     
     @type.setter
     def type(self, value: Union[None, Union[str, "ChartTypeClass"]]) -> None:
+        """Setter: Type of the chart"""
         self._inner_dict['type'] = value
     
     
     @property
     def access(self) -> Union[None, Union[str, "AccessLevelClass"]]:
-        """Access level for the chart"""
+        """Getter: Access level for the chart"""
         return self._inner_dict.get('access')  # type: ignore
     
     @access.setter
     def access(self, value: Union[None, Union[str, "AccessLevelClass"]]) -> None:
+        """Setter: Access level for the chart"""
         self._inner_dict['access'] = value
     
     
     @property
     def lastRefreshed(self) -> Union[None, int]:
-        """The time when this chart last refreshed"""
+        """Getter: The time when this chart last refreshed"""
         return self._inner_dict.get('lastRefreshed')  # type: ignore
     
     @lastRefreshed.setter
     def lastRefreshed(self, value: Union[None, int]) -> None:
+        """Setter: The time when this chart last refreshed"""
         self._inner_dict['lastRefreshed'] = value
     
     
 class ChartQueryClass(_Aspect):
     """Information for chart query which is used for getting data of the chart"""
 
 
@@ -1241,36 +1377,45 @@
         type: Union[str, "ChartQueryTypeClass"],
     ):
         super().__init__()
         
         self.rawQuery = rawQuery
         self.type = type
     
+    @classmethod
+    def construct_with_defaults(cls) -> "ChartQueryClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.rawQuery = str()
         self.type = ChartQueryTypeClass.LOOKML
     
     
     @property
     def rawQuery(self) -> str:
-        """Raw query to build a chart from input datasets"""
+        """Getter: Raw query to build a chart from input datasets"""
         return self._inner_dict.get('rawQuery')  # type: ignore
     
     @rawQuery.setter
     def rawQuery(self, value: str) -> None:
+        """Setter: Raw query to build a chart from input datasets"""
         self._inner_dict['rawQuery'] = value
     
     
     @property
     def type(self) -> Union[str, "ChartQueryTypeClass"]:
-        """Chart query type"""
+        """Getter: Chart query type"""
         return self._inner_dict.get('type')  # type: ignore
     
     @type.setter
     def type(self, value: Union[str, "ChartQueryTypeClass"]) -> None:
+        """Setter: Chart query type"""
         self._inner_dict['type'] = value
     
     
 class ChartQueryTypeClass(object):
     # No docs available.
     
     
@@ -1344,91 +1489,105 @@
         else:
             self.partitionSpec = partitionSpec
         self.messageId = messageId
         self.viewsCount = viewsCount
         self.uniqueUserCount = uniqueUserCount
         self.userCounts = userCounts
     
+    @classmethod
+    def construct_with_defaults(cls) -> "ChartUsageStatisticsClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.timestampMillis = int()
         self.eventGranularity = self.RECORD_SCHEMA.fields_dict["eventGranularity"].default
         self.partitionSpec = _json_converter.from_json_object(self.RECORD_SCHEMA.fields_dict["partitionSpec"].default, writers_schema=self.RECORD_SCHEMA.fields_dict["partitionSpec"].type)
         self.messageId = self.RECORD_SCHEMA.fields_dict["messageId"].default
         self.viewsCount = self.RECORD_SCHEMA.fields_dict["viewsCount"].default
         self.uniqueUserCount = self.RECORD_SCHEMA.fields_dict["uniqueUserCount"].default
         self.userCounts = self.RECORD_SCHEMA.fields_dict["userCounts"].default
     
     
     @property
     def timestampMillis(self) -> int:
-        """The event timestamp field as epoch at UTC in milli seconds."""
+        """Getter: The event timestamp field as epoch at UTC in milli seconds."""
         return self._inner_dict.get('timestampMillis')  # type: ignore
     
     @timestampMillis.setter
     def timestampMillis(self, value: int) -> None:
+        """Setter: The event timestamp field as epoch at UTC in milli seconds."""
         self._inner_dict['timestampMillis'] = value
     
     
     @property
     def eventGranularity(self) -> Union[None, "TimeWindowSizeClass"]:
-        """Granularity of the event if applicable"""
+        """Getter: Granularity of the event if applicable"""
         return self._inner_dict.get('eventGranularity')  # type: ignore
     
     @eventGranularity.setter
     def eventGranularity(self, value: Union[None, "TimeWindowSizeClass"]) -> None:
+        """Setter: Granularity of the event if applicable"""
         self._inner_dict['eventGranularity'] = value
     
     
     @property
     def partitionSpec(self) -> Union["PartitionSpecClass", None]:
-        """The optional partition specification."""
+        """Getter: The optional partition specification."""
         return self._inner_dict.get('partitionSpec')  # type: ignore
     
     @partitionSpec.setter
     def partitionSpec(self, value: Union["PartitionSpecClass", None]) -> None:
+        """Setter: The optional partition specification."""
         self._inner_dict['partitionSpec'] = value
     
     
     @property
     def messageId(self) -> Union[None, str]:
-        """The optional messageId, if provided serves as a custom user-defined unique identifier for an aspect value."""
+        """Getter: The optional messageId, if provided serves as a custom user-defined unique identifier for an aspect value."""
         return self._inner_dict.get('messageId')  # type: ignore
     
     @messageId.setter
     def messageId(self, value: Union[None, str]) -> None:
+        """Setter: The optional messageId, if provided serves as a custom user-defined unique identifier for an aspect value."""
         self._inner_dict['messageId'] = value
     
     
     @property
     def viewsCount(self) -> Union[None, int]:
-        """The total number of times chart has been viewed"""
+        """Getter: The total number of times chart has been viewed"""
         return self._inner_dict.get('viewsCount')  # type: ignore
     
     @viewsCount.setter
     def viewsCount(self, value: Union[None, int]) -> None:
+        """Setter: The total number of times chart has been viewed"""
         self._inner_dict['viewsCount'] = value
     
     
     @property
     def uniqueUserCount(self) -> Union[None, int]:
-        """Unique user count"""
+        """Getter: Unique user count"""
         return self._inner_dict.get('uniqueUserCount')  # type: ignore
     
     @uniqueUserCount.setter
     def uniqueUserCount(self, value: Union[None, int]) -> None:
+        """Setter: Unique user count"""
         self._inner_dict['uniqueUserCount'] = value
     
     
     @property
     def userCounts(self) -> Union[None, List["ChartUserUsageCountsClass"]]:
-        """Users within this bucket, with frequency counts"""
+        """Getter: Users within this bucket, with frequency counts"""
         return self._inner_dict.get('userCounts')  # type: ignore
     
     @userCounts.setter
     def userCounts(self, value: Union[None, List["ChartUserUsageCountsClass"]]) -> None:
+        """Setter: Users within this bucket, with frequency counts"""
         self._inner_dict['userCounts'] = value
     
     
 class ChartUserUsageCountsClass(DictWrapper):
     """Records a single user's usage counts for a given resource"""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.chart.ChartUserUsageCounts")
@@ -1437,36 +1596,45 @@
         viewsCount: Union[None, int]=None,
     ):
         super().__init__()
         
         self.user = user
         self.viewsCount = viewsCount
     
+    @classmethod
+    def construct_with_defaults(cls) -> "ChartUserUsageCountsClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.user = str()
         self.viewsCount = self.RECORD_SCHEMA.fields_dict["viewsCount"].default
     
     
     @property
     def user(self) -> str:
-        """The unique id of the user."""
+        """Getter: The unique id of the user."""
         return self._inner_dict.get('user')  # type: ignore
     
     @user.setter
     def user(self, value: str) -> None:
+        """Setter: The unique id of the user."""
         self._inner_dict['user'] = value
     
     
     @property
     def viewsCount(self) -> Union[None, int]:
-        """The number of times the user has viewed the chart"""
+        """Getter: The number of times the user has viewed the chart"""
         return self._inner_dict.get('viewsCount')  # type: ignore
     
     @viewsCount.setter
     def viewsCount(self, value: Union[None, int]) -> None:
+        """Setter: The number of times the user has viewed the chart"""
         self._inner_dict['viewsCount'] = value
     
     
 class EditableChartPropertiesClass(_Aspect):
     """Stores editable changes made to properties. This separates changes made from
     ingestion pipelines and edits in the UI to avoid accidental overwrites of user-provided data by ingestion pipelines"""
 
@@ -1492,58 +1660,69 @@
             # default: {'actor': 'urn:li:corpuser:unknown', 'impersonator': None, 'time': 0, 'message': None}
             self.lastModified = _json_converter.from_json_object(self.RECORD_SCHEMA.fields_dict["lastModified"].default, writers_schema=self.RECORD_SCHEMA.fields_dict["lastModified"].type)
         else:
             self.lastModified = lastModified
         self.deleted = deleted
         self.description = description
     
+    @classmethod
+    def construct_with_defaults(cls) -> "EditableChartPropertiesClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.created = _json_converter.from_json_object(self.RECORD_SCHEMA.fields_dict["created"].default, writers_schema=self.RECORD_SCHEMA.fields_dict["created"].type)
         self.lastModified = _json_converter.from_json_object(self.RECORD_SCHEMA.fields_dict["lastModified"].default, writers_schema=self.RECORD_SCHEMA.fields_dict["lastModified"].type)
         self.deleted = self.RECORD_SCHEMA.fields_dict["deleted"].default
         self.description = self.RECORD_SCHEMA.fields_dict["description"].default
     
     
     @property
     def created(self) -> "AuditStampClass":
-        """An AuditStamp corresponding to the creation of this resource/association/sub-resource. A value of 0 for time indicates missing data."""
+        """Getter: An AuditStamp corresponding to the creation of this resource/association/sub-resource. A value of 0 for time indicates missing data."""
         return self._inner_dict.get('created')  # type: ignore
     
     @created.setter
     def created(self, value: "AuditStampClass") -> None:
+        """Setter: An AuditStamp corresponding to the creation of this resource/association/sub-resource. A value of 0 for time indicates missing data."""
         self._inner_dict['created'] = value
     
     
     @property
     def lastModified(self) -> "AuditStampClass":
-        """An AuditStamp corresponding to the last modification of this resource/association/sub-resource. If no modification has happened since creation, lastModified should be the same as created. A value of 0 for time indicates missing data."""
+        """Getter: An AuditStamp corresponding to the last modification of this resource/association/sub-resource. If no modification has happened since creation, lastModified should be the same as created. A value of 0 for time indicates missing data."""
         return self._inner_dict.get('lastModified')  # type: ignore
     
     @lastModified.setter
     def lastModified(self, value: "AuditStampClass") -> None:
+        """Setter: An AuditStamp corresponding to the last modification of this resource/association/sub-resource. If no modification has happened since creation, lastModified should be the same as created. A value of 0 for time indicates missing data."""
         self._inner_dict['lastModified'] = value
     
     
     @property
     def deleted(self) -> Union[None, "AuditStampClass"]:
-        """An AuditStamp corresponding to the deletion of this resource/association/sub-resource. Logically, deleted MUST have a later timestamp than creation. It may or may not have the same time as lastModified depending upon the resource/association/sub-resource semantics."""
+        """Getter: An AuditStamp corresponding to the deletion of this resource/association/sub-resource. Logically, deleted MUST have a later timestamp than creation. It may or may not have the same time as lastModified depending upon the resource/association/sub-resource semantics."""
         return self._inner_dict.get('deleted')  # type: ignore
     
     @deleted.setter
     def deleted(self, value: Union[None, "AuditStampClass"]) -> None:
+        """Setter: An AuditStamp corresponding to the deletion of this resource/association/sub-resource. Logically, deleted MUST have a later timestamp than creation. It may or may not have the same time as lastModified depending upon the resource/association/sub-resource semantics."""
         self._inner_dict['deleted'] = value
     
     
     @property
     def description(self) -> Union[None, str]:
-        """Edited documentation of the chart """
+        """Getter: Edited documentation of the chart """
         return self._inner_dict.get('description')  # type: ignore
     
     @description.setter
     def description(self, value: Union[None, str]) -> None:
+        """Setter: Edited documentation of the chart """
         self._inner_dict['description'] = value
     
     
 class AccessLevelClass(object):
     """The various access levels"""
     
     
@@ -1567,58 +1746,69 @@
         super().__init__()
         
         self.time = time
         self.actor = actor
         self.impersonator = impersonator
         self.message = message
     
+    @classmethod
+    def construct_with_defaults(cls) -> "AuditStampClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.time = int()
         self.actor = str()
         self.impersonator = self.RECORD_SCHEMA.fields_dict["impersonator"].default
         self.message = self.RECORD_SCHEMA.fields_dict["message"].default
     
     
     @property
     def time(self) -> int:
-        """When did the resource/association/sub-resource move into the specific lifecycle stage represented by this AuditEvent."""
+        """Getter: When did the resource/association/sub-resource move into the specific lifecycle stage represented by this AuditEvent."""
         return self._inner_dict.get('time')  # type: ignore
     
     @time.setter
     def time(self, value: int) -> None:
+        """Setter: When did the resource/association/sub-resource move into the specific lifecycle stage represented by this AuditEvent."""
         self._inner_dict['time'] = value
     
     
     @property
     def actor(self) -> str:
-        """The entity (e.g. a member URN) which will be credited for moving the resource/association/sub-resource into the specific lifecycle stage. It is also the one used to authorize the change."""
+        """Getter: The entity (e.g. a member URN) which will be credited for moving the resource/association/sub-resource into the specific lifecycle stage. It is also the one used to authorize the change."""
         return self._inner_dict.get('actor')  # type: ignore
     
     @actor.setter
     def actor(self, value: str) -> None:
+        """Setter: The entity (e.g. a member URN) which will be credited for moving the resource/association/sub-resource into the specific lifecycle stage. It is also the one used to authorize the change."""
         self._inner_dict['actor'] = value
     
     
     @property
     def impersonator(self) -> Union[None, str]:
-        """The entity (e.g. a service URN) which performs the change on behalf of the Actor and must be authorized to act as the Actor."""
+        """Getter: The entity (e.g. a service URN) which performs the change on behalf of the Actor and must be authorized to act as the Actor."""
         return self._inner_dict.get('impersonator')  # type: ignore
     
     @impersonator.setter
     def impersonator(self, value: Union[None, str]) -> None:
+        """Setter: The entity (e.g. a service URN) which performs the change on behalf of the Actor and must be authorized to act as the Actor."""
         self._inner_dict['impersonator'] = value
     
     
     @property
     def message(self) -> Union[None, str]:
-        """Additional context around how DataHub was informed of the particular change. For example: was the change created by an automated process, or manually."""
+        """Getter: Additional context around how DataHub was informed of the particular change. For example: was the change created by an automated process, or manually."""
         return self._inner_dict.get('message')  # type: ignore
     
     @message.setter
     def message(self, value: Union[None, str]) -> None:
+        """Setter: Additional context around how DataHub was informed of the particular change. For example: was the change created by an automated process, or manually."""
         self._inner_dict['message'] = value
     
     
 class BrowsePathsClass(_Aspect):
     """Shared aspect containing Browse Paths to be indexed for an entity."""
 
 
@@ -1629,27 +1819,37 @@
     def __init__(self,
         paths: List[str],
     ):
         super().__init__()
         
         self.paths = paths
     
+    @classmethod
+    def construct_with_defaults(cls) -> "BrowsePathsClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.paths = list()
     
     
     @property
     def paths(self) -> List[str]:
-        """A list of valid browse paths for the entity.
+        """Getter: A list of valid browse paths for the entity.
     
     Browse paths are expected to be forward slash-separated strings. For example: 'prod/snowflake/datasetName'"""
         return self._inner_dict.get('paths')  # type: ignore
     
     @paths.setter
     def paths(self, value: List[str]) -> None:
+        """Setter: A list of valid browse paths for the entity.
+    
+    Browse paths are expected to be forward slash-separated strings. For example: 'prod/snowflake/datasetName'"""
         self._inner_dict['paths'] = value
     
     
 class ChangeAuditStampsClass(DictWrapper):
     """Data captured on a resource/association/sub-resource level giving insight into when that resource/association/sub-resource moved into various lifecycle stages, and who acted to move it into those lifecycle stages. The recommended best practice is to include this record in your record schema, and annotate its fields as @readOnly in your resource. See https://github.com/linkedin/rest.li/wiki/Validation-in-Rest.li#restli-validation-annotations"""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.common.ChangeAuditStamps")
@@ -1668,47 +1868,57 @@
         if lastModified is None:
             # default: {'actor': 'urn:li:corpuser:unknown', 'impersonator': None, 'time': 0, 'message': None}
             self.lastModified = _json_converter.from_json_object(self.RECORD_SCHEMA.fields_dict["lastModified"].default, writers_schema=self.RECORD_SCHEMA.fields_dict["lastModified"].type)
         else:
             self.lastModified = lastModified
         self.deleted = deleted
     
+    @classmethod
+    def construct_with_defaults(cls) -> "ChangeAuditStampsClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.created = _json_converter.from_json_object(self.RECORD_SCHEMA.fields_dict["created"].default, writers_schema=self.RECORD_SCHEMA.fields_dict["created"].type)
         self.lastModified = _json_converter.from_json_object(self.RECORD_SCHEMA.fields_dict["lastModified"].default, writers_schema=self.RECORD_SCHEMA.fields_dict["lastModified"].type)
         self.deleted = self.RECORD_SCHEMA.fields_dict["deleted"].default
     
     
     @property
     def created(self) -> "AuditStampClass":
-        """An AuditStamp corresponding to the creation of this resource/association/sub-resource. A value of 0 for time indicates missing data."""
+        """Getter: An AuditStamp corresponding to the creation of this resource/association/sub-resource. A value of 0 for time indicates missing data."""
         return self._inner_dict.get('created')  # type: ignore
     
     @created.setter
     def created(self, value: "AuditStampClass") -> None:
+        """Setter: An AuditStamp corresponding to the creation of this resource/association/sub-resource. A value of 0 for time indicates missing data."""
         self._inner_dict['created'] = value
     
     
     @property
     def lastModified(self) -> "AuditStampClass":
-        """An AuditStamp corresponding to the last modification of this resource/association/sub-resource. If no modification has happened since creation, lastModified should be the same as created. A value of 0 for time indicates missing data."""
+        """Getter: An AuditStamp corresponding to the last modification of this resource/association/sub-resource. If no modification has happened since creation, lastModified should be the same as created. A value of 0 for time indicates missing data."""
         return self._inner_dict.get('lastModified')  # type: ignore
     
     @lastModified.setter
     def lastModified(self, value: "AuditStampClass") -> None:
+        """Setter: An AuditStamp corresponding to the last modification of this resource/association/sub-resource. If no modification has happened since creation, lastModified should be the same as created. A value of 0 for time indicates missing data."""
         self._inner_dict['lastModified'] = value
     
     
     @property
     def deleted(self) -> Union[None, "AuditStampClass"]:
-        """An AuditStamp corresponding to the deletion of this resource/association/sub-resource. Logically, deleted MUST have a later timestamp than creation. It may or may not have the same time as lastModified depending upon the resource/association/sub-resource semantics."""
+        """Getter: An AuditStamp corresponding to the deletion of this resource/association/sub-resource. Logically, deleted MUST have a later timestamp than creation. It may or may not have the same time as lastModified depending upon the resource/association/sub-resource semantics."""
         return self._inner_dict.get('deleted')  # type: ignore
     
     @deleted.setter
     def deleted(self, value: Union[None, "AuditStampClass"]) -> None:
+        """Setter: An AuditStamp corresponding to the deletion of this resource/association/sub-resource. Logically, deleted MUST have a later timestamp than creation. It may or may not have the same time as lastModified depending upon the resource/association/sub-resource semantics."""
         self._inner_dict['deleted'] = value
     
     
 class CostClass(_Aspect):
     # No docs available.
 
 
@@ -1721,36 +1931,45 @@
         cost: "CostCostClass",
     ):
         super().__init__()
         
         self.costType = costType
         self.cost = cost
     
+    @classmethod
+    def construct_with_defaults(cls) -> "CostClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.costType = CostTypeClass.ORG_COST_TYPE
-        self.cost = CostCostClass._construct_with_defaults()
+        self.cost = CostCostClass.construct_with_defaults()
     
     
     @property
     def costType(self) -> Union[str, "CostTypeClass"]:
         # No docs available.
         return self._inner_dict.get('costType')  # type: ignore
     
     @costType.setter
     def costType(self, value: Union[str, "CostTypeClass"]) -> None:
+        # No docs available.
         self._inner_dict['costType'] = value
     
     
     @property
     def cost(self) -> "CostCostClass":
         # No docs available.
         return self._inner_dict.get('cost')  # type: ignore
     
     @cost.setter
     def cost(self, value: "CostCostClass") -> None:
+        # No docs available.
         self._inner_dict['cost'] = value
     
     
 class CostCostClass(DictWrapper):
     # No docs available.
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.common.CostCost")
@@ -1761,47 +1980,57 @@
     ):
         super().__init__()
         
         self.costId = costId
         self.costCode = costCode
         self.fieldDiscriminator = fieldDiscriminator
     
+    @classmethod
+    def construct_with_defaults(cls) -> "CostCostClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.costId = self.RECORD_SCHEMA.fields_dict["costId"].default
         self.costCode = self.RECORD_SCHEMA.fields_dict["costCode"].default
         self.fieldDiscriminator = CostCostDiscriminatorClass.costId
     
     
     @property
     def costId(self) -> Union[None, float]:
         # No docs available.
         return self._inner_dict.get('costId')  # type: ignore
     
     @costId.setter
     def costId(self, value: Union[None, float]) -> None:
+        # No docs available.
         self._inner_dict['costId'] = value
     
     
     @property
     def costCode(self) -> Union[None, str]:
         # No docs available.
         return self._inner_dict.get('costCode')  # type: ignore
     
     @costCode.setter
     def costCode(self, value: Union[None, str]) -> None:
+        # No docs available.
         self._inner_dict['costCode'] = value
     
     
     @property
     def fieldDiscriminator(self) -> Union[str, "CostCostDiscriminatorClass"]:
-        """Contains the name of the field that has its value set."""
+        """Getter: Contains the name of the field that has its value set."""
         return self._inner_dict.get('fieldDiscriminator')  # type: ignore
     
     @fieldDiscriminator.setter
     def fieldDiscriminator(self, value: Union[str, "CostCostDiscriminatorClass"]) -> None:
+        """Setter: Contains the name of the field that has its value set."""
         self._inner_dict['fieldDiscriminator'] = value
     
     
 class CostCostDiscriminatorClass(object):
     # No docs available.
     
     costId = "costId"
@@ -1829,36 +2058,45 @@
         instance: Union[None, str]=None,
     ):
         super().__init__()
         
         self.platform = platform
         self.instance = instance
     
+    @classmethod
+    def construct_with_defaults(cls) -> "DataPlatformInstanceClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.platform = str()
         self.instance = self.RECORD_SCHEMA.fields_dict["instance"].default
     
     
     @property
     def platform(self) -> str:
-        """Data Platform"""
+        """Getter: Data Platform"""
         return self._inner_dict.get('platform')  # type: ignore
     
     @platform.setter
     def platform(self, value: str) -> None:
+        """Setter: Data Platform"""
         self._inner_dict['platform'] = value
     
     
     @property
     def instance(self) -> Union[None, str]:
-        """Instance of the data platform (e.g. db instance)"""
+        """Getter: Instance of the data platform (e.g. db instance)"""
         return self._inner_dict.get('instance')  # type: ignore
     
     @instance.setter
     def instance(self, value: Union[None, str]) -> None:
+        """Setter: Instance of the data platform (e.g. db instance)"""
         self._inner_dict['instance'] = value
     
     
 class DeprecationClass(_Aspect):
     """Deprecation status of an entity"""
 
 
@@ -1875,58 +2113,69 @@
         super().__init__()
         
         self.deprecated = deprecated
         self.decommissionTime = decommissionTime
         self.note = note
         self.actor = actor
     
+    @classmethod
+    def construct_with_defaults(cls) -> "DeprecationClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.deprecated = bool()
         self.decommissionTime = self.RECORD_SCHEMA.fields_dict["decommissionTime"].default
         self.note = str()
         self.actor = str()
     
     
     @property
     def deprecated(self) -> bool:
-        """Whether the entity is deprecated."""
+        """Getter: Whether the entity is deprecated."""
         return self._inner_dict.get('deprecated')  # type: ignore
     
     @deprecated.setter
     def deprecated(self, value: bool) -> None:
+        """Setter: Whether the entity is deprecated."""
         self._inner_dict['deprecated'] = value
     
     
     @property
     def decommissionTime(self) -> Union[None, int]:
-        """The time user plan to decommission this entity."""
+        """Getter: The time user plan to decommission this entity."""
         return self._inner_dict.get('decommissionTime')  # type: ignore
     
     @decommissionTime.setter
     def decommissionTime(self, value: Union[None, int]) -> None:
+        """Setter: The time user plan to decommission this entity."""
         self._inner_dict['decommissionTime'] = value
     
     
     @property
     def note(self) -> str:
-        """Additional information about the entity deprecation plan, such as the wiki, doc, RB."""
+        """Getter: Additional information about the entity deprecation plan, such as the wiki, doc, RB."""
         return self._inner_dict.get('note')  # type: ignore
     
     @note.setter
     def note(self, value: str) -> None:
+        """Setter: Additional information about the entity deprecation plan, such as the wiki, doc, RB."""
         self._inner_dict['note'] = value
     
     
     @property
     def actor(self) -> str:
-        """The user URN which will be credited for modifying this deprecation content."""
+        """Getter: The user URN which will be credited for modifying this deprecation content."""
         return self._inner_dict.get('actor')  # type: ignore
     
     @actor.setter
     def actor(self, value: str) -> None:
+        """Setter: The user URN which will be credited for modifying this deprecation content."""
         self._inner_dict['actor'] = value
     
     
 class EdgeClass(DictWrapper):
     """Information about a relatonship edge."""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.common.Edge")
@@ -1941,69 +2190,81 @@
         
         self.sourceUrn = sourceUrn
         self.destinationUrn = destinationUrn
         self.created = created
         self.lastModified = lastModified
         self.properties = properties
     
+    @classmethod
+    def construct_with_defaults(cls) -> "EdgeClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.sourceUrn = str()
         self.destinationUrn = str()
-        self.created = AuditStampClass._construct_with_defaults()
-        self.lastModified = AuditStampClass._construct_with_defaults()
+        self.created = AuditStampClass.construct_with_defaults()
+        self.lastModified = AuditStampClass.construct_with_defaults()
         self.properties = self.RECORD_SCHEMA.fields_dict["properties"].default
     
     
     @property
     def sourceUrn(self) -> str:
-        """Urn of the source of this relationship edge."""
+        """Getter: Urn of the source of this relationship edge."""
         return self._inner_dict.get('sourceUrn')  # type: ignore
     
     @sourceUrn.setter
     def sourceUrn(self, value: str) -> None:
+        """Setter: Urn of the source of this relationship edge."""
         self._inner_dict['sourceUrn'] = value
     
     
     @property
     def destinationUrn(self) -> str:
-        """Urn of the destination of this relationship edge."""
+        """Getter: Urn of the destination of this relationship edge."""
         return self._inner_dict.get('destinationUrn')  # type: ignore
     
     @destinationUrn.setter
     def destinationUrn(self, value: str) -> None:
+        """Setter: Urn of the destination of this relationship edge."""
         self._inner_dict['destinationUrn'] = value
     
     
     @property
     def created(self) -> "AuditStampClass":
-        """Audit stamp containing who created this relationship edge and when"""
+        """Getter: Audit stamp containing who created this relationship edge and when"""
         return self._inner_dict.get('created')  # type: ignore
     
     @created.setter
     def created(self, value: "AuditStampClass") -> None:
+        """Setter: Audit stamp containing who created this relationship edge and when"""
         self._inner_dict['created'] = value
     
     
     @property
     def lastModified(self) -> "AuditStampClass":
-        """Audit stamp containing who last modified this relationship edge and when"""
+        """Getter: Audit stamp containing who last modified this relationship edge and when"""
         return self._inner_dict.get('lastModified')  # type: ignore
     
     @lastModified.setter
     def lastModified(self, value: "AuditStampClass") -> None:
+        """Setter: Audit stamp containing who last modified this relationship edge and when"""
         self._inner_dict['lastModified'] = value
     
     
     @property
     def properties(self) -> Union[None, Dict[str, str]]:
-        """A generic properties bag that allows us to store specific information on this graph edge."""
+        """Getter: A generic properties bag that allows us to store specific information on this graph edge."""
         return self._inner_dict.get('properties')  # type: ignore
     
     @properties.setter
     def properties(self, value: Union[None, Dict[str, str]]) -> None:
+        """Setter: A generic properties bag that allows us to store specific information on this graph edge."""
         self._inner_dict['properties'] = value
     
     
 class EmbedClass(_Aspect):
     """Information regarding rendering an embed for an asset."""
 
 
@@ -2014,25 +2275,33 @@
     def __init__(self,
         renderUrl: Union[None, str]=None,
     ):
         super().__init__()
         
         self.renderUrl = renderUrl
     
+    @classmethod
+    def construct_with_defaults(cls) -> "EmbedClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.renderUrl = self.RECORD_SCHEMA.fields_dict["renderUrl"].default
     
     
     @property
     def renderUrl(self) -> Union[None, str]:
-        """An embed URL to be rendered inside of an iframe."""
+        """Getter: An embed URL to be rendered inside of an iframe."""
         return self._inner_dict.get('renderUrl')  # type: ignore
     
     @renderUrl.setter
     def renderUrl(self, value: Union[None, str]) -> None:
+        """Setter: An embed URL to be rendered inside of an iframe."""
         self._inner_dict['renderUrl'] = value
     
     
 class FabricTypeClass(object):
     """Fabric group type"""
     
     
@@ -2078,25 +2347,33 @@
     def __init__(self,
         tags: List["TagAssociationClass"],
     ):
         super().__init__()
         
         self.tags = tags
     
+    @classmethod
+    def construct_with_defaults(cls) -> "GlobalTagsClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.tags = list()
     
     
     @property
     def tags(self) -> List["TagAssociationClass"]:
-        """Tags associated with a given entity"""
+        """Getter: Tags associated with a given entity"""
         return self._inner_dict.get('tags')  # type: ignore
     
     @tags.setter
     def tags(self, value: List["TagAssociationClass"]) -> None:
+        """Setter: Tags associated with a given entity"""
         self._inner_dict['tags'] = value
     
     
 class GlossaryTermAssociationClass(DictWrapper):
     """Properties of an applied glossary term."""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.common.GlossaryTermAssociation")
@@ -2105,36 +2382,45 @@
         context: Union[None, str]=None,
     ):
         super().__init__()
         
         self.urn = urn
         self.context = context
     
+    @classmethod
+    def construct_with_defaults(cls) -> "GlossaryTermAssociationClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.urn = str()
         self.context = self.RECORD_SCHEMA.fields_dict["context"].default
     
     
     @property
     def urn(self) -> str:
-        """Urn of the applied glossary term"""
+        """Getter: Urn of the applied glossary term"""
         return self._inner_dict.get('urn')  # type: ignore
     
     @urn.setter
     def urn(self, value: str) -> None:
+        """Setter: Urn of the applied glossary term"""
         self._inner_dict['urn'] = value
     
     
     @property
     def context(self) -> Union[None, str]:
-        """Additional context about the association"""
+        """Getter: Additional context about the association"""
         return self._inner_dict.get('context')  # type: ignore
     
     @context.setter
     def context(self, value: Union[None, str]) -> None:
+        """Setter: Additional context about the association"""
         self._inner_dict['context'] = value
     
     
 class GlossaryTermsClass(_Aspect):
     """Related business terms information"""
 
 
@@ -2147,36 +2433,45 @@
         auditStamp: "AuditStampClass",
     ):
         super().__init__()
         
         self.terms = terms
         self.auditStamp = auditStamp
     
+    @classmethod
+    def construct_with_defaults(cls) -> "GlossaryTermsClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.terms = list()
-        self.auditStamp = AuditStampClass._construct_with_defaults()
+        self.auditStamp = AuditStampClass.construct_with_defaults()
     
     
     @property
     def terms(self) -> List["GlossaryTermAssociationClass"]:
-        """The related business terms"""
+        """Getter: The related business terms"""
         return self._inner_dict.get('terms')  # type: ignore
     
     @terms.setter
     def terms(self, value: List["GlossaryTermAssociationClass"]) -> None:
+        """Setter: The related business terms"""
         self._inner_dict['terms'] = value
     
     
     @property
     def auditStamp(self) -> "AuditStampClass":
-        """Audit stamp containing who reported the related business term"""
+        """Getter: Audit stamp containing who reported the related business term"""
         return self._inner_dict.get('auditStamp')  # type: ignore
     
     @auditStamp.setter
     def auditStamp(self, value: "AuditStampClass") -> None:
+        """Setter: Audit stamp containing who reported the related business term"""
         self._inner_dict['auditStamp'] = value
     
     
 class InputFieldClass(DictWrapper):
     """Information about a field a chart or dashboard references"""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.common.InputField")
@@ -2185,36 +2480,45 @@
         schemaField: Union[None, "SchemaFieldClass"]=None,
     ):
         super().__init__()
         
         self.schemaFieldUrn = schemaFieldUrn
         self.schemaField = schemaField
     
+    @classmethod
+    def construct_with_defaults(cls) -> "InputFieldClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.schemaFieldUrn = str()
         self.schemaField = self.RECORD_SCHEMA.fields_dict["schemaField"].default
     
     
     @property
     def schemaFieldUrn(self) -> str:
-        """Urn of the schema being referenced for lineage purposes"""
+        """Getter: Urn of the schema being referenced for lineage purposes"""
         return self._inner_dict.get('schemaFieldUrn')  # type: ignore
     
     @schemaFieldUrn.setter
     def schemaFieldUrn(self, value: str) -> None:
+        """Setter: Urn of the schema being referenced for lineage purposes"""
         self._inner_dict['schemaFieldUrn'] = value
     
     
     @property
     def schemaField(self) -> Union[None, "SchemaFieldClass"]:
-        """Copied version of the referenced schema field object for indexing purposes"""
+        """Getter: Copied version of the referenced schema field object for indexing purposes"""
         return self._inner_dict.get('schemaField')  # type: ignore
     
     @schemaField.setter
     def schemaField(self, value: Union[None, "SchemaFieldClass"]) -> None:
+        """Setter: Copied version of the referenced schema field object for indexing purposes"""
         self._inner_dict['schemaField'] = value
     
     
 class InputFieldsClass(_Aspect):
     """Information about the fields a chart or dashboard references"""
 
 
@@ -2225,25 +2529,33 @@
     def __init__(self,
         fields: List["InputFieldClass"],
     ):
         super().__init__()
         
         self.fields = fields
     
+    @classmethod
+    def construct_with_defaults(cls) -> "InputFieldsClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.fields = list()
     
     
     @property
     def fields(self) -> List["InputFieldClass"]:
-        """List of fields being referenced"""
+        """Getter: List of fields being referenced"""
         return self._inner_dict.get('fields')  # type: ignore
     
     @fields.setter
     def fields(self, value: List["InputFieldClass"]) -> None:
+        """Setter: List of fields being referenced"""
         self._inner_dict['fields'] = value
     
     
 class InstitutionalMemoryClass(_Aspect):
     """Institutional memory of an entity. This is a way to link to relevant documentation and provide description of the documentation. Institutional or tribal knowledge is very important for users to leverage the entity."""
 
 
@@ -2254,25 +2566,33 @@
     def __init__(self,
         elements: List["InstitutionalMemoryMetadataClass"],
     ):
         super().__init__()
         
         self.elements = elements
     
+    @classmethod
+    def construct_with_defaults(cls) -> "InstitutionalMemoryClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.elements = list()
     
     
     @property
     def elements(self) -> List["InstitutionalMemoryMetadataClass"]:
-        """List of records that represent institutional memory of an entity. Each record consists of a link, description, creator and timestamps associated with that record."""
+        """Getter: List of records that represent institutional memory of an entity. Each record consists of a link, description, creator and timestamps associated with that record."""
         return self._inner_dict.get('elements')  # type: ignore
     
     @elements.setter
     def elements(self, value: List["InstitutionalMemoryMetadataClass"]) -> None:
+        """Setter: List of records that represent institutional memory of an entity. Each record consists of a link, description, creator and timestamps associated with that record."""
         self._inner_dict['elements'] = value
     
     
 class InstitutionalMemoryMetadataClass(DictWrapper):
     """Metadata corresponding to a record of institutional memory."""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.common.InstitutionalMemoryMetadata")
@@ -2283,47 +2603,57 @@
     ):
         super().__init__()
         
         self.url = url
         self.description = description
         self.createStamp = createStamp
     
+    @classmethod
+    def construct_with_defaults(cls) -> "InstitutionalMemoryMetadataClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.url = str()
         self.description = str()
-        self.createStamp = AuditStampClass._construct_with_defaults()
+        self.createStamp = AuditStampClass.construct_with_defaults()
     
     
     @property
     def url(self) -> str:
-        """Link to an engineering design document or a wiki page."""
+        """Getter: Link to an engineering design document or a wiki page."""
         return self._inner_dict.get('url')  # type: ignore
     
     @url.setter
     def url(self, value: str) -> None:
+        """Setter: Link to an engineering design document or a wiki page."""
         self._inner_dict['url'] = value
     
     
     @property
     def description(self) -> str:
-        """Description of the link."""
+        """Getter: Description of the link."""
         return self._inner_dict.get('description')  # type: ignore
     
     @description.setter
     def description(self, value: str) -> None:
+        """Setter: Description of the link."""
         self._inner_dict['description'] = value
     
     
     @property
     def createStamp(self) -> "AuditStampClass":
-        """Audit stamp associated with creation of this record"""
+        """Getter: Audit stamp associated with creation of this record"""
         return self._inner_dict.get('createStamp')  # type: ignore
     
     @createStamp.setter
     def createStamp(self, value: "AuditStampClass") -> None:
+        """Setter: Audit stamp associated with creation of this record"""
         self._inner_dict['createStamp'] = value
     
     
 class MLFeatureDataTypeClass(object):
     """MLFeature Data Type"""
     
     
@@ -2394,36 +2724,45 @@
         location: str,
     ):
         super().__init__()
         
         self.type = type
         self.location = location
     
+    @classmethod
+    def construct_with_defaults(cls) -> "MediaClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.type = MediaTypeClass.IMAGE
         self.location = str()
     
     
     @property
     def type(self) -> Union[str, "MediaTypeClass"]:
-        """Type of content the Media is storing, e.g. image, video, etc."""
+        """Getter: Type of content the Media is storing, e.g. image, video, etc."""
         return self._inner_dict.get('type')  # type: ignore
     
     @type.setter
     def type(self, value: Union[str, "MediaTypeClass"]) -> None:
+        """Setter: Type of content the Media is storing, e.g. image, video, etc."""
         self._inner_dict['type'] = value
     
     
     @property
     def location(self) -> str:
-        """Where the media content is stored."""
+        """Getter: Where the media content is stored."""
         return self._inner_dict.get('location')  # type: ignore
     
     @location.setter
     def location(self, value: str) -> None:
+        """Setter: Where the media content is stored."""
         self._inner_dict['location'] = value
     
     
 class MediaTypeClass(object):
     """Enum defining the type of content a Media object holds."""
     
     
@@ -2469,14 +2808,21 @@
         self.customOperationType = customOperationType
         self.numAffectedRows = numAffectedRows
         self.affectedDatasets = affectedDatasets
         self.sourceType = sourceType
         self.customProperties = customProperties
         self.lastUpdatedTimestamp = lastUpdatedTimestamp
     
+    @classmethod
+    def construct_with_defaults(cls) -> "OperationClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.timestampMillis = int()
         self.eventGranularity = self.RECORD_SCHEMA.fields_dict["eventGranularity"].default
         self.partitionSpec = _json_converter.from_json_object(self.RECORD_SCHEMA.fields_dict["partitionSpec"].default, writers_schema=self.RECORD_SCHEMA.fields_dict["partitionSpec"].type)
         self.messageId = self.RECORD_SCHEMA.fields_dict["messageId"].default
         self.actor = self.RECORD_SCHEMA.fields_dict["actor"].default
         self.operationType = OperationTypeClass.INSERT
@@ -2486,129 +2832,141 @@
         self.sourceType = self.RECORD_SCHEMA.fields_dict["sourceType"].default
         self.customProperties = self.RECORD_SCHEMA.fields_dict["customProperties"].default
         self.lastUpdatedTimestamp = int()
     
     
     @property
     def timestampMillis(self) -> int:
-        """The event timestamp field as epoch at UTC in milli seconds."""
+        """Getter: The event timestamp field as epoch at UTC in milli seconds."""
         return self._inner_dict.get('timestampMillis')  # type: ignore
     
     @timestampMillis.setter
     def timestampMillis(self, value: int) -> None:
+        """Setter: The event timestamp field as epoch at UTC in milli seconds."""
         self._inner_dict['timestampMillis'] = value
     
     
     @property
     def eventGranularity(self) -> Union[None, "TimeWindowSizeClass"]:
-        """Granularity of the event if applicable"""
+        """Getter: Granularity of the event if applicable"""
         return self._inner_dict.get('eventGranularity')  # type: ignore
     
     @eventGranularity.setter
     def eventGranularity(self, value: Union[None, "TimeWindowSizeClass"]) -> None:
+        """Setter: Granularity of the event if applicable"""
         self._inner_dict['eventGranularity'] = value
     
     
     @property
     def partitionSpec(self) -> Union["PartitionSpecClass", None]:
-        """The optional partition specification."""
+        """Getter: The optional partition specification."""
         return self._inner_dict.get('partitionSpec')  # type: ignore
     
     @partitionSpec.setter
     def partitionSpec(self, value: Union["PartitionSpecClass", None]) -> None:
+        """Setter: The optional partition specification."""
         self._inner_dict['partitionSpec'] = value
     
     
     @property
     def messageId(self) -> Union[None, str]:
-        """The optional messageId, if provided serves as a custom user-defined unique identifier for an aspect value."""
+        """Getter: The optional messageId, if provided serves as a custom user-defined unique identifier for an aspect value."""
         return self._inner_dict.get('messageId')  # type: ignore
     
     @messageId.setter
     def messageId(self, value: Union[None, str]) -> None:
+        """Setter: The optional messageId, if provided serves as a custom user-defined unique identifier for an aspect value."""
         self._inner_dict['messageId'] = value
     
     
     @property
     def actor(self) -> Union[None, str]:
-        """Actor who issued this operation."""
+        """Getter: Actor who issued this operation."""
         return self._inner_dict.get('actor')  # type: ignore
     
     @actor.setter
     def actor(self, value: Union[None, str]) -> None:
+        """Setter: Actor who issued this operation."""
         self._inner_dict['actor'] = value
     
     
     @property
     def operationType(self) -> Union[str, "OperationTypeClass"]:
-        """Operation type of change."""
+        """Getter: Operation type of change."""
         return self._inner_dict.get('operationType')  # type: ignore
     
     @operationType.setter
     def operationType(self, value: Union[str, "OperationTypeClass"]) -> None:
+        """Setter: Operation type of change."""
         self._inner_dict['operationType'] = value
     
     
     @property
     def customOperationType(self) -> Union[None, str]:
-        """A custom type of operation. Required if operationType is CUSTOM."""
+        """Getter: A custom type of operation. Required if operationType is CUSTOM."""
         return self._inner_dict.get('customOperationType')  # type: ignore
     
     @customOperationType.setter
     def customOperationType(self, value: Union[None, str]) -> None:
+        """Setter: A custom type of operation. Required if operationType is CUSTOM."""
         self._inner_dict['customOperationType'] = value
     
     
     @property
     def numAffectedRows(self) -> Union[None, int]:
-        """How many rows were affected by this operation."""
+        """Getter: How many rows were affected by this operation."""
         return self._inner_dict.get('numAffectedRows')  # type: ignore
     
     @numAffectedRows.setter
     def numAffectedRows(self, value: Union[None, int]) -> None:
+        """Setter: How many rows were affected by this operation."""
         self._inner_dict['numAffectedRows'] = value
     
     
     @property
     def affectedDatasets(self) -> Union[None, List[str]]:
-        """Which other datasets were affected by this operation."""
+        """Getter: Which other datasets were affected by this operation."""
         return self._inner_dict.get('affectedDatasets')  # type: ignore
     
     @affectedDatasets.setter
     def affectedDatasets(self, value: Union[None, List[str]]) -> None:
+        """Setter: Which other datasets were affected by this operation."""
         self._inner_dict['affectedDatasets'] = value
     
     
     @property
     def sourceType(self) -> Union[None, Union[str, "OperationSourceTypeClass"]]:
-        """Source Type"""
+        """Getter: Source Type"""
         return self._inner_dict.get('sourceType')  # type: ignore
     
     @sourceType.setter
     def sourceType(self, value: Union[None, Union[str, "OperationSourceTypeClass"]]) -> None:
+        """Setter: Source Type"""
         self._inner_dict['sourceType'] = value
     
     
     @property
     def customProperties(self) -> Union[None, Dict[str, str]]:
-        """Custom properties"""
+        """Getter: Custom properties"""
         return self._inner_dict.get('customProperties')  # type: ignore
     
     @customProperties.setter
     def customProperties(self, value: Union[None, Dict[str, str]]) -> None:
+        """Setter: Custom properties"""
         self._inner_dict['customProperties'] = value
     
     
     @property
     def lastUpdatedTimestamp(self) -> int:
-        """The time at which the operation occurred. Would be better named 'operationTime'"""
+        """Getter: The time at which the operation occurred. Would be better named 'operationTime'"""
         return self._inner_dict.get('lastUpdatedTimestamp')  # type: ignore
     
     @lastUpdatedTimestamp.setter
     def lastUpdatedTimestamp(self, value: int) -> None:
+        """Setter: The time at which the operation occurred. Would be better named 'operationTime'"""
         self._inner_dict['lastUpdatedTimestamp'] = value
     
     
 class OperationSourceTypeClass(object):
     """The source of an operation"""
     
     
@@ -2660,36 +3018,45 @@
         externalType: Union[None, str]=None,
     ):
         super().__init__()
         
         self.type = type
         self.externalType = externalType
     
+    @classmethod
+    def construct_with_defaults(cls) -> "OriginClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.type = OriginTypeClass.NATIVE
         self.externalType = self.RECORD_SCHEMA.fields_dict["externalType"].default
     
     
     @property
     def type(self) -> Union[str, "OriginTypeClass"]:
-        """Where an entity originated from. Either NATIVE or EXTERNAL."""
+        """Getter: Where an entity originated from. Either NATIVE or EXTERNAL."""
         return self._inner_dict.get('type')  # type: ignore
     
     @type.setter
     def type(self, value: Union[str, "OriginTypeClass"]) -> None:
+        """Setter: Where an entity originated from. Either NATIVE or EXTERNAL."""
         self._inner_dict['type'] = value
     
     
     @property
     def externalType(self) -> Union[None, str]:
-        """Only populated if type is EXTERNAL. The externalType of the entity, such as the name of the identity provider."""
+        """Getter: Only populated if type is EXTERNAL. The externalType of the entity, such as the name of the identity provider."""
         return self._inner_dict.get('externalType')  # type: ignore
     
     @externalType.setter
     def externalType(self, value: Union[None, str]) -> None:
+        """Setter: Only populated if type is EXTERNAL. The externalType of the entity, such as the name of the identity provider."""
         self._inner_dict['externalType'] = value
     
     
 class OriginTypeClass(object):
     """Enum to define where an entity originated from."""
     
     
@@ -2711,48 +3078,59 @@
     ):
         super().__init__()
         
         self.owner = owner
         self.type = type
         self.source = source
     
+    @classmethod
+    def construct_with_defaults(cls) -> "OwnerClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.owner = str()
         self.type = OwnershipTypeClass.TECHNICAL_OWNER
         self.source = self.RECORD_SCHEMA.fields_dict["source"].default
     
     
     @property
     def owner(self) -> str:
-        """Owner URN, e.g. urn:li:corpuser:ldap, urn:li:corpGroup:group_name, and urn:li:multiProduct:mp_name
+        """Getter: Owner URN, e.g. urn:li:corpuser:ldap, urn:li:corpGroup:group_name, and urn:li:multiProduct:mp_name
     (Caveat: only corpuser is currently supported in the frontend.)"""
         return self._inner_dict.get('owner')  # type: ignore
     
     @owner.setter
     def owner(self, value: str) -> None:
+        """Setter: Owner URN, e.g. urn:li:corpuser:ldap, urn:li:corpGroup:group_name, and urn:li:multiProduct:mp_name
+    (Caveat: only corpuser is currently supported in the frontend.)"""
         self._inner_dict['owner'] = value
     
     
     @property
     def type(self) -> Union[str, "OwnershipTypeClass"]:
-        """The type of the ownership"""
+        """Getter: The type of the ownership"""
         return self._inner_dict.get('type')  # type: ignore
     
     @type.setter
     def type(self, value: Union[str, "OwnershipTypeClass"]) -> None:
+        """Setter: The type of the ownership"""
         self._inner_dict['type'] = value
     
     
     @property
     def source(self) -> Union[None, "OwnershipSourceClass"]:
-        """Source information for the ownership"""
+        """Getter: Source information for the ownership"""
         return self._inner_dict.get('source')  # type: ignore
     
     @source.setter
     def source(self, value: Union[None, "OwnershipSourceClass"]) -> None:
+        """Setter: Source information for the ownership"""
         self._inner_dict['source'] = value
     
     
 class OwnershipClass(_Aspect):
     """Ownership information of an entity."""
 
 
@@ -2769,36 +3147,45 @@
         self.owners = owners
         if lastModified is None:
             # default: {'actor': 'urn:li:corpuser:unknown', 'impersonator': None, 'time': 0, 'message': None}
             self.lastModified = _json_converter.from_json_object(self.RECORD_SCHEMA.fields_dict["lastModified"].default, writers_schema=self.RECORD_SCHEMA.fields_dict["lastModified"].type)
         else:
             self.lastModified = lastModified
     
+    @classmethod
+    def construct_with_defaults(cls) -> "OwnershipClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.owners = list()
         self.lastModified = _json_converter.from_json_object(self.RECORD_SCHEMA.fields_dict["lastModified"].default, writers_schema=self.RECORD_SCHEMA.fields_dict["lastModified"].type)
     
     
     @property
     def owners(self) -> List["OwnerClass"]:
-        """List of owners of the entity."""
+        """Getter: List of owners of the entity."""
         return self._inner_dict.get('owners')  # type: ignore
     
     @owners.setter
     def owners(self, value: List["OwnerClass"]) -> None:
+        """Setter: List of owners of the entity."""
         self._inner_dict['owners'] = value
     
     
     @property
     def lastModified(self) -> "AuditStampClass":
-        """Audit stamp containing who last modified the record and when. A value of 0 in the time field indicates missing data."""
+        """Getter: Audit stamp containing who last modified the record and when. A value of 0 in the time field indicates missing data."""
         return self._inner_dict.get('lastModified')  # type: ignore
     
     @lastModified.setter
     def lastModified(self, value: "AuditStampClass") -> None:
+        """Setter: Audit stamp containing who last modified the record and when. A value of 0 in the time field indicates missing data."""
         self._inner_dict['lastModified'] = value
     
     
 class OwnershipSourceClass(DictWrapper):
     """Source/provider of the ownership information"""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.common.OwnershipSource")
@@ -2807,36 +3194,45 @@
         url: Union[None, str]=None,
     ):
         super().__init__()
         
         self.type = type
         self.url = url
     
+    @classmethod
+    def construct_with_defaults(cls) -> "OwnershipSourceClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.type = OwnershipSourceTypeClass.AUDIT
         self.url = self.RECORD_SCHEMA.fields_dict["url"].default
     
     
     @property
     def type(self) -> Union[str, "OwnershipSourceTypeClass"]:
-        """The type of the source"""
+        """Getter: The type of the source"""
         return self._inner_dict.get('type')  # type: ignore
     
     @type.setter
     def type(self, value: Union[str, "OwnershipSourceTypeClass"]) -> None:
+        """Setter: The type of the source"""
         self._inner_dict['type'] = value
     
     
     @property
     def url(self) -> Union[None, str]:
-        """A reference URL for the source"""
+        """Getter: A reference URL for the source"""
         return self._inner_dict.get('url')  # type: ignore
     
     @url.setter
     def url(self, value: Union[None, str]) -> None:
+        """Setter: A reference URL for the source"""
         self._inner_dict['url'] = value
     
     
 class OwnershipSourceTypeClass(object):
     # No docs available.
     
     
@@ -2919,36 +3315,45 @@
         primary: bool,
     ):
         super().__init__()
         
         self.siblings = siblings
         self.primary = primary
     
+    @classmethod
+    def construct_with_defaults(cls) -> "SiblingsClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.siblings = list()
         self.primary = bool()
     
     
     @property
     def siblings(self) -> List[str]:
-        """List of sibling entities"""
+        """Getter: List of sibling entities"""
         return self._inner_dict.get('siblings')  # type: ignore
     
     @siblings.setter
     def siblings(self, value: List[str]) -> None:
+        """Setter: List of sibling entities"""
         self._inner_dict['siblings'] = value
     
     
     @property
     def primary(self) -> bool:
-        """If this is the leader entity of the set of siblings"""
+        """Getter: If this is the leader entity of the set of siblings"""
         return self._inner_dict.get('primary')  # type: ignore
     
     @primary.setter
     def primary(self, value: bool) -> None:
+        """Setter: If this is the leader entity of the set of siblings"""
         self._inner_dict['primary'] = value
     
     
 class StatusClass(_Aspect):
     """The lifecycle status metadata of an entity, e.g. dataset, metric, feature, etc.
     This aspect is used to represent soft deletes conventionally."""
 
@@ -2964,25 +3369,33 @@
         
         if removed is None:
             # default: False
             self.removed = self.RECORD_SCHEMA.fields_dict["removed"].default
         else:
             self.removed = removed
     
+    @classmethod
+    def construct_with_defaults(cls) -> "StatusClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.removed = self.RECORD_SCHEMA.fields_dict["removed"].default
     
     
     @property
     def removed(self) -> bool:
-        """Whether the entity has been removed (soft-deleted)."""
+        """Getter: Whether the entity has been removed (soft-deleted)."""
         return self._inner_dict.get('removed')  # type: ignore
     
     @removed.setter
     def removed(self, value: bool) -> None:
+        """Setter: Whether the entity has been removed (soft-deleted)."""
         self._inner_dict['removed'] = value
     
     
 class SubTypesClass(_Aspect):
     """Sub Types. Use this aspect to specialize a generic Entity
     e.g. Making a Dataset also be a View or also be a LookerExplore"""
 
@@ -2994,25 +3407,33 @@
     def __init__(self,
         typeNames: List[str],
     ):
         super().__init__()
         
         self.typeNames = typeNames
     
+    @classmethod
+    def construct_with_defaults(cls) -> "SubTypesClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.typeNames = list()
     
     
     @property
     def typeNames(self) -> List[str]:
-        """The names of the specific types."""
+        """Getter: The names of the specific types."""
         return self._inner_dict.get('typeNames')  # type: ignore
     
     @typeNames.setter
     def typeNames(self, value: List[str]) -> None:
+        """Setter: The names of the specific types."""
         self._inner_dict['typeNames'] = value
     
     
 class TagAssociationClass(DictWrapper):
     """Properties of an applied tag. For now, just an Urn. In the future we can extend this with other properties, e.g.
     propagation parameters."""
     
@@ -3022,36 +3443,45 @@
         context: Union[None, str]=None,
     ):
         super().__init__()
         
         self.tag = tag
         self.context = context
     
+    @classmethod
+    def construct_with_defaults(cls) -> "TagAssociationClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.tag = str()
         self.context = self.RECORD_SCHEMA.fields_dict["context"].default
     
     
     @property
     def tag(self) -> str:
-        """Urn of the applied tag"""
+        """Getter: Urn of the applied tag"""
         return self._inner_dict.get('tag')  # type: ignore
     
     @tag.setter
     def tag(self, value: str) -> None:
+        """Setter: Urn of the applied tag"""
         self._inner_dict['tag'] = value
     
     
     @property
     def context(self) -> Union[None, str]:
-        """Additional context about the association"""
+        """Getter: Additional context about the association"""
         return self._inner_dict.get('context')  # type: ignore
     
     @context.setter
     def context(self, value: Union[None, str]) -> None:
+        """Setter: Additional context about the association"""
         self._inner_dict['context'] = value
     
     
 class TimeStampClass(DictWrapper):
     """A standard event timestamp"""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.common.TimeStamp")
@@ -3060,61 +3490,78 @@
         actor: Union[None, str]=None,
     ):
         super().__init__()
         
         self.time = time
         self.actor = actor
     
+    @classmethod
+    def construct_with_defaults(cls) -> "TimeStampClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.time = int()
         self.actor = self.RECORD_SCHEMA.fields_dict["actor"].default
     
     
     @property
     def time(self) -> int:
-        """When did the event occur"""
+        """Getter: When did the event occur"""
         return self._inner_dict.get('time')  # type: ignore
     
     @time.setter
     def time(self, value: int) -> None:
+        """Setter: When did the event occur"""
         self._inner_dict['time'] = value
     
     
     @property
     def actor(self) -> Union[None, str]:
-        """Optional: The actor urn involved in the event."""
+        """Getter: Optional: The actor urn involved in the event."""
         return self._inner_dict.get('actor')  # type: ignore
     
     @actor.setter
     def actor(self, value: Union[None, str]) -> None:
+        """Setter: Optional: The actor urn involved in the event."""
         self._inner_dict['actor'] = value
     
     
 class VersionTagClass(DictWrapper):
     """A resource-defined string representing the resource state for the purpose of concurrency control"""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.common.VersionTag")
     def __init__(self,
         versionTag: Union[None, str]=None,
     ):
         super().__init__()
         
         self.versionTag = versionTag
     
+    @classmethod
+    def construct_with_defaults(cls) -> "VersionTagClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.versionTag = self.RECORD_SCHEMA.fields_dict["versionTag"].default
     
     
     @property
     def versionTag(self) -> Union[None, str]:
         # No docs available.
         return self._inner_dict.get('versionTag')  # type: ignore
     
     @versionTag.setter
     def versionTag(self, value: Union[None, str]) -> None:
+        # No docs available.
         self._inner_dict['versionTag'] = value
     
     
 class WindowDurationClass(object):
     """Enum to define the length of a bucket when doing aggregations"""
     
     YEAR = "YEAR"
@@ -3142,25 +3589,33 @@
     def __init__(self,
         udf: str,
     ):
         super().__init__()
         
         self.udf = udf
     
+    @classmethod
+    def construct_with_defaults(cls) -> "UDFTransformerClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.udf = str()
     
     
     @property
     def udf(self) -> str:
-        """A UDF mentioning how the source fields got transformed to destination field. This is the FQCN(Fully Qualified Class Name) of the udf."""
+        """Getter: A UDF mentioning how the source fields got transformed to destination field. This is the FQCN(Fully Qualified Class Name) of the udf."""
         return self._inner_dict.get('udf')  # type: ignore
     
     @udf.setter
     def udf(self, value: str) -> None:
+        """Setter: A UDF mentioning how the source fields got transformed to destination field. This is the FQCN(Fully Qualified Class Name) of the udf."""
         self._inner_dict['udf'] = value
     
     
 class ContainerClass(_Aspect):
     """Link from an asset to its parent container"""
 
 
@@ -3171,25 +3626,33 @@
     def __init__(self,
         container: str,
     ):
         super().__init__()
         
         self.container = container
     
+    @classmethod
+    def construct_with_defaults(cls) -> "ContainerClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.container = str()
     
     
     @property
     def container(self) -> str:
-        """The parent container of an asset"""
+        """Getter: The parent container of an asset"""
         return self._inner_dict.get('container')  # type: ignore
     
     @container.setter
     def container(self, value: str) -> None:
+        """Setter: The parent container of an asset"""
         self._inner_dict['container'] = value
     
     
 class ContainerPropertiesClass(_Aspect):
     """Information about a Asset Container as received from a 3rd party source system"""
 
 
@@ -3216,91 +3679,105 @@
         self.externalUrl = externalUrl
         self.name = name
         self.qualifiedName = qualifiedName
         self.description = description
         self.created = created
         self.lastModified = lastModified
     
+    @classmethod
+    def construct_with_defaults(cls) -> "ContainerPropertiesClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.customProperties = dict()
         self.externalUrl = self.RECORD_SCHEMA.fields_dict["externalUrl"].default
         self.name = str()
         self.qualifiedName = self.RECORD_SCHEMA.fields_dict["qualifiedName"].default
         self.description = self.RECORD_SCHEMA.fields_dict["description"].default
         self.created = self.RECORD_SCHEMA.fields_dict["created"].default
         self.lastModified = self.RECORD_SCHEMA.fields_dict["lastModified"].default
     
     
     @property
     def customProperties(self) -> Dict[str, str]:
-        """Custom property bag."""
+        """Getter: Custom property bag."""
         return self._inner_dict.get('customProperties')  # type: ignore
     
     @customProperties.setter
     def customProperties(self, value: Dict[str, str]) -> None:
+        """Setter: Custom property bag."""
         self._inner_dict['customProperties'] = value
     
     
     @property
     def externalUrl(self) -> Union[None, str]:
-        """URL where the reference exist"""
+        """Getter: URL where the reference exist"""
         return self._inner_dict.get('externalUrl')  # type: ignore
     
     @externalUrl.setter
     def externalUrl(self, value: Union[None, str]) -> None:
+        """Setter: URL where the reference exist"""
         self._inner_dict['externalUrl'] = value
     
     
     @property
     def name(self) -> str:
-        """Display name of the Asset Container"""
+        """Getter: Display name of the Asset Container"""
         return self._inner_dict.get('name')  # type: ignore
     
     @name.setter
     def name(self, value: str) -> None:
+        """Setter: Display name of the Asset Container"""
         self._inner_dict['name'] = value
     
     
     @property
     def qualifiedName(self) -> Union[None, str]:
-        """Fully-qualified name of the Container"""
+        """Getter: Fully-qualified name of the Container"""
         return self._inner_dict.get('qualifiedName')  # type: ignore
     
     @qualifiedName.setter
     def qualifiedName(self, value: Union[None, str]) -> None:
+        """Setter: Fully-qualified name of the Container"""
         self._inner_dict['qualifiedName'] = value
     
     
     @property
     def description(self) -> Union[None, str]:
-        """Description of the Asset Container as it exists inside a source system"""
+        """Getter: Description of the Asset Container as it exists inside a source system"""
         return self._inner_dict.get('description')  # type: ignore
     
     @description.setter
     def description(self, value: Union[None, str]) -> None:
+        """Setter: Description of the Asset Container as it exists inside a source system"""
         self._inner_dict['description'] = value
     
     
     @property
     def created(self) -> Union[None, "TimeStampClass"]:
-        """A timestamp documenting when the asset was created in the source Data Platform (not on DataHub)"""
+        """Getter: A timestamp documenting when the asset was created in the source Data Platform (not on DataHub)"""
         return self._inner_dict.get('created')  # type: ignore
     
     @created.setter
     def created(self, value: Union[None, "TimeStampClass"]) -> None:
+        """Setter: A timestamp documenting when the asset was created in the source Data Platform (not on DataHub)"""
         self._inner_dict['created'] = value
     
     
     @property
     def lastModified(self) -> Union[None, "TimeStampClass"]:
-        """A timestamp documenting when the asset was last modified in the source Data Platform (not on DataHub)"""
+        """Getter: A timestamp documenting when the asset was last modified in the source Data Platform (not on DataHub)"""
         return self._inner_dict.get('lastModified')  # type: ignore
     
     @lastModified.setter
     def lastModified(self, value: Union[None, "TimeStampClass"]) -> None:
+        """Setter: A timestamp documenting when the asset was last modified in the source Data Platform (not on DataHub)"""
         self._inner_dict['lastModified'] = value
     
     
 class EditableContainerPropertiesClass(_Aspect):
     """Editable information about an Asset Container as defined on the DataHub Platform"""
 
 
@@ -3311,25 +3788,33 @@
     def __init__(self,
         description: Union[None, str]=None,
     ):
         super().__init__()
         
         self.description = description
     
+    @classmethod
+    def construct_with_defaults(cls) -> "EditableContainerPropertiesClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.description = self.RECORD_SCHEMA.fields_dict["description"].default
     
     
     @property
     def description(self) -> Union[None, str]:
-        """Description of the Asset Container as its received on the DataHub Platform"""
+        """Getter: Description of the Asset Container as its received on the DataHub Platform"""
         return self._inner_dict.get('description')  # type: ignore
     
     @description.setter
     def description(self, value: Union[None, str]) -> None:
+        """Setter: Description of the Asset Container as its received on the DataHub Platform"""
         self._inner_dict['description'] = value
     
     
 class DashboardInfoClass(_Aspect):
     """Information about a dashboard"""
 
 
@@ -3374,148 +3859,169 @@
             self.datasets = datasets
         self.datasetEdges = datasetEdges
         self.lastModified = lastModified
         self.dashboardUrl = dashboardUrl
         self.access = access
         self.lastRefreshed = lastRefreshed
     
+    @classmethod
+    def construct_with_defaults(cls) -> "DashboardInfoClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.customProperties = dict()
         self.externalUrl = self.RECORD_SCHEMA.fields_dict["externalUrl"].default
         self.title = str()
         self.description = str()
         self.charts = list()
         self.chartEdges = self.RECORD_SCHEMA.fields_dict["chartEdges"].default
         self.datasets = list()
         self.datasetEdges = self.RECORD_SCHEMA.fields_dict["datasetEdges"].default
-        self.lastModified = ChangeAuditStampsClass._construct_with_defaults()
+        self.lastModified = ChangeAuditStampsClass.construct_with_defaults()
         self.dashboardUrl = self.RECORD_SCHEMA.fields_dict["dashboardUrl"].default
         self.access = self.RECORD_SCHEMA.fields_dict["access"].default
         self.lastRefreshed = self.RECORD_SCHEMA.fields_dict["lastRefreshed"].default
     
     
     @property
     def customProperties(self) -> Dict[str, str]:
-        """Custom property bag."""
+        """Getter: Custom property bag."""
         return self._inner_dict.get('customProperties')  # type: ignore
     
     @customProperties.setter
     def customProperties(self, value: Dict[str, str]) -> None:
+        """Setter: Custom property bag."""
         self._inner_dict['customProperties'] = value
     
     
     @property
     def externalUrl(self) -> Union[None, str]:
-        """URL where the reference exist"""
+        """Getter: URL where the reference exist"""
         return self._inner_dict.get('externalUrl')  # type: ignore
     
     @externalUrl.setter
     def externalUrl(self, value: Union[None, str]) -> None:
+        """Setter: URL where the reference exist"""
         self._inner_dict['externalUrl'] = value
     
     
     @property
     def title(self) -> str:
-        """Title of the dashboard"""
+        """Getter: Title of the dashboard"""
         return self._inner_dict.get('title')  # type: ignore
     
     @title.setter
     def title(self, value: str) -> None:
+        """Setter: Title of the dashboard"""
         self._inner_dict['title'] = value
     
     
     @property
     def description(self) -> str:
-        """Detailed description about the dashboard"""
+        """Getter: Detailed description about the dashboard"""
         return self._inner_dict.get('description')  # type: ignore
     
     @description.setter
     def description(self, value: str) -> None:
+        """Setter: Detailed description about the dashboard"""
         self._inner_dict['description'] = value
     
     
     @property
     def charts(self) -> List[str]:
-        """Charts in a dashboard
+        """Getter: Charts in a dashboard
     Deprecated! Use chartEdges instead."""
         return self._inner_dict.get('charts')  # type: ignore
     
     @charts.setter
     def charts(self, value: List[str]) -> None:
+        """Setter: Charts in a dashboard
+    Deprecated! Use chartEdges instead."""
         self._inner_dict['charts'] = value
     
     
     @property
     def chartEdges(self) -> Union[None, List["EdgeClass"]]:
-        """Charts in a dashboard"""
+        """Getter: Charts in a dashboard"""
         return self._inner_dict.get('chartEdges')  # type: ignore
     
     @chartEdges.setter
     def chartEdges(self, value: Union[None, List["EdgeClass"]]) -> None:
+        """Setter: Charts in a dashboard"""
         self._inner_dict['chartEdges'] = value
     
     
     @property
     def datasets(self) -> List[str]:
-        """Datasets consumed by a dashboard
+        """Getter: Datasets consumed by a dashboard
     Deprecated! Use datasetEdges instead."""
         return self._inner_dict.get('datasets')  # type: ignore
     
     @datasets.setter
     def datasets(self, value: List[str]) -> None:
+        """Setter: Datasets consumed by a dashboard
+    Deprecated! Use datasetEdges instead."""
         self._inner_dict['datasets'] = value
     
     
     @property
     def datasetEdges(self) -> Union[None, List["EdgeClass"]]:
-        """Datasets consumed by a dashboard"""
+        """Getter: Datasets consumed by a dashboard"""
         return self._inner_dict.get('datasetEdges')  # type: ignore
     
     @datasetEdges.setter
     def datasetEdges(self, value: Union[None, List["EdgeClass"]]) -> None:
+        """Setter: Datasets consumed by a dashboard"""
         self._inner_dict['datasetEdges'] = value
     
     
     @property
     def lastModified(self) -> "ChangeAuditStampsClass":
-        """Captures information about who created/last modified/deleted this dashboard and when"""
+        """Getter: Captures information about who created/last modified/deleted this dashboard and when"""
         return self._inner_dict.get('lastModified')  # type: ignore
     
     @lastModified.setter
     def lastModified(self, value: "ChangeAuditStampsClass") -> None:
+        """Setter: Captures information about who created/last modified/deleted this dashboard and when"""
         self._inner_dict['lastModified'] = value
     
     
     @property
     def dashboardUrl(self) -> Union[None, str]:
-        """URL for the dashboard. This could be used as an external link on DataHub to allow users access/view the dashboard"""
+        """Getter: URL for the dashboard. This could be used as an external link on DataHub to allow users access/view the dashboard"""
         return self._inner_dict.get('dashboardUrl')  # type: ignore
     
     @dashboardUrl.setter
     def dashboardUrl(self, value: Union[None, str]) -> None:
+        """Setter: URL for the dashboard. This could be used as an external link on DataHub to allow users access/view the dashboard"""
         self._inner_dict['dashboardUrl'] = value
     
     
     @property
     def access(self) -> Union[None, Union[str, "AccessLevelClass"]]:
-        """Access level for the dashboard"""
+        """Getter: Access level for the dashboard"""
         return self._inner_dict.get('access')  # type: ignore
     
     @access.setter
     def access(self, value: Union[None, Union[str, "AccessLevelClass"]]) -> None:
+        """Setter: Access level for the dashboard"""
         self._inner_dict['access'] = value
     
     
     @property
     def lastRefreshed(self) -> Union[None, int]:
-        """The time when this dashboard last refreshed"""
+        """Getter: The time when this dashboard last refreshed"""
         return self._inner_dict.get('lastRefreshed')  # type: ignore
     
     @lastRefreshed.setter
     def lastRefreshed(self, value: Union[None, int]) -> None:
+        """Setter: The time when this dashboard last refreshed"""
         self._inner_dict['lastRefreshed'] = value
     
     
 class DashboardUsageStatisticsClass(_Aspect):
     """Experimental (Subject to breaking change) -- Stats corresponding to dashboard's usage.
     
     If this aspect represents the latest snapshot of the statistics about a Dashboard, the eventGranularity field should be null. 
@@ -3552,14 +4058,21 @@
         self.viewsCount = viewsCount
         self.executionsCount = executionsCount
         self.uniqueUserCount = uniqueUserCount
         self.userCounts = userCounts
         self.favoritesCount = favoritesCount
         self.lastViewedAt = lastViewedAt
     
+    @classmethod
+    def construct_with_defaults(cls) -> "DashboardUsageStatisticsClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.timestampMillis = int()
         self.eventGranularity = self.RECORD_SCHEMA.fields_dict["eventGranularity"].default
         self.partitionSpec = _json_converter.from_json_object(self.RECORD_SCHEMA.fields_dict["partitionSpec"].default, writers_schema=self.RECORD_SCHEMA.fields_dict["partitionSpec"].type)
         self.messageId = self.RECORD_SCHEMA.fields_dict["messageId"].default
         self.viewsCount = self.RECORD_SCHEMA.fields_dict["viewsCount"].default
         self.executionsCount = self.RECORD_SCHEMA.fields_dict["executionsCount"].default
@@ -3567,111 +4080,123 @@
         self.userCounts = self.RECORD_SCHEMA.fields_dict["userCounts"].default
         self.favoritesCount = self.RECORD_SCHEMA.fields_dict["favoritesCount"].default
         self.lastViewedAt = self.RECORD_SCHEMA.fields_dict["lastViewedAt"].default
     
     
     @property
     def timestampMillis(self) -> int:
-        """The event timestamp field as epoch at UTC in milli seconds."""
+        """Getter: The event timestamp field as epoch at UTC in milli seconds."""
         return self._inner_dict.get('timestampMillis')  # type: ignore
     
     @timestampMillis.setter
     def timestampMillis(self, value: int) -> None:
+        """Setter: The event timestamp field as epoch at UTC in milli seconds."""
         self._inner_dict['timestampMillis'] = value
     
     
     @property
     def eventGranularity(self) -> Union[None, "TimeWindowSizeClass"]:
-        """Granularity of the event if applicable"""
+        """Getter: Granularity of the event if applicable"""
         return self._inner_dict.get('eventGranularity')  # type: ignore
     
     @eventGranularity.setter
     def eventGranularity(self, value: Union[None, "TimeWindowSizeClass"]) -> None:
+        """Setter: Granularity of the event if applicable"""
         self._inner_dict['eventGranularity'] = value
     
     
     @property
     def partitionSpec(self) -> Union["PartitionSpecClass", None]:
-        """The optional partition specification."""
+        """Getter: The optional partition specification."""
         return self._inner_dict.get('partitionSpec')  # type: ignore
     
     @partitionSpec.setter
     def partitionSpec(self, value: Union["PartitionSpecClass", None]) -> None:
+        """Setter: The optional partition specification."""
         self._inner_dict['partitionSpec'] = value
     
     
     @property
     def messageId(self) -> Union[None, str]:
-        """The optional messageId, if provided serves as a custom user-defined unique identifier for an aspect value."""
+        """Getter: The optional messageId, if provided serves as a custom user-defined unique identifier for an aspect value."""
         return self._inner_dict.get('messageId')  # type: ignore
     
     @messageId.setter
     def messageId(self, value: Union[None, str]) -> None:
+        """Setter: The optional messageId, if provided serves as a custom user-defined unique identifier for an aspect value."""
         self._inner_dict['messageId'] = value
     
     
     @property
     def viewsCount(self) -> Union[None, int]:
-        """The total number of times dashboard has been viewed"""
+        """Getter: The total number of times dashboard has been viewed"""
         return self._inner_dict.get('viewsCount')  # type: ignore
     
     @viewsCount.setter
     def viewsCount(self, value: Union[None, int]) -> None:
+        """Setter: The total number of times dashboard has been viewed"""
         self._inner_dict['viewsCount'] = value
     
     
     @property
     def executionsCount(self) -> Union[None, int]:
-        """The total number of dashboard executions (refreshes / syncs) """
+        """Getter: The total number of dashboard executions (refreshes / syncs) """
         return self._inner_dict.get('executionsCount')  # type: ignore
     
     @executionsCount.setter
     def executionsCount(self, value: Union[None, int]) -> None:
+        """Setter: The total number of dashboard executions (refreshes / syncs) """
         self._inner_dict['executionsCount'] = value
     
     
     @property
     def uniqueUserCount(self) -> Union[None, int]:
-        """Unique user count"""
+        """Getter: Unique user count"""
         return self._inner_dict.get('uniqueUserCount')  # type: ignore
     
     @uniqueUserCount.setter
     def uniqueUserCount(self, value: Union[None, int]) -> None:
+        """Setter: Unique user count"""
         self._inner_dict['uniqueUserCount'] = value
     
     
     @property
     def userCounts(self) -> Union[None, List["DashboardUserUsageCountsClass"]]:
-        """Users within this bucket, with frequency counts"""
+        """Getter: Users within this bucket, with frequency counts"""
         return self._inner_dict.get('userCounts')  # type: ignore
     
     @userCounts.setter
     def userCounts(self, value: Union[None, List["DashboardUserUsageCountsClass"]]) -> None:
+        """Setter: Users within this bucket, with frequency counts"""
         self._inner_dict['userCounts'] = value
     
     
     @property
     def favoritesCount(self) -> Union[None, int]:
-        """The total number of times that the dashboard has been favorited """
+        """Getter: The total number of times that the dashboard has been favorited """
         return self._inner_dict.get('favoritesCount')  # type: ignore
     
     @favoritesCount.setter
     def favoritesCount(self, value: Union[None, int]) -> None:
+        """Setter: The total number of times that the dashboard has been favorited """
         self._inner_dict['favoritesCount'] = value
     
     
     @property
     def lastViewedAt(self) -> Union[None, int]:
-        """Last viewed at
+        """Getter: Last viewed at
     
     This should not be set in cases where statistics are windowed. """
         return self._inner_dict.get('lastViewedAt')  # type: ignore
     
     @lastViewedAt.setter
     def lastViewedAt(self, value: Union[None, int]) -> None:
+        """Setter: Last viewed at
+    
+    This should not be set in cases where statistics are windowed. """
         self._inner_dict['lastViewedAt'] = value
     
     
 class DashboardUserUsageCountsClass(DictWrapper):
     """Records a single user's usage counts for a given resource"""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.dashboard.DashboardUserUsageCounts")
@@ -3686,69 +4211,81 @@
         
         self.user = user
         self.viewsCount = viewsCount
         self.executionsCount = executionsCount
         self.usageCount = usageCount
         self.userEmail = userEmail
     
+    @classmethod
+    def construct_with_defaults(cls) -> "DashboardUserUsageCountsClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.user = str()
         self.viewsCount = self.RECORD_SCHEMA.fields_dict["viewsCount"].default
         self.executionsCount = self.RECORD_SCHEMA.fields_dict["executionsCount"].default
         self.usageCount = self.RECORD_SCHEMA.fields_dict["usageCount"].default
         self.userEmail = self.RECORD_SCHEMA.fields_dict["userEmail"].default
     
     
     @property
     def user(self) -> str:
-        """The unique id of the user."""
+        """Getter: The unique id of the user."""
         return self._inner_dict.get('user')  # type: ignore
     
     @user.setter
     def user(self, value: str) -> None:
+        """Setter: The unique id of the user."""
         self._inner_dict['user'] = value
     
     
     @property
     def viewsCount(self) -> Union[None, int]:
-        """The number of times the user has viewed the dashboard"""
+        """Getter: The number of times the user has viewed the dashboard"""
         return self._inner_dict.get('viewsCount')  # type: ignore
     
     @viewsCount.setter
     def viewsCount(self, value: Union[None, int]) -> None:
+        """Setter: The number of times the user has viewed the dashboard"""
         self._inner_dict['viewsCount'] = value
     
     
     @property
     def executionsCount(self) -> Union[None, int]:
-        """The number of times the user has executed (refreshed) the dashboard"""
+        """Getter: The number of times the user has executed (refreshed) the dashboard"""
         return self._inner_dict.get('executionsCount')  # type: ignore
     
     @executionsCount.setter
     def executionsCount(self, value: Union[None, int]) -> None:
+        """Setter: The number of times the user has executed (refreshed) the dashboard"""
         self._inner_dict['executionsCount'] = value
     
     
     @property
     def usageCount(self) -> Union[None, int]:
-        """Normalized numeric metric representing user's dashboard usage -- the number of times the user executed or viewed the dashboard. """
+        """Getter: Normalized numeric metric representing user's dashboard usage -- the number of times the user executed or viewed the dashboard. """
         return self._inner_dict.get('usageCount')  # type: ignore
     
     @usageCount.setter
     def usageCount(self, value: Union[None, int]) -> None:
+        """Setter: Normalized numeric metric representing user's dashboard usage -- the number of times the user executed or viewed the dashboard. """
         self._inner_dict['usageCount'] = value
     
     
     @property
     def userEmail(self) -> Union[None, str]:
-        """If user_email is set, we attempt to resolve the user's urn upon ingest"""
+        """Getter: If user_email is set, we attempt to resolve the user's urn upon ingest"""
         return self._inner_dict.get('userEmail')  # type: ignore
     
     @userEmail.setter
     def userEmail(self, value: Union[None, str]) -> None:
+        """Setter: If user_email is set, we attempt to resolve the user's urn upon ingest"""
         self._inner_dict['userEmail'] = value
     
     
 class EditableDashboardPropertiesClass(_Aspect):
     """Stores editable changes made to properties. This separates changes made from
     ingestion pipelines and edits in the UI to avoid accidental overwrites of user-provided data by ingestion pipelines"""
 
@@ -3774,58 +4311,69 @@
             # default: {'actor': 'urn:li:corpuser:unknown', 'impersonator': None, 'time': 0, 'message': None}
             self.lastModified = _json_converter.from_json_object(self.RECORD_SCHEMA.fields_dict["lastModified"].default, writers_schema=self.RECORD_SCHEMA.fields_dict["lastModified"].type)
         else:
             self.lastModified = lastModified
         self.deleted = deleted
         self.description = description
     
+    @classmethod
+    def construct_with_defaults(cls) -> "EditableDashboardPropertiesClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.created = _json_converter.from_json_object(self.RECORD_SCHEMA.fields_dict["created"].default, writers_schema=self.RECORD_SCHEMA.fields_dict["created"].type)
         self.lastModified = _json_converter.from_json_object(self.RECORD_SCHEMA.fields_dict["lastModified"].default, writers_schema=self.RECORD_SCHEMA.fields_dict["lastModified"].type)
         self.deleted = self.RECORD_SCHEMA.fields_dict["deleted"].default
         self.description = self.RECORD_SCHEMA.fields_dict["description"].default
     
     
     @property
     def created(self) -> "AuditStampClass":
-        """An AuditStamp corresponding to the creation of this resource/association/sub-resource. A value of 0 for time indicates missing data."""
+        """Getter: An AuditStamp corresponding to the creation of this resource/association/sub-resource. A value of 0 for time indicates missing data."""
         return self._inner_dict.get('created')  # type: ignore
     
     @created.setter
     def created(self, value: "AuditStampClass") -> None:
+        """Setter: An AuditStamp corresponding to the creation of this resource/association/sub-resource. A value of 0 for time indicates missing data."""
         self._inner_dict['created'] = value
     
     
     @property
     def lastModified(self) -> "AuditStampClass":
-        """An AuditStamp corresponding to the last modification of this resource/association/sub-resource. If no modification has happened since creation, lastModified should be the same as created. A value of 0 for time indicates missing data."""
+        """Getter: An AuditStamp corresponding to the last modification of this resource/association/sub-resource. If no modification has happened since creation, lastModified should be the same as created. A value of 0 for time indicates missing data."""
         return self._inner_dict.get('lastModified')  # type: ignore
     
     @lastModified.setter
     def lastModified(self, value: "AuditStampClass") -> None:
+        """Setter: An AuditStamp corresponding to the last modification of this resource/association/sub-resource. If no modification has happened since creation, lastModified should be the same as created. A value of 0 for time indicates missing data."""
         self._inner_dict['lastModified'] = value
     
     
     @property
     def deleted(self) -> Union[None, "AuditStampClass"]:
-        """An AuditStamp corresponding to the deletion of this resource/association/sub-resource. Logically, deleted MUST have a later timestamp than creation. It may or may not have the same time as lastModified depending upon the resource/association/sub-resource semantics."""
+        """Getter: An AuditStamp corresponding to the deletion of this resource/association/sub-resource. Logically, deleted MUST have a later timestamp than creation. It may or may not have the same time as lastModified depending upon the resource/association/sub-resource semantics."""
         return self._inner_dict.get('deleted')  # type: ignore
     
     @deleted.setter
     def deleted(self, value: Union[None, "AuditStampClass"]) -> None:
+        """Setter: An AuditStamp corresponding to the deletion of this resource/association/sub-resource. Logically, deleted MUST have a later timestamp than creation. It may or may not have the same time as lastModified depending upon the resource/association/sub-resource semantics."""
         self._inner_dict['deleted'] = value
     
     
     @property
     def description(self) -> Union[None, str]:
-        """Edited documentation of the dashboard"""
+        """Getter: Edited documentation of the dashboard"""
         return self._inner_dict.get('description')  # type: ignore
     
     @description.setter
     def description(self, value: Union[None, str]) -> None:
+        """Setter: Edited documentation of the dashboard"""
         self._inner_dict['description'] = value
     
     
 class DataFlowInfoClass(_Aspect):
     """Information about a Data processing flow"""
 
 
@@ -3852,91 +4400,105 @@
         self.externalUrl = externalUrl
         self.name = name
         self.description = description
         self.project = project
         self.created = created
         self.lastModified = lastModified
     
+    @classmethod
+    def construct_with_defaults(cls) -> "DataFlowInfoClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.customProperties = dict()
         self.externalUrl = self.RECORD_SCHEMA.fields_dict["externalUrl"].default
         self.name = str()
         self.description = self.RECORD_SCHEMA.fields_dict["description"].default
         self.project = self.RECORD_SCHEMA.fields_dict["project"].default
         self.created = self.RECORD_SCHEMA.fields_dict["created"].default
         self.lastModified = self.RECORD_SCHEMA.fields_dict["lastModified"].default
     
     
     @property
     def customProperties(self) -> Dict[str, str]:
-        """Custom property bag."""
+        """Getter: Custom property bag."""
         return self._inner_dict.get('customProperties')  # type: ignore
     
     @customProperties.setter
     def customProperties(self, value: Dict[str, str]) -> None:
+        """Setter: Custom property bag."""
         self._inner_dict['customProperties'] = value
     
     
     @property
     def externalUrl(self) -> Union[None, str]:
-        """URL where the reference exist"""
+        """Getter: URL where the reference exist"""
         return self._inner_dict.get('externalUrl')  # type: ignore
     
     @externalUrl.setter
     def externalUrl(self, value: Union[None, str]) -> None:
+        """Setter: URL where the reference exist"""
         self._inner_dict['externalUrl'] = value
     
     
     @property
     def name(self) -> str:
-        """Flow name"""
+        """Getter: Flow name"""
         return self._inner_dict.get('name')  # type: ignore
     
     @name.setter
     def name(self, value: str) -> None:
+        """Setter: Flow name"""
         self._inner_dict['name'] = value
     
     
     @property
     def description(self) -> Union[None, str]:
-        """Flow description"""
+        """Getter: Flow description"""
         return self._inner_dict.get('description')  # type: ignore
     
     @description.setter
     def description(self, value: Union[None, str]) -> None:
+        """Setter: Flow description"""
         self._inner_dict['description'] = value
     
     
     @property
     def project(self) -> Union[None, str]:
-        """Optional project/namespace associated with the flow"""
+        """Getter: Optional project/namespace associated with the flow"""
         return self._inner_dict.get('project')  # type: ignore
     
     @project.setter
     def project(self, value: Union[None, str]) -> None:
+        """Setter: Optional project/namespace associated with the flow"""
         self._inner_dict['project'] = value
     
     
     @property
     def created(self) -> Union[None, "TimeStampClass"]:
-        """A timestamp documenting when the asset was created in the source Data Platform (not on DataHub)"""
+        """Getter: A timestamp documenting when the asset was created in the source Data Platform (not on DataHub)"""
         return self._inner_dict.get('created')  # type: ignore
     
     @created.setter
     def created(self, value: Union[None, "TimeStampClass"]) -> None:
+        """Setter: A timestamp documenting when the asset was created in the source Data Platform (not on DataHub)"""
         self._inner_dict['created'] = value
     
     
     @property
     def lastModified(self) -> Union[None, "TimeStampClass"]:
-        """A timestamp documenting when the asset was last modified in the source Data Platform (not on DataHub)"""
+        """Getter: A timestamp documenting when the asset was last modified in the source Data Platform (not on DataHub)"""
         return self._inner_dict.get('lastModified')  # type: ignore
     
     @lastModified.setter
     def lastModified(self, value: Union[None, "TimeStampClass"]) -> None:
+        """Setter: A timestamp documenting when the asset was last modified in the source Data Platform (not on DataHub)"""
         self._inner_dict['lastModified'] = value
     
     
 class DataJobInfoClass(_Aspect):
     """Information about a Data processing job"""
 
 
@@ -3967,114 +4529,131 @@
         self.description = description
         self.type = type
         self.flowUrn = flowUrn
         self.created = created
         self.lastModified = lastModified
         self.status = status
     
+    @classmethod
+    def construct_with_defaults(cls) -> "DataJobInfoClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.customProperties = dict()
         self.externalUrl = self.RECORD_SCHEMA.fields_dict["externalUrl"].default
         self.name = str()
         self.description = self.RECORD_SCHEMA.fields_dict["description"].default
         self.type = AzkabanJobTypeClass.COMMAND
         self.flowUrn = self.RECORD_SCHEMA.fields_dict["flowUrn"].default
         self.created = self.RECORD_SCHEMA.fields_dict["created"].default
         self.lastModified = self.RECORD_SCHEMA.fields_dict["lastModified"].default
         self.status = self.RECORD_SCHEMA.fields_dict["status"].default
     
     
     @property
     def customProperties(self) -> Dict[str, str]:
-        """Custom property bag."""
+        """Getter: Custom property bag."""
         return self._inner_dict.get('customProperties')  # type: ignore
     
     @customProperties.setter
     def customProperties(self, value: Dict[str, str]) -> None:
+        """Setter: Custom property bag."""
         self._inner_dict['customProperties'] = value
     
     
     @property
     def externalUrl(self) -> Union[None, str]:
-        """URL where the reference exist"""
+        """Getter: URL where the reference exist"""
         return self._inner_dict.get('externalUrl')  # type: ignore
     
     @externalUrl.setter
     def externalUrl(self, value: Union[None, str]) -> None:
+        """Setter: URL where the reference exist"""
         self._inner_dict['externalUrl'] = value
     
     
     @property
     def name(self) -> str:
-        """Job name"""
+        """Getter: Job name"""
         return self._inner_dict.get('name')  # type: ignore
     
     @name.setter
     def name(self, value: str) -> None:
+        """Setter: Job name"""
         self._inner_dict['name'] = value
     
     
     @property
     def description(self) -> Union[None, str]:
-        """Job description"""
+        """Getter: Job description"""
         return self._inner_dict.get('description')  # type: ignore
     
     @description.setter
     def description(self, value: Union[None, str]) -> None:
+        """Setter: Job description"""
         self._inner_dict['description'] = value
     
     
     @property
     def type(self) -> Union[Union[str, "AzkabanJobTypeClass"], str]:
-        """Datajob type
+        """Getter: Datajob type
     *NOTE**: AzkabanJobType is deprecated. Please use strings instead."""
         return self._inner_dict.get('type')  # type: ignore
     
     @type.setter
     def type(self, value: Union[Union[str, "AzkabanJobTypeClass"], str]) -> None:
+        """Setter: Datajob type
+    *NOTE**: AzkabanJobType is deprecated. Please use strings instead."""
         self._inner_dict['type'] = value
     
     
     @property
     def flowUrn(self) -> Union[None, str]:
-        """DataFlow urn that this job is part of"""
+        """Getter: DataFlow urn that this job is part of"""
         return self._inner_dict.get('flowUrn')  # type: ignore
     
     @flowUrn.setter
     def flowUrn(self, value: Union[None, str]) -> None:
+        """Setter: DataFlow urn that this job is part of"""
         self._inner_dict['flowUrn'] = value
     
     
     @property
     def created(self) -> Union[None, "TimeStampClass"]:
-        """A timestamp documenting when the asset was created in the source Data Platform (not on DataHub)"""
+        """Getter: A timestamp documenting when the asset was created in the source Data Platform (not on DataHub)"""
         return self._inner_dict.get('created')  # type: ignore
     
     @created.setter
     def created(self, value: Union[None, "TimeStampClass"]) -> None:
+        """Setter: A timestamp documenting when the asset was created in the source Data Platform (not on DataHub)"""
         self._inner_dict['created'] = value
     
     
     @property
     def lastModified(self) -> Union[None, "TimeStampClass"]:
-        """A timestamp documenting when the asset was last modified in the source Data Platform (not on DataHub)"""
+        """Getter: A timestamp documenting when the asset was last modified in the source Data Platform (not on DataHub)"""
         return self._inner_dict.get('lastModified')  # type: ignore
     
     @lastModified.setter
     def lastModified(self, value: Union[None, "TimeStampClass"]) -> None:
+        """Setter: A timestamp documenting when the asset was last modified in the source Data Platform (not on DataHub)"""
         self._inner_dict['lastModified'] = value
     
     
     @property
     def status(self) -> Union[None, Union[str, "JobStatusClass"]]:
-        """Status of the job - Deprecated for Data Process Instance model."""
+        """Getter: Status of the job - Deprecated for Data Process Instance model."""
         return self._inner_dict.get('status')  # type: ignore
     
     @status.setter
     def status(self, value: Union[None, Union[str, "JobStatusClass"]]) -> None:
+        """Setter: Status of the job - Deprecated for Data Process Instance model."""
         self._inner_dict['status'] = value
     
     
 class DataJobInputOutputClass(_Aspect):
     """Information about the inputs and outputs of a Data processing job"""
 
 
@@ -4101,116 +4680,135 @@
         self.outputDatasetEdges = outputDatasetEdges
         self.inputDatajobs = inputDatajobs
         self.inputDatajobEdges = inputDatajobEdges
         self.inputDatasetFields = inputDatasetFields
         self.outputDatasetFields = outputDatasetFields
         self.fineGrainedLineages = fineGrainedLineages
     
+    @classmethod
+    def construct_with_defaults(cls) -> "DataJobInputOutputClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.inputDatasets = list()
         self.inputDatasetEdges = self.RECORD_SCHEMA.fields_dict["inputDatasetEdges"].default
         self.outputDatasets = list()
         self.outputDatasetEdges = self.RECORD_SCHEMA.fields_dict["outputDatasetEdges"].default
         self.inputDatajobs = self.RECORD_SCHEMA.fields_dict["inputDatajobs"].default
         self.inputDatajobEdges = self.RECORD_SCHEMA.fields_dict["inputDatajobEdges"].default
         self.inputDatasetFields = self.RECORD_SCHEMA.fields_dict["inputDatasetFields"].default
         self.outputDatasetFields = self.RECORD_SCHEMA.fields_dict["outputDatasetFields"].default
         self.fineGrainedLineages = self.RECORD_SCHEMA.fields_dict["fineGrainedLineages"].default
     
     
     @property
     def inputDatasets(self) -> List[str]:
-        """Input datasets consumed by the data job during processing
+        """Getter: Input datasets consumed by the data job during processing
     Deprecated! Use inputDatasetEdges instead."""
         return self._inner_dict.get('inputDatasets')  # type: ignore
     
     @inputDatasets.setter
     def inputDatasets(self, value: List[str]) -> None:
+        """Setter: Input datasets consumed by the data job during processing
+    Deprecated! Use inputDatasetEdges instead."""
         self._inner_dict['inputDatasets'] = value
     
     
     @property
     def inputDatasetEdges(self) -> Union[None, List["EdgeClass"]]:
-        """Input datasets consumed by the data job during processing"""
+        """Getter: Input datasets consumed by the data job during processing"""
         return self._inner_dict.get('inputDatasetEdges')  # type: ignore
     
     @inputDatasetEdges.setter
     def inputDatasetEdges(self, value: Union[None, List["EdgeClass"]]) -> None:
+        """Setter: Input datasets consumed by the data job during processing"""
         self._inner_dict['inputDatasetEdges'] = value
     
     
     @property
     def outputDatasets(self) -> List[str]:
-        """Output datasets produced by the data job during processing
+        """Getter: Output datasets produced by the data job during processing
     Deprecated! Use outputDatasetEdges instead."""
         return self._inner_dict.get('outputDatasets')  # type: ignore
     
     @outputDatasets.setter
     def outputDatasets(self, value: List[str]) -> None:
+        """Setter: Output datasets produced by the data job during processing
+    Deprecated! Use outputDatasetEdges instead."""
         self._inner_dict['outputDatasets'] = value
     
     
     @property
     def outputDatasetEdges(self) -> Union[None, List["EdgeClass"]]:
-        """Output datasets produced by the data job during processing"""
+        """Getter: Output datasets produced by the data job during processing"""
         return self._inner_dict.get('outputDatasetEdges')  # type: ignore
     
     @outputDatasetEdges.setter
     def outputDatasetEdges(self, value: Union[None, List["EdgeClass"]]) -> None:
+        """Setter: Output datasets produced by the data job during processing"""
         self._inner_dict['outputDatasetEdges'] = value
     
     
     @property
     def inputDatajobs(self) -> Union[None, List[str]]:
-        """Input datajobs that this data job depends on
+        """Getter: Input datajobs that this data job depends on
     Deprecated! Use inputDatajobEdges instead."""
         return self._inner_dict.get('inputDatajobs')  # type: ignore
     
     @inputDatajobs.setter
     def inputDatajobs(self, value: Union[None, List[str]]) -> None:
+        """Setter: Input datajobs that this data job depends on
+    Deprecated! Use inputDatajobEdges instead."""
         self._inner_dict['inputDatajobs'] = value
     
     
     @property
     def inputDatajobEdges(self) -> Union[None, List["EdgeClass"]]:
-        """Input datajobs that this data job depends on"""
+        """Getter: Input datajobs that this data job depends on"""
         return self._inner_dict.get('inputDatajobEdges')  # type: ignore
     
     @inputDatajobEdges.setter
     def inputDatajobEdges(self, value: Union[None, List["EdgeClass"]]) -> None:
+        """Setter: Input datajobs that this data job depends on"""
         self._inner_dict['inputDatajobEdges'] = value
     
     
     @property
     def inputDatasetFields(self) -> Union[None, List[str]]:
-        """Fields of the input datasets used by this job"""
+        """Getter: Fields of the input datasets used by this job"""
         return self._inner_dict.get('inputDatasetFields')  # type: ignore
     
     @inputDatasetFields.setter
     def inputDatasetFields(self, value: Union[None, List[str]]) -> None:
+        """Setter: Fields of the input datasets used by this job"""
         self._inner_dict['inputDatasetFields'] = value
     
     
     @property
     def outputDatasetFields(self) -> Union[None, List[str]]:
-        """Fields of the output datasets this job writes to"""
+        """Getter: Fields of the output datasets this job writes to"""
         return self._inner_dict.get('outputDatasetFields')  # type: ignore
     
     @outputDatasetFields.setter
     def outputDatasetFields(self, value: Union[None, List[str]]) -> None:
+        """Setter: Fields of the output datasets this job writes to"""
         self._inner_dict['outputDatasetFields'] = value
     
     
     @property
     def fineGrainedLineages(self) -> Union[None, List["FineGrainedLineageClass"]]:
-        """Fine-grained column-level lineages"""
+        """Getter: Fine-grained column-level lineages"""
         return self._inner_dict.get('fineGrainedLineages')  # type: ignore
     
     @fineGrainedLineages.setter
     def fineGrainedLineages(self, value: Union[None, List["FineGrainedLineageClass"]]) -> None:
+        """Setter: Fine-grained column-level lineages"""
         self._inner_dict['fineGrainedLineages'] = value
     
     
 class EditableDataFlowPropertiesClass(_Aspect):
     """Stores editable changes made to properties. This separates changes made from
     ingestion pipelines and edits in the UI to avoid accidental overwrites of user-provided data by ingestion pipelines"""
 
@@ -4236,58 +4834,69 @@
             # default: {'actor': 'urn:li:corpuser:unknown', 'impersonator': None, 'time': 0, 'message': None}
             self.lastModified = _json_converter.from_json_object(self.RECORD_SCHEMA.fields_dict["lastModified"].default, writers_schema=self.RECORD_SCHEMA.fields_dict["lastModified"].type)
         else:
             self.lastModified = lastModified
         self.deleted = deleted
         self.description = description
     
+    @classmethod
+    def construct_with_defaults(cls) -> "EditableDataFlowPropertiesClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.created = _json_converter.from_json_object(self.RECORD_SCHEMA.fields_dict["created"].default, writers_schema=self.RECORD_SCHEMA.fields_dict["created"].type)
         self.lastModified = _json_converter.from_json_object(self.RECORD_SCHEMA.fields_dict["lastModified"].default, writers_schema=self.RECORD_SCHEMA.fields_dict["lastModified"].type)
         self.deleted = self.RECORD_SCHEMA.fields_dict["deleted"].default
         self.description = self.RECORD_SCHEMA.fields_dict["description"].default
     
     
     @property
     def created(self) -> "AuditStampClass":
-        """An AuditStamp corresponding to the creation of this resource/association/sub-resource. A value of 0 for time indicates missing data."""
+        """Getter: An AuditStamp corresponding to the creation of this resource/association/sub-resource. A value of 0 for time indicates missing data."""
         return self._inner_dict.get('created')  # type: ignore
     
     @created.setter
     def created(self, value: "AuditStampClass") -> None:
+        """Setter: An AuditStamp corresponding to the creation of this resource/association/sub-resource. A value of 0 for time indicates missing data."""
         self._inner_dict['created'] = value
     
     
     @property
     def lastModified(self) -> "AuditStampClass":
-        """An AuditStamp corresponding to the last modification of this resource/association/sub-resource. If no modification has happened since creation, lastModified should be the same as created. A value of 0 for time indicates missing data."""
+        """Getter: An AuditStamp corresponding to the last modification of this resource/association/sub-resource. If no modification has happened since creation, lastModified should be the same as created. A value of 0 for time indicates missing data."""
         return self._inner_dict.get('lastModified')  # type: ignore
     
     @lastModified.setter
     def lastModified(self, value: "AuditStampClass") -> None:
+        """Setter: An AuditStamp corresponding to the last modification of this resource/association/sub-resource. If no modification has happened since creation, lastModified should be the same as created. A value of 0 for time indicates missing data."""
         self._inner_dict['lastModified'] = value
     
     
     @property
     def deleted(self) -> Union[None, "AuditStampClass"]:
-        """An AuditStamp corresponding to the deletion of this resource/association/sub-resource. Logically, deleted MUST have a later timestamp than creation. It may or may not have the same time as lastModified depending upon the resource/association/sub-resource semantics."""
+        """Getter: An AuditStamp corresponding to the deletion of this resource/association/sub-resource. Logically, deleted MUST have a later timestamp than creation. It may or may not have the same time as lastModified depending upon the resource/association/sub-resource semantics."""
         return self._inner_dict.get('deleted')  # type: ignore
     
     @deleted.setter
     def deleted(self, value: Union[None, "AuditStampClass"]) -> None:
+        """Setter: An AuditStamp corresponding to the deletion of this resource/association/sub-resource. Logically, deleted MUST have a later timestamp than creation. It may or may not have the same time as lastModified depending upon the resource/association/sub-resource semantics."""
         self._inner_dict['deleted'] = value
     
     
     @property
     def description(self) -> Union[None, str]:
-        """Edited documentation of the data flow"""
+        """Getter: Edited documentation of the data flow"""
         return self._inner_dict.get('description')  # type: ignore
     
     @description.setter
     def description(self, value: Union[None, str]) -> None:
+        """Setter: Edited documentation of the data flow"""
         self._inner_dict['description'] = value
     
     
 class EditableDataJobPropertiesClass(_Aspect):
     """Stores editable changes made to properties. This separates changes made from
     ingestion pipelines and edits in the UI to avoid accidental overwrites of user-provided data by ingestion pipelines"""
 
@@ -4313,58 +4922,69 @@
             # default: {'actor': 'urn:li:corpuser:unknown', 'impersonator': None, 'time': 0, 'message': None}
             self.lastModified = _json_converter.from_json_object(self.RECORD_SCHEMA.fields_dict["lastModified"].default, writers_schema=self.RECORD_SCHEMA.fields_dict["lastModified"].type)
         else:
             self.lastModified = lastModified
         self.deleted = deleted
         self.description = description
     
+    @classmethod
+    def construct_with_defaults(cls) -> "EditableDataJobPropertiesClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.created = _json_converter.from_json_object(self.RECORD_SCHEMA.fields_dict["created"].default, writers_schema=self.RECORD_SCHEMA.fields_dict["created"].type)
         self.lastModified = _json_converter.from_json_object(self.RECORD_SCHEMA.fields_dict["lastModified"].default, writers_schema=self.RECORD_SCHEMA.fields_dict["lastModified"].type)
         self.deleted = self.RECORD_SCHEMA.fields_dict["deleted"].default
         self.description = self.RECORD_SCHEMA.fields_dict["description"].default
     
     
     @property
     def created(self) -> "AuditStampClass":
-        """An AuditStamp corresponding to the creation of this resource/association/sub-resource. A value of 0 for time indicates missing data."""
+        """Getter: An AuditStamp corresponding to the creation of this resource/association/sub-resource. A value of 0 for time indicates missing data."""
         return self._inner_dict.get('created')  # type: ignore
     
     @created.setter
     def created(self, value: "AuditStampClass") -> None:
+        """Setter: An AuditStamp corresponding to the creation of this resource/association/sub-resource. A value of 0 for time indicates missing data."""
         self._inner_dict['created'] = value
     
     
     @property
     def lastModified(self) -> "AuditStampClass":
-        """An AuditStamp corresponding to the last modification of this resource/association/sub-resource. If no modification has happened since creation, lastModified should be the same as created. A value of 0 for time indicates missing data."""
+        """Getter: An AuditStamp corresponding to the last modification of this resource/association/sub-resource. If no modification has happened since creation, lastModified should be the same as created. A value of 0 for time indicates missing data."""
         return self._inner_dict.get('lastModified')  # type: ignore
     
     @lastModified.setter
     def lastModified(self, value: "AuditStampClass") -> None:
+        """Setter: An AuditStamp corresponding to the last modification of this resource/association/sub-resource. If no modification has happened since creation, lastModified should be the same as created. A value of 0 for time indicates missing data."""
         self._inner_dict['lastModified'] = value
     
     
     @property
     def deleted(self) -> Union[None, "AuditStampClass"]:
-        """An AuditStamp corresponding to the deletion of this resource/association/sub-resource. Logically, deleted MUST have a later timestamp than creation. It may or may not have the same time as lastModified depending upon the resource/association/sub-resource semantics."""
+        """Getter: An AuditStamp corresponding to the deletion of this resource/association/sub-resource. Logically, deleted MUST have a later timestamp than creation. It may or may not have the same time as lastModified depending upon the resource/association/sub-resource semantics."""
         return self._inner_dict.get('deleted')  # type: ignore
     
     @deleted.setter
     def deleted(self, value: Union[None, "AuditStampClass"]) -> None:
+        """Setter: An AuditStamp corresponding to the deletion of this resource/association/sub-resource. Logically, deleted MUST have a later timestamp than creation. It may or may not have the same time as lastModified depending upon the resource/association/sub-resource semantics."""
         self._inner_dict['deleted'] = value
     
     
     @property
     def description(self) -> Union[None, str]:
-        """Edited documentation of the data job """
+        """Getter: Edited documentation of the data job """
         return self._inner_dict.get('description')  # type: ignore
     
     @description.setter
     def description(self, value: Union[None, str]) -> None:
+        """Setter: Edited documentation of the data job """
         self._inner_dict['description'] = value
     
     
 class JobStatusClass(object):
     """Job statuses"""
     
     
@@ -4414,58 +5034,69 @@
             self.customProperties = dict()
         else:
             self.customProperties = customProperties
         self.externalUrl = externalUrl
         self.version = version
         self.versionType = versionType
     
+    @classmethod
+    def construct_with_defaults(cls) -> "VersionInfoClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.customProperties = dict()
         self.externalUrl = self.RECORD_SCHEMA.fields_dict["externalUrl"].default
         self.version = str()
         self.versionType = str()
     
     
     @property
     def customProperties(self) -> Dict[str, str]:
-        """Custom property bag."""
+        """Getter: Custom property bag."""
         return self._inner_dict.get('customProperties')  # type: ignore
     
     @customProperties.setter
     def customProperties(self, value: Dict[str, str]) -> None:
+        """Setter: Custom property bag."""
         self._inner_dict['customProperties'] = value
     
     
     @property
     def externalUrl(self) -> Union[None, str]:
-        """URL where the reference exist"""
+        """Getter: URL where the reference exist"""
         return self._inner_dict.get('externalUrl')  # type: ignore
     
     @externalUrl.setter
     def externalUrl(self, value: Union[None, str]) -> None:
+        """Setter: URL where the reference exist"""
         self._inner_dict['externalUrl'] = value
     
     
     @property
     def version(self) -> str:
-        """The version which can indentify a job version like a commit hash or md5 hash"""
+        """Getter: The version which can indentify a job version like a commit hash or md5 hash"""
         return self._inner_dict.get('version')  # type: ignore
     
     @version.setter
     def version(self, value: str) -> None:
+        """Setter: The version which can indentify a job version like a commit hash or md5 hash"""
         self._inner_dict['version'] = value
     
     
     @property
     def versionType(self) -> str:
-        """The type of the version like git hash or md5 hash"""
+        """Getter: The type of the version like git hash or md5 hash"""
         return self._inner_dict.get('versionType')  # type: ignore
     
     @versionType.setter
     def versionType(self, value: str) -> None:
+        """Setter: The type of the version like git hash or md5 hash"""
         self._inner_dict['versionType'] = value
     
     
 class AzkabanJobTypeClass(object):
     """The various types of support azkaban jobs"""
     
     
@@ -4526,115 +5157,133 @@
         self.messageId = messageId
         self.pipelineName = pipelineName
         self.platformInstanceId = platformInstanceId
         self.config = config
         self.state = state
         self.runId = runId
     
+    @classmethod
+    def construct_with_defaults(cls) -> "DatahubIngestionCheckpointClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.timestampMillis = int()
         self.eventGranularity = self.RECORD_SCHEMA.fields_dict["eventGranularity"].default
         self.partitionSpec = _json_converter.from_json_object(self.RECORD_SCHEMA.fields_dict["partitionSpec"].default, writers_schema=self.RECORD_SCHEMA.fields_dict["partitionSpec"].type)
         self.messageId = self.RECORD_SCHEMA.fields_dict["messageId"].default
         self.pipelineName = str()
         self.platformInstanceId = str()
         self.config = str()
-        self.state = IngestionCheckpointStateClass._construct_with_defaults()
+        self.state = IngestionCheckpointStateClass.construct_with_defaults()
         self.runId = str()
     
     
     @property
     def timestampMillis(self) -> int:
-        """The event timestamp field as epoch at UTC in milli seconds."""
+        """Getter: The event timestamp field as epoch at UTC in milli seconds."""
         return self._inner_dict.get('timestampMillis')  # type: ignore
     
     @timestampMillis.setter
     def timestampMillis(self, value: int) -> None:
+        """Setter: The event timestamp field as epoch at UTC in milli seconds."""
         self._inner_dict['timestampMillis'] = value
     
     
     @property
     def eventGranularity(self) -> Union[None, "TimeWindowSizeClass"]:
-        """Granularity of the event if applicable"""
+        """Getter: Granularity of the event if applicable"""
         return self._inner_dict.get('eventGranularity')  # type: ignore
     
     @eventGranularity.setter
     def eventGranularity(self, value: Union[None, "TimeWindowSizeClass"]) -> None:
+        """Setter: Granularity of the event if applicable"""
         self._inner_dict['eventGranularity'] = value
     
     
     @property
     def partitionSpec(self) -> Union["PartitionSpecClass", None]:
-        """The optional partition specification."""
+        """Getter: The optional partition specification."""
         return self._inner_dict.get('partitionSpec')  # type: ignore
     
     @partitionSpec.setter
     def partitionSpec(self, value: Union["PartitionSpecClass", None]) -> None:
+        """Setter: The optional partition specification."""
         self._inner_dict['partitionSpec'] = value
     
     
     @property
     def messageId(self) -> Union[None, str]:
-        """The optional messageId, if provided serves as a custom user-defined unique identifier for an aspect value."""
+        """Getter: The optional messageId, if provided serves as a custom user-defined unique identifier for an aspect value."""
         return self._inner_dict.get('messageId')  # type: ignore
     
     @messageId.setter
     def messageId(self, value: Union[None, str]) -> None:
+        """Setter: The optional messageId, if provided serves as a custom user-defined unique identifier for an aspect value."""
         self._inner_dict['messageId'] = value
     
     
     @property
     def pipelineName(self) -> str:
-        """The name of the pipeline that ran ingestion, a stable unique user provided identifier.
+        """Getter: The name of the pipeline that ran ingestion, a stable unique user provided identifier.
      e.g. my_snowflake1-to-datahub."""
         return self._inner_dict.get('pipelineName')  # type: ignore
     
     @pipelineName.setter
     def pipelineName(self, value: str) -> None:
+        """Setter: The name of the pipeline that ran ingestion, a stable unique user provided identifier.
+     e.g. my_snowflake1-to-datahub."""
         self._inner_dict['pipelineName'] = value
     
     
     @property
     def platformInstanceId(self) -> str:
-        """The id of the instance against which the ingestion pipeline ran.
+        """Getter: The id of the instance against which the ingestion pipeline ran.
     e.g.: Bigquery project ids, MySQL hostnames etc."""
         return self._inner_dict.get('platformInstanceId')  # type: ignore
     
     @platformInstanceId.setter
     def platformInstanceId(self, value: str) -> None:
+        """Setter: The id of the instance against which the ingestion pipeline ran.
+    e.g.: Bigquery project ids, MySQL hostnames etc."""
         self._inner_dict['platformInstanceId'] = value
     
     
     @property
     def config(self) -> str:
-        """Json-encoded string representation of the non-secret members of the config ."""
+        """Getter: Json-encoded string representation of the non-secret members of the config ."""
         return self._inner_dict.get('config')  # type: ignore
     
     @config.setter
     def config(self, value: str) -> None:
+        """Setter: Json-encoded string representation of the non-secret members of the config ."""
         self._inner_dict['config'] = value
     
     
     @property
     def state(self) -> "IngestionCheckpointStateClass":
-        """Opaque blob of the state representation."""
+        """Getter: Opaque blob of the state representation."""
         return self._inner_dict.get('state')  # type: ignore
     
     @state.setter
     def state(self, value: "IngestionCheckpointStateClass") -> None:
+        """Setter: Opaque blob of the state representation."""
         self._inner_dict['state'] = value
     
     
     @property
     def runId(self) -> str:
-        """The run identifier of this job."""
+        """Getter: The run identifier of this job."""
         return self._inner_dict.get('runId')  # type: ignore
     
     @runId.setter
     def runId(self, value: str) -> None:
+        """Setter: The run identifier of this job."""
         self._inner_dict['runId'] = value
     
     
 class DatahubIngestionRunSummaryClass(_Aspect):
     """Summary of a datahub ingestion run for a given platform."""
 
 
@@ -4704,14 +5353,21 @@
         self.softwareVersion = softwareVersion
         self.systemHostName = systemHostName
         self.operatingSystemName = operatingSystemName
         self.numProcessors = numProcessors
         self.totalMemory = totalMemory
         self.availableMemory = availableMemory
     
+    @classmethod
+    def construct_with_defaults(cls) -> "DatahubIngestionRunSummaryClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.timestampMillis = int()
         self.eventGranularity = self.RECORD_SCHEMA.fields_dict["eventGranularity"].default
         self.partitionSpec = _json_converter.from_json_object(self.RECORD_SCHEMA.fields_dict["partitionSpec"].default, writers_schema=self.RECORD_SCHEMA.fields_dict["partitionSpec"].type)
         self.messageId = self.RECORD_SCHEMA.fields_dict["messageId"].default
         self.pipelineName = str()
         self.platformInstanceId = str()
@@ -4737,291 +5393,321 @@
         self.numProcessors = self.RECORD_SCHEMA.fields_dict["numProcessors"].default
         self.totalMemory = self.RECORD_SCHEMA.fields_dict["totalMemory"].default
         self.availableMemory = self.RECORD_SCHEMA.fields_dict["availableMemory"].default
     
     
     @property
     def timestampMillis(self) -> int:
-        """The event timestamp field as epoch at UTC in milli seconds."""
+        """Getter: The event timestamp field as epoch at UTC in milli seconds."""
         return self._inner_dict.get('timestampMillis')  # type: ignore
     
     @timestampMillis.setter
     def timestampMillis(self, value: int) -> None:
+        """Setter: The event timestamp field as epoch at UTC in milli seconds."""
         self._inner_dict['timestampMillis'] = value
     
     
     @property
     def eventGranularity(self) -> Union[None, "TimeWindowSizeClass"]:
-        """Granularity of the event if applicable"""
+        """Getter: Granularity of the event if applicable"""
         return self._inner_dict.get('eventGranularity')  # type: ignore
     
     @eventGranularity.setter
     def eventGranularity(self, value: Union[None, "TimeWindowSizeClass"]) -> None:
+        """Setter: Granularity of the event if applicable"""
         self._inner_dict['eventGranularity'] = value
     
     
     @property
     def partitionSpec(self) -> Union["PartitionSpecClass", None]:
-        """The optional partition specification."""
+        """Getter: The optional partition specification."""
         return self._inner_dict.get('partitionSpec')  # type: ignore
     
     @partitionSpec.setter
     def partitionSpec(self, value: Union["PartitionSpecClass", None]) -> None:
+        """Setter: The optional partition specification."""
         self._inner_dict['partitionSpec'] = value
     
     
     @property
     def messageId(self) -> Union[None, str]:
-        """The optional messageId, if provided serves as a custom user-defined unique identifier for an aspect value."""
+        """Getter: The optional messageId, if provided serves as a custom user-defined unique identifier for an aspect value."""
         return self._inner_dict.get('messageId')  # type: ignore
     
     @messageId.setter
     def messageId(self, value: Union[None, str]) -> None:
+        """Setter: The optional messageId, if provided serves as a custom user-defined unique identifier for an aspect value."""
         self._inner_dict['messageId'] = value
     
     
     @property
     def pipelineName(self) -> str:
-        """The name of the pipeline that ran ingestion, a stable unique user provided identifier.
+        """Getter: The name of the pipeline that ran ingestion, a stable unique user provided identifier.
      e.g. my_snowflake1-to-datahub."""
         return self._inner_dict.get('pipelineName')  # type: ignore
     
     @pipelineName.setter
     def pipelineName(self, value: str) -> None:
+        """Setter: The name of the pipeline that ran ingestion, a stable unique user provided identifier.
+     e.g. my_snowflake1-to-datahub."""
         self._inner_dict['pipelineName'] = value
     
     
     @property
     def platformInstanceId(self) -> str:
-        """The id of the instance against which the ingestion pipeline ran.
+        """Getter: The id of the instance against which the ingestion pipeline ran.
     e.g.: Bigquery project ids, MySQL hostnames etc."""
         return self._inner_dict.get('platformInstanceId')  # type: ignore
     
     @platformInstanceId.setter
     def platformInstanceId(self, value: str) -> None:
+        """Setter: The id of the instance against which the ingestion pipeline ran.
+    e.g.: Bigquery project ids, MySQL hostnames etc."""
         self._inner_dict['platformInstanceId'] = value
     
     
     @property
     def runId(self) -> str:
-        """The runId for this pipeline instance."""
+        """Getter: The runId for this pipeline instance."""
         return self._inner_dict.get('runId')  # type: ignore
     
     @runId.setter
     def runId(self, value: str) -> None:
+        """Setter: The runId for this pipeline instance."""
         self._inner_dict['runId'] = value
     
     
     @property
     def runStatus(self) -> Union[str, "JobStatusClass"]:
-        """Run Status - Succeeded/Skipped/Failed etc."""
+        """Getter: Run Status - Succeeded/Skipped/Failed etc."""
         return self._inner_dict.get('runStatus')  # type: ignore
     
     @runStatus.setter
     def runStatus(self, value: Union[str, "JobStatusClass"]) -> None:
+        """Setter: Run Status - Succeeded/Skipped/Failed etc."""
         self._inner_dict['runStatus'] = value
     
     
     @property
     def numWorkUnitsCommitted(self) -> Union[None, int]:
-        """The number of workunits written to sink."""
+        """Getter: The number of workunits written to sink."""
         return self._inner_dict.get('numWorkUnitsCommitted')  # type: ignore
     
     @numWorkUnitsCommitted.setter
     def numWorkUnitsCommitted(self, value: Union[None, int]) -> None:
+        """Setter: The number of workunits written to sink."""
         self._inner_dict['numWorkUnitsCommitted'] = value
     
     
     @property
     def numWorkUnitsCreated(self) -> Union[None, int]:
-        """The number of workunits that are produced."""
+        """Getter: The number of workunits that are produced."""
         return self._inner_dict.get('numWorkUnitsCreated')  # type: ignore
     
     @numWorkUnitsCreated.setter
     def numWorkUnitsCreated(self, value: Union[None, int]) -> None:
+        """Setter: The number of workunits that are produced."""
         self._inner_dict['numWorkUnitsCreated'] = value
     
     
     @property
     def numEvents(self) -> Union[None, int]:
-        """The number of events produced (MCE + MCP)."""
+        """Getter: The number of events produced (MCE + MCP)."""
         return self._inner_dict.get('numEvents')  # type: ignore
     
     @numEvents.setter
     def numEvents(self, value: Union[None, int]) -> None:
+        """Setter: The number of events produced (MCE + MCP)."""
         self._inner_dict['numEvents'] = value
     
     
     @property
     def numEntities(self) -> Union[None, int]:
-        """The total number of entities produced (unique entity urns)."""
+        """Getter: The total number of entities produced (unique entity urns)."""
         return self._inner_dict.get('numEntities')  # type: ignore
     
     @numEntities.setter
     def numEntities(self, value: Union[None, int]) -> None:
+        """Setter: The total number of entities produced (unique entity urns)."""
         self._inner_dict['numEntities'] = value
     
     
     @property
     def numAspects(self) -> Union[None, int]:
-        """The total number of aspects produced across all entities."""
+        """Getter: The total number of aspects produced across all entities."""
         return self._inner_dict.get('numAspects')  # type: ignore
     
     @numAspects.setter
     def numAspects(self, value: Union[None, int]) -> None:
+        """Setter: The total number of aspects produced across all entities."""
         self._inner_dict['numAspects'] = value
     
     
     @property
     def numSourceAPICalls(self) -> Union[None, int]:
-        """Total number of source API calls."""
+        """Getter: Total number of source API calls."""
         return self._inner_dict.get('numSourceAPICalls')  # type: ignore
     
     @numSourceAPICalls.setter
     def numSourceAPICalls(self, value: Union[None, int]) -> None:
+        """Setter: Total number of source API calls."""
         self._inner_dict['numSourceAPICalls'] = value
     
     
     @property
     def totalLatencySourceAPICalls(self) -> Union[None, int]:
-        """Total latency across all source API calls."""
+        """Getter: Total latency across all source API calls."""
         return self._inner_dict.get('totalLatencySourceAPICalls')  # type: ignore
     
     @totalLatencySourceAPICalls.setter
     def totalLatencySourceAPICalls(self, value: Union[None, int]) -> None:
+        """Setter: Total latency across all source API calls."""
         self._inner_dict['totalLatencySourceAPICalls'] = value
     
     
     @property
     def numSinkAPICalls(self) -> Union[None, int]:
-        """Total number of sink API calls."""
+        """Getter: Total number of sink API calls."""
         return self._inner_dict.get('numSinkAPICalls')  # type: ignore
     
     @numSinkAPICalls.setter
     def numSinkAPICalls(self, value: Union[None, int]) -> None:
+        """Setter: Total number of sink API calls."""
         self._inner_dict['numSinkAPICalls'] = value
     
     
     @property
     def totalLatencySinkAPICalls(self) -> Union[None, int]:
-        """Total latency across all sink API calls."""
+        """Getter: Total latency across all sink API calls."""
         return self._inner_dict.get('totalLatencySinkAPICalls')  # type: ignore
     
     @totalLatencySinkAPICalls.setter
     def totalLatencySinkAPICalls(self, value: Union[None, int]) -> None:
+        """Setter: Total latency across all sink API calls."""
         self._inner_dict['totalLatencySinkAPICalls'] = value
     
     
     @property
     def numWarnings(self) -> Union[None, int]:
-        """Number of warnings generated."""
+        """Getter: Number of warnings generated."""
         return self._inner_dict.get('numWarnings')  # type: ignore
     
     @numWarnings.setter
     def numWarnings(self, value: Union[None, int]) -> None:
+        """Setter: Number of warnings generated."""
         self._inner_dict['numWarnings'] = value
     
     
     @property
     def numErrors(self) -> Union[None, int]:
-        """Number of errors generated."""
+        """Getter: Number of errors generated."""
         return self._inner_dict.get('numErrors')  # type: ignore
     
     @numErrors.setter
     def numErrors(self, value: Union[None, int]) -> None:
+        """Setter: Number of errors generated."""
         self._inner_dict['numErrors'] = value
     
     
     @property
     def numEntitiesSkipped(self) -> Union[None, int]:
-        """Number of entities skipped."""
+        """Getter: Number of entities skipped."""
         return self._inner_dict.get('numEntitiesSkipped')  # type: ignore
     
     @numEntitiesSkipped.setter
     def numEntitiesSkipped(self, value: Union[None, int]) -> None:
+        """Setter: Number of entities skipped."""
         self._inner_dict['numEntitiesSkipped'] = value
     
     
     @property
     def config(self) -> Union[None, str]:
-        """The non-sensitive key-value pairs of the yaml config used as json string."""
+        """Getter: The non-sensitive key-value pairs of the yaml config used as json string."""
         return self._inner_dict.get('config')  # type: ignore
     
     @config.setter
     def config(self, value: Union[None, str]) -> None:
+        """Setter: The non-sensitive key-value pairs of the yaml config used as json string."""
         self._inner_dict['config'] = value
     
     
     @property
     def custom_summary(self) -> Union[None, str]:
-        """Custom value."""
+        """Getter: Custom value."""
         return self._inner_dict.get('custom_summary')  # type: ignore
     
     @custom_summary.setter
     def custom_summary(self, value: Union[None, str]) -> None:
+        """Setter: Custom value."""
         self._inner_dict['custom_summary'] = value
     
     
     @property
     def softwareVersion(self) -> Union[None, str]:
-        """The software version of this ingestion."""
+        """Getter: The software version of this ingestion."""
         return self._inner_dict.get('softwareVersion')  # type: ignore
     
     @softwareVersion.setter
     def softwareVersion(self, value: Union[None, str]) -> None:
+        """Setter: The software version of this ingestion."""
         self._inner_dict['softwareVersion'] = value
     
     
     @property
     def systemHostName(self) -> Union[None, str]:
-        """The hostname the ingestion pipeline ran on."""
+        """Getter: The hostname the ingestion pipeline ran on."""
         return self._inner_dict.get('systemHostName')  # type: ignore
     
     @systemHostName.setter
     def systemHostName(self, value: Union[None, str]) -> None:
+        """Setter: The hostname the ingestion pipeline ran on."""
         self._inner_dict['systemHostName'] = value
     
     
     @property
     def operatingSystemName(self) -> Union[None, str]:
-        """The os the ingestion pipeline ran on."""
+        """Getter: The os the ingestion pipeline ran on."""
         return self._inner_dict.get('operatingSystemName')  # type: ignore
     
     @operatingSystemName.setter
     def operatingSystemName(self, value: Union[None, str]) -> None:
+        """Setter: The os the ingestion pipeline ran on."""
         self._inner_dict['operatingSystemName'] = value
     
     
     @property
     def numProcessors(self) -> Union[None, int]:
-        """The number of processors on the host the ingestion pipeline ran on."""
+        """Getter: The number of processors on the host the ingestion pipeline ran on."""
         return self._inner_dict.get('numProcessors')  # type: ignore
     
     @numProcessors.setter
     def numProcessors(self, value: Union[None, int]) -> None:
+        """Setter: The number of processors on the host the ingestion pipeline ran on."""
         self._inner_dict['numProcessors'] = value
     
     
     @property
     def totalMemory(self) -> Union[None, int]:
-        """The total amount of memory on the host the ingestion pipeline ran on."""
+        """Getter: The total amount of memory on the host the ingestion pipeline ran on."""
         return self._inner_dict.get('totalMemory')  # type: ignore
     
     @totalMemory.setter
     def totalMemory(self, value: Union[None, int]) -> None:
+        """Setter: The total amount of memory on the host the ingestion pipeline ran on."""
         self._inner_dict['totalMemory'] = value
     
     
     @property
     def availableMemory(self) -> Union[None, int]:
-        """The available memory on the host the ingestion pipeline ran on."""
+        """Getter: The available memory on the host the ingestion pipeline ran on."""
         return self._inner_dict.get('availableMemory')  # type: ignore
     
     @availableMemory.setter
     def availableMemory(self, value: Union[None, int]) -> None:
+        """Setter: The available memory on the host the ingestion pipeline ran on."""
         self._inner_dict['availableMemory'] = value
     
     
 class IngestionCheckpointStateClass(DictWrapper):
     """The checkpoint state object of a datahub ingestion run for a given job."""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.datajob.datahub.IngestionCheckpointState")
@@ -5032,47 +5718,57 @@
     ):
         super().__init__()
         
         self.formatVersion = formatVersion
         self.serde = serde
         self.payload = payload
     
+    @classmethod
+    def construct_with_defaults(cls) -> "IngestionCheckpointStateClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.formatVersion = str()
         self.serde = str()
         self.payload = self.RECORD_SCHEMA.fields_dict["payload"].default
     
     
     @property
     def formatVersion(self) -> str:
-        """The version of the state format."""
+        """Getter: The version of the state format."""
         return self._inner_dict.get('formatVersion')  # type: ignore
     
     @formatVersion.setter
     def formatVersion(self, value: str) -> None:
+        """Setter: The version of the state format."""
         self._inner_dict['formatVersion'] = value
     
     
     @property
     def serde(self) -> str:
-        """The serialization/deserialization protocol."""
+        """Getter: The serialization/deserialization protocol."""
         return self._inner_dict.get('serde')  # type: ignore
     
     @serde.setter
     def serde(self, value: str) -> None:
+        """Setter: The serialization/deserialization protocol."""
         self._inner_dict['serde'] = value
     
     
     @property
     def payload(self) -> Union[None, bytes]:
-        """Opaque blob of the state representation."""
+        """Getter: Opaque blob of the state representation."""
         return self._inner_dict.get('payload')  # type: ignore
     
     @payload.setter
     def payload(self, value: Union[None, bytes]) -> None:
+        """Setter: Opaque blob of the state representation."""
         self._inner_dict['payload'] = value
     
     
 class DataPlatformInfoClass(_Aspect):
     """Information about a data platform"""
 
 
@@ -5091,69 +5787,81 @@
         
         self.name = name
         self.displayName = displayName
         self.type = type
         self.datasetNameDelimiter = datasetNameDelimiter
         self.logoUrl = logoUrl
     
+    @classmethod
+    def construct_with_defaults(cls) -> "DataPlatformInfoClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.name = str()
         self.displayName = self.RECORD_SCHEMA.fields_dict["displayName"].default
         self.type = PlatformTypeClass.FILE_SYSTEM
         self.datasetNameDelimiter = str()
         self.logoUrl = self.RECORD_SCHEMA.fields_dict["logoUrl"].default
     
     
     @property
     def name(self) -> str:
-        """Name of the data platform"""
+        """Getter: Name of the data platform"""
         return self._inner_dict.get('name')  # type: ignore
     
     @name.setter
     def name(self, value: str) -> None:
+        """Setter: Name of the data platform"""
         self._inner_dict['name'] = value
     
     
     @property
     def displayName(self) -> Union[None, str]:
-        """The name that will be used for displaying a platform type."""
+        """Getter: The name that will be used for displaying a platform type."""
         return self._inner_dict.get('displayName')  # type: ignore
     
     @displayName.setter
     def displayName(self, value: Union[None, str]) -> None:
+        """Setter: The name that will be used for displaying a platform type."""
         self._inner_dict['displayName'] = value
     
     
     @property
     def type(self) -> Union[str, "PlatformTypeClass"]:
-        """Platform type this data platform describes"""
+        """Getter: Platform type this data platform describes"""
         return self._inner_dict.get('type')  # type: ignore
     
     @type.setter
     def type(self, value: Union[str, "PlatformTypeClass"]) -> None:
+        """Setter: Platform type this data platform describes"""
         self._inner_dict['type'] = value
     
     
     @property
     def datasetNameDelimiter(self) -> str:
-        """The delimiter in the dataset names on the data platform, e.g. '/' for HDFS and '.' for Oracle"""
+        """Getter: The delimiter in the dataset names on the data platform, e.g. '/' for HDFS and '.' for Oracle"""
         return self._inner_dict.get('datasetNameDelimiter')  # type: ignore
     
     @datasetNameDelimiter.setter
     def datasetNameDelimiter(self, value: str) -> None:
+        """Setter: The delimiter in the dataset names on the data platform, e.g. '/' for HDFS and '.' for Oracle"""
         self._inner_dict['datasetNameDelimiter'] = value
     
     
     @property
     def logoUrl(self) -> Union[None, str]:
-        """The URL for a logo associated with the platform"""
+        """Getter: The URL for a logo associated with the platform"""
         return self._inner_dict.get('logoUrl')  # type: ignore
     
     @logoUrl.setter
     def logoUrl(self, value: Union[None, str]) -> None:
+        """Setter: The URL for a logo associated with the platform"""
         self._inner_dict['logoUrl'] = value
     
     
 class PlatformTypeClass(object):
     """Platform types available at LinkedIn"""
     
     
@@ -5206,58 +5914,69 @@
             self.customProperties = dict()
         else:
             self.customProperties = customProperties
         self.externalUrl = externalUrl
         self.name = name
         self.description = description
     
+    @classmethod
+    def construct_with_defaults(cls) -> "DataPlatformInstancePropertiesClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.customProperties = dict()
         self.externalUrl = self.RECORD_SCHEMA.fields_dict["externalUrl"].default
         self.name = self.RECORD_SCHEMA.fields_dict["name"].default
         self.description = self.RECORD_SCHEMA.fields_dict["description"].default
     
     
     @property
     def customProperties(self) -> Dict[str, str]:
-        """Custom property bag."""
+        """Getter: Custom property bag."""
         return self._inner_dict.get('customProperties')  # type: ignore
     
     @customProperties.setter
     def customProperties(self, value: Dict[str, str]) -> None:
+        """Setter: Custom property bag."""
         self._inner_dict['customProperties'] = value
     
     
     @property
     def externalUrl(self) -> Union[None, str]:
-        """URL where the reference exist"""
+        """Getter: URL where the reference exist"""
         return self._inner_dict.get('externalUrl')  # type: ignore
     
     @externalUrl.setter
     def externalUrl(self, value: Union[None, str]) -> None:
+        """Setter: URL where the reference exist"""
         self._inner_dict['externalUrl'] = value
     
     
     @property
     def name(self) -> Union[None, str]:
-        """Display name of the Data Platform Instance"""
+        """Getter: Display name of the Data Platform Instance"""
         return self._inner_dict.get('name')  # type: ignore
     
     @name.setter
     def name(self, value: Union[None, str]) -> None:
+        """Setter: Display name of the Data Platform Instance"""
         self._inner_dict['name'] = value
     
     
     @property
     def description(self) -> Union[None, str]:
-        """Documentation of the Data Platform Instance"""
+        """Getter: Documentation of the Data Platform Instance"""
         return self._inner_dict.get('description')  # type: ignore
     
     @description.setter
     def description(self, value: Union[None, str]) -> None:
+        """Setter: Documentation of the Data Platform Instance"""
         self._inner_dict['description'] = value
     
     
 class DataProcessInfoClass(_Aspect):
     """The inputs and outputs of this data process"""
 
 
@@ -5270,36 +5989,45 @@
         outputs: Union[None, List[str]]=None,
     ):
         super().__init__()
         
         self.inputs = inputs
         self.outputs = outputs
     
+    @classmethod
+    def construct_with_defaults(cls) -> "DataProcessInfoClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.inputs = self.RECORD_SCHEMA.fields_dict["inputs"].default
         self.outputs = self.RECORD_SCHEMA.fields_dict["outputs"].default
     
     
     @property
     def inputs(self) -> Union[None, List[str]]:
-        """the inputs of the data process"""
+        """Getter: the inputs of the data process"""
         return self._inner_dict.get('inputs')  # type: ignore
     
     @inputs.setter
     def inputs(self, value: Union[None, List[str]]) -> None:
+        """Setter: the inputs of the data process"""
         self._inner_dict['inputs'] = value
     
     
     @property
     def outputs(self) -> Union[None, List[str]]:
-        """the outputs of the data process"""
+        """Getter: the outputs of the data process"""
         return self._inner_dict.get('outputs')  # type: ignore
     
     @outputs.setter
     def outputs(self, value: Union[None, List[str]]) -> None:
+        """Setter: the outputs of the data process"""
         self._inner_dict['outputs'] = value
     
     
 class DataProcessInstanceInputClass(_Aspect):
     """Information about the inputs datasets of a Data process"""
 
 
@@ -5310,25 +6038,33 @@
     def __init__(self,
         inputs: List[str],
     ):
         super().__init__()
         
         self.inputs = inputs
     
+    @classmethod
+    def construct_with_defaults(cls) -> "DataProcessInstanceInputClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.inputs = list()
     
     
     @property
     def inputs(self) -> List[str]:
-        """Input datasets to be consumed"""
+        """Getter: Input datasets to be consumed"""
         return self._inner_dict.get('inputs')  # type: ignore
     
     @inputs.setter
     def inputs(self, value: List[str]) -> None:
+        """Setter: Input datasets to be consumed"""
         self._inner_dict['inputs'] = value
     
     
 class DataProcessInstanceOutputClass(_Aspect):
     """Information about the outputs of a Data process"""
 
 
@@ -5339,25 +6075,33 @@
     def __init__(self,
         outputs: List[str],
     ):
         super().__init__()
         
         self.outputs = outputs
     
+    @classmethod
+    def construct_with_defaults(cls) -> "DataProcessInstanceOutputClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.outputs = list()
     
     
     @property
     def outputs(self) -> List[str]:
-        """Output datasets to be produced"""
+        """Getter: Output datasets to be produced"""
         return self._inner_dict.get('outputs')  # type: ignore
     
     @outputs.setter
     def outputs(self, value: List[str]) -> None:
+        """Setter: Output datasets to be produced"""
         self._inner_dict['outputs'] = value
     
     
 class DataProcessInstancePropertiesClass(_Aspect):
     """The inputs and outputs of this data process"""
 
 
@@ -5380,69 +6124,81 @@
         else:
             self.customProperties = customProperties
         self.externalUrl = externalUrl
         self.name = name
         self.type = type
         self.created = created
     
+    @classmethod
+    def construct_with_defaults(cls) -> "DataProcessInstancePropertiesClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.customProperties = dict()
         self.externalUrl = self.RECORD_SCHEMA.fields_dict["externalUrl"].default
         self.name = str()
         self.type = self.RECORD_SCHEMA.fields_dict["type"].default
-        self.created = AuditStampClass._construct_with_defaults()
+        self.created = AuditStampClass.construct_with_defaults()
     
     
     @property
     def customProperties(self) -> Dict[str, str]:
-        """Custom property bag."""
+        """Getter: Custom property bag."""
         return self._inner_dict.get('customProperties')  # type: ignore
     
     @customProperties.setter
     def customProperties(self, value: Dict[str, str]) -> None:
+        """Setter: Custom property bag."""
         self._inner_dict['customProperties'] = value
     
     
     @property
     def externalUrl(self) -> Union[None, str]:
-        """URL where the reference exist"""
+        """Getter: URL where the reference exist"""
         return self._inner_dict.get('externalUrl')  # type: ignore
     
     @externalUrl.setter
     def externalUrl(self, value: Union[None, str]) -> None:
+        """Setter: URL where the reference exist"""
         self._inner_dict['externalUrl'] = value
     
     
     @property
     def name(self) -> str:
-        """Process name"""
+        """Getter: Process name"""
         return self._inner_dict.get('name')  # type: ignore
     
     @name.setter
     def name(self, value: str) -> None:
+        """Setter: Process name"""
         self._inner_dict['name'] = value
     
     
     @property
     def type(self) -> Union[None, Union[str, "DataProcessTypeClass"]]:
-        """Process type"""
+        """Getter: Process type"""
         return self._inner_dict.get('type')  # type: ignore
     
     @type.setter
     def type(self, value: Union[None, Union[str, "DataProcessTypeClass"]]) -> None:
+        """Setter: Process type"""
         self._inner_dict['type'] = value
     
     
     @property
     def created(self) -> "AuditStampClass":
-        """Audit stamp containing who reported the lineage and when"""
+        """Getter: Audit stamp containing who reported the lineage and when"""
         return self._inner_dict.get('created')  # type: ignore
     
     @created.setter
     def created(self, value: "AuditStampClass") -> None:
+        """Setter: Audit stamp containing who reported the lineage and when"""
         self._inner_dict['created'] = value
     
     
 class DataProcessInstanceRelationshipsClass(_Aspect):
     """Information about Data process relationships"""
 
 
@@ -5457,49 +6213,61 @@
     ):
         super().__init__()
         
         self.parentTemplate = parentTemplate
         self.parentInstance = parentInstance
         self.upstreamInstances = upstreamInstances
     
+    @classmethod
+    def construct_with_defaults(cls) -> "DataProcessInstanceRelationshipsClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.parentTemplate = self.RECORD_SCHEMA.fields_dict["parentTemplate"].default
         self.parentInstance = self.RECORD_SCHEMA.fields_dict["parentInstance"].default
         self.upstreamInstances = list()
     
     
     @property
     def parentTemplate(self) -> Union[None, str]:
-        """The parent entity whose run instance it is"""
+        """Getter: The parent entity whose run instance it is"""
         return self._inner_dict.get('parentTemplate')  # type: ignore
     
     @parentTemplate.setter
     def parentTemplate(self, value: Union[None, str]) -> None:
+        """Setter: The parent entity whose run instance it is"""
         self._inner_dict['parentTemplate'] = value
     
     
     @property
     def parentInstance(self) -> Union[None, str]:
-        """The parent DataProcessInstance where it belongs to.
+        """Getter: The parent DataProcessInstance where it belongs to.
     If it is a Airflow Task then it should belong to an Airflow Dag run as well
     which will be another DataProcessInstance"""
         return self._inner_dict.get('parentInstance')  # type: ignore
     
     @parentInstance.setter
     def parentInstance(self, value: Union[None, str]) -> None:
+        """Setter: The parent DataProcessInstance where it belongs to.
+    If it is a Airflow Task then it should belong to an Airflow Dag run as well
+    which will be another DataProcessInstance"""
         self._inner_dict['parentInstance'] = value
     
     
     @property
     def upstreamInstances(self) -> List[str]:
-        """Input DataProcessInstance which triggered this dataprocess instance"""
+        """Getter: Input DataProcessInstance which triggered this dataprocess instance"""
         return self._inner_dict.get('upstreamInstances')  # type: ignore
     
     @upstreamInstances.setter
     def upstreamInstances(self, value: List[str]) -> None:
+        """Setter: Input DataProcessInstance which triggered this dataprocess instance"""
         self._inner_dict['upstreamInstances'] = value
     
     
 class DataProcessInstanceRunEventClass(_Aspect):
     """An event representing the current status of data process run.
     DataProcessRunEvent should be used for reporting the status of a dataProcess' run."""
 
@@ -5530,102 +6298,117 @@
             self.partitionSpec = partitionSpec
         self.messageId = messageId
         self.externalUrl = externalUrl
         self.status = status
         self.attempt = attempt
         self.result = result
     
+    @classmethod
+    def construct_with_defaults(cls) -> "DataProcessInstanceRunEventClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.timestampMillis = int()
         self.eventGranularity = self.RECORD_SCHEMA.fields_dict["eventGranularity"].default
         self.partitionSpec = _json_converter.from_json_object(self.RECORD_SCHEMA.fields_dict["partitionSpec"].default, writers_schema=self.RECORD_SCHEMA.fields_dict["partitionSpec"].type)
         self.messageId = self.RECORD_SCHEMA.fields_dict["messageId"].default
         self.externalUrl = self.RECORD_SCHEMA.fields_dict["externalUrl"].default
         self.status = DataProcessRunStatusClass.STARTED
         self.attempt = self.RECORD_SCHEMA.fields_dict["attempt"].default
         self.result = self.RECORD_SCHEMA.fields_dict["result"].default
     
     
     @property
     def timestampMillis(self) -> int:
-        """The event timestamp field as epoch at UTC in milli seconds."""
+        """Getter: The event timestamp field as epoch at UTC in milli seconds."""
         return self._inner_dict.get('timestampMillis')  # type: ignore
     
     @timestampMillis.setter
     def timestampMillis(self, value: int) -> None:
+        """Setter: The event timestamp field as epoch at UTC in milli seconds."""
         self._inner_dict['timestampMillis'] = value
     
     
     @property
     def eventGranularity(self) -> Union[None, "TimeWindowSizeClass"]:
-        """Granularity of the event if applicable"""
+        """Getter: Granularity of the event if applicable"""
         return self._inner_dict.get('eventGranularity')  # type: ignore
     
     @eventGranularity.setter
     def eventGranularity(self, value: Union[None, "TimeWindowSizeClass"]) -> None:
+        """Setter: Granularity of the event if applicable"""
         self._inner_dict['eventGranularity'] = value
     
     
     @property
     def partitionSpec(self) -> Union["PartitionSpecClass", None]:
-        """The optional partition specification."""
+        """Getter: The optional partition specification."""
         return self._inner_dict.get('partitionSpec')  # type: ignore
     
     @partitionSpec.setter
     def partitionSpec(self, value: Union["PartitionSpecClass", None]) -> None:
+        """Setter: The optional partition specification."""
         self._inner_dict['partitionSpec'] = value
     
     
     @property
     def messageId(self) -> Union[None, str]:
-        """The optional messageId, if provided serves as a custom user-defined unique identifier for an aspect value."""
+        """Getter: The optional messageId, if provided serves as a custom user-defined unique identifier for an aspect value."""
         return self._inner_dict.get('messageId')  # type: ignore
     
     @messageId.setter
     def messageId(self, value: Union[None, str]) -> None:
+        """Setter: The optional messageId, if provided serves as a custom user-defined unique identifier for an aspect value."""
         self._inner_dict['messageId'] = value
     
     
     @property
     def externalUrl(self) -> Union[None, str]:
-        """URL where the reference exist"""
+        """Getter: URL where the reference exist"""
         return self._inner_dict.get('externalUrl')  # type: ignore
     
     @externalUrl.setter
     def externalUrl(self, value: Union[None, str]) -> None:
+        """Setter: URL where the reference exist"""
         self._inner_dict['externalUrl'] = value
     
     
     @property
     def status(self) -> Union[str, "DataProcessRunStatusClass"]:
         # No docs available.
         return self._inner_dict.get('status')  # type: ignore
     
     @status.setter
     def status(self, value: Union[str, "DataProcessRunStatusClass"]) -> None:
+        # No docs available.
         self._inner_dict['status'] = value
     
     
     @property
     def attempt(self) -> Union[None, int]:
-        """Return the try number that this Instance Run is in"""
+        """Getter: Return the try number that this Instance Run is in"""
         return self._inner_dict.get('attempt')  # type: ignore
     
     @attempt.setter
     def attempt(self, value: Union[None, int]) -> None:
+        """Setter: Return the try number that this Instance Run is in"""
         self._inner_dict['attempt'] = value
     
     
     @property
     def result(self) -> Union[None, "DataProcessInstanceRunResultClass"]:
-        """The final result of the Data Processing run."""
+        """Getter: The final result of the Data Processing run."""
         return self._inner_dict.get('result')  # type: ignore
     
     @result.setter
     def result(self, value: Union[None, "DataProcessInstanceRunResultClass"]) -> None:
+        """Setter: The final result of the Data Processing run."""
         self._inner_dict['result'] = value
     
     
 class DataProcessInstanceRunResultClass(DictWrapper):
     # No docs available.
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.dataprocess.DataProcessInstanceRunResult")
@@ -5634,36 +6417,45 @@
         nativeResultType: str,
     ):
         super().__init__()
         
         self.type = type
         self.nativeResultType = nativeResultType
     
+    @classmethod
+    def construct_with_defaults(cls) -> "DataProcessInstanceRunResultClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.type = RunResultTypeClass.SUCCESS
         self.nativeResultType = str()
     
     
     @property
     def type(self) -> Union[str, "RunResultTypeClass"]:
-        """ The final result, e.g. SUCCESS, FAILURE, SKIPPED, or UP_FOR_RETRY."""
+        """Getter:  The final result, e.g. SUCCESS, FAILURE, SKIPPED, or UP_FOR_RETRY."""
         return self._inner_dict.get('type')  # type: ignore
     
     @type.setter
     def type(self, value: Union[str, "RunResultTypeClass"]) -> None:
+        """Setter:  The final result, e.g. SUCCESS, FAILURE, SKIPPED, or UP_FOR_RETRY."""
         self._inner_dict['type'] = value
     
     
     @property
     def nativeResultType(self) -> str:
-        """It identifies the system where the native result comes from like Airflow, Azkaban, etc.."""
+        """Getter: It identifies the system where the native result comes from like Airflow, Azkaban, etc.."""
         return self._inner_dict.get('nativeResultType')  # type: ignore
     
     @nativeResultType.setter
     def nativeResultType(self, value: str) -> None:
+        """Setter: It identifies the system where the native result comes from like Airflow, Azkaban, etc.."""
         self._inner_dict['nativeResultType'] = value
     
     
 class DataProcessRunStatusClass(object):
     # No docs available.
     
     
@@ -5716,58 +6508,69 @@
         super().__init__()
         
         self.deprecated = deprecated
         self.decommissionTime = decommissionTime
         self.note = note
         self.actor = actor
     
+    @classmethod
+    def construct_with_defaults(cls) -> "DatasetDeprecationClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.deprecated = bool()
         self.decommissionTime = self.RECORD_SCHEMA.fields_dict["decommissionTime"].default
         self.note = str()
         self.actor = self.RECORD_SCHEMA.fields_dict["actor"].default
     
     
     @property
     def deprecated(self) -> bool:
-        """Whether the dataset is deprecated by owner."""
+        """Getter: Whether the dataset is deprecated by owner."""
         return self._inner_dict.get('deprecated')  # type: ignore
     
     @deprecated.setter
     def deprecated(self, value: bool) -> None:
+        """Setter: Whether the dataset is deprecated by owner."""
         self._inner_dict['deprecated'] = value
     
     
     @property
     def decommissionTime(self) -> Union[None, int]:
-        """The time user plan to decommission this dataset."""
+        """Getter: The time user plan to decommission this dataset."""
         return self._inner_dict.get('decommissionTime')  # type: ignore
     
     @decommissionTime.setter
     def decommissionTime(self, value: Union[None, int]) -> None:
+        """Setter: The time user plan to decommission this dataset."""
         self._inner_dict['decommissionTime'] = value
     
     
     @property
     def note(self) -> str:
-        """Additional information about the dataset deprecation plan, such as the wiki, doc, RB."""
+        """Getter: Additional information about the dataset deprecation plan, such as the wiki, doc, RB."""
         return self._inner_dict.get('note')  # type: ignore
     
     @note.setter
     def note(self, value: str) -> None:
+        """Setter: Additional information about the dataset deprecation plan, such as the wiki, doc, RB."""
         self._inner_dict['note'] = value
     
     
     @property
     def actor(self) -> Union[None, str]:
-        """The corpuser URN which will be credited for modifying this deprecation content."""
+        """Getter: The corpuser URN which will be credited for modifying this deprecation content."""
         return self._inner_dict.get('actor')  # type: ignore
     
     @actor.setter
     def actor(self, value: Union[None, str]) -> None:
+        """Setter: The corpuser URN which will be credited for modifying this deprecation content."""
         self._inner_dict['actor'] = value
     
     
 class DatasetFieldMappingClass(DictWrapper):
     """Representation of mapping between fields in source dataset to the field in destination dataset"""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.dataset.DatasetFieldMapping")
@@ -5780,58 +6583,69 @@
         super().__init__()
         
         self.created = created
         self.transformation = transformation
         self.sourceFields = sourceFields
         self.destinationField = destinationField
     
+    @classmethod
+    def construct_with_defaults(cls) -> "DatasetFieldMappingClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
-        self.created = AuditStampClass._construct_with_defaults()
+        self.created = AuditStampClass.construct_with_defaults()
         self.transformation = TransformationTypeClass.BLACKBOX
         self.sourceFields = list()
         self.destinationField = str()
     
     
     @property
     def created(self) -> "AuditStampClass":
-        """Audit stamp containing who reported the field mapping and when"""
+        """Getter: Audit stamp containing who reported the field mapping and when"""
         return self._inner_dict.get('created')  # type: ignore
     
     @created.setter
     def created(self, value: "AuditStampClass") -> None:
+        """Setter: Audit stamp containing who reported the field mapping and when"""
         self._inner_dict['created'] = value
     
     
     @property
     def transformation(self) -> Union[Union[str, "TransformationTypeClass"], "UDFTransformerClass"]:
-        """Transfomration function between the fields involved"""
+        """Getter: Transfomration function between the fields involved"""
         return self._inner_dict.get('transformation')  # type: ignore
     
     @transformation.setter
     def transformation(self, value: Union[Union[str, "TransformationTypeClass"], "UDFTransformerClass"]) -> None:
+        """Setter: Transfomration function between the fields involved"""
         self._inner_dict['transformation'] = value
     
     
     @property
     def sourceFields(self) -> List[str]:
-        """Source fields from which the fine grained lineage is derived"""
+        """Getter: Source fields from which the fine grained lineage is derived"""
         return self._inner_dict.get('sourceFields')  # type: ignore
     
     @sourceFields.setter
     def sourceFields(self, value: List[str]) -> None:
+        """Setter: Source fields from which the fine grained lineage is derived"""
         self._inner_dict['sourceFields'] = value
     
     
     @property
     def destinationField(self) -> str:
-        """Destination field which is derived from source fields"""
+        """Getter: Destination field which is derived from source fields"""
         return self._inner_dict.get('destinationField')  # type: ignore
     
     @destinationField.setter
     def destinationField(self, value: str) -> None:
+        """Setter: Destination field which is derived from source fields"""
         self._inner_dict['destinationField'] = value
     
     
 class DatasetFieldProfileClass(DictWrapper):
     """Stats corresponding to fields in a dataset"""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.dataset.DatasetFieldProfile")
@@ -5864,14 +6678,21 @@
         self.median = median
         self.stdev = stdev
         self.quantiles = quantiles
         self.distinctValueFrequencies = distinctValueFrequencies
         self.histogram = histogram
         self.sampleValues = sampleValues
     
+    @classmethod
+    def construct_with_defaults(cls) -> "DatasetFieldProfileClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.fieldPath = str()
         self.uniqueCount = self.RECORD_SCHEMA.fields_dict["uniqueCount"].default
         self.uniqueProportion = self.RECORD_SCHEMA.fields_dict["uniqueProportion"].default
         self.nullCount = self.RECORD_SCHEMA.fields_dict["nullCount"].default
         self.nullProportion = self.RECORD_SCHEMA.fields_dict["nullProportion"].default
         self.min = self.RECORD_SCHEMA.fields_dict["min"].default
@@ -5888,144 +6709,158 @@
     @property
     def fieldPath(self) -> str:
         # No docs available.
         return self._inner_dict.get('fieldPath')  # type: ignore
     
     @fieldPath.setter
     def fieldPath(self, value: str) -> None:
+        # No docs available.
         self._inner_dict['fieldPath'] = value
     
     
     @property
     def uniqueCount(self) -> Union[None, int]:
         # No docs available.
         return self._inner_dict.get('uniqueCount')  # type: ignore
     
     @uniqueCount.setter
     def uniqueCount(self, value: Union[None, int]) -> None:
+        # No docs available.
         self._inner_dict['uniqueCount'] = value
     
     
     @property
     def uniqueProportion(self) -> Union[None, float]:
         # No docs available.
         return self._inner_dict.get('uniqueProportion')  # type: ignore
     
     @uniqueProportion.setter
     def uniqueProportion(self, value: Union[None, float]) -> None:
+        # No docs available.
         self._inner_dict['uniqueProportion'] = value
     
     
     @property
     def nullCount(self) -> Union[None, int]:
         # No docs available.
         return self._inner_dict.get('nullCount')  # type: ignore
     
     @nullCount.setter
     def nullCount(self, value: Union[None, int]) -> None:
+        # No docs available.
         self._inner_dict['nullCount'] = value
     
     
     @property
     def nullProportion(self) -> Union[None, float]:
         # No docs available.
         return self._inner_dict.get('nullProportion')  # type: ignore
     
     @nullProportion.setter
     def nullProportion(self, value: Union[None, float]) -> None:
+        # No docs available.
         self._inner_dict['nullProportion'] = value
     
     
     @property
     def min(self) -> Union[None, str]:
         # No docs available.
         return self._inner_dict.get('min')  # type: ignore
     
     @min.setter
     def min(self, value: Union[None, str]) -> None:
+        # No docs available.
         self._inner_dict['min'] = value
     
     
     @property
     def max(self) -> Union[None, str]:
         # No docs available.
         return self._inner_dict.get('max')  # type: ignore
     
     @max.setter
     def max(self, value: Union[None, str]) -> None:
+        # No docs available.
         self._inner_dict['max'] = value
     
     
     @property
     def mean(self) -> Union[None, str]:
         # No docs available.
         return self._inner_dict.get('mean')  # type: ignore
     
     @mean.setter
     def mean(self, value: Union[None, str]) -> None:
+        # No docs available.
         self._inner_dict['mean'] = value
     
     
     @property
     def median(self) -> Union[None, str]:
         # No docs available.
         return self._inner_dict.get('median')  # type: ignore
     
     @median.setter
     def median(self, value: Union[None, str]) -> None:
+        # No docs available.
         self._inner_dict['median'] = value
     
     
     @property
     def stdev(self) -> Union[None, str]:
         # No docs available.
         return self._inner_dict.get('stdev')  # type: ignore
     
     @stdev.setter
     def stdev(self, value: Union[None, str]) -> None:
+        # No docs available.
         self._inner_dict['stdev'] = value
     
     
     @property
     def quantiles(self) -> Union[None, List["QuantileClass"]]:
         # No docs available.
         return self._inner_dict.get('quantiles')  # type: ignore
     
     @quantiles.setter
     def quantiles(self, value: Union[None, List["QuantileClass"]]) -> None:
+        # No docs available.
         self._inner_dict['quantiles'] = value
     
     
     @property
     def distinctValueFrequencies(self) -> Union[None, List["ValueFrequencyClass"]]:
         # No docs available.
         return self._inner_dict.get('distinctValueFrequencies')  # type: ignore
     
     @distinctValueFrequencies.setter
     def distinctValueFrequencies(self, value: Union[None, List["ValueFrequencyClass"]]) -> None:
+        # No docs available.
         self._inner_dict['distinctValueFrequencies'] = value
     
     
     @property
     def histogram(self) -> Union[None, "HistogramClass"]:
         # No docs available.
         return self._inner_dict.get('histogram')  # type: ignore
     
     @histogram.setter
     def histogram(self, value: Union[None, "HistogramClass"]) -> None:
+        # No docs available.
         self._inner_dict['histogram'] = value
     
     
     @property
     def sampleValues(self) -> Union[None, List[str]]:
         # No docs available.
         return self._inner_dict.get('sampleValues')  # type: ignore
     
     @sampleValues.setter
     def sampleValues(self, value: Union[None, List[str]]) -> None:
+        # No docs available.
         self._inner_dict['sampleValues'] = value
     
     
 class DatasetFieldUsageCountsClass(DictWrapper):
     """Records field-level usage counts for a given dataset"""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.dataset.DatasetFieldUsageCounts")
@@ -6034,36 +6869,45 @@
         count: int,
     ):
         super().__init__()
         
         self.fieldPath = fieldPath
         self.count = count
     
+    @classmethod
+    def construct_with_defaults(cls) -> "DatasetFieldUsageCountsClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.fieldPath = str()
         self.count = int()
     
     
     @property
     def fieldPath(self) -> str:
-        """The name of the field."""
+        """Getter: The name of the field."""
         return self._inner_dict.get('fieldPath')  # type: ignore
     
     @fieldPath.setter
     def fieldPath(self, value: str) -> None:
+        """Setter: The name of the field."""
         self._inner_dict['fieldPath'] = value
     
     
     @property
     def count(self) -> int:
-        """Number of times the field has been used."""
+        """Getter: Number of times the field has been used."""
         return self._inner_dict.get('count')  # type: ignore
     
     @count.setter
     def count(self, value: int) -> None:
+        """Setter: Number of times the field has been used."""
         self._inner_dict['count'] = value
     
     
 class DatasetLineageTypeClass(object):
     """The various types of supported dataset lineage"""
     
     
@@ -6107,102 +6951,117 @@
             self.partitionSpec = partitionSpec
         self.messageId = messageId
         self.rowCount = rowCount
         self.columnCount = columnCount
         self.fieldProfiles = fieldProfiles
         self.sizeInBytes = sizeInBytes
     
+    @classmethod
+    def construct_with_defaults(cls) -> "DatasetProfileClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.timestampMillis = int()
         self.eventGranularity = self.RECORD_SCHEMA.fields_dict["eventGranularity"].default
         self.partitionSpec = _json_converter.from_json_object(self.RECORD_SCHEMA.fields_dict["partitionSpec"].default, writers_schema=self.RECORD_SCHEMA.fields_dict["partitionSpec"].type)
         self.messageId = self.RECORD_SCHEMA.fields_dict["messageId"].default
         self.rowCount = self.RECORD_SCHEMA.fields_dict["rowCount"].default
         self.columnCount = self.RECORD_SCHEMA.fields_dict["columnCount"].default
         self.fieldProfiles = self.RECORD_SCHEMA.fields_dict["fieldProfiles"].default
         self.sizeInBytes = self.RECORD_SCHEMA.fields_dict["sizeInBytes"].default
     
     
     @property
     def timestampMillis(self) -> int:
-        """The event timestamp field as epoch at UTC in milli seconds."""
+        """Getter: The event timestamp field as epoch at UTC in milli seconds."""
         return self._inner_dict.get('timestampMillis')  # type: ignore
     
     @timestampMillis.setter
     def timestampMillis(self, value: int) -> None:
+        """Setter: The event timestamp field as epoch at UTC in milli seconds."""
         self._inner_dict['timestampMillis'] = value
     
     
     @property
     def eventGranularity(self) -> Union[None, "TimeWindowSizeClass"]:
-        """Granularity of the event if applicable"""
+        """Getter: Granularity of the event if applicable"""
         return self._inner_dict.get('eventGranularity')  # type: ignore
     
     @eventGranularity.setter
     def eventGranularity(self, value: Union[None, "TimeWindowSizeClass"]) -> None:
+        """Setter: Granularity of the event if applicable"""
         self._inner_dict['eventGranularity'] = value
     
     
     @property
     def partitionSpec(self) -> Union["PartitionSpecClass", None]:
-        """The optional partition specification."""
+        """Getter: The optional partition specification."""
         return self._inner_dict.get('partitionSpec')  # type: ignore
     
     @partitionSpec.setter
     def partitionSpec(self, value: Union["PartitionSpecClass", None]) -> None:
+        """Setter: The optional partition specification."""
         self._inner_dict['partitionSpec'] = value
     
     
     @property
     def messageId(self) -> Union[None, str]:
-        """The optional messageId, if provided serves as a custom user-defined unique identifier for an aspect value."""
+        """Getter: The optional messageId, if provided serves as a custom user-defined unique identifier for an aspect value."""
         return self._inner_dict.get('messageId')  # type: ignore
     
     @messageId.setter
     def messageId(self, value: Union[None, str]) -> None:
+        """Setter: The optional messageId, if provided serves as a custom user-defined unique identifier for an aspect value."""
         self._inner_dict['messageId'] = value
     
     
     @property
     def rowCount(self) -> Union[None, int]:
-        """The total number of rows"""
+        """Getter: The total number of rows"""
         return self._inner_dict.get('rowCount')  # type: ignore
     
     @rowCount.setter
     def rowCount(self, value: Union[None, int]) -> None:
+        """Setter: The total number of rows"""
         self._inner_dict['rowCount'] = value
     
     
     @property
     def columnCount(self) -> Union[None, int]:
-        """The total number of columns (or schema fields)"""
+        """Getter: The total number of columns (or schema fields)"""
         return self._inner_dict.get('columnCount')  # type: ignore
     
     @columnCount.setter
     def columnCount(self, value: Union[None, int]) -> None:
+        """Setter: The total number of columns (or schema fields)"""
         self._inner_dict['columnCount'] = value
     
     
     @property
     def fieldProfiles(self) -> Union[None, List["DatasetFieldProfileClass"]]:
-        """Profiles for each column (or schema field)"""
+        """Getter: Profiles for each column (or schema field)"""
         return self._inner_dict.get('fieldProfiles')  # type: ignore
     
     @fieldProfiles.setter
     def fieldProfiles(self, value: Union[None, List["DatasetFieldProfileClass"]]) -> None:
+        """Setter: Profiles for each column (or schema field)"""
         self._inner_dict['fieldProfiles'] = value
     
     
     @property
     def sizeInBytes(self) -> Union[None, int]:
-        """Storage size in bytes"""
+        """Getter: Storage size in bytes"""
         return self._inner_dict.get('sizeInBytes')  # type: ignore
     
     @sizeInBytes.setter
     def sizeInBytes(self, value: Union[None, int]) -> None:
+        """Setter: Storage size in bytes"""
         self._inner_dict['sizeInBytes'] = value
     
     
 class DatasetPropertiesClass(_Aspect):
     """Properties associated with a Dataset"""
 
 
@@ -6237,114 +7096,131 @@
         self.lastModified = lastModified
         if tags is None:
             # default: []
             self.tags = list()
         else:
             self.tags = tags
     
+    @classmethod
+    def construct_with_defaults(cls) -> "DatasetPropertiesClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.customProperties = dict()
         self.externalUrl = self.RECORD_SCHEMA.fields_dict["externalUrl"].default
         self.name = self.RECORD_SCHEMA.fields_dict["name"].default
         self.qualifiedName = self.RECORD_SCHEMA.fields_dict["qualifiedName"].default
         self.description = self.RECORD_SCHEMA.fields_dict["description"].default
         self.uri = self.RECORD_SCHEMA.fields_dict["uri"].default
         self.created = self.RECORD_SCHEMA.fields_dict["created"].default
         self.lastModified = self.RECORD_SCHEMA.fields_dict["lastModified"].default
         self.tags = list()
     
     
     @property
     def customProperties(self) -> Dict[str, str]:
-        """Custom property bag."""
+        """Getter: Custom property bag."""
         return self._inner_dict.get('customProperties')  # type: ignore
     
     @customProperties.setter
     def customProperties(self, value: Dict[str, str]) -> None:
+        """Setter: Custom property bag."""
         self._inner_dict['customProperties'] = value
     
     
     @property
     def externalUrl(self) -> Union[None, str]:
-        """URL where the reference exist"""
+        """Getter: URL where the reference exist"""
         return self._inner_dict.get('externalUrl')  # type: ignore
     
     @externalUrl.setter
     def externalUrl(self, value: Union[None, str]) -> None:
+        """Setter: URL where the reference exist"""
         self._inner_dict['externalUrl'] = value
     
     
     @property
     def name(self) -> Union[None, str]:
-        """Display name of the Dataset"""
+        """Getter: Display name of the Dataset"""
         return self._inner_dict.get('name')  # type: ignore
     
     @name.setter
     def name(self, value: Union[None, str]) -> None:
+        """Setter: Display name of the Dataset"""
         self._inner_dict['name'] = value
     
     
     @property
     def qualifiedName(self) -> Union[None, str]:
-        """Fully-qualified name of the Dataset"""
+        """Getter: Fully-qualified name of the Dataset"""
         return self._inner_dict.get('qualifiedName')  # type: ignore
     
     @qualifiedName.setter
     def qualifiedName(self, value: Union[None, str]) -> None:
+        """Setter: Fully-qualified name of the Dataset"""
         self._inner_dict['qualifiedName'] = value
     
     
     @property
     def description(self) -> Union[None, str]:
-        """Documentation of the dataset"""
+        """Getter: Documentation of the dataset"""
         return self._inner_dict.get('description')  # type: ignore
     
     @description.setter
     def description(self, value: Union[None, str]) -> None:
+        """Setter: Documentation of the dataset"""
         self._inner_dict['description'] = value
     
     
     @property
     def uri(self) -> Union[None, str]:
-        """The abstracted URI such as hdfs:///data/tracking/PageViewEvent, file:///dir/file_name. Uri should not include any environment specific properties. Some datasets might not have a standardized uri, which makes this field optional (i.e. kafka topic)."""
+        """Getter: The abstracted URI such as hdfs:///data/tracking/PageViewEvent, file:///dir/file_name. Uri should not include any environment specific properties. Some datasets might not have a standardized uri, which makes this field optional (i.e. kafka topic)."""
         return self._inner_dict.get('uri')  # type: ignore
     
     @uri.setter
     def uri(self, value: Union[None, str]) -> None:
+        """Setter: The abstracted URI such as hdfs:///data/tracking/PageViewEvent, file:///dir/file_name. Uri should not include any environment specific properties. Some datasets might not have a standardized uri, which makes this field optional (i.e. kafka topic)."""
         self._inner_dict['uri'] = value
     
     
     @property
     def created(self) -> Union[None, "TimeStampClass"]:
-        """A timestamp documenting when the asset was created in the source Data Platform (not on DataHub)"""
+        """Getter: A timestamp documenting when the asset was created in the source Data Platform (not on DataHub)"""
         return self._inner_dict.get('created')  # type: ignore
     
     @created.setter
     def created(self, value: Union[None, "TimeStampClass"]) -> None:
+        """Setter: A timestamp documenting when the asset was created in the source Data Platform (not on DataHub)"""
         self._inner_dict['created'] = value
     
     
     @property
     def lastModified(self) -> Union[None, "TimeStampClass"]:
-        """A timestamp documenting when the asset was last modified in the source Data Platform (not on DataHub)"""
+        """Getter: A timestamp documenting when the asset was last modified in the source Data Platform (not on DataHub)"""
         return self._inner_dict.get('lastModified')  # type: ignore
     
     @lastModified.setter
     def lastModified(self, value: Union[None, "TimeStampClass"]) -> None:
+        """Setter: A timestamp documenting when the asset was last modified in the source Data Platform (not on DataHub)"""
         self._inner_dict['lastModified'] = value
     
     
     @property
     def tags(self) -> List[str]:
-        """[Legacy] Unstructured tags for the dataset. Structured tags can be applied via the `GlobalTags` aspect.
+        """Getter: [Legacy] Unstructured tags for the dataset. Structured tags can be applied via the `GlobalTags` aspect.
     This is now deprecated."""
         return self._inner_dict.get('tags')  # type: ignore
     
     @tags.setter
     def tags(self, value: List[str]) -> None:
+        """Setter: [Legacy] Unstructured tags for the dataset. Structured tags can be applied via the `GlobalTags` aspect.
+    This is now deprecated."""
         self._inner_dict['tags'] = value
     
     
 class DatasetUpstreamLineageClass(_Aspect):
     """Fine Grained upstream lineage for fields in a dataset"""
 
 
@@ -6355,25 +7231,33 @@
     def __init__(self,
         fieldMappings: List["DatasetFieldMappingClass"],
     ):
         super().__init__()
         
         self.fieldMappings = fieldMappings
     
+    @classmethod
+    def construct_with_defaults(cls) -> "DatasetUpstreamLineageClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.fieldMappings = list()
     
     
     @property
     def fieldMappings(self) -> List["DatasetFieldMappingClass"]:
-        """Upstream to downstream field level lineage mappings"""
+        """Getter: Upstream to downstream field level lineage mappings"""
         return self._inner_dict.get('fieldMappings')  # type: ignore
     
     @fieldMappings.setter
     def fieldMappings(self, value: List["DatasetFieldMappingClass"]) -> None:
+        """Setter: Upstream to downstream field level lineage mappings"""
         self._inner_dict['fieldMappings'] = value
     
     
 class DatasetUsageStatisticsClass(_Aspect):
     """Stats corresponding to dataset's usage."""
 
 
@@ -6405,113 +7289,129 @@
         self.messageId = messageId
         self.uniqueUserCount = uniqueUserCount
         self.totalSqlQueries = totalSqlQueries
         self.topSqlQueries = topSqlQueries
         self.userCounts = userCounts
         self.fieldCounts = fieldCounts
     
+    @classmethod
+    def construct_with_defaults(cls) -> "DatasetUsageStatisticsClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.timestampMillis = int()
         self.eventGranularity = self.RECORD_SCHEMA.fields_dict["eventGranularity"].default
         self.partitionSpec = _json_converter.from_json_object(self.RECORD_SCHEMA.fields_dict["partitionSpec"].default, writers_schema=self.RECORD_SCHEMA.fields_dict["partitionSpec"].type)
         self.messageId = self.RECORD_SCHEMA.fields_dict["messageId"].default
         self.uniqueUserCount = self.RECORD_SCHEMA.fields_dict["uniqueUserCount"].default
         self.totalSqlQueries = self.RECORD_SCHEMA.fields_dict["totalSqlQueries"].default
         self.topSqlQueries = self.RECORD_SCHEMA.fields_dict["topSqlQueries"].default
         self.userCounts = self.RECORD_SCHEMA.fields_dict["userCounts"].default
         self.fieldCounts = self.RECORD_SCHEMA.fields_dict["fieldCounts"].default
     
     
     @property
     def timestampMillis(self) -> int:
-        """The event timestamp field as epoch at UTC in milli seconds."""
+        """Getter: The event timestamp field as epoch at UTC in milli seconds."""
         return self._inner_dict.get('timestampMillis')  # type: ignore
     
     @timestampMillis.setter
     def timestampMillis(self, value: int) -> None:
+        """Setter: The event timestamp field as epoch at UTC in milli seconds."""
         self._inner_dict['timestampMillis'] = value
     
     
     @property
     def eventGranularity(self) -> Union[None, "TimeWindowSizeClass"]:
-        """Granularity of the event if applicable"""
+        """Getter: Granularity of the event if applicable"""
         return self._inner_dict.get('eventGranularity')  # type: ignore
     
     @eventGranularity.setter
     def eventGranularity(self, value: Union[None, "TimeWindowSizeClass"]) -> None:
+        """Setter: Granularity of the event if applicable"""
         self._inner_dict['eventGranularity'] = value
     
     
     @property
     def partitionSpec(self) -> Union["PartitionSpecClass", None]:
-        """The optional partition specification."""
+        """Getter: The optional partition specification."""
         return self._inner_dict.get('partitionSpec')  # type: ignore
     
     @partitionSpec.setter
     def partitionSpec(self, value: Union["PartitionSpecClass", None]) -> None:
+        """Setter: The optional partition specification."""
         self._inner_dict['partitionSpec'] = value
     
     
     @property
     def messageId(self) -> Union[None, str]:
-        """The optional messageId, if provided serves as a custom user-defined unique identifier for an aspect value."""
+        """Getter: The optional messageId, if provided serves as a custom user-defined unique identifier for an aspect value."""
         return self._inner_dict.get('messageId')  # type: ignore
     
     @messageId.setter
     def messageId(self, value: Union[None, str]) -> None:
+        """Setter: The optional messageId, if provided serves as a custom user-defined unique identifier for an aspect value."""
         self._inner_dict['messageId'] = value
     
     
     @property
     def uniqueUserCount(self) -> Union[None, int]:
-        """Unique user count"""
+        """Getter: Unique user count"""
         return self._inner_dict.get('uniqueUserCount')  # type: ignore
     
     @uniqueUserCount.setter
     def uniqueUserCount(self, value: Union[None, int]) -> None:
+        """Setter: Unique user count"""
         self._inner_dict['uniqueUserCount'] = value
     
     
     @property
     def totalSqlQueries(self) -> Union[None, int]:
-        """Total SQL query count"""
+        """Getter: Total SQL query count"""
         return self._inner_dict.get('totalSqlQueries')  # type: ignore
     
     @totalSqlQueries.setter
     def totalSqlQueries(self, value: Union[None, int]) -> None:
+        """Setter: Total SQL query count"""
         self._inner_dict['totalSqlQueries'] = value
     
     
     @property
     def topSqlQueries(self) -> Union[None, List[str]]:
-        """Frequent SQL queries; mostly makes sense for datasets in SQL databases"""
+        """Getter: Frequent SQL queries; mostly makes sense for datasets in SQL databases"""
         return self._inner_dict.get('topSqlQueries')  # type: ignore
     
     @topSqlQueries.setter
     def topSqlQueries(self, value: Union[None, List[str]]) -> None:
+        """Setter: Frequent SQL queries; mostly makes sense for datasets in SQL databases"""
         self._inner_dict['topSqlQueries'] = value
     
     
     @property
     def userCounts(self) -> Union[None, List["DatasetUserUsageCountsClass"]]:
-        """Users within this bucket, with frequency counts"""
+        """Getter: Users within this bucket, with frequency counts"""
         return self._inner_dict.get('userCounts')  # type: ignore
     
     @userCounts.setter
     def userCounts(self, value: Union[None, List["DatasetUserUsageCountsClass"]]) -> None:
+        """Setter: Users within this bucket, with frequency counts"""
         self._inner_dict['userCounts'] = value
     
     
     @property
     def fieldCounts(self) -> Union[None, List["DatasetFieldUsageCountsClass"]]:
-        """Field-level usage stats"""
+        """Getter: Field-level usage stats"""
         return self._inner_dict.get('fieldCounts')  # type: ignore
     
     @fieldCounts.setter
     def fieldCounts(self, value: Union[None, List["DatasetFieldUsageCountsClass"]]) -> None:
+        """Setter: Field-level usage stats"""
         self._inner_dict['fieldCounts'] = value
     
     
 class DatasetUserUsageCountsClass(DictWrapper):
     """Records a single user's usage counts for a given resource"""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.dataset.DatasetUserUsageCounts")
@@ -6522,47 +7422,57 @@
     ):
         super().__init__()
         
         self.user = user
         self.count = count
         self.userEmail = userEmail
     
+    @classmethod
+    def construct_with_defaults(cls) -> "DatasetUserUsageCountsClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.user = str()
         self.count = int()
         self.userEmail = self.RECORD_SCHEMA.fields_dict["userEmail"].default
     
     
     @property
     def user(self) -> str:
-        """The unique id of the user."""
+        """Getter: The unique id of the user."""
         return self._inner_dict.get('user')  # type: ignore
     
     @user.setter
     def user(self, value: str) -> None:
+        """Setter: The unique id of the user."""
         self._inner_dict['user'] = value
     
     
     @property
     def count(self) -> int:
-        """Number of times the dataset has been used by the user."""
+        """Getter: Number of times the dataset has been used by the user."""
         return self._inner_dict.get('count')  # type: ignore
     
     @count.setter
     def count(self, value: int) -> None:
+        """Setter: Number of times the dataset has been used by the user."""
         self._inner_dict['count'] = value
     
     
     @property
     def userEmail(self) -> Union[None, str]:
-        """If user_email is set, we attempt to resolve the user's urn upon ingest"""
+        """Getter: If user_email is set, we attempt to resolve the user's urn upon ingest"""
         return self._inner_dict.get('userEmail')  # type: ignore
     
     @userEmail.setter
     def userEmail(self, value: Union[None, str]) -> None:
+        """Setter: If user_email is set, we attempt to resolve the user's urn upon ingest"""
         self._inner_dict['userEmail'] = value
     
     
 class EditableDatasetPropertiesClass(_Aspect):
     """EditableDatasetProperties stores editable changes made to dataset properties. This separates changes made from
     ingestion pipelines and edits in the UI to avoid accidental overwrites of user-provided data by ingestion pipelines"""
 
@@ -6588,58 +7498,69 @@
             # default: {'actor': 'urn:li:corpuser:unknown', 'impersonator': None, 'time': 0, 'message': None}
             self.lastModified = _json_converter.from_json_object(self.RECORD_SCHEMA.fields_dict["lastModified"].default, writers_schema=self.RECORD_SCHEMA.fields_dict["lastModified"].type)
         else:
             self.lastModified = lastModified
         self.deleted = deleted
         self.description = description
     
+    @classmethod
+    def construct_with_defaults(cls) -> "EditableDatasetPropertiesClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.created = _json_converter.from_json_object(self.RECORD_SCHEMA.fields_dict["created"].default, writers_schema=self.RECORD_SCHEMA.fields_dict["created"].type)
         self.lastModified = _json_converter.from_json_object(self.RECORD_SCHEMA.fields_dict["lastModified"].default, writers_schema=self.RECORD_SCHEMA.fields_dict["lastModified"].type)
         self.deleted = self.RECORD_SCHEMA.fields_dict["deleted"].default
         self.description = self.RECORD_SCHEMA.fields_dict["description"].default
     
     
     @property
     def created(self) -> "AuditStampClass":
-        """An AuditStamp corresponding to the creation of this resource/association/sub-resource. A value of 0 for time indicates missing data."""
+        """Getter: An AuditStamp corresponding to the creation of this resource/association/sub-resource. A value of 0 for time indicates missing data."""
         return self._inner_dict.get('created')  # type: ignore
     
     @created.setter
     def created(self, value: "AuditStampClass") -> None:
+        """Setter: An AuditStamp corresponding to the creation of this resource/association/sub-resource. A value of 0 for time indicates missing data."""
         self._inner_dict['created'] = value
     
     
     @property
     def lastModified(self) -> "AuditStampClass":
-        """An AuditStamp corresponding to the last modification of this resource/association/sub-resource. If no modification has happened since creation, lastModified should be the same as created. A value of 0 for time indicates missing data."""
+        """Getter: An AuditStamp corresponding to the last modification of this resource/association/sub-resource. If no modification has happened since creation, lastModified should be the same as created. A value of 0 for time indicates missing data."""
         return self._inner_dict.get('lastModified')  # type: ignore
     
     @lastModified.setter
     def lastModified(self, value: "AuditStampClass") -> None:
+        """Setter: An AuditStamp corresponding to the last modification of this resource/association/sub-resource. If no modification has happened since creation, lastModified should be the same as created. A value of 0 for time indicates missing data."""
         self._inner_dict['lastModified'] = value
     
     
     @property
     def deleted(self) -> Union[None, "AuditStampClass"]:
-        """An AuditStamp corresponding to the deletion of this resource/association/sub-resource. Logically, deleted MUST have a later timestamp than creation. It may or may not have the same time as lastModified depending upon the resource/association/sub-resource semantics."""
+        """Getter: An AuditStamp corresponding to the deletion of this resource/association/sub-resource. Logically, deleted MUST have a later timestamp than creation. It may or may not have the same time as lastModified depending upon the resource/association/sub-resource semantics."""
         return self._inner_dict.get('deleted')  # type: ignore
     
     @deleted.setter
     def deleted(self, value: Union[None, "AuditStampClass"]) -> None:
+        """Setter: An AuditStamp corresponding to the deletion of this resource/association/sub-resource. Logically, deleted MUST have a later timestamp than creation. It may or may not have the same time as lastModified depending upon the resource/association/sub-resource semantics."""
         self._inner_dict['deleted'] = value
     
     
     @property
     def description(self) -> Union[None, str]:
-        """Documentation of the dataset"""
+        """Getter: Documentation of the dataset"""
         return self._inner_dict.get('description')  # type: ignore
     
     @description.setter
     def description(self, value: Union[None, str]) -> None:
+        """Setter: Documentation of the dataset"""
         self._inner_dict['description'] = value
     
     
 class FineGrainedLineageClass(DictWrapper):
     """A fine-grained lineage from upstream fields/datasets to downstream field(s)"""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.dataset.FineGrainedLineage")
@@ -6660,80 +7581,93 @@
         self.transformOperation = transformOperation
         if confidenceScore is None:
             # default: 1.0
             self.confidenceScore = self.RECORD_SCHEMA.fields_dict["confidenceScore"].default
         else:
             self.confidenceScore = confidenceScore
     
+    @classmethod
+    def construct_with_defaults(cls) -> "FineGrainedLineageClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.upstreamType = FineGrainedLineageUpstreamTypeClass.FIELD_SET
         self.upstreams = self.RECORD_SCHEMA.fields_dict["upstreams"].default
         self.downstreamType = FineGrainedLineageDownstreamTypeClass.FIELD
         self.downstreams = self.RECORD_SCHEMA.fields_dict["downstreams"].default
         self.transformOperation = self.RECORD_SCHEMA.fields_dict["transformOperation"].default
         self.confidenceScore = self.RECORD_SCHEMA.fields_dict["confidenceScore"].default
     
     
     @property
     def upstreamType(self) -> Union[str, "FineGrainedLineageUpstreamTypeClass"]:
-        """The type of upstream entity"""
+        """Getter: The type of upstream entity"""
         return self._inner_dict.get('upstreamType')  # type: ignore
     
     @upstreamType.setter
     def upstreamType(self, value: Union[str, "FineGrainedLineageUpstreamTypeClass"]) -> None:
+        """Setter: The type of upstream entity"""
         self._inner_dict['upstreamType'] = value
     
     
     @property
     def upstreams(self) -> Union[None, List[str]]:
-        """Upstream entities in the lineage"""
+        """Getter: Upstream entities in the lineage"""
         return self._inner_dict.get('upstreams')  # type: ignore
     
     @upstreams.setter
     def upstreams(self, value: Union[None, List[str]]) -> None:
+        """Setter: Upstream entities in the lineage"""
         self._inner_dict['upstreams'] = value
     
     
     @property
     def downstreamType(self) -> Union[str, "FineGrainedLineageDownstreamTypeClass"]:
-        """The type of downstream field(s)"""
+        """Getter: The type of downstream field(s)"""
         return self._inner_dict.get('downstreamType')  # type: ignore
     
     @downstreamType.setter
     def downstreamType(self, value: Union[str, "FineGrainedLineageDownstreamTypeClass"]) -> None:
+        """Setter: The type of downstream field(s)"""
         self._inner_dict['downstreamType'] = value
     
     
     @property
     def downstreams(self) -> Union[None, List[str]]:
-        """Downstream fields in the lineage"""
+        """Getter: Downstream fields in the lineage"""
         return self._inner_dict.get('downstreams')  # type: ignore
     
     @downstreams.setter
     def downstreams(self, value: Union[None, List[str]]) -> None:
+        """Setter: Downstream fields in the lineage"""
         self._inner_dict['downstreams'] = value
     
     
     @property
     def transformOperation(self) -> Union[None, str]:
-        """The transform operation applied to the upstream entities to produce the downstream field(s)"""
+        """Getter: The transform operation applied to the upstream entities to produce the downstream field(s)"""
         return self._inner_dict.get('transformOperation')  # type: ignore
     
     @transformOperation.setter
     def transformOperation(self, value: Union[None, str]) -> None:
+        """Setter: The transform operation applied to the upstream entities to produce the downstream field(s)"""
         self._inner_dict['transformOperation'] = value
     
     
     @property
     def confidenceScore(self) -> float:
-        """The confidence in this lineage between 0 (low confidence) and 1 (high confidence)"""
+        """Getter: The confidence in this lineage between 0 (low confidence) and 1 (high confidence)"""
         return self._inner_dict.get('confidenceScore')  # type: ignore
     
     @confidenceScore.setter
     def confidenceScore(self, value: float) -> None:
+        """Setter: The confidence in this lineage between 0 (low confidence) and 1 (high confidence)"""
         self._inner_dict['confidenceScore'] = value
     
     
 class FineGrainedLineageDownstreamTypeClass(object):
     """The type of downstream field(s) in a fine-grained lineage"""
     
     
@@ -6767,36 +7701,45 @@
         heights: List[float],
     ):
         super().__init__()
         
         self.boundaries = boundaries
         self.heights = heights
     
+    @classmethod
+    def construct_with_defaults(cls) -> "HistogramClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.boundaries = list()
         self.heights = list()
     
     
     @property
     def boundaries(self) -> List[str]:
         # No docs available.
         return self._inner_dict.get('boundaries')  # type: ignore
     
     @boundaries.setter
     def boundaries(self, value: List[str]) -> None:
+        # No docs available.
         self._inner_dict['boundaries'] = value
     
     
     @property
     def heights(self) -> List[float]:
         # No docs available.
         return self._inner_dict.get('heights')  # type: ignore
     
     @heights.setter
     def heights(self, value: List[float]) -> None:
+        # No docs available.
         self._inner_dict['heights'] = value
     
     
 class QuantileClass(DictWrapper):
     # No docs available.
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.dataset.Quantile")
@@ -6805,36 +7748,45 @@
         value: str,
     ):
         super().__init__()
         
         self.quantile = quantile
         self.value = value
     
+    @classmethod
+    def construct_with_defaults(cls) -> "QuantileClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.quantile = str()
         self.value = str()
     
     
     @property
     def quantile(self) -> str:
         # No docs available.
         return self._inner_dict.get('quantile')  # type: ignore
     
     @quantile.setter
     def quantile(self, value: str) -> None:
+        # No docs available.
         self._inner_dict['quantile'] = value
     
     
     @property
     def value(self) -> str:
         # No docs available.
         return self._inner_dict.get('value')  # type: ignore
     
     @value.setter
     def value(self, value: str) -> None:
+        # No docs available.
         self._inner_dict['value'] = value
     
     
 class UpstreamClass(DictWrapper):
     """Upstream lineage information about a dataset including the source reporting the lineage"""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.dataset.Upstream")
@@ -6853,69 +7805,81 @@
         else:
             self.auditStamp = auditStamp
         self.created = created
         self.dataset = dataset
         self.type = type
         self.properties = properties
     
+    @classmethod
+    def construct_with_defaults(cls) -> "UpstreamClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.auditStamp = _json_converter.from_json_object(self.RECORD_SCHEMA.fields_dict["auditStamp"].default, writers_schema=self.RECORD_SCHEMA.fields_dict["auditStamp"].type)
         self.created = self.RECORD_SCHEMA.fields_dict["created"].default
         self.dataset = str()
         self.type = DatasetLineageTypeClass.COPY
         self.properties = self.RECORD_SCHEMA.fields_dict["properties"].default
     
     
     @property
     def auditStamp(self) -> "AuditStampClass":
-        """Audit stamp containing who reported the lineage and when."""
+        """Getter: Audit stamp containing who reported the lineage and when."""
         return self._inner_dict.get('auditStamp')  # type: ignore
     
     @auditStamp.setter
     def auditStamp(self, value: "AuditStampClass") -> None:
+        """Setter: Audit stamp containing who reported the lineage and when."""
         self._inner_dict['auditStamp'] = value
     
     
     @property
     def created(self) -> Union[None, "AuditStampClass"]:
-        """Audit stamp containing who created the lineage and when."""
+        """Getter: Audit stamp containing who created the lineage and when."""
         return self._inner_dict.get('created')  # type: ignore
     
     @created.setter
     def created(self, value: Union[None, "AuditStampClass"]) -> None:
+        """Setter: Audit stamp containing who created the lineage and when."""
         self._inner_dict['created'] = value
     
     
     @property
     def dataset(self) -> str:
-        """The upstream dataset the lineage points to"""
+        """Getter: The upstream dataset the lineage points to"""
         return self._inner_dict.get('dataset')  # type: ignore
     
     @dataset.setter
     def dataset(self, value: str) -> None:
+        """Setter: The upstream dataset the lineage points to"""
         self._inner_dict['dataset'] = value
     
     
     @property
     def type(self) -> Union[str, "DatasetLineageTypeClass"]:
-        """The type of the lineage"""
+        """Getter: The type of the lineage"""
         return self._inner_dict.get('type')  # type: ignore
     
     @type.setter
     def type(self, value: Union[str, "DatasetLineageTypeClass"]) -> None:
+        """Setter: The type of the lineage"""
         self._inner_dict['type'] = value
     
     
     @property
     def properties(self) -> Union[None, Dict[str, str]]:
-        """A generic properties bag that allows us to store specific information on this graph edge."""
+        """Getter: A generic properties bag that allows us to store specific information on this graph edge."""
         return self._inner_dict.get('properties')  # type: ignore
     
     @properties.setter
     def properties(self, value: Union[None, Dict[str, str]]) -> None:
+        """Setter: A generic properties bag that allows us to store specific information on this graph edge."""
         self._inner_dict['properties'] = value
     
     
 class UpstreamLineageClass(_Aspect):
     """Upstream lineage of a dataset"""
 
 
@@ -6928,36 +7892,45 @@
         fineGrainedLineages: Union[None, List["FineGrainedLineageClass"]]=None,
     ):
         super().__init__()
         
         self.upstreams = upstreams
         self.fineGrainedLineages = fineGrainedLineages
     
+    @classmethod
+    def construct_with_defaults(cls) -> "UpstreamLineageClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.upstreams = list()
         self.fineGrainedLineages = self.RECORD_SCHEMA.fields_dict["fineGrainedLineages"].default
     
     
     @property
     def upstreams(self) -> List["UpstreamClass"]:
-        """List of upstream dataset lineage information"""
+        """Getter: List of upstream dataset lineage information"""
         return self._inner_dict.get('upstreams')  # type: ignore
     
     @upstreams.setter
     def upstreams(self, value: List["UpstreamClass"]) -> None:
+        """Setter: List of upstream dataset lineage information"""
         self._inner_dict['upstreams'] = value
     
     
     @property
     def fineGrainedLineages(self) -> Union[None, List["FineGrainedLineageClass"]]:
-        """ List of fine-grained lineage information, including field-level lineage"""
+        """Getter:  List of fine-grained lineage information, including field-level lineage"""
         return self._inner_dict.get('fineGrainedLineages')  # type: ignore
     
     @fineGrainedLineages.setter
     def fineGrainedLineages(self, value: Union[None, List["FineGrainedLineageClass"]]) -> None:
+        """Setter:  List of fine-grained lineage information, including field-level lineage"""
         self._inner_dict['fineGrainedLineages'] = value
     
     
 class ValueFrequencyClass(DictWrapper):
     # No docs available.
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.dataset.ValueFrequency")
@@ -6966,36 +7939,45 @@
         frequency: int,
     ):
         super().__init__()
         
         self.value = value
         self.frequency = frequency
     
+    @classmethod
+    def construct_with_defaults(cls) -> "ValueFrequencyClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.value = str()
         self.frequency = int()
     
     
     @property
     def value(self) -> str:
         # No docs available.
         return self._inner_dict.get('value')  # type: ignore
     
     @value.setter
     def value(self, value: str) -> None:
+        # No docs available.
         self._inner_dict['value'] = value
     
     
     @property
     def frequency(self) -> int:
         # No docs available.
         return self._inner_dict.get('frequency')  # type: ignore
     
     @frequency.setter
     def frequency(self, value: int) -> None:
+        # No docs available.
         self._inner_dict['frequency'] = value
     
     
 class ViewPropertiesClass(_Aspect):
     """Details about a View. 
     e.g. Gets activated when subTypes is view"""
 
@@ -7011,47 +7993,57 @@
     ):
         super().__init__()
         
         self.materialized = materialized
         self.viewLogic = viewLogic
         self.viewLanguage = viewLanguage
     
+    @classmethod
+    def construct_with_defaults(cls) -> "ViewPropertiesClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.materialized = bool()
         self.viewLogic = str()
         self.viewLanguage = str()
     
     
     @property
     def materialized(self) -> bool:
-        """Whether the view is materialized"""
+        """Getter: Whether the view is materialized"""
         return self._inner_dict.get('materialized')  # type: ignore
     
     @materialized.setter
     def materialized(self, value: bool) -> None:
+        """Setter: Whether the view is materialized"""
         self._inner_dict['materialized'] = value
     
     
     @property
     def viewLogic(self) -> str:
-        """The view logic"""
+        """Getter: The view logic"""
         return self._inner_dict.get('viewLogic')  # type: ignore
     
     @viewLogic.setter
     def viewLogic(self, value: str) -> None:
+        """Setter: The view logic"""
         self._inner_dict['viewLogic'] = value
     
     
     @property
     def viewLanguage(self) -> str:
-        """The view logic language / dialect"""
+        """Getter: The view logic language / dialect"""
         return self._inner_dict.get('viewLanguage')  # type: ignore
     
     @viewLanguage.setter
     def viewLanguage(self, value: str) -> None:
+        """Setter: The view logic language / dialect"""
         self._inner_dict['viewLanguage'] = value
     
     
 class DomainPropertiesClass(_Aspect):
     """Information about a Domain"""
 
 
@@ -7066,47 +8058,57 @@
     ):
         super().__init__()
         
         self.name = name
         self.description = description
         self.created = created
     
+    @classmethod
+    def construct_with_defaults(cls) -> "DomainPropertiesClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.name = str()
         self.description = self.RECORD_SCHEMA.fields_dict["description"].default
         self.created = self.RECORD_SCHEMA.fields_dict["created"].default
     
     
     @property
     def name(self) -> str:
-        """Display name of the Domain"""
+        """Getter: Display name of the Domain"""
         return self._inner_dict.get('name')  # type: ignore
     
     @name.setter
     def name(self, value: str) -> None:
+        """Setter: Display name of the Domain"""
         self._inner_dict['name'] = value
     
     
     @property
     def description(self) -> Union[None, str]:
-        """Description of the Domain"""
+        """Getter: Description of the Domain"""
         return self._inner_dict.get('description')  # type: ignore
     
     @description.setter
     def description(self, value: Union[None, str]) -> None:
+        """Setter: Description of the Domain"""
         self._inner_dict['description'] = value
     
     
     @property
     def created(self) -> Union[None, "AuditStampClass"]:
-        """Created Audit stamp"""
+        """Getter: Created Audit stamp"""
         return self._inner_dict.get('created')  # type: ignore
     
     @created.setter
     def created(self, value: Union[None, "AuditStampClass"]) -> None:
+        """Setter: Created Audit stamp"""
         self._inner_dict['created'] = value
     
     
 class DomainsClass(_Aspect):
     """Links from an Asset to its Domains"""
 
 
@@ -7117,25 +8119,33 @@
     def __init__(self,
         domains: List[str],
     ):
         super().__init__()
         
         self.domains = domains
     
+    @classmethod
+    def construct_with_defaults(cls) -> "DomainsClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.domains = list()
     
     
     @property
     def domains(self) -> List[str]:
-        """The Domains attached to an Asset"""
+        """Getter: The Domains attached to an Asset"""
         return self._inner_dict.get('domains')  # type: ignore
     
     @domains.setter
     def domains(self, value: List[str]) -> None:
+        """Setter: The Domains attached to an Asset"""
         self._inner_dict['domains'] = value
     
     
 class ChangeTypeClass(object):
     """Descriptor for a change action"""
     
     
@@ -7182,69 +8192,81 @@
         
         self.task = task
         self.args = args
         self.executorId = executorId
         self.source = source
         self.requestedAt = requestedAt
     
+    @classmethod
+    def construct_with_defaults(cls) -> "ExecutionRequestInputClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.task = str()
         self.args = dict()
         self.executorId = str()
-        self.source = ExecutionRequestSourceClass._construct_with_defaults()
+        self.source = ExecutionRequestSourceClass.construct_with_defaults()
         self.requestedAt = int()
     
     
     @property
     def task(self) -> str:
-        """The name of the task to execute, for example RUN_INGEST"""
+        """Getter: The name of the task to execute, for example RUN_INGEST"""
         return self._inner_dict.get('task')  # type: ignore
     
     @task.setter
     def task(self, value: str) -> None:
+        """Setter: The name of the task to execute, for example RUN_INGEST"""
         self._inner_dict['task'] = value
     
     
     @property
     def args(self) -> Dict[str, str]:
-        """Arguments provided to the task"""
+        """Getter: Arguments provided to the task"""
         return self._inner_dict.get('args')  # type: ignore
     
     @args.setter
     def args(self, value: Dict[str, str]) -> None:
+        """Setter: Arguments provided to the task"""
         self._inner_dict['args'] = value
     
     
     @property
     def executorId(self) -> str:
-        """Advanced: specify a specific executor to route the request to. If none is provided, a "default" executor is used."""
+        """Getter: Advanced: specify a specific executor to route the request to. If none is provided, a "default" executor is used."""
         return self._inner_dict.get('executorId')  # type: ignore
     
     @executorId.setter
     def executorId(self, value: str) -> None:
+        """Setter: Advanced: specify a specific executor to route the request to. If none is provided, a "default" executor is used."""
         self._inner_dict['executorId'] = value
     
     
     @property
     def source(self) -> "ExecutionRequestSourceClass":
-        """Source which created the execution request"""
+        """Getter: Source which created the execution request"""
         return self._inner_dict.get('source')  # type: ignore
     
     @source.setter
     def source(self, value: "ExecutionRequestSourceClass") -> None:
+        """Setter: Source which created the execution request"""
         self._inner_dict['source'] = value
     
     
     @property
     def requestedAt(self) -> int:
-        """Time at which the execution request input was created"""
+        """Getter: Time at which the execution request input was created"""
         return self._inner_dict.get('requestedAt')  # type: ignore
     
     @requestedAt.setter
     def requestedAt(self, value: int) -> None:
+        """Setter: Time at which the execution request input was created"""
         self._inner_dict['requestedAt'] = value
     
     
 class ExecutionRequestResultClass(_Aspect):
     """The result of an execution request"""
 
 
@@ -7263,69 +8285,81 @@
         
         self.status = status
         self.report = report
         self.structuredReport = structuredReport
         self.startTimeMs = startTimeMs
         self.durationMs = durationMs
     
+    @classmethod
+    def construct_with_defaults(cls) -> "ExecutionRequestResultClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.status = str()
         self.report = self.RECORD_SCHEMA.fields_dict["report"].default
         self.structuredReport = self.RECORD_SCHEMA.fields_dict["structuredReport"].default
         self.startTimeMs = self.RECORD_SCHEMA.fields_dict["startTimeMs"].default
         self.durationMs = self.RECORD_SCHEMA.fields_dict["durationMs"].default
     
     
     @property
     def status(self) -> str:
-        """The status of the execution request"""
+        """Getter: The status of the execution request"""
         return self._inner_dict.get('status')  # type: ignore
     
     @status.setter
     def status(self, value: str) -> None:
+        """Setter: The status of the execution request"""
         self._inner_dict['status'] = value
     
     
     @property
     def report(self) -> Union[None, str]:
-        """The pretty-printed execution report."""
+        """Getter: The pretty-printed execution report."""
         return self._inner_dict.get('report')  # type: ignore
     
     @report.setter
     def report(self, value: Union[None, str]) -> None:
+        """Setter: The pretty-printed execution report."""
         self._inner_dict['report'] = value
     
     
     @property
     def structuredReport(self) -> Union[None, "StructuredExecutionReportClass"]:
-        """A structured report if available."""
+        """Getter: A structured report if available."""
         return self._inner_dict.get('structuredReport')  # type: ignore
     
     @structuredReport.setter
     def structuredReport(self, value: Union[None, "StructuredExecutionReportClass"]) -> None:
+        """Setter: A structured report if available."""
         self._inner_dict['structuredReport'] = value
     
     
     @property
     def startTimeMs(self) -> Union[None, int]:
-        """Time at which the request was created"""
+        """Getter: Time at which the request was created"""
         return self._inner_dict.get('startTimeMs')  # type: ignore
     
     @startTimeMs.setter
     def startTimeMs(self, value: Union[None, int]) -> None:
+        """Setter: Time at which the request was created"""
         self._inner_dict['startTimeMs'] = value
     
     
     @property
     def durationMs(self) -> Union[None, int]:
-        """Duration in milliseconds"""
+        """Getter: Duration in milliseconds"""
         return self._inner_dict.get('durationMs')  # type: ignore
     
     @durationMs.setter
     def durationMs(self, value: Union[None, int]) -> None:
+        """Setter: Duration in milliseconds"""
         self._inner_dict['durationMs'] = value
     
     
 class ExecutionRequestSignalClass(_Aspect):
     """An signal sent to a running execution request"""
 
 
@@ -7340,47 +8374,57 @@
     ):
         super().__init__()
         
         self.signal = signal
         self.executorId = executorId
         self.createdAt = createdAt
     
+    @classmethod
+    def construct_with_defaults(cls) -> "ExecutionRequestSignalClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.signal = str()
         self.executorId = self.RECORD_SCHEMA.fields_dict["executorId"].default
-        self.createdAt = AuditStampClass._construct_with_defaults()
+        self.createdAt = AuditStampClass.construct_with_defaults()
     
     
     @property
     def signal(self) -> str:
-        """The signal to issue, e.g. KILL"""
+        """Getter: The signal to issue, e.g. KILL"""
         return self._inner_dict.get('signal')  # type: ignore
     
     @signal.setter
     def signal(self, value: str) -> None:
+        """Setter: The signal to issue, e.g. KILL"""
         self._inner_dict['signal'] = value
     
     
     @property
     def executorId(self) -> Union[None, str]:
-        """Advanced: specify a specific executor to route the request to. If none is provided, a "default" executor is used."""
+        """Getter: Advanced: specify a specific executor to route the request to. If none is provided, a "default" executor is used."""
         return self._inner_dict.get('executorId')  # type: ignore
     
     @executorId.setter
     def executorId(self, value: Union[None, str]) -> None:
+        """Setter: Advanced: specify a specific executor to route the request to. If none is provided, a "default" executor is used."""
         self._inner_dict['executorId'] = value
     
     
     @property
     def createdAt(self) -> "AuditStampClass":
-        """Audit Stamp"""
+        """Getter: Audit Stamp"""
         return self._inner_dict.get('createdAt')  # type: ignore
     
     @createdAt.setter
     def createdAt(self, value: "AuditStampClass") -> None:
+        """Setter: Audit Stamp"""
         self._inner_dict['createdAt'] = value
     
     
 class ExecutionRequestSourceClass(DictWrapper):
     # No docs available.
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.execution.ExecutionRequestSource")
@@ -7389,36 +8433,45 @@
         ingestionSource: Union[None, str]=None,
     ):
         super().__init__()
         
         self.type = type
         self.ingestionSource = ingestionSource
     
+    @classmethod
+    def construct_with_defaults(cls) -> "ExecutionRequestSourceClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.type = str()
         self.ingestionSource = self.RECORD_SCHEMA.fields_dict["ingestionSource"].default
     
     
     @property
     def type(self) -> str:
-        """The type of the execution request source, e.g. INGESTION_SOURCE"""
+        """Getter: The type of the execution request source, e.g. INGESTION_SOURCE"""
         return self._inner_dict.get('type')  # type: ignore
     
     @type.setter
     def type(self, value: str) -> None:
+        """Setter: The type of the execution request source, e.g. INGESTION_SOURCE"""
         self._inner_dict['type'] = value
     
     
     @property
     def ingestionSource(self) -> Union[None, str]:
-        """The urn of the ingestion source associated with the ingestion request. Present if type is INGESTION_SOURCE"""
+        """Getter: The urn of the ingestion source associated with the ingestion request. Present if type is INGESTION_SOURCE"""
         return self._inner_dict.get('ingestionSource')  # type: ignore
     
     @ingestionSource.setter
     def ingestionSource(self, value: Union[None, str]) -> None:
+        """Setter: The urn of the ingestion source associated with the ingestion request. Present if type is INGESTION_SOURCE"""
         self._inner_dict['ingestionSource'] = value
     
     
 class StructuredExecutionReportClass(DictWrapper):
     """A flexible carrier for structured results of an execution request.
     The goal is to allow for free flow of structured responses from execution tasks to the orchestrator or observer.
     The full spectrum of different execution report types is not intended to be modeled by this object."""
@@ -7431,47 +8484,57 @@
     ):
         super().__init__()
         
         self.type = type
         self.serializedValue = serializedValue
         self.contentType = contentType
     
+    @classmethod
+    def construct_with_defaults(cls) -> "StructuredExecutionReportClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.type = str()
         self.serializedValue = str()
         self.contentType = str()
     
     
     @property
     def type(self) -> str:
-        """The type of the structured report. (e.g. INGESTION_REPORT, TEST_CONNECTION_REPORT, etc.)"""
+        """Getter: The type of the structured report. (e.g. INGESTION_REPORT, TEST_CONNECTION_REPORT, etc.)"""
         return self._inner_dict.get('type')  # type: ignore
     
     @type.setter
     def type(self, value: str) -> None:
+        """Setter: The type of the structured report. (e.g. INGESTION_REPORT, TEST_CONNECTION_REPORT, etc.)"""
         self._inner_dict['type'] = value
     
     
     @property
     def serializedValue(self) -> str:
-        """The serialized value of the structured report"""
+        """Getter: The serialized value of the structured report"""
         return self._inner_dict.get('serializedValue')  # type: ignore
     
     @serializedValue.setter
     def serializedValue(self, value: str) -> None:
+        """Setter: The serialized value of the structured report"""
         self._inner_dict['serializedValue'] = value
     
     
     @property
     def contentType(self) -> str:
-        """The content-type of the serialized value (e.g. application/json, application/json;gzip etc.)"""
+        """Getter: The content-type of the serialized value (e.g. application/json, application/json;gzip etc.)"""
         return self._inner_dict.get('contentType')  # type: ignore
     
     @contentType.setter
     def contentType(self, value: str) -> None:
+        """Setter: The content-type of the serialized value (e.g. application/json, application/json;gzip etc.)"""
         self._inner_dict['contentType'] = value
     
     
 class GlossaryNodeInfoClass(_Aspect):
     """Properties associated with a GlossaryNode"""
 
 
@@ -7488,58 +8551,69 @@
         super().__init__()
         
         self.definition = definition
         self.parentNode = parentNode
         self.name = name
         self.id = id
     
+    @classmethod
+    def construct_with_defaults(cls) -> "GlossaryNodeInfoClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.definition = str()
         self.parentNode = self.RECORD_SCHEMA.fields_dict["parentNode"].default
         self.name = self.RECORD_SCHEMA.fields_dict["name"].default
         self.id = self.RECORD_SCHEMA.fields_dict["id"].default
     
     
     @property
     def definition(self) -> str:
-        """Definition of business node"""
+        """Getter: Definition of business node"""
         return self._inner_dict.get('definition')  # type: ignore
     
     @definition.setter
     def definition(self, value: str) -> None:
+        """Setter: Definition of business node"""
         self._inner_dict['definition'] = value
     
     
     @property
     def parentNode(self) -> Union[None, str]:
-        """Parent node of the glossary term"""
+        """Getter: Parent node of the glossary term"""
         return self._inner_dict.get('parentNode')  # type: ignore
     
     @parentNode.setter
     def parentNode(self, value: Union[None, str]) -> None:
+        """Setter: Parent node of the glossary term"""
         self._inner_dict['parentNode'] = value
     
     
     @property
     def name(self) -> Union[None, str]:
-        """Display name of the node"""
+        """Getter: Display name of the node"""
         return self._inner_dict.get('name')  # type: ignore
     
     @name.setter
     def name(self, value: Union[None, str]) -> None:
+        """Setter: Display name of the node"""
         self._inner_dict['name'] = value
     
     
     @property
     def id(self) -> Union[None, str]:
-        """Optional id for the GlossaryNode"""
+        """Getter: Optional id for the GlossaryNode"""
         return self._inner_dict.get('id')  # type: ignore
     
     @id.setter
     def id(self, value: Union[None, str]) -> None:
+        """Setter: Optional id for the GlossaryNode"""
         self._inner_dict['id'] = value
     
     
 class GlossaryRelatedTermsClass(_Aspect):
     """Has A / Is A lineage information about a glossary Term reporting the lineage"""
 
 
@@ -7556,59 +8630,71 @@
         super().__init__()
         
         self.isRelatedTerms = isRelatedTerms
         self.hasRelatedTerms = hasRelatedTerms
         self.values = values
         self.relatedTerms = relatedTerms
     
+    @classmethod
+    def construct_with_defaults(cls) -> "GlossaryRelatedTermsClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.isRelatedTerms = self.RECORD_SCHEMA.fields_dict["isRelatedTerms"].default
         self.hasRelatedTerms = self.RECORD_SCHEMA.fields_dict["hasRelatedTerms"].default
         self.values = self.RECORD_SCHEMA.fields_dict["values"].default
         self.relatedTerms = self.RECORD_SCHEMA.fields_dict["relatedTerms"].default
     
     
     @property
     def isRelatedTerms(self) -> Union[None, List[str]]:
-        """The relationship Is A with glossary term"""
+        """Getter: The relationship Is A with glossary term"""
         return self._inner_dict.get('isRelatedTerms')  # type: ignore
     
     @isRelatedTerms.setter
     def isRelatedTerms(self, value: Union[None, List[str]]) -> None:
+        """Setter: The relationship Is A with glossary term"""
         self._inner_dict['isRelatedTerms'] = value
     
     
     @property
     def hasRelatedTerms(self) -> Union[None, List[str]]:
-        """The relationship Has A with glossary term"""
+        """Getter: The relationship Has A with glossary term"""
         return self._inner_dict.get('hasRelatedTerms')  # type: ignore
     
     @hasRelatedTerms.setter
     def hasRelatedTerms(self, value: Union[None, List[str]]) -> None:
+        """Setter: The relationship Has A with glossary term"""
         self._inner_dict['hasRelatedTerms'] = value
     
     
     @property
     def values(self) -> Union[None, List[str]]:
-        """The relationship Has Value with glossary term.
+        """Getter: The relationship Has Value with glossary term.
     These are fixed value a term has. For example a ColorEnum where RED, GREEN and YELLOW are fixed values."""
         return self._inner_dict.get('values')  # type: ignore
     
     @values.setter
     def values(self, value: Union[None, List[str]]) -> None:
+        """Setter: The relationship Has Value with glossary term.
+    These are fixed value a term has. For example a ColorEnum where RED, GREEN and YELLOW are fixed values."""
         self._inner_dict['values'] = value
     
     
     @property
     def relatedTerms(self) -> Union[None, List[str]]:
-        """The relationship isRelatedTo with glossary term"""
+        """Getter: The relationship isRelatedTo with glossary term"""
         return self._inner_dict.get('relatedTerms')  # type: ignore
     
     @relatedTerms.setter
     def relatedTerms(self, value: Union[None, List[str]]) -> None:
+        """Setter: The relationship isRelatedTo with glossary term"""
         self._inner_dict['relatedTerms'] = value
     
     
 class GlossaryTermInfoClass(_Aspect):
     """Properties associated with a GlossaryTerm"""
 
 
@@ -7639,113 +8725,129 @@
         self.definition = definition
         self.parentNode = parentNode
         self.termSource = termSource
         self.sourceRef = sourceRef
         self.sourceUrl = sourceUrl
         self.rawSchema = rawSchema
     
+    @classmethod
+    def construct_with_defaults(cls) -> "GlossaryTermInfoClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.customProperties = dict()
         self.id = self.RECORD_SCHEMA.fields_dict["id"].default
         self.name = self.RECORD_SCHEMA.fields_dict["name"].default
         self.definition = str()
         self.parentNode = self.RECORD_SCHEMA.fields_dict["parentNode"].default
         self.termSource = str()
         self.sourceRef = self.RECORD_SCHEMA.fields_dict["sourceRef"].default
         self.sourceUrl = self.RECORD_SCHEMA.fields_dict["sourceUrl"].default
         self.rawSchema = self.RECORD_SCHEMA.fields_dict["rawSchema"].default
     
     
     @property
     def customProperties(self) -> Dict[str, str]:
-        """Custom property bag."""
+        """Getter: Custom property bag."""
         return self._inner_dict.get('customProperties')  # type: ignore
     
     @customProperties.setter
     def customProperties(self, value: Dict[str, str]) -> None:
+        """Setter: Custom property bag."""
         self._inner_dict['customProperties'] = value
     
     
     @property
     def id(self) -> Union[None, str]:
-        """Optional id for the term"""
+        """Getter: Optional id for the term"""
         return self._inner_dict.get('id')  # type: ignore
     
     @id.setter
     def id(self, value: Union[None, str]) -> None:
+        """Setter: Optional id for the term"""
         self._inner_dict['id'] = value
     
     
     @property
     def name(self) -> Union[None, str]:
-        """Display name of the term"""
+        """Getter: Display name of the term"""
         return self._inner_dict.get('name')  # type: ignore
     
     @name.setter
     def name(self, value: Union[None, str]) -> None:
+        """Setter: Display name of the term"""
         self._inner_dict['name'] = value
     
     
     @property
     def definition(self) -> str:
-        """Definition of business term."""
+        """Getter: Definition of business term."""
         return self._inner_dict.get('definition')  # type: ignore
     
     @definition.setter
     def definition(self, value: str) -> None:
+        """Setter: Definition of business term."""
         self._inner_dict['definition'] = value
     
     
     @property
     def parentNode(self) -> Union[None, str]:
-        """Parent node of the glossary term"""
+        """Getter: Parent node of the glossary term"""
         return self._inner_dict.get('parentNode')  # type: ignore
     
     @parentNode.setter
     def parentNode(self, value: Union[None, str]) -> None:
+        """Setter: Parent node of the glossary term"""
         self._inner_dict['parentNode'] = value
     
     
     @property
     def termSource(self) -> str:
-        """Source of the Business Term (INTERNAL or EXTERNAL) with default value as INTERNAL"""
+        """Getter: Source of the Business Term (INTERNAL or EXTERNAL) with default value as INTERNAL"""
         return self._inner_dict.get('termSource')  # type: ignore
     
     @termSource.setter
     def termSource(self, value: str) -> None:
+        """Setter: Source of the Business Term (INTERNAL or EXTERNAL) with default value as INTERNAL"""
         self._inner_dict['termSource'] = value
     
     
     @property
     def sourceRef(self) -> Union[None, str]:
-        """External Reference to the business-term"""
+        """Getter: External Reference to the business-term"""
         return self._inner_dict.get('sourceRef')  # type: ignore
     
     @sourceRef.setter
     def sourceRef(self, value: Union[None, str]) -> None:
+        """Setter: External Reference to the business-term"""
         self._inner_dict['sourceRef'] = value
     
     
     @property
     def sourceUrl(self) -> Union[None, str]:
-        """The abstracted URL such as https://spec.edmcouncil.org/fibo/ontology/FBC/FinancialInstruments/FinancialInstruments/CashInstrument."""
+        """Getter: The abstracted URL such as https://spec.edmcouncil.org/fibo/ontology/FBC/FinancialInstruments/FinancialInstruments/CashInstrument."""
         return self._inner_dict.get('sourceUrl')  # type: ignore
     
     @sourceUrl.setter
     def sourceUrl(self, value: Union[None, str]) -> None:
+        """Setter: The abstracted URL such as https://spec.edmcouncil.org/fibo/ontology/FBC/FinancialInstruments/FinancialInstruments/CashInstrument."""
         self._inner_dict['sourceUrl'] = value
     
     
     @property
     def rawSchema(self) -> Union[None, str]:
-        """Schema definition of the glossary term"""
+        """Getter: Schema definition of the glossary term"""
         return self._inner_dict.get('rawSchema')  # type: ignore
     
     @rawSchema.setter
     def rawSchema(self, value: Union[None, str]) -> None:
+        """Setter: Schema definition of the glossary term"""
         self._inner_dict['rawSchema'] = value
     
     
 class CorpGroupEditableInfoClass(_Aspect):
     """Group information that can be edited from UI"""
 
 
@@ -7766,58 +8868,69 @@
             # default: 'https://raw.githubusercontent.com/datahub-project/datahub/master/datahub-web-react/src/images/default_avatar.png'
             self.pictureLink = self.RECORD_SCHEMA.fields_dict["pictureLink"].default
         else:
             self.pictureLink = pictureLink
         self.slack = slack
         self.email = email
     
+    @classmethod
+    def construct_with_defaults(cls) -> "CorpGroupEditableInfoClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.description = self.RECORD_SCHEMA.fields_dict["description"].default
         self.pictureLink = self.RECORD_SCHEMA.fields_dict["pictureLink"].default
         self.slack = self.RECORD_SCHEMA.fields_dict["slack"].default
         self.email = self.RECORD_SCHEMA.fields_dict["email"].default
     
     
     @property
     def description(self) -> Union[None, str]:
-        """A description of the group"""
+        """Getter: A description of the group"""
         return self._inner_dict.get('description')  # type: ignore
     
     @description.setter
     def description(self, value: Union[None, str]) -> None:
+        """Setter: A description of the group"""
         self._inner_dict['description'] = value
     
     
     @property
     def pictureLink(self) -> str:
-        """A URL which points to a picture which user wants to set as the photo for the group"""
+        """Getter: A URL which points to a picture which user wants to set as the photo for the group"""
         return self._inner_dict.get('pictureLink')  # type: ignore
     
     @pictureLink.setter
     def pictureLink(self, value: str) -> None:
+        """Setter: A URL which points to a picture which user wants to set as the photo for the group"""
         self._inner_dict['pictureLink'] = value
     
     
     @property
     def slack(self) -> Union[None, str]:
-        """Slack channel for the group"""
+        """Getter: Slack channel for the group"""
         return self._inner_dict.get('slack')  # type: ignore
     
     @slack.setter
     def slack(self, value: Union[None, str]) -> None:
+        """Setter: Slack channel for the group"""
         self._inner_dict['slack'] = value
     
     
     @property
     def email(self) -> Union[None, str]:
-        """Email address to contact the group"""
+        """Getter: Email address to contact the group"""
         return self._inner_dict.get('email')  # type: ignore
     
     @email.setter
     def email(self, value: Union[None, str]) -> None:
+        """Setter: Email address to contact the group"""
         self._inner_dict['email'] = value
     
     
 class CorpGroupInfoClass(_Aspect):
     """Information about a Corp Group ingested from a third party source"""
 
 
@@ -7842,131 +8955,158 @@
         self.admins = admins
         self.members = members
         self.groups = groups
         self.description = description
         self.slack = slack
         self.created = created
     
+    @classmethod
+    def construct_with_defaults(cls) -> "CorpGroupInfoClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.displayName = self.RECORD_SCHEMA.fields_dict["displayName"].default
         self.email = self.RECORD_SCHEMA.fields_dict["email"].default
         self.admins = list()
         self.members = list()
         self.groups = list()
         self.description = self.RECORD_SCHEMA.fields_dict["description"].default
         self.slack = self.RECORD_SCHEMA.fields_dict["slack"].default
         self.created = self.RECORD_SCHEMA.fields_dict["created"].default
     
     
     @property
     def displayName(self) -> Union[None, str]:
-        """The name of the group."""
+        """Getter: The name of the group."""
         return self._inner_dict.get('displayName')  # type: ignore
     
     @displayName.setter
     def displayName(self, value: Union[None, str]) -> None:
+        """Setter: The name of the group."""
         self._inner_dict['displayName'] = value
     
     
     @property
     def email(self) -> Union[None, str]:
-        """email of this group"""
+        """Getter: email of this group"""
         return self._inner_dict.get('email')  # type: ignore
     
     @email.setter
     def email(self, value: Union[None, str]) -> None:
+        """Setter: email of this group"""
         self._inner_dict['email'] = value
     
     
     @property
     def admins(self) -> List[str]:
-        """owners of this group
+        """Getter: owners of this group
     Deprecated! Replaced by Ownership aspect."""
         return self._inner_dict.get('admins')  # type: ignore
     
     @admins.setter
     def admins(self, value: List[str]) -> None:
+        """Setter: owners of this group
+    Deprecated! Replaced by Ownership aspect."""
         self._inner_dict['admins'] = value
     
     
     @property
     def members(self) -> List[str]:
-        """List of ldap urn in this group.
+        """Getter: List of ldap urn in this group.
     Deprecated! Replaced by GroupMembership aspect."""
         return self._inner_dict.get('members')  # type: ignore
     
     @members.setter
     def members(self, value: List[str]) -> None:
+        """Setter: List of ldap urn in this group.
+    Deprecated! Replaced by GroupMembership aspect."""
         self._inner_dict['members'] = value
     
     
     @property
     def groups(self) -> List[str]:
-        """List of groups in this group.
+        """Getter: List of groups in this group.
     Deprecated! This field is unused."""
         return self._inner_dict.get('groups')  # type: ignore
     
     @groups.setter
     def groups(self, value: List[str]) -> None:
+        """Setter: List of groups in this group.
+    Deprecated! This field is unused."""
         self._inner_dict['groups'] = value
     
     
     @property
     def description(self) -> Union[None, str]:
-        """A description of the group."""
+        """Getter: A description of the group."""
         return self._inner_dict.get('description')  # type: ignore
     
     @description.setter
     def description(self, value: Union[None, str]) -> None:
+        """Setter: A description of the group."""
         self._inner_dict['description'] = value
     
     
     @property
     def slack(self) -> Union[None, str]:
-        """Slack channel for the group"""
+        """Getter: Slack channel for the group"""
         return self._inner_dict.get('slack')  # type: ignore
     
     @slack.setter
     def slack(self, value: Union[None, str]) -> None:
+        """Setter: Slack channel for the group"""
         self._inner_dict['slack'] = value
     
     
     @property
     def created(self) -> Union[None, "AuditStampClass"]:
-        """Created Audit stamp"""
+        """Getter: Created Audit stamp"""
         return self._inner_dict.get('created')  # type: ignore
     
     @created.setter
     def created(self, value: Union[None, "AuditStampClass"]) -> None:
+        """Setter: Created Audit stamp"""
         self._inner_dict['created'] = value
     
     
 class CorpUserAppearanceSettingsClass(DictWrapper):
     """Settings for a user around the appearance of their DataHub UI"""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.identity.CorpUserAppearanceSettings")
     def __init__(self,
         showSimplifiedHomepage: Union[None, bool]=None,
     ):
         super().__init__()
         
         self.showSimplifiedHomepage = showSimplifiedHomepage
     
+    @classmethod
+    def construct_with_defaults(cls) -> "CorpUserAppearanceSettingsClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.showSimplifiedHomepage = self.RECORD_SCHEMA.fields_dict["showSimplifiedHomepage"].default
     
     
     @property
     def showSimplifiedHomepage(self) -> Union[None, bool]:
-        """Flag whether the user should see a homepage with only datasets, charts and dashboards. Intended for users
+        """Getter: Flag whether the user should see a homepage with only datasets, charts and dashboards. Intended for users
     who have less operational use cases for the datahub tool."""
         return self._inner_dict.get('showSimplifiedHomepage')  # type: ignore
     
     @showSimplifiedHomepage.setter
     def showSimplifiedHomepage(self, value: Union[None, bool]) -> None:
+        """Setter: Flag whether the user should see a homepage with only datasets, charts and dashboards. Intended for users
+    who have less operational use cases for the datahub tool."""
         self._inner_dict['showSimplifiedHomepage'] = value
     
     
 class CorpUserCredentialsClass(_Aspect):
     """Corp user credentials"""
 
 
@@ -7983,58 +9123,69 @@
         super().__init__()
         
         self.salt = salt
         self.hashedPassword = hashedPassword
         self.passwordResetToken = passwordResetToken
         self.passwordResetTokenExpirationTimeMillis = passwordResetTokenExpirationTimeMillis
     
+    @classmethod
+    def construct_with_defaults(cls) -> "CorpUserCredentialsClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.salt = str()
         self.hashedPassword = str()
         self.passwordResetToken = self.RECORD_SCHEMA.fields_dict["passwordResetToken"].default
         self.passwordResetTokenExpirationTimeMillis = self.RECORD_SCHEMA.fields_dict["passwordResetTokenExpirationTimeMillis"].default
     
     
     @property
     def salt(self) -> str:
-        """Salt used to hash password"""
+        """Getter: Salt used to hash password"""
         return self._inner_dict.get('salt')  # type: ignore
     
     @salt.setter
     def salt(self, value: str) -> None:
+        """Setter: Salt used to hash password"""
         self._inner_dict['salt'] = value
     
     
     @property
     def hashedPassword(self) -> str:
-        """Hashed password generated by concatenating salt and password, then hashing"""
+        """Getter: Hashed password generated by concatenating salt and password, then hashing"""
         return self._inner_dict.get('hashedPassword')  # type: ignore
     
     @hashedPassword.setter
     def hashedPassword(self, value: str) -> None:
+        """Setter: Hashed password generated by concatenating salt and password, then hashing"""
         self._inner_dict['hashedPassword'] = value
     
     
     @property
     def passwordResetToken(self) -> Union[None, str]:
-        """Optional token needed to reset a user's password. Can only be set by the admin."""
+        """Getter: Optional token needed to reset a user's password. Can only be set by the admin."""
         return self._inner_dict.get('passwordResetToken')  # type: ignore
     
     @passwordResetToken.setter
     def passwordResetToken(self, value: Union[None, str]) -> None:
+        """Setter: Optional token needed to reset a user's password. Can only be set by the admin."""
         self._inner_dict['passwordResetToken'] = value
     
     
     @property
     def passwordResetTokenExpirationTimeMillis(self) -> Union[None, int]:
-        """When the password reset token expires."""
+        """Getter: When the password reset token expires."""
         return self._inner_dict.get('passwordResetTokenExpirationTimeMillis')  # type: ignore
     
     @passwordResetTokenExpirationTimeMillis.setter
     def passwordResetTokenExpirationTimeMillis(self, value: Union[None, int]) -> None:
+        """Setter: When the password reset token expires."""
         self._inner_dict['passwordResetTokenExpirationTimeMillis'] = value
     
     
 class CorpUserEditableInfoClass(_Aspect):
     """Linkedin corp user information that can be edited from UI"""
 
 
@@ -8073,113 +9224,129 @@
             self.pictureLink = pictureLink
         self.displayName = displayName
         self.title = title
         self.slack = slack
         self.phone = phone
         self.email = email
     
+    @classmethod
+    def construct_with_defaults(cls) -> "CorpUserEditableInfoClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.aboutMe = self.RECORD_SCHEMA.fields_dict["aboutMe"].default
         self.teams = list()
         self.skills = list()
         self.pictureLink = self.RECORD_SCHEMA.fields_dict["pictureLink"].default
         self.displayName = self.RECORD_SCHEMA.fields_dict["displayName"].default
         self.title = self.RECORD_SCHEMA.fields_dict["title"].default
         self.slack = self.RECORD_SCHEMA.fields_dict["slack"].default
         self.phone = self.RECORD_SCHEMA.fields_dict["phone"].default
         self.email = self.RECORD_SCHEMA.fields_dict["email"].default
     
     
     @property
     def aboutMe(self) -> Union[None, str]:
-        """About me section of the user"""
+        """Getter: About me section of the user"""
         return self._inner_dict.get('aboutMe')  # type: ignore
     
     @aboutMe.setter
     def aboutMe(self, value: Union[None, str]) -> None:
+        """Setter: About me section of the user"""
         self._inner_dict['aboutMe'] = value
     
     
     @property
     def teams(self) -> List[str]:
-        """Teams that the user belongs to e.g. Metadata"""
+        """Getter: Teams that the user belongs to e.g. Metadata"""
         return self._inner_dict.get('teams')  # type: ignore
     
     @teams.setter
     def teams(self, value: List[str]) -> None:
+        """Setter: Teams that the user belongs to e.g. Metadata"""
         self._inner_dict['teams'] = value
     
     
     @property
     def skills(self) -> List[str]:
-        """Skills that the user possesses e.g. Machine Learning"""
+        """Getter: Skills that the user possesses e.g. Machine Learning"""
         return self._inner_dict.get('skills')  # type: ignore
     
     @skills.setter
     def skills(self, value: List[str]) -> None:
+        """Setter: Skills that the user possesses e.g. Machine Learning"""
         self._inner_dict['skills'] = value
     
     
     @property
     def pictureLink(self) -> str:
-        """A URL which points to a picture which user wants to set as a profile photo"""
+        """Getter: A URL which points to a picture which user wants to set as a profile photo"""
         return self._inner_dict.get('pictureLink')  # type: ignore
     
     @pictureLink.setter
     def pictureLink(self, value: str) -> None:
+        """Setter: A URL which points to a picture which user wants to set as a profile photo"""
         self._inner_dict['pictureLink'] = value
     
     
     @property
     def displayName(self) -> Union[None, str]:
-        """DataHub-native display name"""
+        """Getter: DataHub-native display name"""
         return self._inner_dict.get('displayName')  # type: ignore
     
     @displayName.setter
     def displayName(self, value: Union[None, str]) -> None:
+        """Setter: DataHub-native display name"""
         self._inner_dict['displayName'] = value
     
     
     @property
     def title(self) -> Union[None, str]:
-        """DataHub-native Title, e.g. 'Software Engineer'"""
+        """Getter: DataHub-native Title, e.g. 'Software Engineer'"""
         return self._inner_dict.get('title')  # type: ignore
     
     @title.setter
     def title(self, value: Union[None, str]) -> None:
+        """Setter: DataHub-native Title, e.g. 'Software Engineer'"""
         self._inner_dict['title'] = value
     
     
     @property
     def slack(self) -> Union[None, str]:
-        """Slack handle for the user"""
+        """Getter: Slack handle for the user"""
         return self._inner_dict.get('slack')  # type: ignore
     
     @slack.setter
     def slack(self, value: Union[None, str]) -> None:
+        """Setter: Slack handle for the user"""
         self._inner_dict['slack'] = value
     
     
     @property
     def phone(self) -> Union[None, str]:
-        """Phone number to contact the user"""
+        """Getter: Phone number to contact the user"""
         return self._inner_dict.get('phone')  # type: ignore
     
     @phone.setter
     def phone(self, value: Union[None, str]) -> None:
+        """Setter: Phone number to contact the user"""
         self._inner_dict['phone'] = value
     
     
     @property
     def email(self) -> Union[None, str]:
-        """Email address to contact the user"""
+        """Getter: Email address to contact the user"""
         return self._inner_dict.get('email')  # type: ignore
     
     @email.setter
     def email(self, value: Union[None, str]) -> None:
+        """Setter: Email address to contact the user"""
         self._inner_dict['email'] = value
     
     
 class CorpUserInfoClass(_Aspect):
     """Linkedin corp user information"""
 
 
@@ -8216,14 +9383,21 @@
         self.departmentId = departmentId
         self.departmentName = departmentName
         self.firstName = firstName
         self.lastName = lastName
         self.fullName = fullName
         self.countryCode = countryCode
     
+    @classmethod
+    def construct_with_defaults(cls) -> "CorpUserInfoClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.customProperties = dict()
         self.active = bool()
         self.displayName = self.RECORD_SCHEMA.fields_dict["displayName"].default
         self.email = self.RECORD_SCHEMA.fields_dict["email"].default
         self.title = self.RECORD_SCHEMA.fields_dict["title"].default
         self.managerUrn = self.RECORD_SCHEMA.fields_dict["managerUrn"].default
@@ -8233,129 +9407,141 @@
         self.lastName = self.RECORD_SCHEMA.fields_dict["lastName"].default
         self.fullName = self.RECORD_SCHEMA.fields_dict["fullName"].default
         self.countryCode = self.RECORD_SCHEMA.fields_dict["countryCode"].default
     
     
     @property
     def customProperties(self) -> Dict[str, str]:
-        """Custom property bag."""
+        """Getter: Custom property bag."""
         return self._inner_dict.get('customProperties')  # type: ignore
     
     @customProperties.setter
     def customProperties(self, value: Dict[str, str]) -> None:
+        """Setter: Custom property bag."""
         self._inner_dict['customProperties'] = value
     
     
     @property
     def active(self) -> bool:
-        """Deprecated! Use CorpUserStatus instead. Whether the corpUser is active, ref: https://iwww.corp.linkedin.com/wiki/cf/display/GTSD/Accessing+Active+Directory+via+LDAP+tools"""
+        """Getter: Deprecated! Use CorpUserStatus instead. Whether the corpUser is active, ref: https://iwww.corp.linkedin.com/wiki/cf/display/GTSD/Accessing+Active+Directory+via+LDAP+tools"""
         return self._inner_dict.get('active')  # type: ignore
     
     @active.setter
     def active(self, value: bool) -> None:
+        """Setter: Deprecated! Use CorpUserStatus instead. Whether the corpUser is active, ref: https://iwww.corp.linkedin.com/wiki/cf/display/GTSD/Accessing+Active+Directory+via+LDAP+tools"""
         self._inner_dict['active'] = value
     
     
     @property
     def displayName(self) -> Union[None, str]:
-        """displayName of this user ,  e.g.  Hang Zhang(DataHQ)"""
+        """Getter: displayName of this user ,  e.g.  Hang Zhang(DataHQ)"""
         return self._inner_dict.get('displayName')  # type: ignore
     
     @displayName.setter
     def displayName(self, value: Union[None, str]) -> None:
+        """Setter: displayName of this user ,  e.g.  Hang Zhang(DataHQ)"""
         self._inner_dict['displayName'] = value
     
     
     @property
     def email(self) -> Union[None, str]:
-        """email address of this user"""
+        """Getter: email address of this user"""
         return self._inner_dict.get('email')  # type: ignore
     
     @email.setter
     def email(self, value: Union[None, str]) -> None:
+        """Setter: email address of this user"""
         self._inner_dict['email'] = value
     
     
     @property
     def title(self) -> Union[None, str]:
-        """title of this user"""
+        """Getter: title of this user"""
         return self._inner_dict.get('title')  # type: ignore
     
     @title.setter
     def title(self, value: Union[None, str]) -> None:
+        """Setter: title of this user"""
         self._inner_dict['title'] = value
     
     
     @property
     def managerUrn(self) -> Union[None, str]:
-        """direct manager of this user"""
+        """Getter: direct manager of this user"""
         return self._inner_dict.get('managerUrn')  # type: ignore
     
     @managerUrn.setter
     def managerUrn(self, value: Union[None, str]) -> None:
+        """Setter: direct manager of this user"""
         self._inner_dict['managerUrn'] = value
     
     
     @property
     def departmentId(self) -> Union[None, int]:
-        """department id this user belong to"""
+        """Getter: department id this user belong to"""
         return self._inner_dict.get('departmentId')  # type: ignore
     
     @departmentId.setter
     def departmentId(self, value: Union[None, int]) -> None:
+        """Setter: department id this user belong to"""
         self._inner_dict['departmentId'] = value
     
     
     @property
     def departmentName(self) -> Union[None, str]:
-        """department name this user belong to"""
+        """Getter: department name this user belong to"""
         return self._inner_dict.get('departmentName')  # type: ignore
     
     @departmentName.setter
     def departmentName(self, value: Union[None, str]) -> None:
+        """Setter: department name this user belong to"""
         self._inner_dict['departmentName'] = value
     
     
     @property
     def firstName(self) -> Union[None, str]:
-        """first name of this user"""
+        """Getter: first name of this user"""
         return self._inner_dict.get('firstName')  # type: ignore
     
     @firstName.setter
     def firstName(self, value: Union[None, str]) -> None:
+        """Setter: first name of this user"""
         self._inner_dict['firstName'] = value
     
     
     @property
     def lastName(self) -> Union[None, str]:
-        """last name of this user"""
+        """Getter: last name of this user"""
         return self._inner_dict.get('lastName')  # type: ignore
     
     @lastName.setter
     def lastName(self, value: Union[None, str]) -> None:
+        """Setter: last name of this user"""
         self._inner_dict['lastName'] = value
     
     
     @property
     def fullName(self) -> Union[None, str]:
-        """Common name of this user, format is firstName + lastName (split by a whitespace)"""
+        """Getter: Common name of this user, format is firstName + lastName (split by a whitespace)"""
         return self._inner_dict.get('fullName')  # type: ignore
     
     @fullName.setter
     def fullName(self, value: Union[None, str]) -> None:
+        """Setter: Common name of this user, format is firstName + lastName (split by a whitespace)"""
         self._inner_dict['fullName'] = value
     
     
     @property
     def countryCode(self) -> Union[None, str]:
-        """two uppercase letters country code. e.g.  US"""
+        """Getter: two uppercase letters country code. e.g.  US"""
         return self._inner_dict.get('countryCode')  # type: ignore
     
     @countryCode.setter
     def countryCode(self, value: Union[None, str]) -> None:
+        """Setter: two uppercase letters country code. e.g.  US"""
         self._inner_dict['countryCode'] = value
     
     
 class CorpUserSettingsClass(_Aspect):
     """Settings that a user can customize through the datahub ui"""
 
 
@@ -8368,36 +9554,45 @@
         views: Union[None, "CorpUserViewsSettingsClass"]=None,
     ):
         super().__init__()
         
         self.appearance = appearance
         self.views = views
     
+    @classmethod
+    def construct_with_defaults(cls) -> "CorpUserSettingsClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
-        self.appearance = CorpUserAppearanceSettingsClass._construct_with_defaults()
+        self.appearance = CorpUserAppearanceSettingsClass.construct_with_defaults()
         self.views = self.RECORD_SCHEMA.fields_dict["views"].default
     
     
     @property
     def appearance(self) -> "CorpUserAppearanceSettingsClass":
-        """Settings for a user around the appearance of their DataHub U"""
+        """Getter: Settings for a user around the appearance of their DataHub U"""
         return self._inner_dict.get('appearance')  # type: ignore
     
     @appearance.setter
     def appearance(self, value: "CorpUserAppearanceSettingsClass") -> None:
+        """Setter: Settings for a user around the appearance of their DataHub U"""
         self._inner_dict['appearance'] = value
     
     
     @property
     def views(self) -> Union[None, "CorpUserViewsSettingsClass"]:
-        """User preferences for the Views feature."""
+        """Getter: User preferences for the Views feature."""
         return self._inner_dict.get('views')  # type: ignore
     
     @views.setter
     def views(self, value: Union[None, "CorpUserViewsSettingsClass"]) -> None:
+        """Setter: User preferences for the Views feature."""
         self._inner_dict['views'] = value
     
     
 class CorpUserStatusClass(_Aspect):
     """The status of the user, e.g. provisioned, active, suspended, etc."""
 
 
@@ -8410,62 +9605,80 @@
         lastModified: "AuditStampClass",
     ):
         super().__init__()
         
         self.status = status
         self.lastModified = lastModified
     
+    @classmethod
+    def construct_with_defaults(cls) -> "CorpUserStatusClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.status = str()
-        self.lastModified = AuditStampClass._construct_with_defaults()
+        self.lastModified = AuditStampClass.construct_with_defaults()
     
     
     @property
     def status(self) -> str:
-        """Status of the user, e.g. PROVISIONED / ACTIVE / SUSPENDED"""
+        """Getter: Status of the user, e.g. PROVISIONED / ACTIVE / SUSPENDED"""
         return self._inner_dict.get('status')  # type: ignore
     
     @status.setter
     def status(self, value: str) -> None:
+        """Setter: Status of the user, e.g. PROVISIONED / ACTIVE / SUSPENDED"""
         self._inner_dict['status'] = value
     
     
     @property
     def lastModified(self) -> "AuditStampClass":
-        """Audit stamp containing who last modified the status and when."""
+        """Getter: Audit stamp containing who last modified the status and when."""
         return self._inner_dict.get('lastModified')  # type: ignore
     
     @lastModified.setter
     def lastModified(self, value: "AuditStampClass") -> None:
+        """Setter: Audit stamp containing who last modified the status and when."""
         self._inner_dict['lastModified'] = value
     
     
 class CorpUserViewsSettingsClass(DictWrapper):
     """Settings related to the 'Views' feature."""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.identity.CorpUserViewsSettings")
     def __init__(self,
         defaultView: Union[None, str]=None,
     ):
         super().__init__()
         
         self.defaultView = defaultView
     
+    @classmethod
+    def construct_with_defaults(cls) -> "CorpUserViewsSettingsClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.defaultView = self.RECORD_SCHEMA.fields_dict["defaultView"].default
     
     
     @property
     def defaultView(self) -> Union[None, str]:
-        """The default View which is selected for the user.
+        """Getter: The default View which is selected for the user.
     If none is chosen, then this value will be left blank."""
         return self._inner_dict.get('defaultView')  # type: ignore
     
     @defaultView.setter
     def defaultView(self, value: Union[None, str]) -> None:
+        """Setter: The default View which is selected for the user.
+    If none is chosen, then this value will be left blank."""
         self._inner_dict['defaultView'] = value
     
     
 class GroupMembershipClass(_Aspect):
     """Carries information about the CorpGroups a user is in."""
 
 
@@ -8476,25 +9689,33 @@
     def __init__(self,
         groups: List[str],
     ):
         super().__init__()
         
         self.groups = groups
     
+    @classmethod
+    def construct_with_defaults(cls) -> "GroupMembershipClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.groups = list()
     
     
     @property
     def groups(self) -> List[str]:
         # No docs available.
         return self._inner_dict.get('groups')  # type: ignore
     
     @groups.setter
     def groups(self, value: List[str]) -> None:
+        # No docs available.
         self._inner_dict['groups'] = value
     
     
 class InviteTokenClass(_Aspect):
     """Aspect used to store invite tokens."""
 
 
@@ -8507,36 +9728,45 @@
         role: Union[None, str]=None,
     ):
         super().__init__()
         
         self.token = token
         self.role = role
     
+    @classmethod
+    def construct_with_defaults(cls) -> "InviteTokenClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.token = str()
         self.role = self.RECORD_SCHEMA.fields_dict["role"].default
     
     
     @property
     def token(self) -> str:
-        """The encrypted invite token."""
+        """Getter: The encrypted invite token."""
         return self._inner_dict.get('token')  # type: ignore
     
     @token.setter
     def token(self, value: str) -> None:
+        """Setter: The encrypted invite token."""
         self._inner_dict['token'] = value
     
     
     @property
     def role(self) -> Union[None, str]:
-        """The role that this invite token may be associated with"""
+        """Getter: The role that this invite token may be associated with"""
         return self._inner_dict.get('role')  # type: ignore
     
     @role.setter
     def role(self, value: Union[None, str]) -> None:
+        """Setter: The role that this invite token may be associated with"""
         self._inner_dict['role'] = value
     
     
 class NativeGroupMembershipClass(_Aspect):
     """Carries information about the native CorpGroups a user is in."""
 
 
@@ -8547,25 +9777,33 @@
     def __init__(self,
         nativeGroups: List[str],
     ):
         super().__init__()
         
         self.nativeGroups = nativeGroups
     
+    @classmethod
+    def construct_with_defaults(cls) -> "NativeGroupMembershipClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.nativeGroups = list()
     
     
     @property
     def nativeGroups(self) -> List[str]:
         # No docs available.
         return self._inner_dict.get('nativeGroups')  # type: ignore
     
     @nativeGroups.setter
     def nativeGroups(self, value: List[str]) -> None:
+        # No docs available.
         self._inner_dict['nativeGroups'] = value
     
     
 class RoleMembershipClass(_Aspect):
     """Carries information about which roles a user is assigned to."""
 
 
@@ -8576,25 +9814,33 @@
     def __init__(self,
         roles: List[str],
     ):
         super().__init__()
         
         self.roles = roles
     
+    @classmethod
+    def construct_with_defaults(cls) -> "RoleMembershipClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.roles = list()
     
     
     @property
     def roles(self) -> List[str]:
         # No docs available.
         return self._inner_dict.get('roles')  # type: ignore
     
     @roles.setter
     def roles(self, value: List[str]) -> None:
+        # No docs available.
         self._inner_dict['roles'] = value
     
     
 class DataHubIngestionSourceConfigClass(DictWrapper):
     # No docs available.
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.ingestion.DataHubIngestionSourceConfig")
@@ -8607,58 +9853,69 @@
         super().__init__()
         
         self.recipe = recipe
         self.version = version
         self.executorId = executorId
         self.debugMode = debugMode
     
+    @classmethod
+    def construct_with_defaults(cls) -> "DataHubIngestionSourceConfigClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.recipe = str()
         self.version = self.RECORD_SCHEMA.fields_dict["version"].default
         self.executorId = self.RECORD_SCHEMA.fields_dict["executorId"].default
         self.debugMode = self.RECORD_SCHEMA.fields_dict["debugMode"].default
     
     
     @property
     def recipe(self) -> str:
-        """The JSON recipe to use for ingestion"""
+        """Getter: The JSON recipe to use for ingestion"""
         return self._inner_dict.get('recipe')  # type: ignore
     
     @recipe.setter
     def recipe(self, value: str) -> None:
+        """Setter: The JSON recipe to use for ingestion"""
         self._inner_dict['recipe'] = value
     
     
     @property
     def version(self) -> Union[None, str]:
-        """The PyPI version of the datahub CLI to use when executing a recipe"""
+        """Getter: The PyPI version of the datahub CLI to use when executing a recipe"""
         return self._inner_dict.get('version')  # type: ignore
     
     @version.setter
     def version(self, value: Union[None, str]) -> None:
+        """Setter: The PyPI version of the datahub CLI to use when executing a recipe"""
         self._inner_dict['version'] = value
     
     
     @property
     def executorId(self) -> Union[None, str]:
-        """The id of the executor to use to execute the ingestion run"""
+        """Getter: The id of the executor to use to execute the ingestion run"""
         return self._inner_dict.get('executorId')  # type: ignore
     
     @executorId.setter
     def executorId(self, value: Union[None, str]) -> None:
+        """Setter: The id of the executor to use to execute the ingestion run"""
         self._inner_dict['executorId'] = value
     
     
     @property
     def debugMode(self) -> Union[None, bool]:
-        """Whether or not to run this ingestion source in debug mode"""
+        """Getter: Whether or not to run this ingestion source in debug mode"""
         return self._inner_dict.get('debugMode')  # type: ignore
     
     @debugMode.setter
     def debugMode(self, value: Union[None, bool]) -> None:
+        """Setter: Whether or not to run this ingestion source in debug mode"""
         self._inner_dict['debugMode'] = value
     
     
 class DataHubIngestionSourceInfoClass(_Aspect):
     """Info about a DataHub ingestion source"""
 
 
@@ -8677,69 +9934,81 @@
         
         self.name = name
         self.type = type
         self.platform = platform
         self.schedule = schedule
         self.config = config
     
+    @classmethod
+    def construct_with_defaults(cls) -> "DataHubIngestionSourceInfoClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.name = str()
         self.type = str()
         self.platform = self.RECORD_SCHEMA.fields_dict["platform"].default
         self.schedule = self.RECORD_SCHEMA.fields_dict["schedule"].default
-        self.config = DataHubIngestionSourceConfigClass._construct_with_defaults()
+        self.config = DataHubIngestionSourceConfigClass.construct_with_defaults()
     
     
     @property
     def name(self) -> str:
-        """The display name of the ingestion source"""
+        """Getter: The display name of the ingestion source"""
         return self._inner_dict.get('name')  # type: ignore
     
     @name.setter
     def name(self, value: str) -> None:
+        """Setter: The display name of the ingestion source"""
         self._inner_dict['name'] = value
     
     
     @property
     def type(self) -> str:
-        """The type of the source itself, e.g. mysql, bigquery, bigquery-usage. Should match the recipe."""
+        """Getter: The type of the source itself, e.g. mysql, bigquery, bigquery-usage. Should match the recipe."""
         return self._inner_dict.get('type')  # type: ignore
     
     @type.setter
     def type(self, value: str) -> None:
+        """Setter: The type of the source itself, e.g. mysql, bigquery, bigquery-usage. Should match the recipe."""
         self._inner_dict['type'] = value
     
     
     @property
     def platform(self) -> Union[None, str]:
-        """Data Platform URN associated with the source"""
+        """Getter: Data Platform URN associated with the source"""
         return self._inner_dict.get('platform')  # type: ignore
     
     @platform.setter
     def platform(self, value: Union[None, str]) -> None:
+        """Setter: Data Platform URN associated with the source"""
         self._inner_dict['platform'] = value
     
     
     @property
     def schedule(self) -> Union[None, "DataHubIngestionSourceScheduleClass"]:
-        """The schedule on which the ingestion source is executed"""
+        """Getter: The schedule on which the ingestion source is executed"""
         return self._inner_dict.get('schedule')  # type: ignore
     
     @schedule.setter
     def schedule(self, value: Union[None, "DataHubIngestionSourceScheduleClass"]) -> None:
+        """Setter: The schedule on which the ingestion source is executed"""
         self._inner_dict['schedule'] = value
     
     
     @property
     def config(self) -> "DataHubIngestionSourceConfigClass":
-        """Parameters associated with the Ingestion Source"""
+        """Getter: Parameters associated with the Ingestion Source"""
         return self._inner_dict.get('config')  # type: ignore
     
     @config.setter
     def config(self, value: "DataHubIngestionSourceConfigClass") -> None:
+        """Setter: Parameters associated with the Ingestion Source"""
         self._inner_dict['config'] = value
     
     
 class DataHubIngestionSourceScheduleClass(DictWrapper):
     """The schedule associated with an ingestion source."""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.ingestion.DataHubIngestionSourceSchedule")
@@ -8748,36 +10017,45 @@
         timezone: str,
     ):
         super().__init__()
         
         self.interval = interval
         self.timezone = timezone
     
+    @classmethod
+    def construct_with_defaults(cls) -> "DataHubIngestionSourceScheduleClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.interval = str()
         self.timezone = str()
     
     
     @property
     def interval(self) -> str:
-        """A cron-formatted execution interval, as a cron string, e.g. * * * * *"""
+        """Getter: A cron-formatted execution interval, as a cron string, e.g. * * * * *"""
         return self._inner_dict.get('interval')  # type: ignore
     
     @interval.setter
     def interval(self, value: str) -> None:
+        """Setter: A cron-formatted execution interval, as a cron string, e.g. * * * * *"""
         self._inner_dict['interval'] = value
     
     
     @property
     def timezone(self) -> str:
-        """Timezone in which the cron interval applies, e.g. America/Los Angeles"""
+        """Getter: Timezone in which the cron interval applies, e.g. America/Los Angeles"""
         return self._inner_dict.get('timezone')  # type: ignore
     
     @timezone.setter
     def timezone(self, value: str) -> None:
+        """Setter: Timezone in which the cron interval applies, e.g. America/Los Angeles"""
         self._inner_dict['timezone'] = value
     
     
 class AssertionKeyClass(_Aspect):
     """Key for a Assertion"""
 
 
@@ -8788,25 +10066,33 @@
     def __init__(self,
         assertionId: str,
     ):
         super().__init__()
         
         self.assertionId = assertionId
     
+    @classmethod
+    def construct_with_defaults(cls) -> "AssertionKeyClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.assertionId = str()
     
     
     @property
     def assertionId(self) -> str:
-        """Unique id for the assertion."""
+        """Getter: Unique id for the assertion."""
         return self._inner_dict.get('assertionId')  # type: ignore
     
     @assertionId.setter
     def assertionId(self, value: str) -> None:
+        """Setter: Unique id for the assertion."""
         self._inner_dict['assertionId'] = value
     
     
 class ChartKeyClass(_Aspect):
     """Key for a Chart"""
 
 
@@ -8819,36 +10105,45 @@
         chartId: str,
     ):
         super().__init__()
         
         self.dashboardTool = dashboardTool
         self.chartId = chartId
     
+    @classmethod
+    def construct_with_defaults(cls) -> "ChartKeyClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.dashboardTool = str()
         self.chartId = str()
     
     
     @property
     def dashboardTool(self) -> str:
-        """The name of the dashboard tool such as looker, redash etc."""
+        """Getter: The name of the dashboard tool such as looker, redash etc."""
         return self._inner_dict.get('dashboardTool')  # type: ignore
     
     @dashboardTool.setter
     def dashboardTool(self, value: str) -> None:
+        """Setter: The name of the dashboard tool such as looker, redash etc."""
         self._inner_dict['dashboardTool'] = value
     
     
     @property
     def chartId(self) -> str:
-        """Unique id for the chart. This id should be globally unique for a dashboarding tool even when there are multiple deployments of it. As an example, chart URL could be used here for Looker such as 'looker.linkedin.com/looks/1234'"""
+        """Getter: Unique id for the chart. This id should be globally unique for a dashboarding tool even when there are multiple deployments of it. As an example, chart URL could be used here for Looker such as 'looker.linkedin.com/looks/1234'"""
         return self._inner_dict.get('chartId')  # type: ignore
     
     @chartId.setter
     def chartId(self, value: str) -> None:
+        """Setter: Unique id for the chart. This id should be globally unique for a dashboarding tool even when there are multiple deployments of it. As an example, chart URL could be used here for Looker such as 'looker.linkedin.com/looks/1234'"""
         self._inner_dict['chartId'] = value
     
     
 class ContainerKeyClass(_Aspect):
     """Key for an Asset Container"""
 
 
@@ -8859,25 +10154,33 @@
     def __init__(self,
         guid: Union[None, str]=None,
     ):
         super().__init__()
         
         self.guid = guid
     
+    @classmethod
+    def construct_with_defaults(cls) -> "ContainerKeyClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.guid = self.RECORD_SCHEMA.fields_dict["guid"].default
     
     
     @property
     def guid(self) -> Union[None, str]:
-        """Unique guid for container"""
+        """Getter: Unique guid for container"""
         return self._inner_dict.get('guid')  # type: ignore
     
     @guid.setter
     def guid(self, value: Union[None, str]) -> None:
+        """Setter: Unique guid for container"""
         self._inner_dict['guid'] = value
     
     
 class CorpGroupKeyClass(_Aspect):
     """Key for a CorpGroup"""
 
 
@@ -8888,25 +10191,33 @@
     def __init__(self,
         name: str,
     ):
         super().__init__()
         
         self.name = name
     
+    @classmethod
+    def construct_with_defaults(cls) -> "CorpGroupKeyClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.name = str()
     
     
     @property
     def name(self) -> str:
-        """The URL-encoded name of the AD/LDAP group. Serves as a globally unique identifier within DataHub."""
+        """Getter: The URL-encoded name of the AD/LDAP group. Serves as a globally unique identifier within DataHub."""
         return self._inner_dict.get('name')  # type: ignore
     
     @name.setter
     def name(self, value: str) -> None:
+        """Setter: The URL-encoded name of the AD/LDAP group. Serves as a globally unique identifier within DataHub."""
         self._inner_dict['name'] = value
     
     
 class CorpUserKeyClass(_Aspect):
     """Key for a CorpUser"""
 
 
@@ -8917,25 +10228,33 @@
     def __init__(self,
         username: str,
     ):
         super().__init__()
         
         self.username = username
     
+    @classmethod
+    def construct_with_defaults(cls) -> "CorpUserKeyClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.username = str()
     
     
     @property
     def username(self) -> str:
-        """The name of the AD/LDAP user."""
+        """Getter: The name of the AD/LDAP user."""
         return self._inner_dict.get('username')  # type: ignore
     
     @username.setter
     def username(self, value: str) -> None:
+        """Setter: The name of the AD/LDAP user."""
         self._inner_dict['username'] = value
     
     
 class DashboardKeyClass(_Aspect):
     """Key for a Dashboard"""
 
 
@@ -8948,36 +10267,45 @@
         dashboardId: str,
     ):
         super().__init__()
         
         self.dashboardTool = dashboardTool
         self.dashboardId = dashboardId
     
+    @classmethod
+    def construct_with_defaults(cls) -> "DashboardKeyClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.dashboardTool = str()
         self.dashboardId = str()
     
     
     @property
     def dashboardTool(self) -> str:
-        """The name of the dashboard tool such as looker, redash etc."""
+        """Getter: The name of the dashboard tool such as looker, redash etc."""
         return self._inner_dict.get('dashboardTool')  # type: ignore
     
     @dashboardTool.setter
     def dashboardTool(self, value: str) -> None:
+        """Setter: The name of the dashboard tool such as looker, redash etc."""
         self._inner_dict['dashboardTool'] = value
     
     
     @property
     def dashboardId(self) -> str:
-        """Unique id for the dashboard. This id should be globally unique for a dashboarding tool even when there are multiple deployments of it. As an example, dashboard URL could be used here for Looker such as 'looker.linkedin.com/dashboards/1234'"""
+        """Getter: Unique id for the dashboard. This id should be globally unique for a dashboarding tool even when there are multiple deployments of it. As an example, dashboard URL could be used here for Looker such as 'looker.linkedin.com/dashboards/1234'"""
         return self._inner_dict.get('dashboardId')  # type: ignore
     
     @dashboardId.setter
     def dashboardId(self, value: str) -> None:
+        """Setter: Unique id for the dashboard. This id should be globally unique for a dashboarding tool even when there are multiple deployments of it. As an example, dashboard URL could be used here for Looker such as 'looker.linkedin.com/dashboards/1234'"""
         self._inner_dict['dashboardId'] = value
     
     
 class DataFlowKeyClass(_Aspect):
     """Key for a Data Flow"""
 
 
@@ -8992,47 +10320,57 @@
     ):
         super().__init__()
         
         self.orchestrator = orchestrator
         self.flowId = flowId
         self.cluster = cluster
     
+    @classmethod
+    def construct_with_defaults(cls) -> "DataFlowKeyClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.orchestrator = str()
         self.flowId = str()
         self.cluster = str()
     
     
     @property
     def orchestrator(self) -> str:
-        """Workflow manager like azkaban, airflow which orchestrates the flow"""
+        """Getter: Workflow manager like azkaban, airflow which orchestrates the flow"""
         return self._inner_dict.get('orchestrator')  # type: ignore
     
     @orchestrator.setter
     def orchestrator(self, value: str) -> None:
+        """Setter: Workflow manager like azkaban, airflow which orchestrates the flow"""
         self._inner_dict['orchestrator'] = value
     
     
     @property
     def flowId(self) -> str:
-        """Unique Identifier of the data flow"""
+        """Getter: Unique Identifier of the data flow"""
         return self._inner_dict.get('flowId')  # type: ignore
     
     @flowId.setter
     def flowId(self, value: str) -> None:
+        """Setter: Unique Identifier of the data flow"""
         self._inner_dict['flowId'] = value
     
     
     @property
     def cluster(self) -> str:
-        """Cluster where the flow is executed"""
+        """Getter: Cluster where the flow is executed"""
         return self._inner_dict.get('cluster')  # type: ignore
     
     @cluster.setter
     def cluster(self, value: str) -> None:
+        """Setter: Cluster where the flow is executed"""
         self._inner_dict['cluster'] = value
     
     
 class DataHubAccessTokenKeyClass(_Aspect):
     """Key for a DataHub Access Token"""
 
 
@@ -9043,25 +10381,33 @@
     def __init__(self,
         id: str,
     ):
         super().__init__()
         
         self.id = id
     
+    @classmethod
+    def construct_with_defaults(cls) -> "DataHubAccessTokenKeyClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.id = str()
     
     
     @property
     def id(self) -> str:
-        """Access token's SHA-256 hashed JWT signature"""
+        """Getter: Access token's SHA-256 hashed JWT signature"""
         return self._inner_dict.get('id')  # type: ignore
     
     @id.setter
     def id(self, value: str) -> None:
+        """Setter: Access token's SHA-256 hashed JWT signature"""
         self._inner_dict['id'] = value
     
     
 class DataHubIngestionSourceKeyClass(_Aspect):
     """Key for a DataHub ingestion source"""
 
 
@@ -9072,25 +10418,33 @@
     def __init__(self,
         id: str,
     ):
         super().__init__()
         
         self.id = id
     
+    @classmethod
+    def construct_with_defaults(cls) -> "DataHubIngestionSourceKeyClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.id = str()
     
     
     @property
     def id(self) -> str:
-        """A unique id for the Ingestion Source, either generated or provided"""
+        """Getter: A unique id for the Ingestion Source, either generated or provided"""
         return self._inner_dict.get('id')  # type: ignore
     
     @id.setter
     def id(self, value: str) -> None:
+        """Setter: A unique id for the Ingestion Source, either generated or provided"""
         self._inner_dict['id'] = value
     
     
 class DataHubPolicyKeyClass(_Aspect):
     """Key for a DataHub Policy"""
 
 
@@ -9101,25 +10455,33 @@
     def __init__(self,
         id: str,
     ):
         super().__init__()
         
         self.id = id
     
+    @classmethod
+    def construct_with_defaults(cls) -> "DataHubPolicyKeyClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.id = str()
     
     
     @property
     def id(self) -> str:
-        """A unique id for the DataHub access policy record. Generated on the server side at policy creation time."""
+        """Getter: A unique id for the DataHub access policy record. Generated on the server side at policy creation time."""
         return self._inner_dict.get('id')  # type: ignore
     
     @id.setter
     def id(self, value: str) -> None:
+        """Setter: A unique id for the DataHub access policy record. Generated on the server side at policy creation time."""
         self._inner_dict['id'] = value
     
     
 class DataHubRetentionKeyClass(_Aspect):
     """Key for a DataHub Retention"""
 
 
@@ -9132,36 +10494,45 @@
         aspectName: str,
     ):
         super().__init__()
         
         self.entityName = entityName
         self.aspectName = aspectName
     
+    @classmethod
+    def construct_with_defaults(cls) -> "DataHubRetentionKeyClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.entityName = str()
         self.aspectName = str()
     
     
     @property
     def entityName(self) -> str:
-        """Entity name to apply retention to. * (or empty) for applying defaults."""
+        """Getter: Entity name to apply retention to. * (or empty) for applying defaults."""
         return self._inner_dict.get('entityName')  # type: ignore
     
     @entityName.setter
     def entityName(self, value: str) -> None:
+        """Setter: Entity name to apply retention to. * (or empty) for applying defaults."""
         self._inner_dict['entityName'] = value
     
     
     @property
     def aspectName(self) -> str:
-        """Aspect name to apply retention to. * (or empty) for applying defaults."""
+        """Getter: Aspect name to apply retention to. * (or empty) for applying defaults."""
         return self._inner_dict.get('aspectName')  # type: ignore
     
     @aspectName.setter
     def aspectName(self, value: str) -> None:
+        """Setter: Aspect name to apply retention to. * (or empty) for applying defaults."""
         self._inner_dict['aspectName'] = value
     
     
 class DataHubRoleKeyClass(_Aspect):
     """Key for a DataHub Role"""
 
 
@@ -9172,25 +10543,33 @@
     def __init__(self,
         id: str,
     ):
         super().__init__()
         
         self.id = id
     
+    @classmethod
+    def construct_with_defaults(cls) -> "DataHubRoleKeyClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.id = str()
     
     
     @property
     def id(self) -> str:
-        """A unique id for the DataHub role record. Generated on the server side at role creation time."""
+        """Getter: A unique id for the DataHub role record. Generated on the server side at role creation time."""
         return self._inner_dict.get('id')  # type: ignore
     
     @id.setter
     def id(self, value: str) -> None:
+        """Setter: A unique id for the DataHub role record. Generated on the server side at role creation time."""
         self._inner_dict['id'] = value
     
     
 class DataHubSecretKeyClass(_Aspect):
     """Key for a DataHub Secret"""
 
 
@@ -9201,25 +10580,33 @@
     def __init__(self,
         id: str,
     ):
         super().__init__()
         
         self.id = id
     
+    @classmethod
+    def construct_with_defaults(cls) -> "DataHubSecretKeyClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.id = str()
     
     
     @property
     def id(self) -> str:
-        """A unique id for the Secret"""
+        """Getter: A unique id for the Secret"""
         return self._inner_dict.get('id')  # type: ignore
     
     @id.setter
     def id(self, value: str) -> None:
+        """Setter: A unique id for the Secret"""
         self._inner_dict['id'] = value
     
     
 class DataHubStepStateKeyClass(_Aspect):
     """Key for a DataHub Step State"""
 
 
@@ -9230,25 +10617,33 @@
     def __init__(self,
         id: str,
     ):
         super().__init__()
         
         self.id = id
     
+    @classmethod
+    def construct_with_defaults(cls) -> "DataHubStepStateKeyClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.id = str()
     
     
     @property
     def id(self) -> str:
-        """A unique id for the state"""
+        """Getter: A unique id for the state"""
         return self._inner_dict.get('id')  # type: ignore
     
     @id.setter
     def id(self, value: str) -> None:
+        """Setter: A unique id for the state"""
         self._inner_dict['id'] = value
     
     
 class DataHubUpgradeKeyClass(_Aspect):
     """Key for a DataHubUpgrade"""
 
 
@@ -9259,25 +10654,33 @@
     def __init__(self,
         id: str,
     ):
         super().__init__()
         
         self.id = id
     
+    @classmethod
+    def construct_with_defaults(cls) -> "DataHubUpgradeKeyClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.id = str()
     
     
     @property
     def id(self) -> str:
         # No docs available.
         return self._inner_dict.get('id')  # type: ignore
     
     @id.setter
     def id(self, value: str) -> None:
+        # No docs available.
         self._inner_dict['id'] = value
     
     
 class DataHubViewKeyClass(_Aspect):
     """Key for a DataHub View"""
 
 
@@ -9288,25 +10691,33 @@
     def __init__(self,
         id: str,
     ):
         super().__init__()
         
         self.id = id
     
+    @classmethod
+    def construct_with_defaults(cls) -> "DataHubViewKeyClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.id = str()
     
     
     @property
     def id(self) -> str:
-        """A unique id for the View"""
+        """Getter: A unique id for the View"""
         return self._inner_dict.get('id')  # type: ignore
     
     @id.setter
     def id(self, value: str) -> None:
+        """Setter: A unique id for the View"""
         self._inner_dict['id'] = value
     
     
 class DataJobKeyClass(_Aspect):
     """Key for a Data Job"""
 
 
@@ -9319,36 +10730,45 @@
         jobId: str,
     ):
         super().__init__()
         
         self.flow = flow
         self.jobId = jobId
     
+    @classmethod
+    def construct_with_defaults(cls) -> "DataJobKeyClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.flow = str()
         self.jobId = str()
     
     
     @property
     def flow(self) -> str:
-        """Standardized data processing flow urn representing the flow for the job"""
+        """Getter: Standardized data processing flow urn representing the flow for the job"""
         return self._inner_dict.get('flow')  # type: ignore
     
     @flow.setter
     def flow(self, value: str) -> None:
+        """Setter: Standardized data processing flow urn representing the flow for the job"""
         self._inner_dict['flow'] = value
     
     
     @property
     def jobId(self) -> str:
-        """Unique Identifier of the data job"""
+        """Getter: Unique Identifier of the data job"""
         return self._inner_dict.get('jobId')  # type: ignore
     
     @jobId.setter
     def jobId(self, value: str) -> None:
+        """Setter: Unique Identifier of the data job"""
         self._inner_dict['jobId'] = value
     
     
 class DataPlatformInstanceKeyClass(_Aspect):
     """Key for a Dataset"""
 
 
@@ -9361,36 +10781,45 @@
         instance: str,
     ):
         super().__init__()
         
         self.platform = platform
         self.instance = instance
     
+    @classmethod
+    def construct_with_defaults(cls) -> "DataPlatformInstanceKeyClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.platform = str()
         self.instance = str()
     
     
     @property
     def platform(self) -> str:
-        """Data platform urn associated with the instance"""
+        """Getter: Data platform urn associated with the instance"""
         return self._inner_dict.get('platform')  # type: ignore
     
     @platform.setter
     def platform(self, value: str) -> None:
+        """Setter: Data platform urn associated with the instance"""
         self._inner_dict['platform'] = value
     
     
     @property
     def instance(self) -> str:
-        """Unique instance id"""
+        """Getter: Unique instance id"""
         return self._inner_dict.get('instance')  # type: ignore
     
     @instance.setter
     def instance(self, value: str) -> None:
+        """Setter: Unique instance id"""
         self._inner_dict['instance'] = value
     
     
 class DataPlatformKeyClass(_Aspect):
     """Key for a Data Platform"""
 
 
@@ -9401,25 +10830,33 @@
     def __init__(self,
         platformName: str,
     ):
         super().__init__()
         
         self.platformName = platformName
     
+    @classmethod
+    def construct_with_defaults(cls) -> "DataPlatformKeyClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.platformName = str()
     
     
     @property
     def platformName(self) -> str:
-        """Data platform name i.e. hdfs, oracle, espresso"""
+        """Getter: Data platform name i.e. hdfs, oracle, espresso"""
         return self._inner_dict.get('platformName')  # type: ignore
     
     @platformName.setter
     def platformName(self, value: str) -> None:
+        """Setter: Data platform name i.e. hdfs, oracle, espresso"""
         self._inner_dict['platformName'] = value
     
     
 class DataProcessInstanceKeyClass(_Aspect):
     """Key for an Asset DataProcessInstance"""
 
 
@@ -9430,25 +10867,33 @@
     def __init__(self,
         id: str,
     ):
         super().__init__()
         
         self.id = id
     
+    @classmethod
+    def construct_with_defaults(cls) -> "DataProcessInstanceKeyClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.id = str()
     
     
     @property
     def id(self) -> str:
-        """A unique id for the DataProcessInstance . Should be separate from the name used for displaying a DataProcessInstance."""
+        """Getter: A unique id for the DataProcessInstance . Should be separate from the name used for displaying a DataProcessInstance."""
         return self._inner_dict.get('id')  # type: ignore
     
     @id.setter
     def id(self, value: str) -> None:
+        """Setter: A unique id for the DataProcessInstance . Should be separate from the name used for displaying a DataProcessInstance."""
         self._inner_dict['id'] = value
     
     
 class DataProcessKeyClass(_Aspect):
     """Key for a Data Process"""
 
 
@@ -9463,48 +10908,59 @@
     ):
         super().__init__()
         
         self.name = name
         self.orchestrator = orchestrator
         self.origin = origin
     
+    @classmethod
+    def construct_with_defaults(cls) -> "DataProcessKeyClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.name = str()
         self.orchestrator = str()
         self.origin = FabricTypeClass.DEV
     
     
     @property
     def name(self) -> str:
-        """Process name i.e. an ETL job name"""
+        """Getter: Process name i.e. an ETL job name"""
         return self._inner_dict.get('name')  # type: ignore
     
     @name.setter
     def name(self, value: str) -> None:
+        """Setter: Process name i.e. an ETL job name"""
         self._inner_dict['name'] = value
     
     
     @property
     def orchestrator(self) -> str:
-        """Standardized Orchestrator where data process is defined.
+        """Getter: Standardized Orchestrator where data process is defined.
     TODO: Migrate towards something that can be validated like DataPlatform urn"""
         return self._inner_dict.get('orchestrator')  # type: ignore
     
     @orchestrator.setter
     def orchestrator(self, value: str) -> None:
+        """Setter: Standardized Orchestrator where data process is defined.
+    TODO: Migrate towards something that can be validated like DataPlatform urn"""
         self._inner_dict['orchestrator'] = value
     
     
     @property
     def origin(self) -> Union[str, "FabricTypeClass"]:
-        """Fabric type where dataset belongs to or where it was generated."""
+        """Getter: Fabric type where dataset belongs to or where it was generated."""
         return self._inner_dict.get('origin')  # type: ignore
     
     @origin.setter
     def origin(self, value: Union[str, "FabricTypeClass"]) -> None:
+        """Setter: Fabric type where dataset belongs to or where it was generated."""
         self._inner_dict['origin'] = value
     
     
 class DatasetKeyClass(_Aspect):
     """Key for a Dataset"""
 
 
@@ -9519,47 +10975,57 @@
     ):
         super().__init__()
         
         self.platform = platform
         self.name = name
         self.origin = origin
     
+    @classmethod
+    def construct_with_defaults(cls) -> "DatasetKeyClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.platform = str()
         self.name = str()
         self.origin = FabricTypeClass.DEV
     
     
     @property
     def platform(self) -> str:
-        """Data platform urn associated with the dataset"""
+        """Getter: Data platform urn associated with the dataset"""
         return self._inner_dict.get('platform')  # type: ignore
     
     @platform.setter
     def platform(self, value: str) -> None:
+        """Setter: Data platform urn associated with the dataset"""
         self._inner_dict['platform'] = value
     
     
     @property
     def name(self) -> str:
-        """Unique guid for dataset"""
+        """Getter: Unique guid for dataset"""
         return self._inner_dict.get('name')  # type: ignore
     
     @name.setter
     def name(self, value: str) -> None:
+        """Setter: Unique guid for dataset"""
         self._inner_dict['name'] = value
     
     
     @property
     def origin(self) -> Union[str, "FabricTypeClass"]:
-        """Fabric type where dataset belongs to or where it was generated."""
+        """Getter: Fabric type where dataset belongs to or where it was generated."""
         return self._inner_dict.get('origin')  # type: ignore
     
     @origin.setter
     def origin(self, value: Union[str, "FabricTypeClass"]) -> None:
+        """Setter: Fabric type where dataset belongs to or where it was generated."""
         self._inner_dict['origin'] = value
     
     
 class DomainKeyClass(_Aspect):
     """Key for an Asset Domain"""
 
 
@@ -9570,25 +11036,33 @@
     def __init__(self,
         id: str,
     ):
         super().__init__()
         
         self.id = id
     
+    @classmethod
+    def construct_with_defaults(cls) -> "DomainKeyClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.id = str()
     
     
     @property
     def id(self) -> str:
-        """A unique id for the domain. Should be separate from the name used for displaying a Domain."""
+        """Getter: A unique id for the domain. Should be separate from the name used for displaying a Domain."""
         return self._inner_dict.get('id')  # type: ignore
     
     @id.setter
     def id(self, value: str) -> None:
+        """Setter: A unique id for the domain. Should be separate from the name used for displaying a Domain."""
         self._inner_dict['id'] = value
     
     
 class ExecutionRequestKeyClass(_Aspect):
     """Key for an DataHub Execution Request"""
 
 
@@ -9599,25 +11073,33 @@
     def __init__(self,
         id: str,
     ):
         super().__init__()
         
         self.id = id
     
+    @classmethod
+    def construct_with_defaults(cls) -> "ExecutionRequestKeyClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.id = str()
     
     
     @property
     def id(self) -> str:
-        """A unique id for the DataHub execution request."""
+        """Getter: A unique id for the DataHub execution request."""
         return self._inner_dict.get('id')  # type: ignore
     
     @id.setter
     def id(self, value: str) -> None:
+        """Setter: A unique id for the DataHub execution request."""
         self._inner_dict['id'] = value
     
     
 class GlobalSettingsKeyClass(_Aspect):
     """Key for a Global Settings"""
 
 
@@ -9628,25 +11110,33 @@
     def __init__(self,
         id: str,
     ):
         super().__init__()
         
         self.id = id
     
+    @classmethod
+    def construct_with_defaults(cls) -> "GlobalSettingsKeyClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.id = str()
     
     
     @property
     def id(self) -> str:
-        """Id for the settings. There should be only 1 global settings urn: urn:li:globalSettings:0"""
+        """Getter: Id for the settings. There should be only 1 global settings urn: urn:li:globalSettings:0"""
         return self._inner_dict.get('id')  # type: ignore
     
     @id.setter
     def id(self, value: str) -> None:
+        """Setter: Id for the settings. There should be only 1 global settings urn: urn:li:globalSettings:0"""
         self._inner_dict['id'] = value
     
     
 class GlossaryNodeKeyClass(_Aspect):
     """Key for a GlossaryNode"""
 
 
@@ -9657,25 +11147,33 @@
     def __init__(self,
         name: str,
     ):
         super().__init__()
         
         self.name = name
     
+    @classmethod
+    def construct_with_defaults(cls) -> "GlossaryNodeKeyClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.name = str()
     
     
     @property
     def name(self) -> str:
         # No docs available.
         return self._inner_dict.get('name')  # type: ignore
     
     @name.setter
     def name(self, value: str) -> None:
+        # No docs available.
         self._inner_dict['name'] = value
     
     
 class GlossaryTermKeyClass(_Aspect):
     """Key for a GlossaryTerm"""
 
 
@@ -9686,25 +11184,33 @@
     def __init__(self,
         name: str,
     ):
         super().__init__()
         
         self.name = name
     
+    @classmethod
+    def construct_with_defaults(cls) -> "GlossaryTermKeyClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.name = str()
     
     
     @property
     def name(self) -> str:
-        """The term name, which serves as a unique id"""
+        """Getter: The term name, which serves as a unique id"""
         return self._inner_dict.get('name')  # type: ignore
     
     @name.setter
     def name(self, value: str) -> None:
+        """Setter: The term name, which serves as a unique id"""
         self._inner_dict['name'] = value
     
     
 class InviteTokenKeyClass(_Aspect):
     """Key for an InviteToken."""
 
 
@@ -9715,25 +11221,33 @@
     def __init__(self,
         id: str,
     ):
         super().__init__()
         
         self.id = id
     
+    @classmethod
+    def construct_with_defaults(cls) -> "InviteTokenKeyClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.id = str()
     
     
     @property
     def id(self) -> str:
-        """A unique id for the invite token."""
+        """Getter: A unique id for the invite token."""
         return self._inner_dict.get('id')  # type: ignore
     
     @id.setter
     def id(self, value: str) -> None:
+        """Setter: A unique id for the invite token."""
         self._inner_dict['id'] = value
     
     
 class MLFeatureKeyClass(_Aspect):
     """Key for an MLFeature"""
 
 
@@ -9746,36 +11260,45 @@
         name: str,
     ):
         super().__init__()
         
         self.featureNamespace = featureNamespace
         self.name = name
     
+    @classmethod
+    def construct_with_defaults(cls) -> "MLFeatureKeyClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.featureNamespace = str()
         self.name = str()
     
     
     @property
     def featureNamespace(self) -> str:
-        """Namespace for the feature"""
+        """Getter: Namespace for the feature"""
         return self._inner_dict.get('featureNamespace')  # type: ignore
     
     @featureNamespace.setter
     def featureNamespace(self, value: str) -> None:
+        """Setter: Namespace for the feature"""
         self._inner_dict['featureNamespace'] = value
     
     
     @property
     def name(self) -> str:
-        """Name of the feature"""
+        """Getter: Name of the feature"""
         return self._inner_dict.get('name')  # type: ignore
     
     @name.setter
     def name(self, value: str) -> None:
+        """Setter: Name of the feature"""
         self._inner_dict['name'] = value
     
     
 class MLFeatureTableKeyClass(_Aspect):
     """Key for an MLFeatureTable"""
 
 
@@ -9788,36 +11311,45 @@
         name: str,
     ):
         super().__init__()
         
         self.platform = platform
         self.name = name
     
+    @classmethod
+    def construct_with_defaults(cls) -> "MLFeatureTableKeyClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.platform = str()
         self.name = str()
     
     
     @property
     def platform(self) -> str:
-        """Data platform urn associated with the feature table"""
+        """Getter: Data platform urn associated with the feature table"""
         return self._inner_dict.get('platform')  # type: ignore
     
     @platform.setter
     def platform(self, value: str) -> None:
+        """Setter: Data platform urn associated with the feature table"""
         self._inner_dict['platform'] = value
     
     
     @property
     def name(self) -> str:
-        """Name of the feature table"""
+        """Getter: Name of the feature table"""
         return self._inner_dict.get('name')  # type: ignore
     
     @name.setter
     def name(self, value: str) -> None:
+        """Setter: Name of the feature table"""
         self._inner_dict['name'] = value
     
     
 class MLModelDeploymentKeyClass(_Aspect):
     """Key for an ML model deployment"""
 
 
@@ -9832,47 +11364,57 @@
     ):
         super().__init__()
         
         self.platform = platform
         self.name = name
         self.origin = origin
     
+    @classmethod
+    def construct_with_defaults(cls) -> "MLModelDeploymentKeyClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.platform = str()
         self.name = str()
         self.origin = FabricTypeClass.DEV
     
     
     @property
     def platform(self) -> str:
-        """Standardized platform urn for the model Deployment"""
+        """Getter: Standardized platform urn for the model Deployment"""
         return self._inner_dict.get('platform')  # type: ignore
     
     @platform.setter
     def platform(self, value: str) -> None:
+        """Setter: Standardized platform urn for the model Deployment"""
         self._inner_dict['platform'] = value
     
     
     @property
     def name(self) -> str:
-        """Name of the MLModelDeployment"""
+        """Getter: Name of the MLModelDeployment"""
         return self._inner_dict.get('name')  # type: ignore
     
     @name.setter
     def name(self, value: str) -> None:
+        """Setter: Name of the MLModelDeployment"""
         self._inner_dict['name'] = value
     
     
     @property
     def origin(self) -> Union[str, "FabricTypeClass"]:
-        """Fabric type where model Deployment belongs to or where it was generated"""
+        """Getter: Fabric type where model Deployment belongs to or where it was generated"""
         return self._inner_dict.get('origin')  # type: ignore
     
     @origin.setter
     def origin(self, value: Union[str, "FabricTypeClass"]) -> None:
+        """Setter: Fabric type where model Deployment belongs to or where it was generated"""
         self._inner_dict['origin'] = value
     
     
 class MLModelGroupKeyClass(_Aspect):
     """Key for an ML model group"""
 
 
@@ -9887,47 +11429,57 @@
     ):
         super().__init__()
         
         self.platform = platform
         self.name = name
         self.origin = origin
     
+    @classmethod
+    def construct_with_defaults(cls) -> "MLModelGroupKeyClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.platform = str()
         self.name = str()
         self.origin = FabricTypeClass.DEV
     
     
     @property
     def platform(self) -> str:
-        """Standardized platform urn for the model group"""
+        """Getter: Standardized platform urn for the model group"""
         return self._inner_dict.get('platform')  # type: ignore
     
     @platform.setter
     def platform(self, value: str) -> None:
+        """Setter: Standardized platform urn for the model group"""
         self._inner_dict['platform'] = value
     
     
     @property
     def name(self) -> str:
-        """Name of the MLModelGroup"""
+        """Getter: Name of the MLModelGroup"""
         return self._inner_dict.get('name')  # type: ignore
     
     @name.setter
     def name(self, value: str) -> None:
+        """Setter: Name of the MLModelGroup"""
         self._inner_dict['name'] = value
     
     
     @property
     def origin(self) -> Union[str, "FabricTypeClass"]:
-        """Fabric type where model group belongs to or where it was generated"""
+        """Getter: Fabric type where model group belongs to or where it was generated"""
         return self._inner_dict.get('origin')  # type: ignore
     
     @origin.setter
     def origin(self, value: Union[str, "FabricTypeClass"]) -> None:
+        """Setter: Fabric type where model group belongs to or where it was generated"""
         self._inner_dict['origin'] = value
     
     
 class MLModelKeyClass(_Aspect):
     """Key for an ML model"""
 
 
@@ -9942,47 +11494,57 @@
     ):
         super().__init__()
         
         self.platform = platform
         self.name = name
         self.origin = origin
     
+    @classmethod
+    def construct_with_defaults(cls) -> "MLModelKeyClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.platform = str()
         self.name = str()
         self.origin = FabricTypeClass.DEV
     
     
     @property
     def platform(self) -> str:
-        """Standardized platform urn for the model"""
+        """Getter: Standardized platform urn for the model"""
         return self._inner_dict.get('platform')  # type: ignore
     
     @platform.setter
     def platform(self, value: str) -> None:
+        """Setter: Standardized platform urn for the model"""
         self._inner_dict['platform'] = value
     
     
     @property
     def name(self) -> str:
-        """Name of the MLModel"""
+        """Getter: Name of the MLModel"""
         return self._inner_dict.get('name')  # type: ignore
     
     @name.setter
     def name(self, value: str) -> None:
+        """Setter: Name of the MLModel"""
         self._inner_dict['name'] = value
     
     
     @property
     def origin(self) -> Union[str, "FabricTypeClass"]:
-        """Fabric type where model belongs to or where it was generated"""
+        """Getter: Fabric type where model belongs to or where it was generated"""
         return self._inner_dict.get('origin')  # type: ignore
     
     @origin.setter
     def origin(self, value: Union[str, "FabricTypeClass"]) -> None:
+        """Setter: Fabric type where model belongs to or where it was generated"""
         self._inner_dict['origin'] = value
     
     
 class MLPrimaryKeyKeyClass(_Aspect):
     """Key for an MLPrimaryKey"""
 
 
@@ -9995,36 +11557,45 @@
         name: str,
     ):
         super().__init__()
         
         self.featureNamespace = featureNamespace
         self.name = name
     
+    @classmethod
+    def construct_with_defaults(cls) -> "MLPrimaryKeyKeyClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.featureNamespace = str()
         self.name = str()
     
     
     @property
     def featureNamespace(self) -> str:
-        """Namespace for the primary key"""
+        """Getter: Namespace for the primary key"""
         return self._inner_dict.get('featureNamespace')  # type: ignore
     
     @featureNamespace.setter
     def featureNamespace(self, value: str) -> None:
+        """Setter: Namespace for the primary key"""
         self._inner_dict['featureNamespace'] = value
     
     
     @property
     def name(self) -> str:
-        """Name of the primary key"""
+        """Getter: Name of the primary key"""
         return self._inner_dict.get('name')  # type: ignore
     
     @name.setter
     def name(self, value: str) -> None:
+        """Setter: Name of the primary key"""
         self._inner_dict['name'] = value
     
     
 class NotebookKeyClass(_Aspect):
     """Key for a Notebook"""
 
 
@@ -10037,36 +11608,45 @@
         notebookId: str,
     ):
         super().__init__()
         
         self.notebookTool = notebookTool
         self.notebookId = notebookId
     
+    @classmethod
+    def construct_with_defaults(cls) -> "NotebookKeyClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.notebookTool = str()
         self.notebookId = str()
     
     
     @property
     def notebookTool(self) -> str:
-        """The name of the Notebook tool such as QueryBook, etc."""
+        """Getter: The name of the Notebook tool such as QueryBook, etc."""
         return self._inner_dict.get('notebookTool')  # type: ignore
     
     @notebookTool.setter
     def notebookTool(self, value: str) -> None:
+        """Setter: The name of the Notebook tool such as QueryBook, etc."""
         self._inner_dict['notebookTool'] = value
     
     
     @property
     def notebookId(self) -> str:
-        """Unique id for the Notebook. This id should be globally unique for a Notebook tool even when there are multiple deployments of it. As an example, Notebook URL could be used here for QueryBook such as 'querybook.com/notebook/773'"""
+        """Getter: Unique id for the Notebook. This id should be globally unique for a Notebook tool even when there are multiple deployments of it. As an example, Notebook URL could be used here for QueryBook such as 'querybook.com/notebook/773'"""
         return self._inner_dict.get('notebookId')  # type: ignore
     
     @notebookId.setter
     def notebookId(self, value: str) -> None:
+        """Setter: Unique id for the Notebook. This id should be globally unique for a Notebook tool even when there are multiple deployments of it. As an example, Notebook URL could be used here for QueryBook such as 'querybook.com/notebook/773'"""
         self._inner_dict['notebookId'] = value
     
     
 class PostKeyClass(_Aspect):
     """Key for a Post."""
 
 
@@ -10077,25 +11657,33 @@
     def __init__(self,
         id: str,
     ):
         super().__init__()
         
         self.id = id
     
+    @classmethod
+    def construct_with_defaults(cls) -> "PostKeyClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.id = str()
     
     
     @property
     def id(self) -> str:
-        """A unique id for the DataHub Post record. Generated on the server side at Post creation time."""
+        """Getter: A unique id for the DataHub Post record. Generated on the server side at Post creation time."""
         return self._inner_dict.get('id')  # type: ignore
     
     @id.setter
     def id(self, value: str) -> None:
+        """Setter: A unique id for the DataHub Post record. Generated on the server side at Post creation time."""
         self._inner_dict['id'] = value
     
     
 class QueryKeyClass(_Aspect):
     """Key for a Query"""
 
 
@@ -10106,25 +11694,33 @@
     def __init__(self,
         id: str,
     ):
         super().__init__()
         
         self.id = id
     
+    @classmethod
+    def construct_with_defaults(cls) -> "QueryKeyClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.id = str()
     
     
     @property
     def id(self) -> str:
-        """A unique id for the Query."""
+        """Getter: A unique id for the Query."""
         return self._inner_dict.get('id')  # type: ignore
     
     @id.setter
     def id(self, value: str) -> None:
+        """Setter: A unique id for the Query."""
         self._inner_dict['id'] = value
     
     
 class SchemaFieldKeyClass(_Aspect):
     """Key for a SchemaField"""
 
 
@@ -10137,36 +11733,45 @@
         fieldPath: str,
     ):
         super().__init__()
         
         self.parent = parent
         self.fieldPath = fieldPath
     
+    @classmethod
+    def construct_with_defaults(cls) -> "SchemaFieldKeyClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.parent = str()
         self.fieldPath = str()
     
     
     @property
     def parent(self) -> str:
-        """Parent associated with the schema field"""
+        """Getter: Parent associated with the schema field"""
         return self._inner_dict.get('parent')  # type: ignore
     
     @parent.setter
     def parent(self, value: str) -> None:
+        """Setter: Parent associated with the schema field"""
         self._inner_dict['parent'] = value
     
     
     @property
     def fieldPath(self) -> str:
-        """fieldPath identifying the schema field"""
+        """Getter: fieldPath identifying the schema field"""
         return self._inner_dict.get('fieldPath')  # type: ignore
     
     @fieldPath.setter
     def fieldPath(self, value: str) -> None:
+        """Setter: fieldPath identifying the schema field"""
         self._inner_dict['fieldPath'] = value
     
     
 class TagKeyClass(_Aspect):
     """Key for a Tag"""
 
 
@@ -10177,25 +11782,33 @@
     def __init__(self,
         name: str,
     ):
         super().__init__()
         
         self.name = name
     
+    @classmethod
+    def construct_with_defaults(cls) -> "TagKeyClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.name = str()
     
     
     @property
     def name(self) -> str:
-        """The tag name, which serves as a unique id"""
+        """Getter: The tag name, which serves as a unique id"""
         return self._inner_dict.get('name')  # type: ignore
     
     @name.setter
     def name(self, value: str) -> None:
+        """Setter: The tag name, which serves as a unique id"""
         self._inner_dict['name'] = value
     
     
 class TelemetryKeyClass(_Aspect):
     """Key for the telemetry client ID, only one should ever exist"""
 
 
@@ -10206,25 +11819,33 @@
     def __init__(self,
         name: str,
     ):
         super().__init__()
         
         self.name = name
     
+    @classmethod
+    def construct_with_defaults(cls) -> "TelemetryKeyClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.name = str()
     
     
     @property
     def name(self) -> str:
-        """The telemetry entity name, which serves as a unique id"""
+        """Getter: The telemetry entity name, which serves as a unique id"""
         return self._inner_dict.get('name')  # type: ignore
     
     @name.setter
     def name(self, value: str) -> None:
+        """Setter: The telemetry entity name, which serves as a unique id"""
         self._inner_dict['name'] = value
     
     
 class TestKeyClass(_Aspect):
     """Key for a Test"""
 
 
@@ -10235,25 +11856,33 @@
     def __init__(self,
         id: str,
     ):
         super().__init__()
         
         self.id = id
     
+    @classmethod
+    def construct_with_defaults(cls) -> "TestKeyClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.id = str()
     
     
     @property
     def id(self) -> str:
-        """Unique id for the test"""
+        """Getter: Unique id for the test"""
         return self._inner_dict.get('id')  # type: ignore
     
     @id.setter
     def id(self, value: str) -> None:
+        """Setter: Unique id for the test"""
         self._inner_dict['id'] = value
     
     
 class ConditionClass(object):
     """The matching condition in a filter criterion"""
     
     
@@ -10295,25 +11924,33 @@
     def __init__(self,
         and_: List["CriterionClass"],
     ):
         super().__init__()
         
         self.and_ = and_
     
+    @classmethod
+    def construct_with_defaults(cls) -> "ConjunctiveCriterionClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.and_ = list()
     
     
     @property
     def and_(self) -> List["CriterionClass"]:
-        """A list of and criteria the filter applies to the query"""
+        """Getter: A list of and criteria the filter applies to the query"""
         return self._inner_dict.get('and')  # type: ignore
     
     @and_.setter
     def and_(self, value: List["CriterionClass"]) -> None:
+        """Setter: A list of and criteria the filter applies to the query"""
         self._inner_dict['and'] = value
     
     
 class CriterionClass(DictWrapper):
     """A criterion for matching a field with given value"""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.metadata.query.filter.Criterion")
@@ -10340,70 +11977,83 @@
             self.condition = condition
         if negated is None:
             # default: False
             self.negated = self.RECORD_SCHEMA.fields_dict["negated"].default
         else:
             self.negated = negated
     
+    @classmethod
+    def construct_with_defaults(cls) -> "CriterionClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.field = str()
         self.value = str()
         self.values = list()
         self.condition = self.RECORD_SCHEMA.fields_dict["condition"].default
         self.negated = self.RECORD_SCHEMA.fields_dict["negated"].default
     
     
     @property
     def field(self) -> str:
-        """The name of the field that the criterion refers to"""
+        """Getter: The name of the field that the criterion refers to"""
         return self._inner_dict.get('field')  # type: ignore
     
     @field.setter
     def field(self, value: str) -> None:
+        """Setter: The name of the field that the criterion refers to"""
         self._inner_dict['field'] = value
     
     
     @property
     def value(self) -> str:
-        """The value of the intended field"""
+        """Getter: The value of the intended field"""
         return self._inner_dict.get('value')  # type: ignore
     
     @value.setter
     def value(self, value: str) -> None:
+        """Setter: The value of the intended field"""
         self._inner_dict['value'] = value
     
     
     @property
     def values(self) -> List[str]:
-        """Values. one of which the intended field should match
+        """Getter: Values. one of which the intended field should match
     Note, if values is set, the above "value" field will be ignored"""
         return self._inner_dict.get('values')  # type: ignore
     
     @values.setter
     def values(self, value: List[str]) -> None:
+        """Setter: Values. one of which the intended field should match
+    Note, if values is set, the above "value" field will be ignored"""
         self._inner_dict['values'] = value
     
     
     @property
     def condition(self) -> Union[str, "ConditionClass"]:
-        """The condition for the criterion, e.g. EQUAL, START_WITH"""
+        """Getter: The condition for the criterion, e.g. EQUAL, START_WITH"""
         return self._inner_dict.get('condition')  # type: ignore
     
     @condition.setter
     def condition(self, value: Union[str, "ConditionClass"]) -> None:
+        """Setter: The condition for the criterion, e.g. EQUAL, START_WITH"""
         self._inner_dict['condition'] = value
     
     
     @property
     def negated(self) -> bool:
-        """Whether the condition should be negated"""
+        """Getter: Whether the condition should be negated"""
         return self._inner_dict.get('negated')  # type: ignore
     
     @negated.setter
     def negated(self, value: bool) -> None:
+        """Setter: Whether the condition should be negated"""
         self._inner_dict['negated'] = value
     
     
 class FilterClass(DictWrapper):
     """The filter for finding a record or a collection of records"""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.metadata.query.filter.Filter")
@@ -10412,36 +12062,45 @@
         criteria: Union[None, List["CriterionClass"]]=None,
     ):
         super().__init__()
         
         self.or_ = or_
         self.criteria = criteria
     
+    @classmethod
+    def construct_with_defaults(cls) -> "FilterClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.or_ = self.RECORD_SCHEMA.fields_dict["or"].default
         self.criteria = self.RECORD_SCHEMA.fields_dict["criteria"].default
     
     
     @property
     def or_(self) -> Union[None, List["ConjunctiveCriterionClass"]]:
-        """A list of disjunctive criterion for the filter. (or operation to combine filters)"""
+        """Getter: A list of disjunctive criterion for the filter. (or operation to combine filters)"""
         return self._inner_dict.get('or')  # type: ignore
     
     @or_.setter
     def or_(self, value: Union[None, List["ConjunctiveCriterionClass"]]) -> None:
+        """Setter: A list of disjunctive criterion for the filter. (or operation to combine filters)"""
         self._inner_dict['or'] = value
     
     
     @property
     def criteria(self) -> Union[None, List["CriterionClass"]]:
-        """Deprecated! A list of conjunctive criterion for the filter. If "or" field is provided, then this field is ignored."""
+        """Getter: Deprecated! A list of conjunctive criterion for the filter. If "or" field is provided, then this field is ignored."""
         return self._inner_dict.get('criteria')  # type: ignore
     
     @criteria.setter
     def criteria(self, value: Union[None, List["CriterionClass"]]) -> None:
+        """Setter: Deprecated! A list of conjunctive criterion for the filter. If "or" field is provided, then this field is ignored."""
         self._inner_dict['criteria'] = value
     
     
 class ChartSnapshotClass(DictWrapper):
     """A metadata snapshot for a specific Chart entity."""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.metadata.snapshot.ChartSnapshot")
@@ -10450,36 +12109,45 @@
         aspects: List[Union["ChartKeyClass", "ChartInfoClass", "ChartQueryClass", "EditableChartPropertiesClass", "OwnershipClass", "StatusClass", "GlobalTagsClass", "BrowsePathsClass", "GlossaryTermsClass", "InstitutionalMemoryClass", "DataPlatformInstanceClass"]],
     ):
         super().__init__()
         
         self.urn = urn
         self.aspects = aspects
     
+    @classmethod
+    def construct_with_defaults(cls) -> "ChartSnapshotClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.urn = str()
         self.aspects = list()
     
     
     @property
     def urn(self) -> str:
-        """URN for the entity the metadata snapshot is associated with."""
+        """Getter: URN for the entity the metadata snapshot is associated with."""
         return self._inner_dict.get('urn')  # type: ignore
     
     @urn.setter
     def urn(self, value: str) -> None:
+        """Setter: URN for the entity the metadata snapshot is associated with."""
         self._inner_dict['urn'] = value
     
     
     @property
     def aspects(self) -> List[Union["ChartKeyClass", "ChartInfoClass", "ChartQueryClass", "EditableChartPropertiesClass", "OwnershipClass", "StatusClass", "GlobalTagsClass", "BrowsePathsClass", "GlossaryTermsClass", "InstitutionalMemoryClass", "DataPlatformInstanceClass"]]:
-        """The list of metadata aspects associated with the chart. Depending on the use case, this can either be all, or a selection, of supported aspects."""
+        """Getter: The list of metadata aspects associated with the chart. Depending on the use case, this can either be all, or a selection, of supported aspects."""
         return self._inner_dict.get('aspects')  # type: ignore
     
     @aspects.setter
     def aspects(self, value: List[Union["ChartKeyClass", "ChartInfoClass", "ChartQueryClass", "EditableChartPropertiesClass", "OwnershipClass", "StatusClass", "GlobalTagsClass", "BrowsePathsClass", "GlossaryTermsClass", "InstitutionalMemoryClass", "DataPlatformInstanceClass"]]) -> None:
+        """Setter: The list of metadata aspects associated with the chart. Depending on the use case, this can either be all, or a selection, of supported aspects."""
         self._inner_dict['aspects'] = value
     
     
 class CorpGroupSnapshotClass(DictWrapper):
     """A metadata snapshot for a specific CorpGroup entity."""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.metadata.snapshot.CorpGroupSnapshot")
@@ -10488,36 +12156,45 @@
         aspects: List[Union["CorpGroupKeyClass", "CorpGroupInfoClass", "GlobalTagsClass", "StatusClass"]],
     ):
         super().__init__()
         
         self.urn = urn
         self.aspects = aspects
     
+    @classmethod
+    def construct_with_defaults(cls) -> "CorpGroupSnapshotClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.urn = str()
         self.aspects = list()
     
     
     @property
     def urn(self) -> str:
-        """URN for the entity the metadata snapshot is associated with."""
+        """Getter: URN for the entity the metadata snapshot is associated with."""
         return self._inner_dict.get('urn')  # type: ignore
     
     @urn.setter
     def urn(self, value: str) -> None:
+        """Setter: URN for the entity the metadata snapshot is associated with."""
         self._inner_dict['urn'] = value
     
     
     @property
     def aspects(self) -> List[Union["CorpGroupKeyClass", "CorpGroupInfoClass", "GlobalTagsClass", "StatusClass"]]:
-        """The list of metadata aspects associated with the LdapUser. Depending on the use case, this can either be all, or a selection, of supported aspects."""
+        """Getter: The list of metadata aspects associated with the LdapUser. Depending on the use case, this can either be all, or a selection, of supported aspects."""
         return self._inner_dict.get('aspects')  # type: ignore
     
     @aspects.setter
     def aspects(self, value: List[Union["CorpGroupKeyClass", "CorpGroupInfoClass", "GlobalTagsClass", "StatusClass"]]) -> None:
+        """Setter: The list of metadata aspects associated with the LdapUser. Depending on the use case, this can either be all, or a selection, of supported aspects."""
         self._inner_dict['aspects'] = value
     
     
 class CorpUserSnapshotClass(DictWrapper):
     """A metadata snapshot for a specific CorpUser entity."""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.metadata.snapshot.CorpUserSnapshot")
@@ -10526,36 +12203,45 @@
         aspects: List[Union["CorpUserKeyClass", "CorpUserInfoClass", "CorpUserEditableInfoClass", "CorpUserStatusClass", "GroupMembershipClass", "GlobalTagsClass", "StatusClass"]],
     ):
         super().__init__()
         
         self.urn = urn
         self.aspects = aspects
     
+    @classmethod
+    def construct_with_defaults(cls) -> "CorpUserSnapshotClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.urn = str()
         self.aspects = list()
     
     
     @property
     def urn(self) -> str:
-        """URN for the entity the metadata snapshot is associated with."""
+        """Getter: URN for the entity the metadata snapshot is associated with."""
         return self._inner_dict.get('urn')  # type: ignore
     
     @urn.setter
     def urn(self, value: str) -> None:
+        """Setter: URN for the entity the metadata snapshot is associated with."""
         self._inner_dict['urn'] = value
     
     
     @property
     def aspects(self) -> List[Union["CorpUserKeyClass", "CorpUserInfoClass", "CorpUserEditableInfoClass", "CorpUserStatusClass", "GroupMembershipClass", "GlobalTagsClass", "StatusClass"]]:
-        """The list of metadata aspects associated with the CorpUser. Depending on the use case, this can either be all, or a selection, of supported aspects."""
+        """Getter: The list of metadata aspects associated with the CorpUser. Depending on the use case, this can either be all, or a selection, of supported aspects."""
         return self._inner_dict.get('aspects')  # type: ignore
     
     @aspects.setter
     def aspects(self, value: List[Union["CorpUserKeyClass", "CorpUserInfoClass", "CorpUserEditableInfoClass", "CorpUserStatusClass", "GroupMembershipClass", "GlobalTagsClass", "StatusClass"]]) -> None:
+        """Setter: The list of metadata aspects associated with the CorpUser. Depending on the use case, this can either be all, or a selection, of supported aspects."""
         self._inner_dict['aspects'] = value
     
     
 class DashboardSnapshotClass(DictWrapper):
     """A metadata snapshot for a specific Dashboard entity."""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.metadata.snapshot.DashboardSnapshot")
@@ -10564,36 +12250,45 @@
         aspects: List[Union["DashboardKeyClass", "DashboardInfoClass", "EditableDashboardPropertiesClass", "OwnershipClass", "StatusClass", "GlobalTagsClass", "BrowsePathsClass", "GlossaryTermsClass", "InstitutionalMemoryClass", "DataPlatformInstanceClass"]],
     ):
         super().__init__()
         
         self.urn = urn
         self.aspects = aspects
     
+    @classmethod
+    def construct_with_defaults(cls) -> "DashboardSnapshotClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.urn = str()
         self.aspects = list()
     
     
     @property
     def urn(self) -> str:
-        """URN for the entity the metadata snapshot is associated with."""
+        """Getter: URN for the entity the metadata snapshot is associated with."""
         return self._inner_dict.get('urn')  # type: ignore
     
     @urn.setter
     def urn(self, value: str) -> None:
+        """Setter: URN for the entity the metadata snapshot is associated with."""
         self._inner_dict['urn'] = value
     
     
     @property
     def aspects(self) -> List[Union["DashboardKeyClass", "DashboardInfoClass", "EditableDashboardPropertiesClass", "OwnershipClass", "StatusClass", "GlobalTagsClass", "BrowsePathsClass", "GlossaryTermsClass", "InstitutionalMemoryClass", "DataPlatformInstanceClass"]]:
-        """The list of metadata aspects associated with the dashboard. Depending on the use case, this can either be all, or a selection, of supported aspects."""
+        """Getter: The list of metadata aspects associated with the dashboard. Depending on the use case, this can either be all, or a selection, of supported aspects."""
         return self._inner_dict.get('aspects')  # type: ignore
     
     @aspects.setter
     def aspects(self, value: List[Union["DashboardKeyClass", "DashboardInfoClass", "EditableDashboardPropertiesClass", "OwnershipClass", "StatusClass", "GlobalTagsClass", "BrowsePathsClass", "GlossaryTermsClass", "InstitutionalMemoryClass", "DataPlatformInstanceClass"]]) -> None:
+        """Setter: The list of metadata aspects associated with the dashboard. Depending on the use case, this can either be all, or a selection, of supported aspects."""
         self._inner_dict['aspects'] = value
     
     
 class DataFlowSnapshotClass(DictWrapper):
     """A metadata snapshot for a specific DataFlow entity."""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.metadata.snapshot.DataFlowSnapshot")
@@ -10602,36 +12297,45 @@
         aspects: List[Union["DataFlowKeyClass", "DataFlowInfoClass", "EditableDataFlowPropertiesClass", "OwnershipClass", "StatusClass", "GlobalTagsClass", "BrowsePathsClass", "GlossaryTermsClass", "InstitutionalMemoryClass", "DataPlatformInstanceClass"]],
     ):
         super().__init__()
         
         self.urn = urn
         self.aspects = aspects
     
+    @classmethod
+    def construct_with_defaults(cls) -> "DataFlowSnapshotClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.urn = str()
         self.aspects = list()
     
     
     @property
     def urn(self) -> str:
-        """URN for the entity the metadata snapshot is associated with."""
+        """Getter: URN for the entity the metadata snapshot is associated with."""
         return self._inner_dict.get('urn')  # type: ignore
     
     @urn.setter
     def urn(self, value: str) -> None:
+        """Setter: URN for the entity the metadata snapshot is associated with."""
         self._inner_dict['urn'] = value
     
     
     @property
     def aspects(self) -> List[Union["DataFlowKeyClass", "DataFlowInfoClass", "EditableDataFlowPropertiesClass", "OwnershipClass", "StatusClass", "GlobalTagsClass", "BrowsePathsClass", "GlossaryTermsClass", "InstitutionalMemoryClass", "DataPlatformInstanceClass"]]:
-        """The list of metadata aspects associated with the data flow. Depending on the use case, this can either be all, or a selection, of supported aspects."""
+        """Getter: The list of metadata aspects associated with the data flow. Depending on the use case, this can either be all, or a selection, of supported aspects."""
         return self._inner_dict.get('aspects')  # type: ignore
     
     @aspects.setter
     def aspects(self, value: List[Union["DataFlowKeyClass", "DataFlowInfoClass", "EditableDataFlowPropertiesClass", "OwnershipClass", "StatusClass", "GlobalTagsClass", "BrowsePathsClass", "GlossaryTermsClass", "InstitutionalMemoryClass", "DataPlatformInstanceClass"]]) -> None:
+        """Setter: The list of metadata aspects associated with the data flow. Depending on the use case, this can either be all, or a selection, of supported aspects."""
         self._inner_dict['aspects'] = value
     
     
 class DataHubPolicySnapshotClass(DictWrapper):
     """A metadata snapshot for DataHub Access Policy data."""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.metadata.snapshot.DataHubPolicySnapshot")
@@ -10640,36 +12344,45 @@
         aspects: List[Union["DataHubPolicyKeyClass", "DataHubPolicyInfoClass"]],
     ):
         super().__init__()
         
         self.urn = urn
         self.aspects = aspects
     
+    @classmethod
+    def construct_with_defaults(cls) -> "DataHubPolicySnapshotClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.urn = str()
         self.aspects = list()
     
     
     @property
     def urn(self) -> str:
-        """URN for the entity the metadata snapshot is associated with."""
+        """Getter: URN for the entity the metadata snapshot is associated with."""
         return self._inner_dict.get('urn')  # type: ignore
     
     @urn.setter
     def urn(self, value: str) -> None:
+        """Setter: URN for the entity the metadata snapshot is associated with."""
         self._inner_dict['urn'] = value
     
     
     @property
     def aspects(self) -> List[Union["DataHubPolicyKeyClass", "DataHubPolicyInfoClass"]]:
-        """The list of metadata aspects associated with the DataHub access policy."""
+        """Getter: The list of metadata aspects associated with the DataHub access policy."""
         return self._inner_dict.get('aspects')  # type: ignore
     
     @aspects.setter
     def aspects(self, value: List[Union["DataHubPolicyKeyClass", "DataHubPolicyInfoClass"]]) -> None:
+        """Setter: The list of metadata aspects associated with the DataHub access policy."""
         self._inner_dict['aspects'] = value
     
     
 class DataHubRetentionSnapshotClass(DictWrapper):
     """A metadata snapshot for DataHub Access Policy data."""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.metadata.snapshot.DataHubRetentionSnapshot")
@@ -10678,36 +12391,45 @@
         aspects: List[Union["DataHubRetentionKeyClass", "DataHubRetentionConfigClass"]],
     ):
         super().__init__()
         
         self.urn = urn
         self.aspects = aspects
     
+    @classmethod
+    def construct_with_defaults(cls) -> "DataHubRetentionSnapshotClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.urn = str()
         self.aspects = list()
     
     
     @property
     def urn(self) -> str:
-        """URN for the entity the metadata snapshot is associated with."""
+        """Getter: URN for the entity the metadata snapshot is associated with."""
         return self._inner_dict.get('urn')  # type: ignore
     
     @urn.setter
     def urn(self, value: str) -> None:
+        """Setter: URN for the entity the metadata snapshot is associated with."""
         self._inner_dict['urn'] = value
     
     
     @property
     def aspects(self) -> List[Union["DataHubRetentionKeyClass", "DataHubRetentionConfigClass"]]:
-        """The list of metadata aspects associated with the DataHub access policy."""
+        """Getter: The list of metadata aspects associated with the DataHub access policy."""
         return self._inner_dict.get('aspects')  # type: ignore
     
     @aspects.setter
     def aspects(self, value: List[Union["DataHubRetentionKeyClass", "DataHubRetentionConfigClass"]]) -> None:
+        """Setter: The list of metadata aspects associated with the DataHub access policy."""
         self._inner_dict['aspects'] = value
     
     
 class DataJobSnapshotClass(DictWrapper):
     """A metadata snapshot for a specific DataJob entity."""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.metadata.snapshot.DataJobSnapshot")
@@ -10716,36 +12438,45 @@
         aspects: List[Union["DataJobKeyClass", "DataJobInfoClass", "DataJobInputOutputClass", "EditableDataJobPropertiesClass", "OwnershipClass", "StatusClass", "GlobalTagsClass", "BrowsePathsClass", "GlossaryTermsClass", "InstitutionalMemoryClass", "DataPlatformInstanceClass"]],
     ):
         super().__init__()
         
         self.urn = urn
         self.aspects = aspects
     
+    @classmethod
+    def construct_with_defaults(cls) -> "DataJobSnapshotClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.urn = str()
         self.aspects = list()
     
     
     @property
     def urn(self) -> str:
-        """URN for the entity the metadata snapshot is associated with."""
+        """Getter: URN for the entity the metadata snapshot is associated with."""
         return self._inner_dict.get('urn')  # type: ignore
     
     @urn.setter
     def urn(self, value: str) -> None:
+        """Setter: URN for the entity the metadata snapshot is associated with."""
         self._inner_dict['urn'] = value
     
     
     @property
     def aspects(self) -> List[Union["DataJobKeyClass", "DataJobInfoClass", "DataJobInputOutputClass", "EditableDataJobPropertiesClass", "OwnershipClass", "StatusClass", "GlobalTagsClass", "BrowsePathsClass", "GlossaryTermsClass", "InstitutionalMemoryClass", "DataPlatformInstanceClass"]]:
-        """The list of metadata aspects associated with the data job. Depending on the use case, this can either be all, or a selection, of supported aspects."""
+        """Getter: The list of metadata aspects associated with the data job. Depending on the use case, this can either be all, or a selection, of supported aspects."""
         return self._inner_dict.get('aspects')  # type: ignore
     
     @aspects.setter
     def aspects(self, value: List[Union["DataJobKeyClass", "DataJobInfoClass", "DataJobInputOutputClass", "EditableDataJobPropertiesClass", "OwnershipClass", "StatusClass", "GlobalTagsClass", "BrowsePathsClass", "GlossaryTermsClass", "InstitutionalMemoryClass", "DataPlatformInstanceClass"]]) -> None:
+        """Setter: The list of metadata aspects associated with the data job. Depending on the use case, this can either be all, or a selection, of supported aspects."""
         self._inner_dict['aspects'] = value
     
     
 class DataPlatformSnapshotClass(DictWrapper):
     """A metadata snapshot for a specific dataplatform entity."""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.metadata.snapshot.DataPlatformSnapshot")
@@ -10754,36 +12485,45 @@
         aspects: List[Union["DataPlatformKeyClass", "DataPlatformInfoClass"]],
     ):
         super().__init__()
         
         self.urn = urn
         self.aspects = aspects
     
+    @classmethod
+    def construct_with_defaults(cls) -> "DataPlatformSnapshotClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.urn = str()
         self.aspects = list()
     
     
     @property
     def urn(self) -> str:
-        """URN for the entity the metadata snapshot is associated with."""
+        """Getter: URN for the entity the metadata snapshot is associated with."""
         return self._inner_dict.get('urn')  # type: ignore
     
     @urn.setter
     def urn(self, value: str) -> None:
+        """Setter: URN for the entity the metadata snapshot is associated with."""
         self._inner_dict['urn'] = value
     
     
     @property
     def aspects(self) -> List[Union["DataPlatformKeyClass", "DataPlatformInfoClass"]]:
-        """The list of metadata aspects associated with the data platform. Depending on the use case, this can either be all, or a selection, of supported aspects."""
+        """Getter: The list of metadata aspects associated with the data platform. Depending on the use case, this can either be all, or a selection, of supported aspects."""
         return self._inner_dict.get('aspects')  # type: ignore
     
     @aspects.setter
     def aspects(self, value: List[Union["DataPlatformKeyClass", "DataPlatformInfoClass"]]) -> None:
+        """Setter: The list of metadata aspects associated with the data platform. Depending on the use case, this can either be all, or a selection, of supported aspects."""
         self._inner_dict['aspects'] = value
     
     
 class DataProcessSnapshotClass(DictWrapper):
     """A metadata snapshot for a specific Data process entity."""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.metadata.snapshot.DataProcessSnapshot")
@@ -10792,36 +12532,45 @@
         aspects: List[Union["DataProcessKeyClass", "OwnershipClass", "DataProcessInfoClass", "StatusClass"]],
     ):
         super().__init__()
         
         self.urn = urn
         self.aspects = aspects
     
+    @classmethod
+    def construct_with_defaults(cls) -> "DataProcessSnapshotClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.urn = str()
         self.aspects = list()
     
     
     @property
     def urn(self) -> str:
-        """URN for the entity the metadata snapshot is associated with."""
+        """Getter: URN for the entity the metadata snapshot is associated with."""
         return self._inner_dict.get('urn')  # type: ignore
     
     @urn.setter
     def urn(self, value: str) -> None:
+        """Setter: URN for the entity the metadata snapshot is associated with."""
         self._inner_dict['urn'] = value
     
     
     @property
     def aspects(self) -> List[Union["DataProcessKeyClass", "OwnershipClass", "DataProcessInfoClass", "StatusClass"]]:
-        """The list of metadata aspects associated with the data process. Depending on the use case, this can either be all, or a selection, of supported aspects."""
+        """Getter: The list of metadata aspects associated with the data process. Depending on the use case, this can either be all, or a selection, of supported aspects."""
         return self._inner_dict.get('aspects')  # type: ignore
     
     @aspects.setter
     def aspects(self, value: List[Union["DataProcessKeyClass", "OwnershipClass", "DataProcessInfoClass", "StatusClass"]]) -> None:
+        """Setter: The list of metadata aspects associated with the data process. Depending on the use case, this can either be all, or a selection, of supported aspects."""
         self._inner_dict['aspects'] = value
     
     
 class DatasetSnapshotClass(DictWrapper):
     """A metadata snapshot for a specific dataset entity."""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.metadata.snapshot.DatasetSnapshot")
@@ -10830,36 +12579,45 @@
         aspects: List[Union["DatasetKeyClass", "DatasetPropertiesClass", "EditableDatasetPropertiesClass", "DatasetDeprecationClass", "DatasetUpstreamLineageClass", "UpstreamLineageClass", "InstitutionalMemoryClass", "OwnershipClass", "StatusClass", "SchemaMetadataClass", "EditableSchemaMetadataClass", "GlobalTagsClass", "GlossaryTermsClass", "BrowsePathsClass", "DataPlatformInstanceClass", "ViewPropertiesClass"]],
     ):
         super().__init__()
         
         self.urn = urn
         self.aspects = aspects
     
+    @classmethod
+    def construct_with_defaults(cls) -> "DatasetSnapshotClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.urn = str()
         self.aspects = list()
     
     
     @property
     def urn(self) -> str:
-        """URN for the entity the metadata snapshot is associated with."""
+        """Getter: URN for the entity the metadata snapshot is associated with."""
         return self._inner_dict.get('urn')  # type: ignore
     
     @urn.setter
     def urn(self, value: str) -> None:
+        """Setter: URN for the entity the metadata snapshot is associated with."""
         self._inner_dict['urn'] = value
     
     
     @property
     def aspects(self) -> List[Union["DatasetKeyClass", "DatasetPropertiesClass", "EditableDatasetPropertiesClass", "DatasetDeprecationClass", "DatasetUpstreamLineageClass", "UpstreamLineageClass", "InstitutionalMemoryClass", "OwnershipClass", "StatusClass", "SchemaMetadataClass", "EditableSchemaMetadataClass", "GlobalTagsClass", "GlossaryTermsClass", "BrowsePathsClass", "DataPlatformInstanceClass", "ViewPropertiesClass"]]:
-        """The list of metadata aspects associated with the dataset. Depending on the use case, this can either be all, or a selection, of supported aspects."""
+        """Getter: The list of metadata aspects associated with the dataset. Depending on the use case, this can either be all, or a selection, of supported aspects."""
         return self._inner_dict.get('aspects')  # type: ignore
     
     @aspects.setter
     def aspects(self, value: List[Union["DatasetKeyClass", "DatasetPropertiesClass", "EditableDatasetPropertiesClass", "DatasetDeprecationClass", "DatasetUpstreamLineageClass", "UpstreamLineageClass", "InstitutionalMemoryClass", "OwnershipClass", "StatusClass", "SchemaMetadataClass", "EditableSchemaMetadataClass", "GlobalTagsClass", "GlossaryTermsClass", "BrowsePathsClass", "DataPlatformInstanceClass", "ViewPropertiesClass"]]) -> None:
+        """Setter: The list of metadata aspects associated with the dataset. Depending on the use case, this can either be all, or a selection, of supported aspects."""
         self._inner_dict['aspects'] = value
     
     
 class GlossaryNodeSnapshotClass(DictWrapper):
     """A metadata snapshot for a specific GlossaryNode entity."""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.metadata.snapshot.GlossaryNodeSnapshot")
@@ -10868,36 +12626,45 @@
         aspects: List[Union["GlossaryNodeKeyClass", "GlossaryNodeInfoClass", "OwnershipClass", "StatusClass"]],
     ):
         super().__init__()
         
         self.urn = urn
         self.aspects = aspects
     
+    @classmethod
+    def construct_with_defaults(cls) -> "GlossaryNodeSnapshotClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.urn = str()
         self.aspects = list()
     
     
     @property
     def urn(self) -> str:
-        """URN for the entity the metadata snapshot is associated with."""
+        """Getter: URN for the entity the metadata snapshot is associated with."""
         return self._inner_dict.get('urn')  # type: ignore
     
     @urn.setter
     def urn(self, value: str) -> None:
+        """Setter: URN for the entity the metadata snapshot is associated with."""
         self._inner_dict['urn'] = value
     
     
     @property
     def aspects(self) -> List[Union["GlossaryNodeKeyClass", "GlossaryNodeInfoClass", "OwnershipClass", "StatusClass"]]:
-        """The list of metadata aspects associated with the GlossaryNode. Depending on the use case, this can either be all, or a selection, of supported aspects."""
+        """Getter: The list of metadata aspects associated with the GlossaryNode. Depending on the use case, this can either be all, or a selection, of supported aspects."""
         return self._inner_dict.get('aspects')  # type: ignore
     
     @aspects.setter
     def aspects(self, value: List[Union["GlossaryNodeKeyClass", "GlossaryNodeInfoClass", "OwnershipClass", "StatusClass"]]) -> None:
+        """Setter: The list of metadata aspects associated with the GlossaryNode. Depending on the use case, this can either be all, or a selection, of supported aspects."""
         self._inner_dict['aspects'] = value
     
     
 class GlossaryTermSnapshotClass(DictWrapper):
     """A metadata snapshot for a specific GlossaryTerm entity."""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.metadata.snapshot.GlossaryTermSnapshot")
@@ -10906,36 +12673,45 @@
         aspects: List[Union["GlossaryTermKeyClass", "GlossaryTermInfoClass", "OwnershipClass", "StatusClass", "BrowsePathsClass", "GlossaryRelatedTermsClass"]],
     ):
         super().__init__()
         
         self.urn = urn
         self.aspects = aspects
     
+    @classmethod
+    def construct_with_defaults(cls) -> "GlossaryTermSnapshotClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.urn = str()
         self.aspects = list()
     
     
     @property
     def urn(self) -> str:
-        """URN for the entity the metadata snapshot is associated with."""
+        """Getter: URN for the entity the metadata snapshot is associated with."""
         return self._inner_dict.get('urn')  # type: ignore
     
     @urn.setter
     def urn(self, value: str) -> None:
+        """Setter: URN for the entity the metadata snapshot is associated with."""
         self._inner_dict['urn'] = value
     
     
     @property
     def aspects(self) -> List[Union["GlossaryTermKeyClass", "GlossaryTermInfoClass", "OwnershipClass", "StatusClass", "BrowsePathsClass", "GlossaryRelatedTermsClass"]]:
-        """The list of metadata aspects associated with the GlossaryTerm. Depending on the use case, this can either be all, or a selection, of supported aspects."""
+        """Getter: The list of metadata aspects associated with the GlossaryTerm. Depending on the use case, this can either be all, or a selection, of supported aspects."""
         return self._inner_dict.get('aspects')  # type: ignore
     
     @aspects.setter
     def aspects(self, value: List[Union["GlossaryTermKeyClass", "GlossaryTermInfoClass", "OwnershipClass", "StatusClass", "BrowsePathsClass", "GlossaryRelatedTermsClass"]]) -> None:
+        """Setter: The list of metadata aspects associated with the GlossaryTerm. Depending on the use case, this can either be all, or a selection, of supported aspects."""
         self._inner_dict['aspects'] = value
     
     
 class MLFeatureSnapshotClass(DictWrapper):
     # No docs available.
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.metadata.snapshot.MLFeatureSnapshot")
@@ -10944,36 +12720,45 @@
         aspects: List[Union["MLFeatureKeyClass", "MLFeaturePropertiesClass", "OwnershipClass", "InstitutionalMemoryClass", "StatusClass", "DeprecationClass", "BrowsePathsClass", "GlobalTagsClass", "DataPlatformInstanceClass"]],
     ):
         super().__init__()
         
         self.urn = urn
         self.aspects = aspects
     
+    @classmethod
+    def construct_with_defaults(cls) -> "MLFeatureSnapshotClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.urn = str()
         self.aspects = list()
     
     
     @property
     def urn(self) -> str:
-        """URN for the entity the metadata snapshot is associated with."""
+        """Getter: URN for the entity the metadata snapshot is associated with."""
         return self._inner_dict.get('urn')  # type: ignore
     
     @urn.setter
     def urn(self, value: str) -> None:
+        """Setter: URN for the entity the metadata snapshot is associated with."""
         self._inner_dict['urn'] = value
     
     
     @property
     def aspects(self) -> List[Union["MLFeatureKeyClass", "MLFeaturePropertiesClass", "OwnershipClass", "InstitutionalMemoryClass", "StatusClass", "DeprecationClass", "BrowsePathsClass", "GlobalTagsClass", "DataPlatformInstanceClass"]]:
-        """The list of metadata aspects associated with the MLFeature. Depending on the use case, this can either be all, or a selection, of supported aspects."""
+        """Getter: The list of metadata aspects associated with the MLFeature. Depending on the use case, this can either be all, or a selection, of supported aspects."""
         return self._inner_dict.get('aspects')  # type: ignore
     
     @aspects.setter
     def aspects(self, value: List[Union["MLFeatureKeyClass", "MLFeaturePropertiesClass", "OwnershipClass", "InstitutionalMemoryClass", "StatusClass", "DeprecationClass", "BrowsePathsClass", "GlobalTagsClass", "DataPlatformInstanceClass"]]) -> None:
+        """Setter: The list of metadata aspects associated with the MLFeature. Depending on the use case, this can either be all, or a selection, of supported aspects."""
         self._inner_dict['aspects'] = value
     
     
 class MLFeatureTableSnapshotClass(DictWrapper):
     # No docs available.
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.metadata.snapshot.MLFeatureTableSnapshot")
@@ -10982,36 +12767,45 @@
         aspects: List[Union["MLFeatureTableKeyClass", "MLFeatureTablePropertiesClass", "OwnershipClass", "InstitutionalMemoryClass", "StatusClass", "DeprecationClass", "BrowsePathsClass", "GlobalTagsClass", "DataPlatformInstanceClass"]],
     ):
         super().__init__()
         
         self.urn = urn
         self.aspects = aspects
     
+    @classmethod
+    def construct_with_defaults(cls) -> "MLFeatureTableSnapshotClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.urn = str()
         self.aspects = list()
     
     
     @property
     def urn(self) -> str:
-        """URN for the entity the metadata snapshot is associated with."""
+        """Getter: URN for the entity the metadata snapshot is associated with."""
         return self._inner_dict.get('urn')  # type: ignore
     
     @urn.setter
     def urn(self, value: str) -> None:
+        """Setter: URN for the entity the metadata snapshot is associated with."""
         self._inner_dict['urn'] = value
     
     
     @property
     def aspects(self) -> List[Union["MLFeatureTableKeyClass", "MLFeatureTablePropertiesClass", "OwnershipClass", "InstitutionalMemoryClass", "StatusClass", "DeprecationClass", "BrowsePathsClass", "GlobalTagsClass", "DataPlatformInstanceClass"]]:
-        """The list of metadata aspects associated with the MLFeatureTable. Depending on the use case, this can either be all, or a selection, of supported aspects."""
+        """Getter: The list of metadata aspects associated with the MLFeatureTable. Depending on the use case, this can either be all, or a selection, of supported aspects."""
         return self._inner_dict.get('aspects')  # type: ignore
     
     @aspects.setter
     def aspects(self, value: List[Union["MLFeatureTableKeyClass", "MLFeatureTablePropertiesClass", "OwnershipClass", "InstitutionalMemoryClass", "StatusClass", "DeprecationClass", "BrowsePathsClass", "GlobalTagsClass", "DataPlatformInstanceClass"]]) -> None:
+        """Setter: The list of metadata aspects associated with the MLFeatureTable. Depending on the use case, this can either be all, or a selection, of supported aspects."""
         self._inner_dict['aspects'] = value
     
     
 class MLModelDeploymentSnapshotClass(DictWrapper):
     # No docs available.
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.metadata.snapshot.MLModelDeploymentSnapshot")
@@ -11020,36 +12814,45 @@
         aspects: List[Union["MLModelDeploymentKeyClass", "MLModelDeploymentPropertiesClass", "OwnershipClass", "StatusClass", "DeprecationClass", "GlobalTagsClass", "DataPlatformInstanceClass"]],
     ):
         super().__init__()
         
         self.urn = urn
         self.aspects = aspects
     
+    @classmethod
+    def construct_with_defaults(cls) -> "MLModelDeploymentSnapshotClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.urn = str()
         self.aspects = list()
     
     
     @property
     def urn(self) -> str:
-        """URN for the entity the metadata snapshot is associated with."""
+        """Getter: URN for the entity the metadata snapshot is associated with."""
         return self._inner_dict.get('urn')  # type: ignore
     
     @urn.setter
     def urn(self, value: str) -> None:
+        """Setter: URN for the entity the metadata snapshot is associated with."""
         self._inner_dict['urn'] = value
     
     
     @property
     def aspects(self) -> List[Union["MLModelDeploymentKeyClass", "MLModelDeploymentPropertiesClass", "OwnershipClass", "StatusClass", "DeprecationClass", "GlobalTagsClass", "DataPlatformInstanceClass"]]:
-        """The list of metadata aspects associated with the MLModelDeployment. Depending on the use case, this can either be all, or a selection, of supported aspects."""
+        """Getter: The list of metadata aspects associated with the MLModelDeployment. Depending on the use case, this can either be all, or a selection, of supported aspects."""
         return self._inner_dict.get('aspects')  # type: ignore
     
     @aspects.setter
     def aspects(self, value: List[Union["MLModelDeploymentKeyClass", "MLModelDeploymentPropertiesClass", "OwnershipClass", "StatusClass", "DeprecationClass", "GlobalTagsClass", "DataPlatformInstanceClass"]]) -> None:
+        """Setter: The list of metadata aspects associated with the MLModelDeployment. Depending on the use case, this can either be all, or a selection, of supported aspects."""
         self._inner_dict['aspects'] = value
     
     
 class MLModelGroupSnapshotClass(DictWrapper):
     # No docs available.
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.metadata.snapshot.MLModelGroupSnapshot")
@@ -11058,36 +12861,45 @@
         aspects: List[Union["MLModelGroupKeyClass", "MLModelGroupPropertiesClass", "OwnershipClass", "StatusClass", "DeprecationClass", "BrowsePathsClass", "GlobalTagsClass", "DataPlatformInstanceClass"]],
     ):
         super().__init__()
         
         self.urn = urn
         self.aspects = aspects
     
+    @classmethod
+    def construct_with_defaults(cls) -> "MLModelGroupSnapshotClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.urn = str()
         self.aspects = list()
     
     
     @property
     def urn(self) -> str:
-        """URN for the entity the metadata snapshot is associated with."""
+        """Getter: URN for the entity the metadata snapshot is associated with."""
         return self._inner_dict.get('urn')  # type: ignore
     
     @urn.setter
     def urn(self, value: str) -> None:
+        """Setter: URN for the entity the metadata snapshot is associated with."""
         self._inner_dict['urn'] = value
     
     
     @property
     def aspects(self) -> List[Union["MLModelGroupKeyClass", "MLModelGroupPropertiesClass", "OwnershipClass", "StatusClass", "DeprecationClass", "BrowsePathsClass", "GlobalTagsClass", "DataPlatformInstanceClass"]]:
-        """The list of metadata aspects associated with the MLModelGroup. Depending on the use case, this can either be all, or a selection, of supported aspects."""
+        """Getter: The list of metadata aspects associated with the MLModelGroup. Depending on the use case, this can either be all, or a selection, of supported aspects."""
         return self._inner_dict.get('aspects')  # type: ignore
     
     @aspects.setter
     def aspects(self, value: List[Union["MLModelGroupKeyClass", "MLModelGroupPropertiesClass", "OwnershipClass", "StatusClass", "DeprecationClass", "BrowsePathsClass", "GlobalTagsClass", "DataPlatformInstanceClass"]]) -> None:
+        """Setter: The list of metadata aspects associated with the MLModelGroup. Depending on the use case, this can either be all, or a selection, of supported aspects."""
         self._inner_dict['aspects'] = value
     
     
 class MLModelSnapshotClass(DictWrapper):
     """MLModel Snapshot entity details."""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.metadata.snapshot.MLModelSnapshot")
@@ -11096,36 +12908,45 @@
         aspects: List[Union["MLModelKeyClass", "OwnershipClass", "MLModelPropertiesClass", "IntendedUseClass", "MLModelFactorPromptsClass", "MetricsClass", "EvaluationDataClass", "TrainingDataClass", "QuantitativeAnalysesClass", "EthicalConsiderationsClass", "CaveatsAndRecommendationsClass", "InstitutionalMemoryClass", "SourceCodeClass", "StatusClass", "CostClass", "DeprecationClass", "BrowsePathsClass", "GlobalTagsClass", "DataPlatformInstanceClass"]],
     ):
         super().__init__()
         
         self.urn = urn
         self.aspects = aspects
     
+    @classmethod
+    def construct_with_defaults(cls) -> "MLModelSnapshotClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.urn = str()
         self.aspects = list()
     
     
     @property
     def urn(self) -> str:
-        """URN for the entity the metadata snapshot is associated with."""
+        """Getter: URN for the entity the metadata snapshot is associated with."""
         return self._inner_dict.get('urn')  # type: ignore
     
     @urn.setter
     def urn(self, value: str) -> None:
+        """Setter: URN for the entity the metadata snapshot is associated with."""
         self._inner_dict['urn'] = value
     
     
     @property
     def aspects(self) -> List[Union["MLModelKeyClass", "OwnershipClass", "MLModelPropertiesClass", "IntendedUseClass", "MLModelFactorPromptsClass", "MetricsClass", "EvaluationDataClass", "TrainingDataClass", "QuantitativeAnalysesClass", "EthicalConsiderationsClass", "CaveatsAndRecommendationsClass", "InstitutionalMemoryClass", "SourceCodeClass", "StatusClass", "CostClass", "DeprecationClass", "BrowsePathsClass", "GlobalTagsClass", "DataPlatformInstanceClass"]]:
-        """The list of metadata aspects associated with the MLModel. Depending on the use case, this can either be all, or a selection, of supported aspects."""
+        """Getter: The list of metadata aspects associated with the MLModel. Depending on the use case, this can either be all, or a selection, of supported aspects."""
         return self._inner_dict.get('aspects')  # type: ignore
     
     @aspects.setter
     def aspects(self, value: List[Union["MLModelKeyClass", "OwnershipClass", "MLModelPropertiesClass", "IntendedUseClass", "MLModelFactorPromptsClass", "MetricsClass", "EvaluationDataClass", "TrainingDataClass", "QuantitativeAnalysesClass", "EthicalConsiderationsClass", "CaveatsAndRecommendationsClass", "InstitutionalMemoryClass", "SourceCodeClass", "StatusClass", "CostClass", "DeprecationClass", "BrowsePathsClass", "GlobalTagsClass", "DataPlatformInstanceClass"]]) -> None:
+        """Setter: The list of metadata aspects associated with the MLModel. Depending on the use case, this can either be all, or a selection, of supported aspects."""
         self._inner_dict['aspects'] = value
     
     
 class MLPrimaryKeySnapshotClass(DictWrapper):
     # No docs available.
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.metadata.snapshot.MLPrimaryKeySnapshot")
@@ -11134,36 +12955,45 @@
         aspects: List[Union["MLPrimaryKeyKeyClass", "MLPrimaryKeyPropertiesClass", "OwnershipClass", "InstitutionalMemoryClass", "StatusClass", "DeprecationClass", "GlobalTagsClass", "DataPlatformInstanceClass"]],
     ):
         super().__init__()
         
         self.urn = urn
         self.aspects = aspects
     
+    @classmethod
+    def construct_with_defaults(cls) -> "MLPrimaryKeySnapshotClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.urn = str()
         self.aspects = list()
     
     
     @property
     def urn(self) -> str:
-        """URN for the entity the metadata snapshot is associated with."""
+        """Getter: URN for the entity the metadata snapshot is associated with."""
         return self._inner_dict.get('urn')  # type: ignore
     
     @urn.setter
     def urn(self, value: str) -> None:
+        """Setter: URN for the entity the metadata snapshot is associated with."""
         self._inner_dict['urn'] = value
     
     
     @property
     def aspects(self) -> List[Union["MLPrimaryKeyKeyClass", "MLPrimaryKeyPropertiesClass", "OwnershipClass", "InstitutionalMemoryClass", "StatusClass", "DeprecationClass", "GlobalTagsClass", "DataPlatformInstanceClass"]]:
-        """The list of metadata aspects associated with the MLPrimaryKey. Depending on the use case, this can either be all, or a selection, of supported aspects."""
+        """Getter: The list of metadata aspects associated with the MLPrimaryKey. Depending on the use case, this can either be all, or a selection, of supported aspects."""
         return self._inner_dict.get('aspects')  # type: ignore
     
     @aspects.setter
     def aspects(self, value: List[Union["MLPrimaryKeyKeyClass", "MLPrimaryKeyPropertiesClass", "OwnershipClass", "InstitutionalMemoryClass", "StatusClass", "DeprecationClass", "GlobalTagsClass", "DataPlatformInstanceClass"]]) -> None:
+        """Setter: The list of metadata aspects associated with the MLPrimaryKey. Depending on the use case, this can either be all, or a selection, of supported aspects."""
         self._inner_dict['aspects'] = value
     
     
 class SchemaFieldSnapshotClass(DictWrapper):
     """A metadata snapshot for a specific schema field entity."""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.metadata.snapshot.SchemaFieldSnapshot")
@@ -11172,36 +13002,45 @@
         aspects: List["SchemaFieldKeyClass"],
     ):
         super().__init__()
         
         self.urn = urn
         self.aspects = aspects
     
+    @classmethod
+    def construct_with_defaults(cls) -> "SchemaFieldSnapshotClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.urn = str()
         self.aspects = list()
     
     
     @property
     def urn(self) -> str:
-        """URN for the entity the metadata snapshot is associated with."""
+        """Getter: URN for the entity the metadata snapshot is associated with."""
         return self._inner_dict.get('urn')  # type: ignore
     
     @urn.setter
     def urn(self, value: str) -> None:
+        """Setter: URN for the entity the metadata snapshot is associated with."""
         self._inner_dict['urn'] = value
     
     
     @property
     def aspects(self) -> List["SchemaFieldKeyClass"]:
-        """The list of metadata aspects associated with the dataset. Depending on the use case, this can either be all, or a selection, of supported aspects."""
+        """Getter: The list of metadata aspects associated with the dataset. Depending on the use case, this can either be all, or a selection, of supported aspects."""
         return self._inner_dict.get('aspects')  # type: ignore
     
     @aspects.setter
     def aspects(self, value: List["SchemaFieldKeyClass"]) -> None:
+        """Setter: The list of metadata aspects associated with the dataset. Depending on the use case, this can either be all, or a selection, of supported aspects."""
         self._inner_dict['aspects'] = value
     
     
 class TagSnapshotClass(DictWrapper):
     """A metadata snapshot for a specific dataset entity."""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.metadata.snapshot.TagSnapshot")
@@ -11210,36 +13049,45 @@
         aspects: List[Union["TagKeyClass", "OwnershipClass", "TagPropertiesClass", "StatusClass"]],
     ):
         super().__init__()
         
         self.urn = urn
         self.aspects = aspects
     
+    @classmethod
+    def construct_with_defaults(cls) -> "TagSnapshotClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.urn = str()
         self.aspects = list()
     
     
     @property
     def urn(self) -> str:
-        """URN for the entity the metadata snapshot is associated with."""
+        """Getter: URN for the entity the metadata snapshot is associated with."""
         return self._inner_dict.get('urn')  # type: ignore
     
     @urn.setter
     def urn(self, value: str) -> None:
+        """Setter: URN for the entity the metadata snapshot is associated with."""
         self._inner_dict['urn'] = value
     
     
     @property
     def aspects(self) -> List[Union["TagKeyClass", "OwnershipClass", "TagPropertiesClass", "StatusClass"]]:
-        """The list of metadata aspects associated with the dataset. Depending on the use case, this can either be all, or a selection, of supported aspects."""
+        """Getter: The list of metadata aspects associated with the dataset. Depending on the use case, this can either be all, or a selection, of supported aspects."""
         return self._inner_dict.get('aspects')  # type: ignore
     
     @aspects.setter
     def aspects(self, value: List[Union["TagKeyClass", "OwnershipClass", "TagPropertiesClass", "StatusClass"]]) -> None:
+        """Setter: The list of metadata aspects associated with the dataset. Depending on the use case, this can either be all, or a selection, of supported aspects."""
         self._inner_dict['aspects'] = value
     
     
 class BaseDataClass(DictWrapper):
     """BaseData record"""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.ml.metadata.BaseData")
@@ -11250,47 +13098,57 @@
     ):
         super().__init__()
         
         self.dataset = dataset
         self.motivation = motivation
         self.preProcessing = preProcessing
     
+    @classmethod
+    def construct_with_defaults(cls) -> "BaseDataClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.dataset = str()
         self.motivation = self.RECORD_SCHEMA.fields_dict["motivation"].default
         self.preProcessing = self.RECORD_SCHEMA.fields_dict["preProcessing"].default
     
     
     @property
     def dataset(self) -> str:
-        """What dataset were used in the MLModel?"""
+        """Getter: What dataset were used in the MLModel?"""
         return self._inner_dict.get('dataset')  # type: ignore
     
     @dataset.setter
     def dataset(self, value: str) -> None:
+        """Setter: What dataset were used in the MLModel?"""
         self._inner_dict['dataset'] = value
     
     
     @property
     def motivation(self) -> Union[None, str]:
-        """Why was this dataset chosen?"""
+        """Getter: Why was this dataset chosen?"""
         return self._inner_dict.get('motivation')  # type: ignore
     
     @motivation.setter
     def motivation(self, value: Union[None, str]) -> None:
+        """Setter: Why was this dataset chosen?"""
         self._inner_dict['motivation'] = value
     
     
     @property
     def preProcessing(self) -> Union[None, List[str]]:
-        """How was the data preprocessed (e.g., tokenization of sentences, cropping of images, any filtering such as dropping images without faces)?"""
+        """Getter: How was the data preprocessed (e.g., tokenization of sentences, cropping of images, any filtering such as dropping images without faces)?"""
         return self._inner_dict.get('preProcessing')  # type: ignore
     
     @preProcessing.setter
     def preProcessing(self, value: Union[None, List[str]]) -> None:
+        """Setter: How was the data preprocessed (e.g., tokenization of sentences, cropping of images, any filtering such as dropping images without faces)?"""
         self._inner_dict['preProcessing'] = value
     
     
 class CaveatDetailsClass(DictWrapper):
     """This section should list additional concerns that were not covered in the previous sections. For example, did the results suggest any further testing? Were there any relevant groups that were not represented in the evaluation dataset? Are there additional recommendations for model use?"""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.ml.metadata.CaveatDetails")
@@ -11301,48 +13159,59 @@
     ):
         super().__init__()
         
         self.needsFurtherTesting = needsFurtherTesting
         self.caveatDescription = caveatDescription
         self.groupsNotRepresented = groupsNotRepresented
     
+    @classmethod
+    def construct_with_defaults(cls) -> "CaveatDetailsClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.needsFurtherTesting = self.RECORD_SCHEMA.fields_dict["needsFurtherTesting"].default
         self.caveatDescription = self.RECORD_SCHEMA.fields_dict["caveatDescription"].default
         self.groupsNotRepresented = self.RECORD_SCHEMA.fields_dict["groupsNotRepresented"].default
     
     
     @property
     def needsFurtherTesting(self) -> Union[None, bool]:
-        """Did the results suggest any further testing?"""
+        """Getter: Did the results suggest any further testing?"""
         return self._inner_dict.get('needsFurtherTesting')  # type: ignore
     
     @needsFurtherTesting.setter
     def needsFurtherTesting(self, value: Union[None, bool]) -> None:
+        """Setter: Did the results suggest any further testing?"""
         self._inner_dict['needsFurtherTesting'] = value
     
     
     @property
     def caveatDescription(self) -> Union[None, str]:
-        """Caveat Description
+        """Getter: Caveat Description
     For ex: Given gender classes are binary (male/not male), which we include as male/female. Further work needed to evaluate across a spectrum of genders."""
         return self._inner_dict.get('caveatDescription')  # type: ignore
     
     @caveatDescription.setter
     def caveatDescription(self, value: Union[None, str]) -> None:
+        """Setter: Caveat Description
+    For ex: Given gender classes are binary (male/not male), which we include as male/female. Further work needed to evaluate across a spectrum of genders."""
         self._inner_dict['caveatDescription'] = value
     
     
     @property
     def groupsNotRepresented(self) -> Union[None, List[str]]:
-        """Relevant groups that were not represented in the evaluation dataset?"""
+        """Getter: Relevant groups that were not represented in the evaluation dataset?"""
         return self._inner_dict.get('groupsNotRepresented')  # type: ignore
     
     @groupsNotRepresented.setter
     def groupsNotRepresented(self, value: Union[None, List[str]]) -> None:
+        """Setter: Relevant groups that were not represented in the evaluation dataset?"""
         self._inner_dict['groupsNotRepresented'] = value
     
     
 class CaveatsAndRecommendationsClass(_Aspect):
     """This section should list additional concerns that were not covered in the previous sections. For example, did the results suggest any further testing? Were there any relevant groups that were not represented in the evaluation dataset? Are there additional recommendations for model use?"""
 
 
@@ -11357,47 +13226,57 @@
     ):
         super().__init__()
         
         self.caveats = caveats
         self.recommendations = recommendations
         self.idealDatasetCharacteristics = idealDatasetCharacteristics
     
+    @classmethod
+    def construct_with_defaults(cls) -> "CaveatsAndRecommendationsClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.caveats = self.RECORD_SCHEMA.fields_dict["caveats"].default
         self.recommendations = self.RECORD_SCHEMA.fields_dict["recommendations"].default
         self.idealDatasetCharacteristics = self.RECORD_SCHEMA.fields_dict["idealDatasetCharacteristics"].default
     
     
     @property
     def caveats(self) -> Union[None, "CaveatDetailsClass"]:
-        """This section should list additional concerns that were not covered in the previous sections. For example, did the results suggest any further testing? Were there any relevant groups that were not represented in the evaluation dataset?"""
+        """Getter: This section should list additional concerns that were not covered in the previous sections. For example, did the results suggest any further testing? Were there any relevant groups that were not represented in the evaluation dataset?"""
         return self._inner_dict.get('caveats')  # type: ignore
     
     @caveats.setter
     def caveats(self, value: Union[None, "CaveatDetailsClass"]) -> None:
+        """Setter: This section should list additional concerns that were not covered in the previous sections. For example, did the results suggest any further testing? Were there any relevant groups that were not represented in the evaluation dataset?"""
         self._inner_dict['caveats'] = value
     
     
     @property
     def recommendations(self) -> Union[None, str]:
-        """Recommendations on where this MLModel should be used."""
+        """Getter: Recommendations on where this MLModel should be used."""
         return self._inner_dict.get('recommendations')  # type: ignore
     
     @recommendations.setter
     def recommendations(self, value: Union[None, str]) -> None:
+        """Setter: Recommendations on where this MLModel should be used."""
         self._inner_dict['recommendations'] = value
     
     
     @property
     def idealDatasetCharacteristics(self) -> Union[None, List[str]]:
-        """Ideal characteristics of an evaluation dataset for this MLModel"""
+        """Getter: Ideal characteristics of an evaluation dataset for this MLModel"""
         return self._inner_dict.get('idealDatasetCharacteristics')  # type: ignore
     
     @idealDatasetCharacteristics.setter
     def idealDatasetCharacteristics(self, value: Union[None, List[str]]) -> None:
+        """Setter: Ideal characteristics of an evaluation dataset for this MLModel"""
         self._inner_dict['idealDatasetCharacteristics'] = value
     
     
 class DeploymentStatusClass(object):
     """Model endpoint statuses"""
     
     
@@ -11437,25 +13316,33 @@
     def __init__(self,
         description: Union[None, str]=None,
     ):
         super().__init__()
         
         self.description = description
     
+    @classmethod
+    def construct_with_defaults(cls) -> "EditableMLFeaturePropertiesClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.description = self.RECORD_SCHEMA.fields_dict["description"].default
     
     
     @property
     def description(self) -> Union[None, str]:
-        """Documentation of the MLFeature"""
+        """Getter: Documentation of the MLFeature"""
         return self._inner_dict.get('description')  # type: ignore
     
     @description.setter
     def description(self, value: Union[None, str]) -> None:
+        """Setter: Documentation of the MLFeature"""
         self._inner_dict['description'] = value
     
     
 class EditableMLFeatureTablePropertiesClass(_Aspect):
     """Properties associated with a MLFeatureTable editable from the ui"""
 
 
@@ -11466,25 +13353,33 @@
     def __init__(self,
         description: Union[None, str]=None,
     ):
         super().__init__()
         
         self.description = description
     
+    @classmethod
+    def construct_with_defaults(cls) -> "EditableMLFeatureTablePropertiesClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.description = self.RECORD_SCHEMA.fields_dict["description"].default
     
     
     @property
     def description(self) -> Union[None, str]:
-        """Documentation of the MLFeatureTable"""
+        """Getter: Documentation of the MLFeatureTable"""
         return self._inner_dict.get('description')  # type: ignore
     
     @description.setter
     def description(self, value: Union[None, str]) -> None:
+        """Setter: Documentation of the MLFeatureTable"""
         self._inner_dict['description'] = value
     
     
 class EditableMLModelGroupPropertiesClass(_Aspect):
     """Properties associated with an ML Model Group editable from the UI"""
 
 
@@ -11495,25 +13390,33 @@
     def __init__(self,
         description: Union[None, str]=None,
     ):
         super().__init__()
         
         self.description = description
     
+    @classmethod
+    def construct_with_defaults(cls) -> "EditableMLModelGroupPropertiesClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.description = self.RECORD_SCHEMA.fields_dict["description"].default
     
     
     @property
     def description(self) -> Union[None, str]:
-        """Documentation of the ml model group"""
+        """Getter: Documentation of the ml model group"""
         return self._inner_dict.get('description')  # type: ignore
     
     @description.setter
     def description(self, value: Union[None, str]) -> None:
+        """Setter: Documentation of the ml model group"""
         self._inner_dict['description'] = value
     
     
 class EditableMLModelPropertiesClass(_Aspect):
     """Properties associated with a ML Model editable from the UI"""
 
 
@@ -11524,25 +13427,33 @@
     def __init__(self,
         description: Union[None, str]=None,
     ):
         super().__init__()
         
         self.description = description
     
+    @classmethod
+    def construct_with_defaults(cls) -> "EditableMLModelPropertiesClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.description = self.RECORD_SCHEMA.fields_dict["description"].default
     
     
     @property
     def description(self) -> Union[None, str]:
-        """Documentation of the ml model"""
+        """Getter: Documentation of the ml model"""
         return self._inner_dict.get('description')  # type: ignore
     
     @description.setter
     def description(self, value: Union[None, str]) -> None:
+        """Setter: Documentation of the ml model"""
         self._inner_dict['description'] = value
     
     
 class EditableMLPrimaryKeyPropertiesClass(_Aspect):
     """Properties associated with a MLPrimaryKey editable from the UI"""
 
 
@@ -11553,25 +13464,33 @@
     def __init__(self,
         description: Union[None, str]=None,
     ):
         super().__init__()
         
         self.description = description
     
+    @classmethod
+    def construct_with_defaults(cls) -> "EditableMLPrimaryKeyPropertiesClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.description = self.RECORD_SCHEMA.fields_dict["description"].default
     
     
     @property
     def description(self) -> Union[None, str]:
-        """Documentation of the MLPrimaryKey"""
+        """Getter: Documentation of the MLPrimaryKey"""
         return self._inner_dict.get('description')  # type: ignore
     
     @description.setter
     def description(self, value: Union[None, str]) -> None:
+        """Setter: Documentation of the MLPrimaryKey"""
         self._inner_dict['description'] = value
     
     
 class EthicalConsiderationsClass(_Aspect):
     """This section is intended to demonstrate the ethical considerations that went into MLModel development, surfacing ethical challenges and solutions to stakeholders."""
 
 
@@ -11590,69 +13509,81 @@
         
         self.data = data
         self.humanLife = humanLife
         self.mitigations = mitigations
         self.risksAndHarms = risksAndHarms
         self.useCases = useCases
     
+    @classmethod
+    def construct_with_defaults(cls) -> "EthicalConsiderationsClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.data = self.RECORD_SCHEMA.fields_dict["data"].default
         self.humanLife = self.RECORD_SCHEMA.fields_dict["humanLife"].default
         self.mitigations = self.RECORD_SCHEMA.fields_dict["mitigations"].default
         self.risksAndHarms = self.RECORD_SCHEMA.fields_dict["risksAndHarms"].default
         self.useCases = self.RECORD_SCHEMA.fields_dict["useCases"].default
     
     
     @property
     def data(self) -> Union[None, List[str]]:
-        """Does the MLModel use any sensitive data (e.g., protected classes)?"""
+        """Getter: Does the MLModel use any sensitive data (e.g., protected classes)?"""
         return self._inner_dict.get('data')  # type: ignore
     
     @data.setter
     def data(self, value: Union[None, List[str]]) -> None:
+        """Setter: Does the MLModel use any sensitive data (e.g., protected classes)?"""
         self._inner_dict['data'] = value
     
     
     @property
     def humanLife(self) -> Union[None, List[str]]:
-        """ Is the MLModel intended to inform decisions about matters central to human life or flourishing - e.g., health or safety? Or could it be used in such a way?"""
+        """Getter:  Is the MLModel intended to inform decisions about matters central to human life or flourishing - e.g., health or safety? Or could it be used in such a way?"""
         return self._inner_dict.get('humanLife')  # type: ignore
     
     @humanLife.setter
     def humanLife(self, value: Union[None, List[str]]) -> None:
+        """Setter:  Is the MLModel intended to inform decisions about matters central to human life or flourishing - e.g., health or safety? Or could it be used in such a way?"""
         self._inner_dict['humanLife'] = value
     
     
     @property
     def mitigations(self) -> Union[None, List[str]]:
-        """What risk mitigation strategies were used during MLModel development?"""
+        """Getter: What risk mitigation strategies were used during MLModel development?"""
         return self._inner_dict.get('mitigations')  # type: ignore
     
     @mitigations.setter
     def mitigations(self, value: Union[None, List[str]]) -> None:
+        """Setter: What risk mitigation strategies were used during MLModel development?"""
         self._inner_dict['mitigations'] = value
     
     
     @property
     def risksAndHarms(self) -> Union[None, List[str]]:
-        """What risks may be present in MLModel usage? Try to identify the potential recipients, likelihood, and magnitude of harms. If these cannot be determined, note that they were considered but remain unknown."""
+        """Getter: What risks may be present in MLModel usage? Try to identify the potential recipients, likelihood, and magnitude of harms. If these cannot be determined, note that they were considered but remain unknown."""
         return self._inner_dict.get('risksAndHarms')  # type: ignore
     
     @risksAndHarms.setter
     def risksAndHarms(self, value: Union[None, List[str]]) -> None:
+        """Setter: What risks may be present in MLModel usage? Try to identify the potential recipients, likelihood, and magnitude of harms. If these cannot be determined, note that they were considered but remain unknown."""
         self._inner_dict['risksAndHarms'] = value
     
     
     @property
     def useCases(self) -> Union[None, List[str]]:
-        """Are there any known MLModel use cases that are especially fraught? This may connect directly to the intended use section"""
+        """Getter: Are there any known MLModel use cases that are especially fraught? This may connect directly to the intended use section"""
         return self._inner_dict.get('useCases')  # type: ignore
     
     @useCases.setter
     def useCases(self, value: Union[None, List[str]]) -> None:
+        """Setter: Are there any known MLModel use cases that are especially fraught? This may connect directly to the intended use section"""
         self._inner_dict['useCases'] = value
     
     
 class EvaluationDataClass(_Aspect):
     """All referenced datasets would ideally point to any set of documents that provide visibility into the source and composition of the dataset."""
 
 
@@ -11663,25 +13594,33 @@
     def __init__(self,
         evaluationData: List["BaseDataClass"],
     ):
         super().__init__()
         
         self.evaluationData = evaluationData
     
+    @classmethod
+    def construct_with_defaults(cls) -> "EvaluationDataClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.evaluationData = list()
     
     
     @property
     def evaluationData(self) -> List["BaseDataClass"]:
-        """Details on the dataset(s) used for the quantitative analyses in the MLModel"""
+        """Getter: Details on the dataset(s) used for the quantitative analyses in the MLModel"""
         return self._inner_dict.get('evaluationData')  # type: ignore
     
     @evaluationData.setter
     def evaluationData(self, value: List["BaseDataClass"]) -> None:
+        """Setter: Details on the dataset(s) used for the quantitative analyses in the MLModel"""
         self._inner_dict['evaluationData'] = value
     
     
 class IntendedUseClass(_Aspect):
     """Intended Use for the ML Model"""
 
 
@@ -11696,47 +13635,57 @@
     ):
         super().__init__()
         
         self.primaryUses = primaryUses
         self.primaryUsers = primaryUsers
         self.outOfScopeUses = outOfScopeUses
     
+    @classmethod
+    def construct_with_defaults(cls) -> "IntendedUseClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.primaryUses = self.RECORD_SCHEMA.fields_dict["primaryUses"].default
         self.primaryUsers = self.RECORD_SCHEMA.fields_dict["primaryUsers"].default
         self.outOfScopeUses = self.RECORD_SCHEMA.fields_dict["outOfScopeUses"].default
     
     
     @property
     def primaryUses(self) -> Union[None, List[str]]:
-        """Primary Use cases for the MLModel."""
+        """Getter: Primary Use cases for the MLModel."""
         return self._inner_dict.get('primaryUses')  # type: ignore
     
     @primaryUses.setter
     def primaryUses(self, value: Union[None, List[str]]) -> None:
+        """Setter: Primary Use cases for the MLModel."""
         self._inner_dict['primaryUses'] = value
     
     
     @property
     def primaryUsers(self) -> Union[None, List[Union[str, "IntendedUserTypeClass"]]]:
-        """Primary Intended Users - For example, was the MLModel developed for entertainment purposes, for hobbyists, or enterprise solutions?"""
+        """Getter: Primary Intended Users - For example, was the MLModel developed for entertainment purposes, for hobbyists, or enterprise solutions?"""
         return self._inner_dict.get('primaryUsers')  # type: ignore
     
     @primaryUsers.setter
     def primaryUsers(self, value: Union[None, List[Union[str, "IntendedUserTypeClass"]]]) -> None:
+        """Setter: Primary Intended Users - For example, was the MLModel developed for entertainment purposes, for hobbyists, or enterprise solutions?"""
         self._inner_dict['primaryUsers'] = value
     
     
     @property
     def outOfScopeUses(self) -> Union[None, List[str]]:
-        """Highlight technology that the MLModel might easily be confused with, or related contexts that users could try to apply the MLModel to."""
+        """Getter: Highlight technology that the MLModel might easily be confused with, or related contexts that users could try to apply the MLModel to."""
         return self._inner_dict.get('outOfScopeUses')  # type: ignore
     
     @outOfScopeUses.setter
     def outOfScopeUses(self, value: Union[None, List[str]]) -> None:
+        """Setter: Highlight technology that the MLModel might easily be confused with, or related contexts that users could try to apply the MLModel to."""
         self._inner_dict['outOfScopeUses'] = value
     
     
 class IntendedUserTypeClass(object):
     # No docs available.
     
     ENTERPRISE = "ENTERPRISE"
@@ -11761,58 +13710,69 @@
         super().__init__()
         
         self.description = description
         self.dataType = dataType
         self.version = version
         self.sources = sources
     
+    @classmethod
+    def construct_with_defaults(cls) -> "MLFeaturePropertiesClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.description = self.RECORD_SCHEMA.fields_dict["description"].default
         self.dataType = self.RECORD_SCHEMA.fields_dict["dataType"].default
         self.version = self.RECORD_SCHEMA.fields_dict["version"].default
         self.sources = self.RECORD_SCHEMA.fields_dict["sources"].default
     
     
     @property
     def description(self) -> Union[None, str]:
-        """Documentation of the MLFeature"""
+        """Getter: Documentation of the MLFeature"""
         return self._inner_dict.get('description')  # type: ignore
     
     @description.setter
     def description(self, value: Union[None, str]) -> None:
+        """Setter: Documentation of the MLFeature"""
         self._inner_dict['description'] = value
     
     
     @property
     def dataType(self) -> Union[None, Union[str, "MLFeatureDataTypeClass"]]:
-        """Data Type of the MLFeature"""
+        """Getter: Data Type of the MLFeature"""
         return self._inner_dict.get('dataType')  # type: ignore
     
     @dataType.setter
     def dataType(self, value: Union[None, Union[str, "MLFeatureDataTypeClass"]]) -> None:
+        """Setter: Data Type of the MLFeature"""
         self._inner_dict['dataType'] = value
     
     
     @property
     def version(self) -> Union[None, "VersionTagClass"]:
-        """Version of the MLFeature"""
+        """Getter: Version of the MLFeature"""
         return self._inner_dict.get('version')  # type: ignore
     
     @version.setter
     def version(self, value: Union[None, "VersionTagClass"]) -> None:
+        """Setter: Version of the MLFeature"""
         self._inner_dict['version'] = value
     
     
     @property
     def sources(self) -> Union[None, List[str]]:
-        """Source of the MLFeature"""
+        """Getter: Source of the MLFeature"""
         return self._inner_dict.get('sources')  # type: ignore
     
     @sources.setter
     def sources(self, value: Union[None, List[str]]) -> None:
+        """Setter: Source of the MLFeature"""
         self._inner_dict['sources'] = value
     
     
 class MLFeatureTablePropertiesClass(_Aspect):
     """Properties associated with a MLFeatureTable"""
 
 
@@ -11833,58 +13793,69 @@
             self.customProperties = dict()
         else:
             self.customProperties = customProperties
         self.description = description
         self.mlFeatures = mlFeatures
         self.mlPrimaryKeys = mlPrimaryKeys
     
+    @classmethod
+    def construct_with_defaults(cls) -> "MLFeatureTablePropertiesClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.customProperties = dict()
         self.description = self.RECORD_SCHEMA.fields_dict["description"].default
         self.mlFeatures = self.RECORD_SCHEMA.fields_dict["mlFeatures"].default
         self.mlPrimaryKeys = self.RECORD_SCHEMA.fields_dict["mlPrimaryKeys"].default
     
     
     @property
     def customProperties(self) -> Dict[str, str]:
-        """Custom property bag."""
+        """Getter: Custom property bag."""
         return self._inner_dict.get('customProperties')  # type: ignore
     
     @customProperties.setter
     def customProperties(self, value: Dict[str, str]) -> None:
+        """Setter: Custom property bag."""
         self._inner_dict['customProperties'] = value
     
     
     @property
     def description(self) -> Union[None, str]:
-        """Documentation of the MLFeatureTable"""
+        """Getter: Documentation of the MLFeatureTable"""
         return self._inner_dict.get('description')  # type: ignore
     
     @description.setter
     def description(self, value: Union[None, str]) -> None:
+        """Setter: Documentation of the MLFeatureTable"""
         self._inner_dict['description'] = value
     
     
     @property
     def mlFeatures(self) -> Union[None, List[str]]:
-        """List of features contained in the feature table"""
+        """Getter: List of features contained in the feature table"""
         return self._inner_dict.get('mlFeatures')  # type: ignore
     
     @mlFeatures.setter
     def mlFeatures(self, value: Union[None, List[str]]) -> None:
+        """Setter: List of features contained in the feature table"""
         self._inner_dict['mlFeatures'] = value
     
     
     @property
     def mlPrimaryKeys(self) -> Union[None, List[str]]:
-        """List of primary keys in the feature table (if multiple, assumed to act as a composite key)"""
+        """Getter: List of primary keys in the feature table (if multiple, assumed to act as a composite key)"""
         return self._inner_dict.get('mlPrimaryKeys')  # type: ignore
     
     @mlPrimaryKeys.setter
     def mlPrimaryKeys(self, value: Union[None, List[str]]) -> None:
+        """Setter: List of primary keys in the feature table (if multiple, assumed to act as a composite key)"""
         self._inner_dict['mlPrimaryKeys'] = value
     
     
 class MLHyperParamClass(_Aspect):
     """Properties associated with an ML Hyper Param"""
 
 
@@ -11901,58 +13872,69 @@
         super().__init__()
         
         self.name = name
         self.description = description
         self.value = value
         self.createdAt = createdAt
     
+    @classmethod
+    def construct_with_defaults(cls) -> "MLHyperParamClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.name = str()
         self.description = self.RECORD_SCHEMA.fields_dict["description"].default
         self.value = self.RECORD_SCHEMA.fields_dict["value"].default
         self.createdAt = self.RECORD_SCHEMA.fields_dict["createdAt"].default
     
     
     @property
     def name(self) -> str:
-        """Name of the MLHyperParam"""
+        """Getter: Name of the MLHyperParam"""
         return self._inner_dict.get('name')  # type: ignore
     
     @name.setter
     def name(self, value: str) -> None:
+        """Setter: Name of the MLHyperParam"""
         self._inner_dict['name'] = value
     
     
     @property
     def description(self) -> Union[None, str]:
-        """Documentation of the MLHyperParam"""
+        """Getter: Documentation of the MLHyperParam"""
         return self._inner_dict.get('description')  # type: ignore
     
     @description.setter
     def description(self, value: Union[None, str]) -> None:
+        """Setter: Documentation of the MLHyperParam"""
         self._inner_dict['description'] = value
     
     
     @property
     def value(self) -> Union[None, str]:
-        """The value of the MLHyperParam"""
+        """Getter: The value of the MLHyperParam"""
         return self._inner_dict.get('value')  # type: ignore
     
     @value.setter
     def value(self, value: Union[None, str]) -> None:
+        """Setter: The value of the MLHyperParam"""
         self._inner_dict['value'] = value
     
     
     @property
     def createdAt(self) -> Union[None, int]:
-        """Date when the MLHyperParam was developed"""
+        """Getter: Date when the MLHyperParam was developed"""
         return self._inner_dict.get('createdAt')  # type: ignore
     
     @createdAt.setter
     def createdAt(self, value: Union[None, int]) -> None:
+        """Setter: Date when the MLHyperParam was developed"""
         self._inner_dict['createdAt'] = value
     
     
 class MLMetricClass(_Aspect):
     """Properties associated with an ML Metric"""
 
 
@@ -11969,58 +13951,69 @@
         super().__init__()
         
         self.name = name
         self.description = description
         self.value = value
         self.createdAt = createdAt
     
+    @classmethod
+    def construct_with_defaults(cls) -> "MLMetricClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.name = str()
         self.description = self.RECORD_SCHEMA.fields_dict["description"].default
         self.value = self.RECORD_SCHEMA.fields_dict["value"].default
         self.createdAt = self.RECORD_SCHEMA.fields_dict["createdAt"].default
     
     
     @property
     def name(self) -> str:
-        """Name of the mlMetric"""
+        """Getter: Name of the mlMetric"""
         return self._inner_dict.get('name')  # type: ignore
     
     @name.setter
     def name(self, value: str) -> None:
+        """Setter: Name of the mlMetric"""
         self._inner_dict['name'] = value
     
     
     @property
     def description(self) -> Union[None, str]:
-        """Documentation of the mlMetric"""
+        """Getter: Documentation of the mlMetric"""
         return self._inner_dict.get('description')  # type: ignore
     
     @description.setter
     def description(self, value: Union[None, str]) -> None:
+        """Setter: Documentation of the mlMetric"""
         self._inner_dict['description'] = value
     
     
     @property
     def value(self) -> Union[None, str]:
-        """The value of the mlMetric"""
+        """Getter: The value of the mlMetric"""
         return self._inner_dict.get('value')  # type: ignore
     
     @value.setter
     def value(self, value: Union[None, str]) -> None:
+        """Setter: The value of the mlMetric"""
         self._inner_dict['value'] = value
     
     
     @property
     def createdAt(self) -> Union[None, int]:
-        """Date when the mlMetric was developed"""
+        """Getter: Date when the mlMetric was developed"""
         return self._inner_dict.get('createdAt')  # type: ignore
     
     @createdAt.setter
     def createdAt(self, value: Union[None, int]) -> None:
+        """Setter: Date when the mlMetric was developed"""
         self._inner_dict['createdAt'] = value
     
     
 class MLModelDeploymentPropertiesClass(_Aspect):
     """Properties associated with an ML Model Deployment"""
 
 
@@ -12045,80 +14038,93 @@
             self.customProperties = customProperties
         self.externalUrl = externalUrl
         self.description = description
         self.createdAt = createdAt
         self.version = version
         self.status = status
     
+    @classmethod
+    def construct_with_defaults(cls) -> "MLModelDeploymentPropertiesClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.customProperties = dict()
         self.externalUrl = self.RECORD_SCHEMA.fields_dict["externalUrl"].default
         self.description = self.RECORD_SCHEMA.fields_dict["description"].default
         self.createdAt = self.RECORD_SCHEMA.fields_dict["createdAt"].default
         self.version = self.RECORD_SCHEMA.fields_dict["version"].default
         self.status = self.RECORD_SCHEMA.fields_dict["status"].default
     
     
     @property
     def customProperties(self) -> Dict[str, str]:
-        """Custom property bag."""
+        """Getter: Custom property bag."""
         return self._inner_dict.get('customProperties')  # type: ignore
     
     @customProperties.setter
     def customProperties(self, value: Dict[str, str]) -> None:
+        """Setter: Custom property bag."""
         self._inner_dict['customProperties'] = value
     
     
     @property
     def externalUrl(self) -> Union[None, str]:
-        """URL where the reference exist"""
+        """Getter: URL where the reference exist"""
         return self._inner_dict.get('externalUrl')  # type: ignore
     
     @externalUrl.setter
     def externalUrl(self, value: Union[None, str]) -> None:
+        """Setter: URL where the reference exist"""
         self._inner_dict['externalUrl'] = value
     
     
     @property
     def description(self) -> Union[None, str]:
-        """Documentation of the MLModelDeployment"""
+        """Getter: Documentation of the MLModelDeployment"""
         return self._inner_dict.get('description')  # type: ignore
     
     @description.setter
     def description(self, value: Union[None, str]) -> None:
+        """Setter: Documentation of the MLModelDeployment"""
         self._inner_dict['description'] = value
     
     
     @property
     def createdAt(self) -> Union[None, int]:
-        """Date when the MLModelDeployment was developed"""
+        """Getter: Date when the MLModelDeployment was developed"""
         return self._inner_dict.get('createdAt')  # type: ignore
     
     @createdAt.setter
     def createdAt(self, value: Union[None, int]) -> None:
+        """Setter: Date when the MLModelDeployment was developed"""
         self._inner_dict['createdAt'] = value
     
     
     @property
     def version(self) -> Union[None, "VersionTagClass"]:
-        """Version of the MLModelDeployment"""
+        """Getter: Version of the MLModelDeployment"""
         return self._inner_dict.get('version')  # type: ignore
     
     @version.setter
     def version(self, value: Union[None, "VersionTagClass"]) -> None:
+        """Setter: Version of the MLModelDeployment"""
         self._inner_dict['version'] = value
     
     
     @property
     def status(self) -> Union[None, Union[str, "DeploymentStatusClass"]]:
-        """Status of the deployment"""
+        """Getter: Status of the deployment"""
         return self._inner_dict.get('status')  # type: ignore
     
     @status.setter
     def status(self, value: Union[None, Union[str, "DeploymentStatusClass"]]) -> None:
+        """Setter: Status of the deployment"""
         self._inner_dict['status'] = value
     
     
 class MLModelFactorPromptsClass(_Aspect):
     """Prompts which affect the performance of the MLModel"""
 
 
@@ -12131,36 +14137,45 @@
         evaluationFactors: Union[None, List["MLModelFactorsClass"]]=None,
     ):
         super().__init__()
         
         self.relevantFactors = relevantFactors
         self.evaluationFactors = evaluationFactors
     
+    @classmethod
+    def construct_with_defaults(cls) -> "MLModelFactorPromptsClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.relevantFactors = self.RECORD_SCHEMA.fields_dict["relevantFactors"].default
         self.evaluationFactors = self.RECORD_SCHEMA.fields_dict["evaluationFactors"].default
     
     
     @property
     def relevantFactors(self) -> Union[None, List["MLModelFactorsClass"]]:
-        """What are foreseeable salient factors for which MLModel performance may vary, and how were these determined?"""
+        """Getter: What are foreseeable salient factors for which MLModel performance may vary, and how were these determined?"""
         return self._inner_dict.get('relevantFactors')  # type: ignore
     
     @relevantFactors.setter
     def relevantFactors(self, value: Union[None, List["MLModelFactorsClass"]]) -> None:
+        """Setter: What are foreseeable salient factors for which MLModel performance may vary, and how were these determined?"""
         self._inner_dict['relevantFactors'] = value
     
     
     @property
     def evaluationFactors(self) -> Union[None, List["MLModelFactorsClass"]]:
-        """Which factors are being reported, and why were these chosen?"""
+        """Getter: Which factors are being reported, and why were these chosen?"""
         return self._inner_dict.get('evaluationFactors')  # type: ignore
     
     @evaluationFactors.setter
     def evaluationFactors(self, value: Union[None, List["MLModelFactorsClass"]]) -> None:
+        """Setter: Which factors are being reported, and why were these chosen?"""
         self._inner_dict['evaluationFactors'] = value
     
     
 class MLModelFactorsClass(DictWrapper):
     """Factors affecting the performance of the MLModel."""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.ml.metadata.MLModelFactors")
@@ -12171,50 +14186,63 @@
     ):
         super().__init__()
         
         self.groups = groups
         self.instrumentation = instrumentation
         self.environment = environment
     
+    @classmethod
+    def construct_with_defaults(cls) -> "MLModelFactorsClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.groups = self.RECORD_SCHEMA.fields_dict["groups"].default
         self.instrumentation = self.RECORD_SCHEMA.fields_dict["instrumentation"].default
         self.environment = self.RECORD_SCHEMA.fields_dict["environment"].default
     
     
     @property
     def groups(self) -> Union[None, List[str]]:
-        """Groups refers to distinct categories with similar characteristics that are present in the evaluation data instances.
+        """Getter: Groups refers to distinct categories with similar characteristics that are present in the evaluation data instances.
     For human-centric machine learning MLModels, groups are people who share one or multiple characteristics."""
         return self._inner_dict.get('groups')  # type: ignore
     
     @groups.setter
     def groups(self, value: Union[None, List[str]]) -> None:
+        """Setter: Groups refers to distinct categories with similar characteristics that are present in the evaluation data instances.
+    For human-centric machine learning MLModels, groups are people who share one or multiple characteristics."""
         self._inner_dict['groups'] = value
     
     
     @property
     def instrumentation(self) -> Union[None, List[str]]:
-        """The performance of a MLModel can vary depending on what instruments were used to capture the input to the MLModel.
+        """Getter: The performance of a MLModel can vary depending on what instruments were used to capture the input to the MLModel.
     For example, a face detection model may perform differently depending on the camera's hardware and software,
     including lens, image stabilization, high dynamic range techniques, and background blurring for portrait mode."""
         return self._inner_dict.get('instrumentation')  # type: ignore
     
     @instrumentation.setter
     def instrumentation(self, value: Union[None, List[str]]) -> None:
+        """Setter: The performance of a MLModel can vary depending on what instruments were used to capture the input to the MLModel.
+    For example, a face detection model may perform differently depending on the camera's hardware and software,
+    including lens, image stabilization, high dynamic range techniques, and background blurring for portrait mode."""
         self._inner_dict['instrumentation'] = value
     
     
     @property
     def environment(self) -> Union[None, List[str]]:
-        """A further factor affecting MLModel performance is the environment in which it is deployed."""
+        """Getter: A further factor affecting MLModel performance is the environment in which it is deployed."""
         return self._inner_dict.get('environment')  # type: ignore
     
     @environment.setter
     def environment(self, value: Union[None, List[str]]) -> None:
+        """Setter: A further factor affecting MLModel performance is the environment in which it is deployed."""
         self._inner_dict['environment'] = value
     
     
 class MLModelGroupPropertiesClass(_Aspect):
     """Properties associated with an ML Model Group"""
 
 
@@ -12235,58 +14263,69 @@
             self.customProperties = dict()
         else:
             self.customProperties = customProperties
         self.description = description
         self.createdAt = createdAt
         self.version = version
     
+    @classmethod
+    def construct_with_defaults(cls) -> "MLModelGroupPropertiesClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.customProperties = dict()
         self.description = self.RECORD_SCHEMA.fields_dict["description"].default
         self.createdAt = self.RECORD_SCHEMA.fields_dict["createdAt"].default
         self.version = self.RECORD_SCHEMA.fields_dict["version"].default
     
     
     @property
     def customProperties(self) -> Dict[str, str]:
-        """Custom property bag."""
+        """Getter: Custom property bag."""
         return self._inner_dict.get('customProperties')  # type: ignore
     
     @customProperties.setter
     def customProperties(self, value: Dict[str, str]) -> None:
+        """Setter: Custom property bag."""
         self._inner_dict['customProperties'] = value
     
     
     @property
     def description(self) -> Union[None, str]:
-        """Documentation of the MLModelGroup"""
+        """Getter: Documentation of the MLModelGroup"""
         return self._inner_dict.get('description')  # type: ignore
     
     @description.setter
     def description(self, value: Union[None, str]) -> None:
+        """Setter: Documentation of the MLModelGroup"""
         self._inner_dict['description'] = value
     
     
     @property
     def createdAt(self) -> Union[None, int]:
-        """Date when the MLModelGroup was developed"""
+        """Getter: Date when the MLModelGroup was developed"""
         return self._inner_dict.get('createdAt')  # type: ignore
     
     @createdAt.setter
     def createdAt(self, value: Union[None, int]) -> None:
+        """Setter: Date when the MLModelGroup was developed"""
         self._inner_dict['createdAt'] = value
     
     
     @property
     def version(self) -> Union[None, "VersionTagClass"]:
-        """Version of the MLModelGroup"""
+        """Getter: Version of the MLModelGroup"""
         return self._inner_dict.get('version')  # type: ignore
     
     @version.setter
     def version(self, value: Union[None, "VersionTagClass"]) -> None:
+        """Setter: Version of the MLModelGroup"""
         self._inner_dict['version'] = value
     
     
 class MLModelPropertiesClass(_Aspect):
     """Properties associated with a ML Model"""
 
 
@@ -12335,14 +14374,21 @@
         else:
             self.tags = tags
         self.deployments = deployments
         self.trainingJobs = trainingJobs
         self.downstreamJobs = downstreamJobs
         self.groups = groups
     
+    @classmethod
+    def construct_with_defaults(cls) -> "MLModelPropertiesClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.customProperties = dict()
         self.externalUrl = self.RECORD_SCHEMA.fields_dict["externalUrl"].default
         self.description = self.RECORD_SCHEMA.fields_dict["description"].default
         self.date = self.RECORD_SCHEMA.fields_dict["date"].default
         self.version = self.RECORD_SCHEMA.fields_dict["version"].default
         self.type = self.RECORD_SCHEMA.fields_dict["type"].default
@@ -12356,171 +14402,189 @@
         self.trainingJobs = self.RECORD_SCHEMA.fields_dict["trainingJobs"].default
         self.downstreamJobs = self.RECORD_SCHEMA.fields_dict["downstreamJobs"].default
         self.groups = self.RECORD_SCHEMA.fields_dict["groups"].default
     
     
     @property
     def customProperties(self) -> Dict[str, str]:
-        """Custom property bag."""
+        """Getter: Custom property bag."""
         return self._inner_dict.get('customProperties')  # type: ignore
     
     @customProperties.setter
     def customProperties(self, value: Dict[str, str]) -> None:
+        """Setter: Custom property bag."""
         self._inner_dict['customProperties'] = value
     
     
     @property
     def externalUrl(self) -> Union[None, str]:
-        """URL where the reference exist"""
+        """Getter: URL where the reference exist"""
         return self._inner_dict.get('externalUrl')  # type: ignore
     
     @externalUrl.setter
     def externalUrl(self, value: Union[None, str]) -> None:
+        """Setter: URL where the reference exist"""
         self._inner_dict['externalUrl'] = value
     
     
     @property
     def description(self) -> Union[None, str]:
-        """Documentation of the MLModel"""
+        """Getter: Documentation of the MLModel"""
         return self._inner_dict.get('description')  # type: ignore
     
     @description.setter
     def description(self, value: Union[None, str]) -> None:
+        """Setter: Documentation of the MLModel"""
         self._inner_dict['description'] = value
     
     
     @property
     def date(self) -> Union[None, int]:
-        """Date when the MLModel was developed"""
+        """Getter: Date when the MLModel was developed"""
         return self._inner_dict.get('date')  # type: ignore
     
     @date.setter
     def date(self, value: Union[None, int]) -> None:
+        """Setter: Date when the MLModel was developed"""
         self._inner_dict['date'] = value
     
     
     @property
     def version(self) -> Union[None, "VersionTagClass"]:
-        """Version of the MLModel"""
+        """Getter: Version of the MLModel"""
         return self._inner_dict.get('version')  # type: ignore
     
     @version.setter
     def version(self, value: Union[None, "VersionTagClass"]) -> None:
+        """Setter: Version of the MLModel"""
         self._inner_dict['version'] = value
     
     
     @property
     def type(self) -> Union[None, str]:
-        """Type of Algorithm or MLModel such as whether it is a Naive Bayes classifier, Convolutional Neural Network, etc"""
+        """Getter: Type of Algorithm or MLModel such as whether it is a Naive Bayes classifier, Convolutional Neural Network, etc"""
         return self._inner_dict.get('type')  # type: ignore
     
     @type.setter
     def type(self, value: Union[None, str]) -> None:
+        """Setter: Type of Algorithm or MLModel such as whether it is a Naive Bayes classifier, Convolutional Neural Network, etc"""
         self._inner_dict['type'] = value
     
     
     @property
     def hyperParameters(self) -> Union[None, Dict[str, Union[str, int, float, float, bool]]]:
-        """Hyper Parameters of the MLModel
+        """Getter: Hyper Parameters of the MLModel
     
     NOTE: these are deprecated in favor of hyperParams"""
         return self._inner_dict.get('hyperParameters')  # type: ignore
     
     @hyperParameters.setter
     def hyperParameters(self, value: Union[None, Dict[str, Union[str, int, float, float, bool]]]) -> None:
+        """Setter: Hyper Parameters of the MLModel
+    
+    NOTE: these are deprecated in favor of hyperParams"""
         self._inner_dict['hyperParameters'] = value
     
     
     @property
     def hyperParams(self) -> Union[None, List["MLHyperParamClass"]]:
-        """Hyperparameters of the MLModel"""
+        """Getter: Hyperparameters of the MLModel"""
         return self._inner_dict.get('hyperParams')  # type: ignore
     
     @hyperParams.setter
     def hyperParams(self, value: Union[None, List["MLHyperParamClass"]]) -> None:
+        """Setter: Hyperparameters of the MLModel"""
         self._inner_dict['hyperParams'] = value
     
     
     @property
     def trainingMetrics(self) -> Union[None, List["MLMetricClass"]]:
-        """Metrics of the MLModel used in training"""
+        """Getter: Metrics of the MLModel used in training"""
         return self._inner_dict.get('trainingMetrics')  # type: ignore
     
     @trainingMetrics.setter
     def trainingMetrics(self, value: Union[None, List["MLMetricClass"]]) -> None:
+        """Setter: Metrics of the MLModel used in training"""
         self._inner_dict['trainingMetrics'] = value
     
     
     @property
     def onlineMetrics(self) -> Union[None, List["MLMetricClass"]]:
-        """Metrics of the MLModel used in production"""
+        """Getter: Metrics of the MLModel used in production"""
         return self._inner_dict.get('onlineMetrics')  # type: ignore
     
     @onlineMetrics.setter
     def onlineMetrics(self, value: Union[None, List["MLMetricClass"]]) -> None:
+        """Setter: Metrics of the MLModel used in production"""
         self._inner_dict['onlineMetrics'] = value
     
     
     @property
     def mlFeatures(self) -> Union[None, List[str]]:
-        """List of features used for MLModel training"""
+        """Getter: List of features used for MLModel training"""
         return self._inner_dict.get('mlFeatures')  # type: ignore
     
     @mlFeatures.setter
     def mlFeatures(self, value: Union[None, List[str]]) -> None:
+        """Setter: List of features used for MLModel training"""
         self._inner_dict['mlFeatures'] = value
     
     
     @property
     def tags(self) -> List[str]:
-        """Tags for the MLModel"""
+        """Getter: Tags for the MLModel"""
         return self._inner_dict.get('tags')  # type: ignore
     
     @tags.setter
     def tags(self, value: List[str]) -> None:
+        """Setter: Tags for the MLModel"""
         self._inner_dict['tags'] = value
     
     
     @property
     def deployments(self) -> Union[None, List[str]]:
-        """Deployments for the MLModel"""
+        """Getter: Deployments for the MLModel"""
         return self._inner_dict.get('deployments')  # type: ignore
     
     @deployments.setter
     def deployments(self, value: Union[None, List[str]]) -> None:
+        """Setter: Deployments for the MLModel"""
         self._inner_dict['deployments'] = value
     
     
     @property
     def trainingJobs(self) -> Union[None, List[str]]:
-        """List of jobs (if any) used to train the model"""
+        """Getter: List of jobs (if any) used to train the model"""
         return self._inner_dict.get('trainingJobs')  # type: ignore
     
     @trainingJobs.setter
     def trainingJobs(self, value: Union[None, List[str]]) -> None:
+        """Setter: List of jobs (if any) used to train the model"""
         self._inner_dict['trainingJobs'] = value
     
     
     @property
     def downstreamJobs(self) -> Union[None, List[str]]:
-        """List of jobs (if any) that use the model"""
+        """Getter: List of jobs (if any) that use the model"""
         return self._inner_dict.get('downstreamJobs')  # type: ignore
     
     @downstreamJobs.setter
     def downstreamJobs(self, value: Union[None, List[str]]) -> None:
+        """Setter: List of jobs (if any) that use the model"""
         self._inner_dict['downstreamJobs'] = value
     
     
     @property
     def groups(self) -> Union[None, List[str]]:
-        """Groups the model belongs to"""
+        """Getter: Groups the model belongs to"""
         return self._inner_dict.get('groups')  # type: ignore
     
     @groups.setter
     def groups(self, value: Union[None, List[str]]) -> None:
+        """Setter: Groups the model belongs to"""
         self._inner_dict['groups'] = value
     
     
 class MLPrimaryKeyPropertiesClass(_Aspect):
     """Properties associated with a MLPrimaryKey"""
 
 
@@ -12537,58 +14601,69 @@
         super().__init__()
         
         self.description = description
         self.dataType = dataType
         self.version = version
         self.sources = sources
     
+    @classmethod
+    def construct_with_defaults(cls) -> "MLPrimaryKeyPropertiesClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.description = self.RECORD_SCHEMA.fields_dict["description"].default
         self.dataType = self.RECORD_SCHEMA.fields_dict["dataType"].default
         self.version = self.RECORD_SCHEMA.fields_dict["version"].default
         self.sources = list()
     
     
     @property
     def description(self) -> Union[None, str]:
-        """Documentation of the MLPrimaryKey"""
+        """Getter: Documentation of the MLPrimaryKey"""
         return self._inner_dict.get('description')  # type: ignore
     
     @description.setter
     def description(self, value: Union[None, str]) -> None:
+        """Setter: Documentation of the MLPrimaryKey"""
         self._inner_dict['description'] = value
     
     
     @property
     def dataType(self) -> Union[None, Union[str, "MLFeatureDataTypeClass"]]:
-        """Data Type of the MLPrimaryKey"""
+        """Getter: Data Type of the MLPrimaryKey"""
         return self._inner_dict.get('dataType')  # type: ignore
     
     @dataType.setter
     def dataType(self, value: Union[None, Union[str, "MLFeatureDataTypeClass"]]) -> None:
+        """Setter: Data Type of the MLPrimaryKey"""
         self._inner_dict['dataType'] = value
     
     
     @property
     def version(self) -> Union[None, "VersionTagClass"]:
-        """Version of the MLPrimaryKey"""
+        """Getter: Version of the MLPrimaryKey"""
         return self._inner_dict.get('version')  # type: ignore
     
     @version.setter
     def version(self, value: Union[None, "VersionTagClass"]) -> None:
+        """Setter: Version of the MLPrimaryKey"""
         self._inner_dict['version'] = value
     
     
     @property
     def sources(self) -> List[str]:
-        """Source of the MLPrimaryKey"""
+        """Getter: Source of the MLPrimaryKey"""
         return self._inner_dict.get('sources')  # type: ignore
     
     @sources.setter
     def sources(self, value: List[str]) -> None:
+        """Setter: Source of the MLPrimaryKey"""
         self._inner_dict['sources'] = value
     
     
 class MetricsClass(_Aspect):
     """Metrics to be featured for the MLModel."""
 
 
@@ -12601,36 +14676,45 @@
         decisionThreshold: Union[None, List[str]]=None,
     ):
         super().__init__()
         
         self.performanceMeasures = performanceMeasures
         self.decisionThreshold = decisionThreshold
     
+    @classmethod
+    def construct_with_defaults(cls) -> "MetricsClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.performanceMeasures = self.RECORD_SCHEMA.fields_dict["performanceMeasures"].default
         self.decisionThreshold = self.RECORD_SCHEMA.fields_dict["decisionThreshold"].default
     
     
     @property
     def performanceMeasures(self) -> Union[None, List[str]]:
-        """Measures of MLModel performance"""
+        """Getter: Measures of MLModel performance"""
         return self._inner_dict.get('performanceMeasures')  # type: ignore
     
     @performanceMeasures.setter
     def performanceMeasures(self, value: Union[None, List[str]]) -> None:
+        """Setter: Measures of MLModel performance"""
         self._inner_dict['performanceMeasures'] = value
     
     
     @property
     def decisionThreshold(self) -> Union[None, List[str]]:
-        """Decision Thresholds used (if any)?"""
+        """Getter: Decision Thresholds used (if any)?"""
         return self._inner_dict.get('decisionThreshold')  # type: ignore
     
     @decisionThreshold.setter
     def decisionThreshold(self, value: Union[None, List[str]]) -> None:
+        """Setter: Decision Thresholds used (if any)?"""
         self._inner_dict['decisionThreshold'] = value
     
     
 class QuantitativeAnalysesClass(_Aspect):
     """Quantitative analyses should be disaggregated, that is, broken down by the chosen factors. Quantitative analyses should provide the results of evaluating the MLModel according to the chosen metrics, providing confidence interval values when possible."""
 
 
@@ -12643,36 +14727,45 @@
         intersectionalResults: Union[None, str]=None,
     ):
         super().__init__()
         
         self.unitaryResults = unitaryResults
         self.intersectionalResults = intersectionalResults
     
+    @classmethod
+    def construct_with_defaults(cls) -> "QuantitativeAnalysesClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.unitaryResults = self.RECORD_SCHEMA.fields_dict["unitaryResults"].default
         self.intersectionalResults = self.RECORD_SCHEMA.fields_dict["intersectionalResults"].default
     
     
     @property
     def unitaryResults(self) -> Union[None, str]:
-        """Link to a dashboard with results showing how the MLModel performed with respect to each factor"""
+        """Getter: Link to a dashboard with results showing how the MLModel performed with respect to each factor"""
         return self._inner_dict.get('unitaryResults')  # type: ignore
     
     @unitaryResults.setter
     def unitaryResults(self, value: Union[None, str]) -> None:
+        """Setter: Link to a dashboard with results showing how the MLModel performed with respect to each factor"""
         self._inner_dict['unitaryResults'] = value
     
     
     @property
     def intersectionalResults(self) -> Union[None, str]:
-        """Link to a dashboard with results showing how the MLModel performed with respect to the intersection of evaluated factors?"""
+        """Getter: Link to a dashboard with results showing how the MLModel performed with respect to the intersection of evaluated factors?"""
         return self._inner_dict.get('intersectionalResults')  # type: ignore
     
     @intersectionalResults.setter
     def intersectionalResults(self, value: Union[None, str]) -> None:
+        """Setter: Link to a dashboard with results showing how the MLModel performed with respect to the intersection of evaluated factors?"""
         self._inner_dict['intersectionalResults'] = value
     
     
 class SourceCodeClass(_Aspect):
     """Source Code"""
 
 
@@ -12683,25 +14776,33 @@
     def __init__(self,
         sourceCode: List["SourceCodeUrlClass"],
     ):
         super().__init__()
         
         self.sourceCode = sourceCode
     
+    @classmethod
+    def construct_with_defaults(cls) -> "SourceCodeClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.sourceCode = list()
     
     
     @property
     def sourceCode(self) -> List["SourceCodeUrlClass"]:
-        """Source Code along with types"""
+        """Getter: Source Code along with types"""
         return self._inner_dict.get('sourceCode')  # type: ignore
     
     @sourceCode.setter
     def sourceCode(self, value: List["SourceCodeUrlClass"]) -> None:
+        """Setter: Source Code along with types"""
         self._inner_dict['sourceCode'] = value
     
     
 class SourceCodeUrlClass(DictWrapper):
     """Source Code Url Entity"""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.ml.metadata.SourceCodeUrl")
@@ -12710,36 +14811,45 @@
         sourceCodeUrl: str,
     ):
         super().__init__()
         
         self.type = type
         self.sourceCodeUrl = sourceCodeUrl
     
+    @classmethod
+    def construct_with_defaults(cls) -> "SourceCodeUrlClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.type = SourceCodeUrlTypeClass.ML_MODEL_SOURCE_CODE
         self.sourceCodeUrl = str()
     
     
     @property
     def type(self) -> Union[str, "SourceCodeUrlTypeClass"]:
-        """Source Code Url Types"""
+        """Getter: Source Code Url Types"""
         return self._inner_dict.get('type')  # type: ignore
     
     @type.setter
     def type(self, value: Union[str, "SourceCodeUrlTypeClass"]) -> None:
+        """Setter: Source Code Url Types"""
         self._inner_dict['type'] = value
     
     
     @property
     def sourceCodeUrl(self) -> str:
-        """Source Code Url"""
+        """Getter: Source Code Url"""
         return self._inner_dict.get('sourceCodeUrl')  # type: ignore
     
     @sourceCodeUrl.setter
     def sourceCodeUrl(self, value: str) -> None:
+        """Setter: Source Code Url"""
         self._inner_dict['sourceCodeUrl'] = value
     
     
 class SourceCodeUrlTypeClass(object):
     # No docs available.
     
     ML_MODEL_SOURCE_CODE = "ML_MODEL_SOURCE_CODE"
@@ -12758,25 +14868,33 @@
     def __init__(self,
         trainingData: List["BaseDataClass"],
     ):
         super().__init__()
         
         self.trainingData = trainingData
     
+    @classmethod
+    def construct_with_defaults(cls) -> "TrainingDataClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.trainingData = list()
     
     
     @property
     def trainingData(self) -> List["BaseDataClass"]:
-        """Details on the dataset(s) used for training the MLModel"""
+        """Getter: Details on the dataset(s) used for training the MLModel"""
         return self._inner_dict.get('trainingData')  # type: ignore
     
     @trainingData.setter
     def trainingData(self, value: List["BaseDataClass"]) -> None:
+        """Setter: Details on the dataset(s) used for training the MLModel"""
         self._inner_dict['trainingData'] = value
     
     
 class GenericAspectClass(DictWrapper):
     """Generic record structure for serializing an Aspect"""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.mxe.GenericAspect")
@@ -12785,37 +14903,47 @@
         contentType: str,
     ):
         super().__init__()
         
         self.value = value
         self.contentType = contentType
     
+    @classmethod
+    def construct_with_defaults(cls) -> "GenericAspectClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.value = bytes()
         self.contentType = str()
     
     
     @property
     def value(self) -> bytes:
-        """The value of the aspect, serialized as bytes."""
+        """Getter: The value of the aspect, serialized as bytes."""
         return self._inner_dict.get('value')  # type: ignore
     
     @value.setter
     def value(self, value: bytes) -> None:
+        """Setter: The value of the aspect, serialized as bytes."""
         self._inner_dict['value'] = value
     
     
     @property
     def contentType(self) -> str:
-        """The content type, which represents the fashion in which the aspect was serialized.
+        """Getter: The content type, which represents the fashion in which the aspect was serialized.
     The only type currently supported is application/json."""
         return self._inner_dict.get('contentType')  # type: ignore
     
     @contentType.setter
     def contentType(self, value: str) -> None:
+        """Setter: The content type, which represents the fashion in which the aspect was serialized.
+    The only type currently supported is application/json."""
         self._inner_dict['contentType'] = value
     
     
 class GenericPayloadClass(DictWrapper):
     """Generic payload record structure for serializing a Platform Event."""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.mxe.GenericPayload")
@@ -12824,37 +14952,47 @@
         contentType: str,
     ):
         super().__init__()
         
         self.value = value
         self.contentType = contentType
     
+    @classmethod
+    def construct_with_defaults(cls) -> "GenericPayloadClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.value = bytes()
         self.contentType = str()
     
     
     @property
     def value(self) -> bytes:
-        """The value of the event, serialized as bytes."""
+        """Getter: The value of the event, serialized as bytes."""
         return self._inner_dict.get('value')  # type: ignore
     
     @value.setter
     def value(self, value: bytes) -> None:
+        """Setter: The value of the event, serialized as bytes."""
         self._inner_dict['value'] = value
     
     
     @property
     def contentType(self) -> str:
-        """The content type, which represents the fashion in which the event was serialized.
+        """Getter: The content type, which represents the fashion in which the event was serialized.
     The only type currently supported is application/json."""
         return self._inner_dict.get('contentType')  # type: ignore
     
     @contentType.setter
     def contentType(self, value: str) -> None:
+        """Setter: The content type, which represents the fashion in which the event was serialized.
+    The only type currently supported is application/json."""
         self._inner_dict['contentType'] = value
     
     
 class MetadataChangeEventClass(DictWrapper):
     """Kafka event for proposing a metadata change for an entity. A corresponding MetadataAuditEvent is emitted when the change is accepted and committed, otherwise a FailedMetadataChangeEvent will be emitted instead."""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.mxe.MetadataChangeEvent")
@@ -12867,58 +15005,69 @@
         super().__init__()
         
         self.auditHeader = auditHeader
         self.proposedSnapshot = proposedSnapshot
         self.proposedDelta = proposedDelta
         self.systemMetadata = systemMetadata
     
+    @classmethod
+    def construct_with_defaults(cls) -> "MetadataChangeEventClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.auditHeader = self.RECORD_SCHEMA.fields_dict["auditHeader"].default
-        self.proposedSnapshot = ChartSnapshotClass._construct_with_defaults()
+        self.proposedSnapshot = ChartSnapshotClass.construct_with_defaults()
         self.proposedDelta = self.RECORD_SCHEMA.fields_dict["proposedDelta"].default
         self.systemMetadata = self.RECORD_SCHEMA.fields_dict["systemMetadata"].default
     
     
     @property
     def auditHeader(self) -> Union[None, "KafkaAuditHeaderClass"]:
-        """Kafka audit header. See go/kafkaauditheader for more info."""
+        """Getter: Kafka audit header. See go/kafkaauditheader for more info."""
         return self._inner_dict.get('auditHeader')  # type: ignore
     
     @auditHeader.setter
     def auditHeader(self, value: Union[None, "KafkaAuditHeaderClass"]) -> None:
+        """Setter: Kafka audit header. See go/kafkaauditheader for more info."""
         self._inner_dict['auditHeader'] = value
     
     
     @property
     def proposedSnapshot(self) -> Union["ChartSnapshotClass", "CorpGroupSnapshotClass", "CorpUserSnapshotClass", "DashboardSnapshotClass", "DataFlowSnapshotClass", "DataJobSnapshotClass", "DatasetSnapshotClass", "DataProcessSnapshotClass", "DataPlatformSnapshotClass", "MLModelSnapshotClass", "MLPrimaryKeySnapshotClass", "MLFeatureSnapshotClass", "MLFeatureTableSnapshotClass", "MLModelDeploymentSnapshotClass", "MLModelGroupSnapshotClass", "TagSnapshotClass", "GlossaryTermSnapshotClass", "GlossaryNodeSnapshotClass", "DataHubPolicySnapshotClass", "SchemaFieldSnapshotClass", "DataHubRetentionSnapshotClass"]:
-        """Snapshot of the proposed metadata change. Include only the aspects affected by the change in the snapshot."""
+        """Getter: Snapshot of the proposed metadata change. Include only the aspects affected by the change in the snapshot."""
         return self._inner_dict.get('proposedSnapshot')  # type: ignore
     
     @proposedSnapshot.setter
     def proposedSnapshot(self, value: Union["ChartSnapshotClass", "CorpGroupSnapshotClass", "CorpUserSnapshotClass", "DashboardSnapshotClass", "DataFlowSnapshotClass", "DataJobSnapshotClass", "DatasetSnapshotClass", "DataProcessSnapshotClass", "DataPlatformSnapshotClass", "MLModelSnapshotClass", "MLPrimaryKeySnapshotClass", "MLFeatureSnapshotClass", "MLFeatureTableSnapshotClass", "MLModelDeploymentSnapshotClass", "MLModelGroupSnapshotClass", "TagSnapshotClass", "GlossaryTermSnapshotClass", "GlossaryNodeSnapshotClass", "DataHubPolicySnapshotClass", "SchemaFieldSnapshotClass", "DataHubRetentionSnapshotClass"]) -> None:
+        """Setter: Snapshot of the proposed metadata change. Include only the aspects affected by the change in the snapshot."""
         self._inner_dict['proposedSnapshot'] = value
     
     
     @property
     def proposedDelta(self) -> None:
-        """Delta of the proposed metadata partial update."""
+        """Getter: Delta of the proposed metadata partial update."""
         return self._inner_dict.get('proposedDelta')  # type: ignore
     
     @proposedDelta.setter
     def proposedDelta(self, value: None) -> None:
+        """Setter: Delta of the proposed metadata partial update."""
         self._inner_dict['proposedDelta'] = value
     
     
     @property
     def systemMetadata(self) -> Union[None, "SystemMetadataClass"]:
-        """Metadata around how the snapshot was ingested"""
+        """Getter: Metadata around how the snapshot was ingested"""
         return self._inner_dict.get('systemMetadata')  # type: ignore
     
     @systemMetadata.setter
     def systemMetadata(self, value: Union[None, "SystemMetadataClass"]) -> None:
+        """Setter: Metadata around how the snapshot was ingested"""
         self._inner_dict['systemMetadata'] = value
     
     
 class MetadataChangeLogClass(DictWrapper):
     """Kafka event for capturing update made to an entity's metadata."""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.mxe.MetadataChangeLog")
@@ -12945,14 +15094,21 @@
         self.aspectName = aspectName
         self.aspect = aspect
         self.systemMetadata = systemMetadata
         self.previousAspectValue = previousAspectValue
         self.previousSystemMetadata = previousSystemMetadata
         self.created = created
     
+    @classmethod
+    def construct_with_defaults(cls) -> "MetadataChangeLogClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.auditHeader = self.RECORD_SCHEMA.fields_dict["auditHeader"].default
         self.entityType = str()
         self.entityUrn = self.RECORD_SCHEMA.fields_dict["entityUrn"].default
         self.entityKeyAspect = self.RECORD_SCHEMA.fields_dict["entityKeyAspect"].default
         self.changeType = ChangeTypeClass.UPSERT
         self.aspectName = self.RECORD_SCHEMA.fields_dict["aspectName"].default
@@ -12961,121 +15117,134 @@
         self.previousAspectValue = self.RECORD_SCHEMA.fields_dict["previousAspectValue"].default
         self.previousSystemMetadata = self.RECORD_SCHEMA.fields_dict["previousSystemMetadata"].default
         self.created = self.RECORD_SCHEMA.fields_dict["created"].default
     
     
     @property
     def auditHeader(self) -> Union[None, "KafkaAuditHeaderClass"]:
-        """Kafka audit header. Currently remains unused in the open source."""
+        """Getter: Kafka audit header. Currently remains unused in the open source."""
         return self._inner_dict.get('auditHeader')  # type: ignore
     
     @auditHeader.setter
     def auditHeader(self, value: Union[None, "KafkaAuditHeaderClass"]) -> None:
+        """Setter: Kafka audit header. Currently remains unused in the open source."""
         self._inner_dict['auditHeader'] = value
     
     
     @property
     def entityType(self) -> str:
-        """Type of the entity being written to"""
+        """Getter: Type of the entity being written to"""
         return self._inner_dict.get('entityType')  # type: ignore
     
     @entityType.setter
     def entityType(self, value: str) -> None:
+        """Setter: Type of the entity being written to"""
         self._inner_dict['entityType'] = value
     
     
     @property
     def entityUrn(self) -> Union[None, str]:
-        """Urn of the entity being written"""
+        """Getter: Urn of the entity being written"""
         return self._inner_dict.get('entityUrn')  # type: ignore
     
     @entityUrn.setter
     def entityUrn(self, value: Union[None, str]) -> None:
+        """Setter: Urn of the entity being written"""
         self._inner_dict['entityUrn'] = value
     
     
     @property
     def entityKeyAspect(self) -> Union[None, "GenericAspectClass"]:
-        """Key aspect of the entity being written"""
+        """Getter: Key aspect of the entity being written"""
         return self._inner_dict.get('entityKeyAspect')  # type: ignore
     
     @entityKeyAspect.setter
     def entityKeyAspect(self, value: Union[None, "GenericAspectClass"]) -> None:
+        """Setter: Key aspect of the entity being written"""
         self._inner_dict['entityKeyAspect'] = value
     
     
     @property
     def changeType(self) -> Union[str, "ChangeTypeClass"]:
-        """Type of change being proposed"""
+        """Getter: Type of change being proposed"""
         return self._inner_dict.get('changeType')  # type: ignore
     
     @changeType.setter
     def changeType(self, value: Union[str, "ChangeTypeClass"]) -> None:
+        """Setter: Type of change being proposed"""
         self._inner_dict['changeType'] = value
     
     
     @property
     def aspectName(self) -> Union[None, str]:
-        """Aspect of the entity being written to
+        """Getter: Aspect of the entity being written to
     Not filling this out implies that the writer wants to affect the entire entity
     Note: This is only valid for CREATE, UPSERT, and DELETE operations."""
         return self._inner_dict.get('aspectName')  # type: ignore
     
     @aspectName.setter
     def aspectName(self, value: Union[None, str]) -> None:
+        """Setter: Aspect of the entity being written to
+    Not filling this out implies that the writer wants to affect the entire entity
+    Note: This is only valid for CREATE, UPSERT, and DELETE operations."""
         self._inner_dict['aspectName'] = value
     
     
     @property
     def aspect(self) -> Union[None, "GenericAspectClass"]:
-        """The value of the new aspect."""
+        """Getter: The value of the new aspect."""
         return self._inner_dict.get('aspect')  # type: ignore
     
     @aspect.setter
     def aspect(self, value: Union[None, "GenericAspectClass"]) -> None:
+        """Setter: The value of the new aspect."""
         self._inner_dict['aspect'] = value
     
     
     @property
     def systemMetadata(self) -> Union[None, "SystemMetadataClass"]:
-        """A string->string map of custom properties that one might want to attach to an event"""
+        """Getter: A string->string map of custom properties that one might want to attach to an event"""
         return self._inner_dict.get('systemMetadata')  # type: ignore
     
     @systemMetadata.setter
     def systemMetadata(self, value: Union[None, "SystemMetadataClass"]) -> None:
+        """Setter: A string->string map of custom properties that one might want to attach to an event"""
         self._inner_dict['systemMetadata'] = value
     
     
     @property
     def previousAspectValue(self) -> Union[None, "GenericAspectClass"]:
-        """The previous value of the aspect that has changed."""
+        """Getter: The previous value of the aspect that has changed."""
         return self._inner_dict.get('previousAspectValue')  # type: ignore
     
     @previousAspectValue.setter
     def previousAspectValue(self, value: Union[None, "GenericAspectClass"]) -> None:
+        """Setter: The previous value of the aspect that has changed."""
         self._inner_dict['previousAspectValue'] = value
     
     
     @property
     def previousSystemMetadata(self) -> Union[None, "SystemMetadataClass"]:
-        """The previous value of the system metadata field that has changed."""
+        """Getter: The previous value of the system metadata field that has changed."""
         return self._inner_dict.get('previousSystemMetadata')  # type: ignore
     
     @previousSystemMetadata.setter
     def previousSystemMetadata(self, value: Union[None, "SystemMetadataClass"]) -> None:
+        """Setter: The previous value of the system metadata field that has changed."""
         self._inner_dict['previousSystemMetadata'] = value
     
     
     @property
     def created(self) -> Union[None, "AuditStampClass"]:
-        """An audit stamp detailing who and when the aspect was changed by. Required for all intents and purposes."""
+        """Getter: An audit stamp detailing who and when the aspect was changed by. Required for all intents and purposes."""
         return self._inner_dict.get('created')  # type: ignore
     
     @created.setter
     def created(self, value: Union[None, "AuditStampClass"]) -> None:
+        """Setter: An audit stamp detailing who and when the aspect was changed by. Required for all intents and purposes."""
         self._inner_dict['created'] = value
     
     
 class MetadataChangeProposalClass(DictWrapper):
     """Kafka event for proposing a metadata change for an entity. A corresponding MetadataChangeLog is emitted when the change is accepted and committed, otherwise a FailedMetadataChangeProposal will be emitted instead."""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.mxe.MetadataChangeProposal")
@@ -13096,104 +15265,121 @@
         self.entityUrn = entityUrn
         self.entityKeyAspect = entityKeyAspect
         self.changeType = changeType
         self.aspectName = aspectName
         self.aspect = aspect
         self.systemMetadata = systemMetadata
     
+    @classmethod
+    def construct_with_defaults(cls) -> "MetadataChangeProposalClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.auditHeader = self.RECORD_SCHEMA.fields_dict["auditHeader"].default
         self.entityType = str()
         self.entityUrn = self.RECORD_SCHEMA.fields_dict["entityUrn"].default
         self.entityKeyAspect = self.RECORD_SCHEMA.fields_dict["entityKeyAspect"].default
         self.changeType = ChangeTypeClass.UPSERT
         self.aspectName = self.RECORD_SCHEMA.fields_dict["aspectName"].default
         self.aspect = self.RECORD_SCHEMA.fields_dict["aspect"].default
         self.systemMetadata = self.RECORD_SCHEMA.fields_dict["systemMetadata"].default
     
     
     @property
     def auditHeader(self) -> Union[None, "KafkaAuditHeaderClass"]:
-        """Kafka audit header. Currently remains unused in the open source."""
+        """Getter: Kafka audit header. Currently remains unused in the open source."""
         return self._inner_dict.get('auditHeader')  # type: ignore
     
     @auditHeader.setter
     def auditHeader(self, value: Union[None, "KafkaAuditHeaderClass"]) -> None:
+        """Setter: Kafka audit header. Currently remains unused in the open source."""
         self._inner_dict['auditHeader'] = value
     
     
     @property
     def entityType(self) -> str:
-        """Type of the entity being written to"""
+        """Getter: Type of the entity being written to"""
         return self._inner_dict.get('entityType')  # type: ignore
     
     @entityType.setter
     def entityType(self, value: str) -> None:
+        """Setter: Type of the entity being written to"""
         self._inner_dict['entityType'] = value
     
     
     @property
     def entityUrn(self) -> Union[None, str]:
-        """Urn of the entity being written"""
+        """Getter: Urn of the entity being written"""
         return self._inner_dict.get('entityUrn')  # type: ignore
     
     @entityUrn.setter
     def entityUrn(self, value: Union[None, str]) -> None:
+        """Setter: Urn of the entity being written"""
         self._inner_dict['entityUrn'] = value
     
     
     @property
     def entityKeyAspect(self) -> Union[None, "GenericAspectClass"]:
-        """Key aspect of the entity being written"""
+        """Getter: Key aspect of the entity being written"""
         return self._inner_dict.get('entityKeyAspect')  # type: ignore
     
     @entityKeyAspect.setter
     def entityKeyAspect(self, value: Union[None, "GenericAspectClass"]) -> None:
+        """Setter: Key aspect of the entity being written"""
         self._inner_dict['entityKeyAspect'] = value
     
     
     @property
     def changeType(self) -> Union[str, "ChangeTypeClass"]:
-        """Type of change being proposed"""
+        """Getter: Type of change being proposed"""
         return self._inner_dict.get('changeType')  # type: ignore
     
     @changeType.setter
     def changeType(self, value: Union[str, "ChangeTypeClass"]) -> None:
+        """Setter: Type of change being proposed"""
         self._inner_dict['changeType'] = value
     
     
     @property
     def aspectName(self) -> Union[None, str]:
-        """Aspect of the entity being written to
+        """Getter: Aspect of the entity being written to
     Not filling this out implies that the writer wants to affect the entire entity
     Note: This is only valid for CREATE, UPSERT, and DELETE operations."""
         return self._inner_dict.get('aspectName')  # type: ignore
     
     @aspectName.setter
     def aspectName(self, value: Union[None, str]) -> None:
+        """Setter: Aspect of the entity being written to
+    Not filling this out implies that the writer wants to affect the entire entity
+    Note: This is only valid for CREATE, UPSERT, and DELETE operations."""
         self._inner_dict['aspectName'] = value
     
     
     @property
     def aspect(self) -> Union[None, "GenericAspectClass"]:
-        """The value of the new aspect."""
+        """Getter: The value of the new aspect."""
         return self._inner_dict.get('aspect')  # type: ignore
     
     @aspect.setter
     def aspect(self, value: Union[None, "GenericAspectClass"]) -> None:
+        """Setter: The value of the new aspect."""
         self._inner_dict['aspect'] = value
     
     
     @property
     def systemMetadata(self) -> Union[None, "SystemMetadataClass"]:
-        """A string->string map of custom properties that one might want to attach to an event"""
+        """Getter: A string->string map of custom properties that one might want to attach to an event"""
         return self._inner_dict.get('systemMetadata')  # type: ignore
     
     @systemMetadata.setter
     def systemMetadata(self, value: Union[None, "SystemMetadataClass"]) -> None:
+        """Setter: A string->string map of custom properties that one might want to attach to an event"""
         self._inner_dict['systemMetadata'] = value
     
     
 class PlatformEventClass(DictWrapper):
     """A DataHub Platform Event."""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.mxe.PlatformEvent")
@@ -13204,72 +15390,90 @@
     ):
         super().__init__()
         
         self.header = header
         self.name = name
         self.payload = payload
     
+    @classmethod
+    def construct_with_defaults(cls) -> "PlatformEventClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
-        self.header = PlatformEventHeaderClass._construct_with_defaults()
+        self.header = PlatformEventHeaderClass.construct_with_defaults()
         self.name = str()
-        self.payload = GenericPayloadClass._construct_with_defaults()
+        self.payload = GenericPayloadClass.construct_with_defaults()
     
     
     @property
     def header(self) -> "PlatformEventHeaderClass":
-        """Header information stored with the event."""
+        """Getter: Header information stored with the event."""
         return self._inner_dict.get('header')  # type: ignore
     
     @header.setter
     def header(self, value: "PlatformEventHeaderClass") -> None:
+        """Setter: Header information stored with the event."""
         self._inner_dict['header'] = value
     
     
     @property
     def name(self) -> str:
-        """The name of the event, e.g. the type of event. For example, 'notificationRequestEvent', 'entityChangeEvent'"""
+        """Getter: The name of the event, e.g. the type of event. For example, 'notificationRequestEvent', 'entityChangeEvent'"""
         return self._inner_dict.get('name')  # type: ignore
     
     @name.setter
     def name(self, value: str) -> None:
+        """Setter: The name of the event, e.g. the type of event. For example, 'notificationRequestEvent', 'entityChangeEvent'"""
         self._inner_dict['name'] = value
     
     
     @property
     def payload(self) -> "GenericPayloadClass":
-        """The event payload."""
+        """Getter: The event payload."""
         return self._inner_dict.get('payload')  # type: ignore
     
     @payload.setter
     def payload(self, value: "GenericPayloadClass") -> None:
+        """Setter: The event payload."""
         self._inner_dict['payload'] = value
     
     
 class PlatformEventHeaderClass(DictWrapper):
     """A header included with each DataHub platform event."""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.mxe.PlatformEventHeader")
     def __init__(self,
         timestampMillis: int,
     ):
         super().__init__()
         
         self.timestampMillis = timestampMillis
     
+    @classmethod
+    def construct_with_defaults(cls) -> "PlatformEventHeaderClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.timestampMillis = int()
     
     
     @property
     def timestampMillis(self) -> int:
-        """The event timestamp field as epoch at UTC in milli seconds."""
+        """Getter: The event timestamp field as epoch at UTC in milli seconds."""
         return self._inner_dict.get('timestampMillis')  # type: ignore
     
     @timestampMillis.setter
     def timestampMillis(self, value: int) -> None:
+        """Setter: The event timestamp field as epoch at UTC in milli seconds."""
         self._inner_dict['timestampMillis'] = value
     
     
 class SystemMetadataClass(DictWrapper):
     """Metadata associated with each metadata change that is processed by the system"""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.mxe.SystemMetadata")
@@ -13292,69 +15496,81 @@
             self.runId = self.RECORD_SCHEMA.fields_dict["runId"].default
         else:
             self.runId = runId
         self.registryName = registryName
         self.registryVersion = registryVersion
         self.properties = properties
     
+    @classmethod
+    def construct_with_defaults(cls) -> "SystemMetadataClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.lastObserved = self.RECORD_SCHEMA.fields_dict["lastObserved"].default
         self.runId = self.RECORD_SCHEMA.fields_dict["runId"].default
         self.registryName = self.RECORD_SCHEMA.fields_dict["registryName"].default
         self.registryVersion = self.RECORD_SCHEMA.fields_dict["registryVersion"].default
         self.properties = self.RECORD_SCHEMA.fields_dict["properties"].default
     
     
     @property
     def lastObserved(self) -> Union[int, None]:
-        """The timestamp the metadata was observed at"""
+        """Getter: The timestamp the metadata was observed at"""
         return self._inner_dict.get('lastObserved')  # type: ignore
     
     @lastObserved.setter
     def lastObserved(self, value: Union[int, None]) -> None:
+        """Setter: The timestamp the metadata was observed at"""
         self._inner_dict['lastObserved'] = value
     
     
     @property
     def runId(self) -> Union[str, None]:
-        """The run id that produced the metadata. Populated in case of batch-ingestion."""
+        """Getter: The run id that produced the metadata. Populated in case of batch-ingestion."""
         return self._inner_dict.get('runId')  # type: ignore
     
     @runId.setter
     def runId(self, value: Union[str, None]) -> None:
+        """Setter: The run id that produced the metadata. Populated in case of batch-ingestion."""
         self._inner_dict['runId'] = value
     
     
     @property
     def registryName(self) -> Union[None, str]:
-        """The model registry name that was used to process this event"""
+        """Getter: The model registry name that was used to process this event"""
         return self._inner_dict.get('registryName')  # type: ignore
     
     @registryName.setter
     def registryName(self, value: Union[None, str]) -> None:
+        """Setter: The model registry name that was used to process this event"""
         self._inner_dict['registryName'] = value
     
     
     @property
     def registryVersion(self) -> Union[None, str]:
-        """The model registry version that was used to process this event"""
+        """Getter: The model registry version that was used to process this event"""
         return self._inner_dict.get('registryVersion')  # type: ignore
     
     @registryVersion.setter
     def registryVersion(self, value: Union[None, str]) -> None:
+        """Setter: The model registry version that was used to process this event"""
         self._inner_dict['registryVersion'] = value
     
     
     @property
     def properties(self) -> Union[None, Dict[str, str]]:
-        """Additional properties"""
+        """Getter: Additional properties"""
         return self._inner_dict.get('properties')  # type: ignore
     
     @properties.setter
     def properties(self, value: Union[None, Dict[str, str]]) -> None:
+        """Setter: Additional properties"""
         self._inner_dict['properties'] = value
     
     
 class ChartCellClass(DictWrapper):
     """Chart cell in a notebook, which will present content in chart format"""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.notebook.ChartCell")
@@ -13365,47 +15581,57 @@
     ):
         super().__init__()
         
         self.cellTitle = cellTitle
         self.cellId = cellId
         self.changeAuditStamps = changeAuditStamps
     
+    @classmethod
+    def construct_with_defaults(cls) -> "ChartCellClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.cellTitle = self.RECORD_SCHEMA.fields_dict["cellTitle"].default
         self.cellId = str()
-        self.changeAuditStamps = ChangeAuditStampsClass._construct_with_defaults()
+        self.changeAuditStamps = ChangeAuditStampsClass.construct_with_defaults()
     
     
     @property
     def cellTitle(self) -> Union[None, str]:
-        """Title of the cell"""
+        """Getter: Title of the cell"""
         return self._inner_dict.get('cellTitle')  # type: ignore
     
     @cellTitle.setter
     def cellTitle(self, value: Union[None, str]) -> None:
+        """Setter: Title of the cell"""
         self._inner_dict['cellTitle'] = value
     
     
     @property
     def cellId(self) -> str:
-        """Unique id for the cell. This id should be globally unique for a Notebook tool even when there are multiple deployments of it. As an example, Notebook URL could be used here for QueryBook such as 'querybook.com/notebook/773/?cellId=1234'"""
+        """Getter: Unique id for the cell. This id should be globally unique for a Notebook tool even when there are multiple deployments of it. As an example, Notebook URL could be used here for QueryBook such as 'querybook.com/notebook/773/?cellId=1234'"""
         return self._inner_dict.get('cellId')  # type: ignore
     
     @cellId.setter
     def cellId(self, value: str) -> None:
+        """Setter: Unique id for the cell. This id should be globally unique for a Notebook tool even when there are multiple deployments of it. As an example, Notebook URL could be used here for QueryBook such as 'querybook.com/notebook/773/?cellId=1234'"""
         self._inner_dict['cellId'] = value
     
     
     @property
     def changeAuditStamps(self) -> "ChangeAuditStampsClass":
-        """Captures information about who created/last modified/deleted this Notebook cell and when"""
+        """Getter: Captures information about who created/last modified/deleted this Notebook cell and when"""
         return self._inner_dict.get('changeAuditStamps')  # type: ignore
     
     @changeAuditStamps.setter
     def changeAuditStamps(self, value: "ChangeAuditStampsClass") -> None:
+        """Setter: Captures information about who created/last modified/deleted this Notebook cell and when"""
         self._inner_dict['changeAuditStamps'] = value
     
     
 class EditableNotebookPropertiesClass(_Aspect):
     """Stores editable changes made to properties. This separates changes made from
     ingestion pipelines and edits in the UI to avoid accidental overwrites of user-provided data by ingestion pipelines
     Note: This is IN BETA version"""
@@ -13432,58 +15658,69 @@
             # default: {'actor': 'urn:li:corpuser:unknown', 'impersonator': None, 'time': 0, 'message': None}
             self.lastModified = _json_converter.from_json_object(self.RECORD_SCHEMA.fields_dict["lastModified"].default, writers_schema=self.RECORD_SCHEMA.fields_dict["lastModified"].type)
         else:
             self.lastModified = lastModified
         self.deleted = deleted
         self.description = description
     
+    @classmethod
+    def construct_with_defaults(cls) -> "EditableNotebookPropertiesClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.created = _json_converter.from_json_object(self.RECORD_SCHEMA.fields_dict["created"].default, writers_schema=self.RECORD_SCHEMA.fields_dict["created"].type)
         self.lastModified = _json_converter.from_json_object(self.RECORD_SCHEMA.fields_dict["lastModified"].default, writers_schema=self.RECORD_SCHEMA.fields_dict["lastModified"].type)
         self.deleted = self.RECORD_SCHEMA.fields_dict["deleted"].default
         self.description = self.RECORD_SCHEMA.fields_dict["description"].default
     
     
     @property
     def created(self) -> "AuditStampClass":
-        """An AuditStamp corresponding to the creation of this resource/association/sub-resource. A value of 0 for time indicates missing data."""
+        """Getter: An AuditStamp corresponding to the creation of this resource/association/sub-resource. A value of 0 for time indicates missing data."""
         return self._inner_dict.get('created')  # type: ignore
     
     @created.setter
     def created(self, value: "AuditStampClass") -> None:
+        """Setter: An AuditStamp corresponding to the creation of this resource/association/sub-resource. A value of 0 for time indicates missing data."""
         self._inner_dict['created'] = value
     
     
     @property
     def lastModified(self) -> "AuditStampClass":
-        """An AuditStamp corresponding to the last modification of this resource/association/sub-resource. If no modification has happened since creation, lastModified should be the same as created. A value of 0 for time indicates missing data."""
+        """Getter: An AuditStamp corresponding to the last modification of this resource/association/sub-resource. If no modification has happened since creation, lastModified should be the same as created. A value of 0 for time indicates missing data."""
         return self._inner_dict.get('lastModified')  # type: ignore
     
     @lastModified.setter
     def lastModified(self, value: "AuditStampClass") -> None:
+        """Setter: An AuditStamp corresponding to the last modification of this resource/association/sub-resource. If no modification has happened since creation, lastModified should be the same as created. A value of 0 for time indicates missing data."""
         self._inner_dict['lastModified'] = value
     
     
     @property
     def deleted(self) -> Union[None, "AuditStampClass"]:
-        """An AuditStamp corresponding to the deletion of this resource/association/sub-resource. Logically, deleted MUST have a later timestamp than creation. It may or may not have the same time as lastModified depending upon the resource/association/sub-resource semantics."""
+        """Getter: An AuditStamp corresponding to the deletion of this resource/association/sub-resource. Logically, deleted MUST have a later timestamp than creation. It may or may not have the same time as lastModified depending upon the resource/association/sub-resource semantics."""
         return self._inner_dict.get('deleted')  # type: ignore
     
     @deleted.setter
     def deleted(self, value: Union[None, "AuditStampClass"]) -> None:
+        """Setter: An AuditStamp corresponding to the deletion of this resource/association/sub-resource. Logically, deleted MUST have a later timestamp than creation. It may or may not have the same time as lastModified depending upon the resource/association/sub-resource semantics."""
         self._inner_dict['deleted'] = value
     
     
     @property
     def description(self) -> Union[None, str]:
-        """Edited documentation of the Notebook"""
+        """Getter: Edited documentation of the Notebook"""
         return self._inner_dict.get('description')  # type: ignore
     
     @description.setter
     def description(self, value: Union[None, str]) -> None:
+        """Setter: Edited documentation of the Notebook"""
         self._inner_dict['description'] = value
     
     
 class NotebookCellClass(DictWrapper):
     """A record of all supported cells for a Notebook. Only one type of cell will be non-null."""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.notebook.NotebookCell")
@@ -13496,58 +15733,69 @@
         super().__init__()
         
         self.textCell = textCell
         self.queryCell = queryCell
         self.chartCell = chartCell
         self.type = type
     
+    @classmethod
+    def construct_with_defaults(cls) -> "NotebookCellClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.textCell = self.RECORD_SCHEMA.fields_dict["textCell"].default
         self.queryCell = self.RECORD_SCHEMA.fields_dict["queryCell"].default
         self.chartCell = self.RECORD_SCHEMA.fields_dict["chartCell"].default
         self.type = NotebookCellTypeClass.TEXT_CELL
     
     
     @property
     def textCell(self) -> Union[None, "TextCellClass"]:
-        """The text cell content. The will be non-null only when all other cell field is null."""
+        """Getter: The text cell content. The will be non-null only when all other cell field is null."""
         return self._inner_dict.get('textCell')  # type: ignore
     
     @textCell.setter
     def textCell(self, value: Union[None, "TextCellClass"]) -> None:
+        """Setter: The text cell content. The will be non-null only when all other cell field is null."""
         self._inner_dict['textCell'] = value
     
     
     @property
     def queryCell(self) -> Union[None, "QueryCellClass"]:
-        """The query cell content. The will be non-null only when all other cell field is null."""
+        """Getter: The query cell content. The will be non-null only when all other cell field is null."""
         return self._inner_dict.get('queryCell')  # type: ignore
     
     @queryCell.setter
     def queryCell(self, value: Union[None, "QueryCellClass"]) -> None:
+        """Setter: The query cell content. The will be non-null only when all other cell field is null."""
         self._inner_dict['queryCell'] = value
     
     
     @property
     def chartCell(self) -> Union[None, "ChartCellClass"]:
-        """The chart cell content. The will be non-null only when all other cell field is null."""
+        """Getter: The chart cell content. The will be non-null only when all other cell field is null."""
         return self._inner_dict.get('chartCell')  # type: ignore
     
     @chartCell.setter
     def chartCell(self, value: Union[None, "ChartCellClass"]) -> None:
+        """Setter: The chart cell content. The will be non-null only when all other cell field is null."""
         self._inner_dict['chartCell'] = value
     
     
     @property
     def type(self) -> Union[str, "NotebookCellTypeClass"]:
-        """The type of this Notebook cell"""
+        """Getter: The type of this Notebook cell"""
         return self._inner_dict.get('type')  # type: ignore
     
     @type.setter
     def type(self, value: Union[str, "NotebookCellTypeClass"]) -> None:
+        """Setter: The type of this Notebook cell"""
         self._inner_dict['type'] = value
     
     
 class NotebookCellTypeClass(object):
     """Type of Notebook Cell"""
     
     
@@ -13577,25 +15825,33 @@
         
         if cells is None:
             # default: []
             self.cells = list()
         else:
             self.cells = cells
     
+    @classmethod
+    def construct_with_defaults(cls) -> "NotebookContentClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.cells = list()
     
     
     @property
     def cells(self) -> List["NotebookCellClass"]:
-        """The content of a Notebook which is composed by a list of NotebookCell"""
+        """Getter: The content of a Notebook which is composed by a list of NotebookCell"""
         return self._inner_dict.get('cells')  # type: ignore
     
     @cells.setter
     def cells(self, value: List["NotebookCellClass"]) -> None:
+        """Setter: The content of a Notebook which is composed by a list of NotebookCell"""
         self._inner_dict['cells'] = value
     
     
 class NotebookInfoClass(_Aspect):
     """Information about a Notebook
     Note: This is IN BETA version"""
 
@@ -13619,69 +15875,81 @@
         else:
             self.customProperties = customProperties
         self.externalUrl = externalUrl
         self.title = title
         self.description = description
         self.changeAuditStamps = changeAuditStamps
     
+    @classmethod
+    def construct_with_defaults(cls) -> "NotebookInfoClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.customProperties = dict()
         self.externalUrl = self.RECORD_SCHEMA.fields_dict["externalUrl"].default
         self.title = str()
         self.description = self.RECORD_SCHEMA.fields_dict["description"].default
-        self.changeAuditStamps = ChangeAuditStampsClass._construct_with_defaults()
+        self.changeAuditStamps = ChangeAuditStampsClass.construct_with_defaults()
     
     
     @property
     def customProperties(self) -> Dict[str, str]:
-        """Custom property bag."""
+        """Getter: Custom property bag."""
         return self._inner_dict.get('customProperties')  # type: ignore
     
     @customProperties.setter
     def customProperties(self, value: Dict[str, str]) -> None:
+        """Setter: Custom property bag."""
         self._inner_dict['customProperties'] = value
     
     
     @property
     def externalUrl(self) -> Union[None, str]:
-        """URL where the reference exist"""
+        """Getter: URL where the reference exist"""
         return self._inner_dict.get('externalUrl')  # type: ignore
     
     @externalUrl.setter
     def externalUrl(self, value: Union[None, str]) -> None:
+        """Setter: URL where the reference exist"""
         self._inner_dict['externalUrl'] = value
     
     
     @property
     def title(self) -> str:
-        """Title of the Notebook"""
+        """Getter: Title of the Notebook"""
         return self._inner_dict.get('title')  # type: ignore
     
     @title.setter
     def title(self, value: str) -> None:
+        """Setter: Title of the Notebook"""
         self._inner_dict['title'] = value
     
     
     @property
     def description(self) -> Union[None, str]:
-        """Detailed description about the Notebook"""
+        """Getter: Detailed description about the Notebook"""
         return self._inner_dict.get('description')  # type: ignore
     
     @description.setter
     def description(self, value: Union[None, str]) -> None:
+        """Setter: Detailed description about the Notebook"""
         self._inner_dict['description'] = value
     
     
     @property
     def changeAuditStamps(self) -> "ChangeAuditStampsClass":
-        """Captures information about who created/last modified/deleted this Notebook and when"""
+        """Getter: Captures information about who created/last modified/deleted this Notebook and when"""
         return self._inner_dict.get('changeAuditStamps')  # type: ignore
     
     @changeAuditStamps.setter
     def changeAuditStamps(self, value: "ChangeAuditStampsClass") -> None:
+        """Setter: Captures information about who created/last modified/deleted this Notebook and when"""
         self._inner_dict['changeAuditStamps'] = value
     
     
 class QueryCellClass(DictWrapper):
     """Query cell in a Notebook, which will present content in query format"""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.notebook.QueryCell")
@@ -13696,69 +15964,81 @@
         
         self.cellTitle = cellTitle
         self.cellId = cellId
         self.changeAuditStamps = changeAuditStamps
         self.rawQuery = rawQuery
         self.lastExecuted = lastExecuted
     
+    @classmethod
+    def construct_with_defaults(cls) -> "QueryCellClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.cellTitle = self.RECORD_SCHEMA.fields_dict["cellTitle"].default
         self.cellId = str()
-        self.changeAuditStamps = ChangeAuditStampsClass._construct_with_defaults()
+        self.changeAuditStamps = ChangeAuditStampsClass.construct_with_defaults()
         self.rawQuery = str()
         self.lastExecuted = self.RECORD_SCHEMA.fields_dict["lastExecuted"].default
     
     
     @property
     def cellTitle(self) -> Union[None, str]:
-        """Title of the cell"""
+        """Getter: Title of the cell"""
         return self._inner_dict.get('cellTitle')  # type: ignore
     
     @cellTitle.setter
     def cellTitle(self, value: Union[None, str]) -> None:
+        """Setter: Title of the cell"""
         self._inner_dict['cellTitle'] = value
     
     
     @property
     def cellId(self) -> str:
-        """Unique id for the cell. This id should be globally unique for a Notebook tool even when there are multiple deployments of it. As an example, Notebook URL could be used here for QueryBook such as 'querybook.com/notebook/773/?cellId=1234'"""
+        """Getter: Unique id for the cell. This id should be globally unique for a Notebook tool even when there are multiple deployments of it. As an example, Notebook URL could be used here for QueryBook such as 'querybook.com/notebook/773/?cellId=1234'"""
         return self._inner_dict.get('cellId')  # type: ignore
     
     @cellId.setter
     def cellId(self, value: str) -> None:
+        """Setter: Unique id for the cell. This id should be globally unique for a Notebook tool even when there are multiple deployments of it. As an example, Notebook URL could be used here for QueryBook such as 'querybook.com/notebook/773/?cellId=1234'"""
         self._inner_dict['cellId'] = value
     
     
     @property
     def changeAuditStamps(self) -> "ChangeAuditStampsClass":
-        """Captures information about who created/last modified/deleted this Notebook cell and when"""
+        """Getter: Captures information about who created/last modified/deleted this Notebook cell and when"""
         return self._inner_dict.get('changeAuditStamps')  # type: ignore
     
     @changeAuditStamps.setter
     def changeAuditStamps(self, value: "ChangeAuditStampsClass") -> None:
+        """Setter: Captures information about who created/last modified/deleted this Notebook cell and when"""
         self._inner_dict['changeAuditStamps'] = value
     
     
     @property
     def rawQuery(self) -> str:
-        """Raw query to explain some specific logic in a Notebook"""
+        """Getter: Raw query to explain some specific logic in a Notebook"""
         return self._inner_dict.get('rawQuery')  # type: ignore
     
     @rawQuery.setter
     def rawQuery(self, value: str) -> None:
+        """Setter: Raw query to explain some specific logic in a Notebook"""
         self._inner_dict['rawQuery'] = value
     
     
     @property
     def lastExecuted(self) -> Union[None, "AuditStampClass"]:
-        """Captures information about who last executed this query cell and when"""
+        """Getter: Captures information about who last executed this query cell and when"""
         return self._inner_dict.get('lastExecuted')  # type: ignore
     
     @lastExecuted.setter
     def lastExecuted(self, value: Union[None, "AuditStampClass"]) -> None:
+        """Setter: Captures information about who last executed this query cell and when"""
         self._inner_dict['lastExecuted'] = value
     
     
 class TextCellClass(DictWrapper):
     """Text cell in a Notebook, which will present content in text format"""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.notebook.TextCell")
@@ -13771,58 +16051,69 @@
         super().__init__()
         
         self.cellTitle = cellTitle
         self.cellId = cellId
         self.changeAuditStamps = changeAuditStamps
         self.text = text
     
+    @classmethod
+    def construct_with_defaults(cls) -> "TextCellClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.cellTitle = self.RECORD_SCHEMA.fields_dict["cellTitle"].default
         self.cellId = str()
-        self.changeAuditStamps = ChangeAuditStampsClass._construct_with_defaults()
+        self.changeAuditStamps = ChangeAuditStampsClass.construct_with_defaults()
         self.text = str()
     
     
     @property
     def cellTitle(self) -> Union[None, str]:
-        """Title of the cell"""
+        """Getter: Title of the cell"""
         return self._inner_dict.get('cellTitle')  # type: ignore
     
     @cellTitle.setter
     def cellTitle(self, value: Union[None, str]) -> None:
+        """Setter: Title of the cell"""
         self._inner_dict['cellTitle'] = value
     
     
     @property
     def cellId(self) -> str:
-        """Unique id for the cell. This id should be globally unique for a Notebook tool even when there are multiple deployments of it. As an example, Notebook URL could be used here for QueryBook such as 'querybook.com/notebook/773/?cellId=1234'"""
+        """Getter: Unique id for the cell. This id should be globally unique for a Notebook tool even when there are multiple deployments of it. As an example, Notebook URL could be used here for QueryBook such as 'querybook.com/notebook/773/?cellId=1234'"""
         return self._inner_dict.get('cellId')  # type: ignore
     
     @cellId.setter
     def cellId(self, value: str) -> None:
+        """Setter: Unique id for the cell. This id should be globally unique for a Notebook tool even when there are multiple deployments of it. As an example, Notebook URL could be used here for QueryBook such as 'querybook.com/notebook/773/?cellId=1234'"""
         self._inner_dict['cellId'] = value
     
     
     @property
     def changeAuditStamps(self) -> "ChangeAuditStampsClass":
-        """Captures information about who created/last modified/deleted this Notebook cell and when"""
+        """Getter: Captures information about who created/last modified/deleted this Notebook cell and when"""
         return self._inner_dict.get('changeAuditStamps')  # type: ignore
     
     @changeAuditStamps.setter
     def changeAuditStamps(self, value: "ChangeAuditStampsClass") -> None:
+        """Setter: Captures information about who created/last modified/deleted this Notebook cell and when"""
         self._inner_dict['changeAuditStamps'] = value
     
     
     @property
     def text(self) -> str:
-        """The actual text in a TextCell in a Notebook"""
+        """Getter: The actual text in a TextCell in a Notebook"""
         return self._inner_dict.get('text')  # type: ignore
     
     @text.setter
     def text(self, value: str) -> None:
+        """Setter: The actual text in a TextCell in a Notebook"""
         self._inner_dict['text'] = value
     
     
 class EntityChangeEventClass(DictWrapper):
     """Shared fields for all entity change events."""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.platform.event.v1.EntityChangeEvent")
@@ -13843,114 +16134,136 @@
         self.category = category
         self.operation = operation
         self.modifier = modifier
         self.parameters = parameters
         self.auditStamp = auditStamp
         self.version = version
     
+    @classmethod
+    def construct_with_defaults(cls) -> "EntityChangeEventClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.entityType = str()
         self.entityUrn = str()
         self.category = str()
         self.operation = str()
         self.modifier = self.RECORD_SCHEMA.fields_dict["modifier"].default
         self.parameters = self.RECORD_SCHEMA.fields_dict["parameters"].default
-        self.auditStamp = AuditStampClass._construct_with_defaults()
+        self.auditStamp = AuditStampClass.construct_with_defaults()
         self.version = int()
     
     
     @property
     def entityType(self) -> str:
-        """The type of the entity affected. Corresponds to the entity registry, e.g. 'dataset', 'chart', 'dashboard', etc."""
+        """Getter: The type of the entity affected. Corresponds to the entity registry, e.g. 'dataset', 'chart', 'dashboard', etc."""
         return self._inner_dict.get('entityType')  # type: ignore
     
     @entityType.setter
     def entityType(self, value: str) -> None:
+        """Setter: The type of the entity affected. Corresponds to the entity registry, e.g. 'dataset', 'chart', 'dashboard', etc."""
         self._inner_dict['entityType'] = value
     
     
     @property
     def entityUrn(self) -> str:
-        """The urn of the entity which was affected."""
+        """Getter: The urn of the entity which was affected."""
         return self._inner_dict.get('entityUrn')  # type: ignore
     
     @entityUrn.setter
     def entityUrn(self, value: str) -> None:
+        """Setter: The urn of the entity which was affected."""
         self._inner_dict['entityUrn'] = value
     
     
     @property
     def category(self) -> str:
-        """The category type (TAG, GLOSSARY_TERM, OWNERSHIP, TECHNICAL_SCHEMA, etc). This is used to determine what the rest of the schema will look like."""
+        """Getter: The category type (TAG, GLOSSARY_TERM, OWNERSHIP, TECHNICAL_SCHEMA, etc). This is used to determine what the rest of the schema will look like."""
         return self._inner_dict.get('category')  # type: ignore
     
     @category.setter
     def category(self, value: str) -> None:
+        """Setter: The category type (TAG, GLOSSARY_TERM, OWNERSHIP, TECHNICAL_SCHEMA, etc). This is used to determine what the rest of the schema will look like."""
         self._inner_dict['category'] = value
     
     
     @property
     def operation(self) -> str:
-        """The operation type. This is used to determine what the rest of the schema will look like."""
+        """Getter: The operation type. This is used to determine what the rest of the schema will look like."""
         return self._inner_dict.get('operation')  # type: ignore
     
     @operation.setter
     def operation(self, value: str) -> None:
+        """Setter: The operation type. This is used to determine what the rest of the schema will look like."""
         self._inner_dict['operation'] = value
     
     
     @property
     def modifier(self) -> Union[None, str]:
-        """The urn of the entity which was affected."""
+        """Getter: The urn of the entity which was affected."""
         return self._inner_dict.get('modifier')  # type: ignore
     
     @modifier.setter
     def modifier(self, value: Union[None, str]) -> None:
+        """Setter: The urn of the entity which was affected."""
         self._inner_dict['modifier'] = value
     
     
     @property
     def parameters(self) -> Union[None, "ParametersClass"]:
-        """Arbitrary key-value parameters corresponding to the event."""
+        """Getter: Arbitrary key-value parameters corresponding to the event."""
         return self._inner_dict.get('parameters')  # type: ignore
     
     @parameters.setter
     def parameters(self, value: Union[None, "ParametersClass"]) -> None:
+        """Setter: Arbitrary key-value parameters corresponding to the event."""
         self._inner_dict['parameters'] = value
     
     
     @property
     def auditStamp(self) -> "AuditStampClass":
-        """Audit stamp of the operation"""
+        """Getter: Audit stamp of the operation"""
         return self._inner_dict.get('auditStamp')  # type: ignore
     
     @auditStamp.setter
     def auditStamp(self, value: "AuditStampClass") -> None:
+        """Setter: Audit stamp of the operation"""
         self._inner_dict['auditStamp'] = value
     
     
     @property
     def version(self) -> int:
-        """The version of the event type, incremented in integers."""
+        """Getter: The version of the event type, incremented in integers."""
         return self._inner_dict.get('version')  # type: ignore
     
     @version.setter
     def version(self, value: int) -> None:
+        """Setter: The version of the event type, incremented in integers."""
         self._inner_dict['version'] = value
     
     
 class ParametersClass(DictWrapper):
     """Arbitrary key-value parameters for an Entity Change Event. (any record)."""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.platform.event.v1.Parameters")
     def __init__(self,
     ):
         super().__init__()
         
     
+    @classmethod
+    def construct_with_defaults(cls) -> "ParametersClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         pass
     
     
 class DataHubActorFilterClass(DictWrapper):
     """Information used to filter DataHub actors."""
     
@@ -13980,81 +16293,95 @@
         if allGroups is None:
             # default: False
             self.allGroups = self.RECORD_SCHEMA.fields_dict["allGroups"].default
         else:
             self.allGroups = allGroups
         self.roles = roles
     
+    @classmethod
+    def construct_with_defaults(cls) -> "DataHubActorFilterClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.users = self.RECORD_SCHEMA.fields_dict["users"].default
         self.groups = self.RECORD_SCHEMA.fields_dict["groups"].default
         self.resourceOwners = self.RECORD_SCHEMA.fields_dict["resourceOwners"].default
         self.allUsers = self.RECORD_SCHEMA.fields_dict["allUsers"].default
         self.allGroups = self.RECORD_SCHEMA.fields_dict["allGroups"].default
         self.roles = self.RECORD_SCHEMA.fields_dict["roles"].default
     
     
     @property
     def users(self) -> Union[None, List[str]]:
-        """A specific set of users to apply the policy to (disjunctive)"""
+        """Getter: A specific set of users to apply the policy to (disjunctive)"""
         return self._inner_dict.get('users')  # type: ignore
     
     @users.setter
     def users(self, value: Union[None, List[str]]) -> None:
+        """Setter: A specific set of users to apply the policy to (disjunctive)"""
         self._inner_dict['users'] = value
     
     
     @property
     def groups(self) -> Union[None, List[str]]:
-        """A specific set of groups to apply the policy to (disjunctive)"""
+        """Getter: A specific set of groups to apply the policy to (disjunctive)"""
         return self._inner_dict.get('groups')  # type: ignore
     
     @groups.setter
     def groups(self, value: Union[None, List[str]]) -> None:
+        """Setter: A specific set of groups to apply the policy to (disjunctive)"""
         self._inner_dict['groups'] = value
     
     
     @property
     def resourceOwners(self) -> bool:
-        """Whether the filter should return true for owners of a particular resource.
+        """Getter: Whether the filter should return true for owners of a particular resource.
     Only applies to policies of type 'Metadata', which have a resource associated with them."""
         return self._inner_dict.get('resourceOwners')  # type: ignore
     
     @resourceOwners.setter
     def resourceOwners(self, value: bool) -> None:
+        """Setter: Whether the filter should return true for owners of a particular resource.
+    Only applies to policies of type 'Metadata', which have a resource associated with them."""
         self._inner_dict['resourceOwners'] = value
     
     
     @property
     def allUsers(self) -> bool:
-        """Whether the filter should apply to all users."""
+        """Getter: Whether the filter should apply to all users."""
         return self._inner_dict.get('allUsers')  # type: ignore
     
     @allUsers.setter
     def allUsers(self, value: bool) -> None:
+        """Setter: Whether the filter should apply to all users."""
         self._inner_dict['allUsers'] = value
     
     
     @property
     def allGroups(self) -> bool:
-        """Whether the filter should apply to all groups."""
+        """Getter: Whether the filter should apply to all groups."""
         return self._inner_dict.get('allGroups')  # type: ignore
     
     @allGroups.setter
     def allGroups(self, value: bool) -> None:
+        """Setter: Whether the filter should apply to all groups."""
         self._inner_dict['allGroups'] = value
     
     
     @property
     def roles(self) -> Union[None, List[str]]:
-        """A specific set of roles to apply the policy to (disjunctive)."""
+        """Getter: A specific set of roles to apply the policy to (disjunctive)."""
         return self._inner_dict.get('roles')  # type: ignore
     
     @roles.setter
     def roles(self, value: Union[None, List[str]]) -> None:
+        """Setter: A specific set of roles to apply the policy to (disjunctive)."""
         self._inner_dict['roles'] = value
     
     
 class DataHubPolicyInfoClass(_Aspect):
     """Information about a DataHub (UI) access policy."""
 
 
@@ -14085,113 +16412,129 @@
         if editable is None:
             # default: True
             self.editable = self.RECORD_SCHEMA.fields_dict["editable"].default
         else:
             self.editable = editable
         self.lastUpdatedTimestamp = lastUpdatedTimestamp
     
+    @classmethod
+    def construct_with_defaults(cls) -> "DataHubPolicyInfoClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.displayName = str()
         self.description = str()
         self.type = str()
         self.state = str()
         self.resources = self.RECORD_SCHEMA.fields_dict["resources"].default
         self.privileges = list()
-        self.actors = DataHubActorFilterClass._construct_with_defaults()
+        self.actors = DataHubActorFilterClass.construct_with_defaults()
         self.editable = self.RECORD_SCHEMA.fields_dict["editable"].default
         self.lastUpdatedTimestamp = self.RECORD_SCHEMA.fields_dict["lastUpdatedTimestamp"].default
     
     
     @property
     def displayName(self) -> str:
-        """Display name of the Policy"""
+        """Getter: Display name of the Policy"""
         return self._inner_dict.get('displayName')  # type: ignore
     
     @displayName.setter
     def displayName(self, value: str) -> None:
+        """Setter: Display name of the Policy"""
         self._inner_dict['displayName'] = value
     
     
     @property
     def description(self) -> str:
-        """Description of the Policy"""
+        """Getter: Description of the Policy"""
         return self._inner_dict.get('description')  # type: ignore
     
     @description.setter
     def description(self, value: str) -> None:
+        """Setter: Description of the Policy"""
         self._inner_dict['description'] = value
     
     
     @property
     def type(self) -> str:
-        """The type of policy"""
+        """Getter: The type of policy"""
         return self._inner_dict.get('type')  # type: ignore
     
     @type.setter
     def type(self, value: str) -> None:
+        """Setter: The type of policy"""
         self._inner_dict['type'] = value
     
     
     @property
     def state(self) -> str:
-        """The state of policy, ACTIVE or INACTIVE"""
+        """Getter: The state of policy, ACTIVE or INACTIVE"""
         return self._inner_dict.get('state')  # type: ignore
     
     @state.setter
     def state(self, value: str) -> None:
+        """Setter: The state of policy, ACTIVE or INACTIVE"""
         self._inner_dict['state'] = value
     
     
     @property
     def resources(self) -> Union[None, "DataHubResourceFilterClass"]:
-        """The resource that the policy applies to. Not required for some 'Platform' privileges."""
+        """Getter: The resource that the policy applies to. Not required for some 'Platform' privileges."""
         return self._inner_dict.get('resources')  # type: ignore
     
     @resources.setter
     def resources(self, value: Union[None, "DataHubResourceFilterClass"]) -> None:
+        """Setter: The resource that the policy applies to. Not required for some 'Platform' privileges."""
         self._inner_dict['resources'] = value
     
     
     @property
     def privileges(self) -> List[str]:
-        """The privileges that the policy grants."""
+        """Getter: The privileges that the policy grants."""
         return self._inner_dict.get('privileges')  # type: ignore
     
     @privileges.setter
     def privileges(self, value: List[str]) -> None:
+        """Setter: The privileges that the policy grants."""
         self._inner_dict['privileges'] = value
     
     
     @property
     def actors(self) -> "DataHubActorFilterClass":
-        """The actors that the policy applies to."""
+        """Getter: The actors that the policy applies to."""
         return self._inner_dict.get('actors')  # type: ignore
     
     @actors.setter
     def actors(self, value: "DataHubActorFilterClass") -> None:
+        """Setter: The actors that the policy applies to."""
         self._inner_dict['actors'] = value
     
     
     @property
     def editable(self) -> bool:
-        """Whether the policy should be editable via the UI"""
+        """Getter: Whether the policy should be editable via the UI"""
         return self._inner_dict.get('editable')  # type: ignore
     
     @editable.setter
     def editable(self, value: bool) -> None:
+        """Setter: Whether the policy should be editable via the UI"""
         self._inner_dict['editable'] = value
     
     
     @property
     def lastUpdatedTimestamp(self) -> Union[None, int]:
-        """Timestamp when the policy was last updated"""
+        """Getter: Timestamp when the policy was last updated"""
         return self._inner_dict.get('lastUpdatedTimestamp')  # type: ignore
     
     @lastUpdatedTimestamp.setter
     def lastUpdatedTimestamp(self, value: Union[None, int]) -> None:
+        """Setter: Timestamp when the policy was last updated"""
         self._inner_dict['lastUpdatedTimestamp'] = value
     
     
 class DataHubResourceFilterClass(DictWrapper):
     """Information used to filter DataHub resource."""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.policy.DataHubResourceFilter")
@@ -14208,60 +16551,73 @@
         if allResources is None:
             # default: False
             self.allResources = self.RECORD_SCHEMA.fields_dict["allResources"].default
         else:
             self.allResources = allResources
         self.filter = filter
     
+    @classmethod
+    def construct_with_defaults(cls) -> "DataHubResourceFilterClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.type = self.RECORD_SCHEMA.fields_dict["type"].default
         self.resources = self.RECORD_SCHEMA.fields_dict["resources"].default
         self.allResources = self.RECORD_SCHEMA.fields_dict["allResources"].default
         self.filter = self.RECORD_SCHEMA.fields_dict["filter"].default
     
     
     @property
     def type(self) -> Union[None, str]:
-        """The type of resource that the policy applies to. This will most often be a data asset entity name, for
+        """Getter: The type of resource that the policy applies to. This will most often be a data asset entity name, for
     example 'dataset'. It is not strictly required because in the future we will want to support filtering a resource
     by domain, as well."""
         return self._inner_dict.get('type')  # type: ignore
     
     @type.setter
     def type(self, value: Union[None, str]) -> None:
+        """Setter: The type of resource that the policy applies to. This will most often be a data asset entity name, for
+    example 'dataset'. It is not strictly required because in the future we will want to support filtering a resource
+    by domain, as well."""
         self._inner_dict['type'] = value
     
     
     @property
     def resources(self) -> Union[None, List[str]]:
-        """A specific set of resources to apply the policy to, e.g. asset urns"""
+        """Getter: A specific set of resources to apply the policy to, e.g. asset urns"""
         return self._inner_dict.get('resources')  # type: ignore
     
     @resources.setter
     def resources(self, value: Union[None, List[str]]) -> None:
+        """Setter: A specific set of resources to apply the policy to, e.g. asset urns"""
         self._inner_dict['resources'] = value
     
     
     @property
     def allResources(self) -> bool:
-        """Whether the policy should be applied to all assets matching the filter."""
+        """Getter: Whether the policy should be applied to all assets matching the filter."""
         return self._inner_dict.get('allResources')  # type: ignore
     
     @allResources.setter
     def allResources(self, value: bool) -> None:
+        """Setter: Whether the policy should be applied to all assets matching the filter."""
         self._inner_dict['allResources'] = value
     
     
     @property
     def filter(self) -> Union[None, "PolicyMatchFilterClass"]:
-        """Filter to apply privileges to"""
+        """Getter: Filter to apply privileges to"""
         return self._inner_dict.get('filter')  # type: ignore
     
     @filter.setter
     def filter(self, value: Union[None, "PolicyMatchFilterClass"]) -> None:
+        """Setter: Filter to apply privileges to"""
         self._inner_dict['filter'] = value
     
     
 class DataHubRoleInfoClass(_Aspect):
     """Information about a DataHub Role."""
 
 
@@ -14280,47 +16636,57 @@
         self.description = description
         if editable is None:
             # default: False
             self.editable = self.RECORD_SCHEMA.fields_dict["editable"].default
         else:
             self.editable = editable
     
+    @classmethod
+    def construct_with_defaults(cls) -> "DataHubRoleInfoClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.name = str()
         self.description = str()
         self.editable = self.RECORD_SCHEMA.fields_dict["editable"].default
     
     
     @property
     def name(self) -> str:
-        """Name of the Role"""
+        """Getter: Name of the Role"""
         return self._inner_dict.get('name')  # type: ignore
     
     @name.setter
     def name(self, value: str) -> None:
+        """Setter: Name of the Role"""
         self._inner_dict['name'] = value
     
     
     @property
     def description(self) -> str:
-        """Description of the Role"""
+        """Getter: Description of the Role"""
         return self._inner_dict.get('description')  # type: ignore
     
     @description.setter
     def description(self, value: str) -> None:
+        """Setter: Description of the Role"""
         self._inner_dict['description'] = value
     
     
     @property
     def editable(self) -> bool:
-        """Whether the role should be editable via the UI"""
+        """Getter: Whether the role should be editable via the UI"""
         return self._inner_dict.get('editable')  # type: ignore
     
     @editable.setter
     def editable(self, value: bool) -> None:
+        """Setter: Whether the role should be editable via the UI"""
         self._inner_dict['editable'] = value
     
     
 class PolicyMatchConditionClass(object):
     """The matching condition in a filter criterion"""
     
     
@@ -14343,72 +16709,90 @@
         self.values = values
         if condition is None:
             # default: 'EQUALS'
             self.condition = self.RECORD_SCHEMA.fields_dict["condition"].default
         else:
             self.condition = condition
     
+    @classmethod
+    def construct_with_defaults(cls) -> "PolicyMatchCriterionClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.field = str()
         self.values = list()
         self.condition = self.RECORD_SCHEMA.fields_dict["condition"].default
     
     
     @property
     def field(self) -> str:
-        """The name of the field that the criterion refers to"""
+        """Getter: The name of the field that the criterion refers to"""
         return self._inner_dict.get('field')  # type: ignore
     
     @field.setter
     def field(self, value: str) -> None:
+        """Setter: The name of the field that the criterion refers to"""
         self._inner_dict['field'] = value
     
     
     @property
     def values(self) -> List[str]:
-        """Values. Matches criterion if any one of the values matches condition (OR-relationship)"""
+        """Getter: Values. Matches criterion if any one of the values matches condition (OR-relationship)"""
         return self._inner_dict.get('values')  # type: ignore
     
     @values.setter
     def values(self, value: List[str]) -> None:
+        """Setter: Values. Matches criterion if any one of the values matches condition (OR-relationship)"""
         self._inner_dict['values'] = value
     
     
     @property
     def condition(self) -> Union[str, "PolicyMatchConditionClass"]:
-        """The condition for the criterion"""
+        """Getter: The condition for the criterion"""
         return self._inner_dict.get('condition')  # type: ignore
     
     @condition.setter
     def condition(self, value: Union[str, "PolicyMatchConditionClass"]) -> None:
+        """Setter: The condition for the criterion"""
         self._inner_dict['condition'] = value
     
     
 class PolicyMatchFilterClass(DictWrapper):
     """The filter for specifying the resource or actor to apply privileges to"""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.policy.PolicyMatchFilter")
     def __init__(self,
         criteria: List["PolicyMatchCriterionClass"],
     ):
         super().__init__()
         
         self.criteria = criteria
     
+    @classmethod
+    def construct_with_defaults(cls) -> "PolicyMatchFilterClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.criteria = list()
     
     
     @property
     def criteria(self) -> List["PolicyMatchCriterionClass"]:
-        """A list of criteria to apply conjunctively (so all criteria must pass)"""
+        """Getter: A list of criteria to apply conjunctively (so all criteria must pass)"""
         return self._inner_dict.get('criteria')  # type: ignore
     
     @criteria.setter
     def criteria(self, value: List["PolicyMatchCriterionClass"]) -> None:
+        """Setter: A list of criteria to apply conjunctively (so all criteria must pass)"""
         self._inner_dict['criteria'] = value
     
     
 class PostContentClass(DictWrapper):
     """Content stored inside a Post."""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.post.PostContent")
@@ -14423,69 +16807,81 @@
         
         self.title = title
         self.type = type
         self.description = description
         self.link = link
         self.media = media
     
+    @classmethod
+    def construct_with_defaults(cls) -> "PostContentClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.title = str()
         self.type = PostContentTypeClass.TEXT
         self.description = self.RECORD_SCHEMA.fields_dict["description"].default
         self.link = self.RECORD_SCHEMA.fields_dict["link"].default
         self.media = self.RECORD_SCHEMA.fields_dict["media"].default
     
     
     @property
     def title(self) -> str:
-        """Title of the post."""
+        """Getter: Title of the post."""
         return self._inner_dict.get('title')  # type: ignore
     
     @title.setter
     def title(self, value: str) -> None:
+        """Setter: Title of the post."""
         self._inner_dict['title'] = value
     
     
     @property
     def type(self) -> Union[str, "PostContentTypeClass"]:
-        """Type of content held in the post."""
+        """Getter: Type of content held in the post."""
         return self._inner_dict.get('type')  # type: ignore
     
     @type.setter
     def type(self, value: Union[str, "PostContentTypeClass"]) -> None:
+        """Setter: Type of content held in the post."""
         self._inner_dict['type'] = value
     
     
     @property
     def description(self) -> Union[None, str]:
-        """Optional description of the post."""
+        """Getter: Optional description of the post."""
         return self._inner_dict.get('description')  # type: ignore
     
     @description.setter
     def description(self, value: Union[None, str]) -> None:
+        """Setter: Optional description of the post."""
         self._inner_dict['description'] = value
     
     
     @property
     def link(self) -> Union[None, str]:
-        """Optional link that the post is associated with."""
+        """Getter: Optional link that the post is associated with."""
         return self._inner_dict.get('link')  # type: ignore
     
     @link.setter
     def link(self, value: Union[None, str]) -> None:
+        """Setter: Optional link that the post is associated with."""
         self._inner_dict['link'] = value
     
     
     @property
     def media(self) -> Union[None, "MediaClass"]:
-        """Optional media that the post is storing"""
+        """Getter: Optional media that the post is storing"""
         return self._inner_dict.get('media')  # type: ignore
     
     @media.setter
     def media(self, value: Union[None, "MediaClass"]) -> None:
+        """Setter: Optional media that the post is storing"""
         self._inner_dict['media'] = value
     
     
 class PostContentTypeClass(object):
     """Enum defining the type of content held in a Post."""
     
     
@@ -14513,58 +16909,69 @@
         super().__init__()
         
         self.type = type
         self.content = content
         self.created = created
         self.lastModified = lastModified
     
+    @classmethod
+    def construct_with_defaults(cls) -> "PostInfoClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.type = PostTypeClass.HOME_PAGE_ANNOUNCEMENT
-        self.content = PostContentClass._construct_with_defaults()
+        self.content = PostContentClass.construct_with_defaults()
         self.created = int()
         self.lastModified = int()
     
     
     @property
     def type(self) -> Union[str, "PostTypeClass"]:
-        """Type of the Post."""
+        """Getter: Type of the Post."""
         return self._inner_dict.get('type')  # type: ignore
     
     @type.setter
     def type(self, value: Union[str, "PostTypeClass"]) -> None:
+        """Setter: Type of the Post."""
         self._inner_dict['type'] = value
     
     
     @property
     def content(self) -> "PostContentClass":
-        """Content stored in the post."""
+        """Getter: Content stored in the post."""
         return self._inner_dict.get('content')  # type: ignore
     
     @content.setter
     def content(self, value: "PostContentClass") -> None:
+        """Setter: Content stored in the post."""
         self._inner_dict['content'] = value
     
     
     @property
     def created(self) -> int:
-        """The time at which the post was initially created"""
+        """Getter: The time at which the post was initially created"""
         return self._inner_dict.get('created')  # type: ignore
     
     @created.setter
     def created(self, value: int) -> None:
+        """Setter: The time at which the post was initially created"""
         self._inner_dict['created'] = value
     
     
     @property
     def lastModified(self) -> int:
-        """The time at which the post was last modified"""
+        """Getter: The time at which the post was last modified"""
         return self._inner_dict.get('lastModified')  # type: ignore
     
     @lastModified.setter
     def lastModified(self, value: int) -> None:
+        """Setter: The time at which the post was last modified"""
         self._inner_dict['lastModified'] = value
     
     
 class PostTypeClass(object):
     """Enum defining types of Posts."""
     
     
@@ -14601,80 +17008,93 @@
         self.statement = statement
         self.source = source
         self.name = name
         self.description = description
         self.created = created
         self.lastModified = lastModified
     
+    @classmethod
+    def construct_with_defaults(cls) -> "QueryPropertiesClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
-        self.statement = QueryStatementClass._construct_with_defaults()
+        self.statement = QueryStatementClass.construct_with_defaults()
         self.source = QuerySourceClass.MANUAL
         self.name = self.RECORD_SCHEMA.fields_dict["name"].default
         self.description = self.RECORD_SCHEMA.fields_dict["description"].default
-        self.created = AuditStampClass._construct_with_defaults()
-        self.lastModified = AuditStampClass._construct_with_defaults()
+        self.created = AuditStampClass.construct_with_defaults()
+        self.lastModified = AuditStampClass.construct_with_defaults()
     
     
     @property
     def statement(self) -> "QueryStatementClass":
-        """The Query Statement."""
+        """Getter: The Query Statement."""
         return self._inner_dict.get('statement')  # type: ignore
     
     @statement.setter
     def statement(self, value: "QueryStatementClass") -> None:
+        """Setter: The Query Statement."""
         self._inner_dict['statement'] = value
     
     
     @property
     def source(self) -> Union[str, "QuerySourceClass"]:
-        """The source of the Query"""
+        """Getter: The source of the Query"""
         return self._inner_dict.get('source')  # type: ignore
     
     @source.setter
     def source(self, value: Union[str, "QuerySourceClass"]) -> None:
+        """Setter: The source of the Query"""
         self._inner_dict['source'] = value
     
     
     @property
     def name(self) -> Union[None, str]:
-        """Optional display name to identify the query."""
+        """Getter: Optional display name to identify the query."""
         return self._inner_dict.get('name')  # type: ignore
     
     @name.setter
     def name(self, value: Union[None, str]) -> None:
+        """Setter: Optional display name to identify the query."""
         self._inner_dict['name'] = value
     
     
     @property
     def description(self) -> Union[None, str]:
-        """The Query description."""
+        """Getter: The Query description."""
         return self._inner_dict.get('description')  # type: ignore
     
     @description.setter
     def description(self, value: Union[None, str]) -> None:
+        """Setter: The Query description."""
         self._inner_dict['description'] = value
     
     
     @property
     def created(self) -> "AuditStampClass":
-        """Audit stamp capturing the time and actor who created the Query."""
+        """Getter: Audit stamp capturing the time and actor who created the Query."""
         return self._inner_dict.get('created')  # type: ignore
     
     @created.setter
     def created(self, value: "AuditStampClass") -> None:
+        """Setter: Audit stamp capturing the time and actor who created the Query."""
         self._inner_dict['created'] = value
     
     
     @property
     def lastModified(self) -> "AuditStampClass":
-        """Audit stamp capturing the time and actor who last modified the Query."""
+        """Getter: Audit stamp capturing the time and actor who last modified the Query."""
         return self._inner_dict.get('lastModified')  # type: ignore
     
     @lastModified.setter
     def lastModified(self, value: "AuditStampClass") -> None:
+        """Setter: Audit stamp capturing the time and actor who last modified the Query."""
         self._inner_dict['lastModified'] = value
     
     
 class QuerySourceClass(object):
     # No docs available.
     
     
@@ -14695,36 +17115,45 @@
         self.value = value
         if language is None:
             # default: 'SQL'
             self.language = self.RECORD_SCHEMA.fields_dict["language"].default
         else:
             self.language = language
     
+    @classmethod
+    def construct_with_defaults(cls) -> "QueryStatementClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.value = str()
         self.language = self.RECORD_SCHEMA.fields_dict["language"].default
     
     
     @property
     def value(self) -> str:
-        """The query text"""
+        """Getter: The query text"""
         return self._inner_dict.get('value')  # type: ignore
     
     @value.setter
     def value(self, value: str) -> None:
+        """Setter: The query text"""
         self._inner_dict['value'] = value
     
     
     @property
     def language(self) -> Union[str, "QueryLanguageClass"]:
-        """The language of the Query, e.g. SQL."""
+        """Getter: The language of the Query, e.g. SQL."""
         return self._inner_dict.get('language')  # type: ignore
     
     @language.setter
     def language(self, value: Union[str, "QueryLanguageClass"]) -> None:
+        """Setter: The language of the Query, e.g. SQL."""
         self._inner_dict['language'] = value
     
     
 class QuerySubjectClass(DictWrapper):
     """A single subject of a particular query.
     In the future, we may evolve this model to include richer details
     about the Query Subject in relation to the query."""
@@ -14733,25 +17162,33 @@
     def __init__(self,
         entity: str,
     ):
         super().__init__()
         
         self.entity = entity
     
+    @classmethod
+    def construct_with_defaults(cls) -> "QuerySubjectClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.entity = str()
     
     
     @property
     def entity(self) -> str:
-        """An entity which is the subject of a query."""
+        """Getter: An entity which is the subject of a query."""
         return self._inner_dict.get('entity')  # type: ignore
     
     @entity.setter
     def entity(self, value: str) -> None:
+        """Setter: An entity which is the subject of a query."""
         self._inner_dict['entity'] = value
     
     
 class QuerySubjectsClass(_Aspect):
     """Information about the subjects of a particular Query, i.e. the assets
     being queried."""
 
@@ -14763,31 +17200,45 @@
     def __init__(self,
         subjects: List["QuerySubjectClass"],
     ):
         super().__init__()
         
         self.subjects = subjects
     
+    @classmethod
+    def construct_with_defaults(cls) -> "QuerySubjectsClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.subjects = list()
     
     
     @property
     def subjects(self) -> List["QuerySubjectClass"]:
-        """One or more subjects of the query.
+        """Getter: One or more subjects of the query.
     
     In single-asset queries (e.g. table select), this will contain the Table reference
     and optionally schema field references.
     
     In multi-asset queries (e.g. table joins), this may contain multiple Table references
     and optionally schema field references."""
         return self._inner_dict.get('subjects')  # type: ignore
     
     @subjects.setter
     def subjects(self, value: List["QuerySubjectClass"]) -> None:
+        """Setter: One or more subjects of the query.
+    
+    In single-asset queries (e.g. table select), this will contain the Table reference
+    and optionally schema field references.
+    
+    In multi-asset queries (e.g. table joins), this may contain multiple Table references
+    and optionally schema field references."""
         self._inner_dict['subjects'] = value
     
     
 class DataHubRetentionConfigClass(_Aspect):
     # No docs available.
 
 
@@ -14798,25 +17249,33 @@
     def __init__(self,
         retention: "RetentionClass",
     ):
         super().__init__()
         
         self.retention = retention
     
+    @classmethod
+    def construct_with_defaults(cls) -> "DataHubRetentionConfigClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
-        self.retention = RetentionClass._construct_with_defaults()
+        self.retention = RetentionClass.construct_with_defaults()
     
     
     @property
     def retention(self) -> "RetentionClass":
         # No docs available.
         return self._inner_dict.get('retention')  # type: ignore
     
     @retention.setter
     def retention(self, value: "RetentionClass") -> None:
+        # No docs available.
         self._inner_dict['retention'] = value
     
     
 class RetentionClass(DictWrapper):
     """Base class that encapsulates different retention policies.
     Only one of the fields should be set"""
     
@@ -14826,161 +17285,216 @@
         time: Union[None, "TimeBasedRetentionClass"]=None,
     ):
         super().__init__()
         
         self.version = version
         self.time = time
     
+    @classmethod
+    def construct_with_defaults(cls) -> "RetentionClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.version = self.RECORD_SCHEMA.fields_dict["version"].default
         self.time = self.RECORD_SCHEMA.fields_dict["time"].default
     
     
     @property
     def version(self) -> Union[None, "VersionBasedRetentionClass"]:
         # No docs available.
         return self._inner_dict.get('version')  # type: ignore
     
     @version.setter
     def version(self, value: Union[None, "VersionBasedRetentionClass"]) -> None:
+        # No docs available.
         self._inner_dict['version'] = value
     
     
     @property
     def time(self) -> Union[None, "TimeBasedRetentionClass"]:
         # No docs available.
         return self._inner_dict.get('time')  # type: ignore
     
     @time.setter
     def time(self, value: Union[None, "TimeBasedRetentionClass"]) -> None:
+        # No docs available.
         self._inner_dict['time'] = value
     
     
 class TimeBasedRetentionClass(DictWrapper):
     """Keep records that are less than X seconds old"""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.retention.TimeBasedRetention")
     def __init__(self,
         maxAgeInSeconds: int,
     ):
         super().__init__()
         
         self.maxAgeInSeconds = maxAgeInSeconds
     
+    @classmethod
+    def construct_with_defaults(cls) -> "TimeBasedRetentionClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.maxAgeInSeconds = int()
     
     
     @property
     def maxAgeInSeconds(self) -> int:
         # No docs available.
         return self._inner_dict.get('maxAgeInSeconds')  # type: ignore
     
     @maxAgeInSeconds.setter
     def maxAgeInSeconds(self, value: int) -> None:
+        # No docs available.
         self._inner_dict['maxAgeInSeconds'] = value
     
     
 class VersionBasedRetentionClass(DictWrapper):
     """Keep max N latest records"""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.retention.VersionBasedRetention")
     def __init__(self,
         maxVersions: int,
     ):
         super().__init__()
         
         self.maxVersions = maxVersions
     
+    @classmethod
+    def construct_with_defaults(cls) -> "VersionBasedRetentionClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.maxVersions = int()
     
     
     @property
     def maxVersions(self) -> int:
         # No docs available.
         return self._inner_dict.get('maxVersions')  # type: ignore
     
     @maxVersions.setter
     def maxVersions(self, value: int) -> None:
+        # No docs available.
         self._inner_dict['maxVersions'] = value
     
     
 class ArrayTypeClass(DictWrapper):
     """Array field type."""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.schema.ArrayType")
     def __init__(self,
         nestedType: Union[None, List[str]]=None,
     ):
         super().__init__()
         
         self.nestedType = nestedType
     
+    @classmethod
+    def construct_with_defaults(cls) -> "ArrayTypeClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.nestedType = self.RECORD_SCHEMA.fields_dict["nestedType"].default
     
     
     @property
     def nestedType(self) -> Union[None, List[str]]:
-        """List of types this array holds."""
+        """Getter: List of types this array holds."""
         return self._inner_dict.get('nestedType')  # type: ignore
     
     @nestedType.setter
     def nestedType(self, value: Union[None, List[str]]) -> None:
+        """Setter: List of types this array holds."""
         self._inner_dict['nestedType'] = value
     
     
 class BinaryJsonSchemaClass(DictWrapper):
     """Schema text of binary JSON schema."""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.schema.BinaryJsonSchema")
     def __init__(self,
         schema: str,
     ):
         super().__init__()
         
         self.schema = schema
     
+    @classmethod
+    def construct_with_defaults(cls) -> "BinaryJsonSchemaClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.schema = str()
     
     
     @property
     def schema(self) -> str:
-        """The native schema text for binary JSON file format."""
+        """Getter: The native schema text for binary JSON file format."""
         return self._inner_dict.get('schema')  # type: ignore
     
     @schema.setter
     def schema(self, value: str) -> None:
+        """Setter: The native schema text for binary JSON file format."""
         self._inner_dict['schema'] = value
     
     
 class BooleanTypeClass(DictWrapper):
     """Boolean field type."""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.schema.BooleanType")
     def __init__(self,
     ):
         super().__init__()
         
     
+    @classmethod
+    def construct_with_defaults(cls) -> "BooleanTypeClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         pass
     
     
 class BytesTypeClass(DictWrapper):
     """Bytes field type."""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.schema.BytesType")
     def __init__(self,
     ):
         super().__init__()
         
     
+    @classmethod
+    def construct_with_defaults(cls) -> "BytesTypeClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         pass
     
     
 class DatasetFieldForeignKeyClass(DictWrapper):
     """For non-urn based foregin keys."""
     
@@ -14992,59 +17506,76 @@
     ):
         super().__init__()
         
         self.parentDataset = parentDataset
         self.currentFieldPaths = currentFieldPaths
         self.parentField = parentField
     
+    @classmethod
+    def construct_with_defaults(cls) -> "DatasetFieldForeignKeyClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.parentDataset = str()
         self.currentFieldPaths = list()
         self.parentField = str()
     
     
     @property
     def parentDataset(self) -> str:
-        """dataset that stores the resource."""
+        """Getter: dataset that stores the resource."""
         return self._inner_dict.get('parentDataset')  # type: ignore
     
     @parentDataset.setter
     def parentDataset(self, value: str) -> None:
+        """Setter: dataset that stores the resource."""
         self._inner_dict['parentDataset'] = value
     
     
     @property
     def currentFieldPaths(self) -> List[str]:
-        """List of fields in hosting(current) SchemaMetadata that conform a foreign key. List can contain a single entry or multiple entries if several entries in hosting schema conform a foreign key in a single parent dataset."""
+        """Getter: List of fields in hosting(current) SchemaMetadata that conform a foreign key. List can contain a single entry or multiple entries if several entries in hosting schema conform a foreign key in a single parent dataset."""
         return self._inner_dict.get('currentFieldPaths')  # type: ignore
     
     @currentFieldPaths.setter
     def currentFieldPaths(self, value: List[str]) -> None:
+        """Setter: List of fields in hosting(current) SchemaMetadata that conform a foreign key. List can contain a single entry or multiple entries if several entries in hosting schema conform a foreign key in a single parent dataset."""
         self._inner_dict['currentFieldPaths'] = value
     
     
     @property
     def parentField(self) -> str:
-        """SchemaField@fieldPath that uniquely identify field in parent dataset that this field references."""
+        """Getter: SchemaField@fieldPath that uniquely identify field in parent dataset that this field references."""
         return self._inner_dict.get('parentField')  # type: ignore
     
     @parentField.setter
     def parentField(self, value: str) -> None:
+        """Setter: SchemaField@fieldPath that uniquely identify field in parent dataset that this field references."""
         self._inner_dict['parentField'] = value
     
     
 class DateTypeClass(DictWrapper):
     """Date field type."""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.schema.DateType")
     def __init__(self,
     ):
         super().__init__()
         
     
+    @classmethod
+    def construct_with_defaults(cls) -> "DateTypeClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         pass
     
     
 class EditableSchemaFieldInfoClass(DictWrapper):
     """SchemaField to describe metadata related to dataset schema."""
     
@@ -15058,58 +17589,69 @@
         super().__init__()
         
         self.fieldPath = fieldPath
         self.description = description
         self.globalTags = globalTags
         self.glossaryTerms = glossaryTerms
     
+    @classmethod
+    def construct_with_defaults(cls) -> "EditableSchemaFieldInfoClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.fieldPath = str()
         self.description = self.RECORD_SCHEMA.fields_dict["description"].default
         self.globalTags = self.RECORD_SCHEMA.fields_dict["globalTags"].default
         self.glossaryTerms = self.RECORD_SCHEMA.fields_dict["glossaryTerms"].default
     
     
     @property
     def fieldPath(self) -> str:
-        """FieldPath uniquely identifying the SchemaField this metadata is associated with"""
+        """Getter: FieldPath uniquely identifying the SchemaField this metadata is associated with"""
         return self._inner_dict.get('fieldPath')  # type: ignore
     
     @fieldPath.setter
     def fieldPath(self, value: str) -> None:
+        """Setter: FieldPath uniquely identifying the SchemaField this metadata is associated with"""
         self._inner_dict['fieldPath'] = value
     
     
     @property
     def description(self) -> Union[None, str]:
-        """Description"""
+        """Getter: Description"""
         return self._inner_dict.get('description')  # type: ignore
     
     @description.setter
     def description(self, value: Union[None, str]) -> None:
+        """Setter: Description"""
         self._inner_dict['description'] = value
     
     
     @property
     def globalTags(self) -> Union[None, "GlobalTagsClass"]:
-        """Tags associated with the field"""
+        """Getter: Tags associated with the field"""
         return self._inner_dict.get('globalTags')  # type: ignore
     
     @globalTags.setter
     def globalTags(self, value: Union[None, "GlobalTagsClass"]) -> None:
+        """Setter: Tags associated with the field"""
         self._inner_dict['globalTags'] = value
     
     
     @property
     def glossaryTerms(self) -> Union[None, "GlossaryTermsClass"]:
-        """Glossary terms associated with the field"""
+        """Getter: Glossary terms associated with the field"""
         return self._inner_dict.get('glossaryTerms')  # type: ignore
     
     @glossaryTerms.setter
     def glossaryTerms(self, value: Union[None, "GlossaryTermsClass"]) -> None:
+        """Setter: Glossary terms associated with the field"""
         self._inner_dict['glossaryTerms'] = value
     
     
 class EditableSchemaMetadataClass(_Aspect):
     """EditableSchemaMetadata stores editable changes made to schema metadata. This separates changes made from
     ingestion pipelines and edits in the UI to avoid accidental overwrites of user-provided data by ingestion pipelines."""
 
@@ -15135,70 +17677,88 @@
             # default: {'actor': 'urn:li:corpuser:unknown', 'impersonator': None, 'time': 0, 'message': None}
             self.lastModified = _json_converter.from_json_object(self.RECORD_SCHEMA.fields_dict["lastModified"].default, writers_schema=self.RECORD_SCHEMA.fields_dict["lastModified"].type)
         else:
             self.lastModified = lastModified
         self.deleted = deleted
         self.editableSchemaFieldInfo = editableSchemaFieldInfo
     
+    @classmethod
+    def construct_with_defaults(cls) -> "EditableSchemaMetadataClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.created = _json_converter.from_json_object(self.RECORD_SCHEMA.fields_dict["created"].default, writers_schema=self.RECORD_SCHEMA.fields_dict["created"].type)
         self.lastModified = _json_converter.from_json_object(self.RECORD_SCHEMA.fields_dict["lastModified"].default, writers_schema=self.RECORD_SCHEMA.fields_dict["lastModified"].type)
         self.deleted = self.RECORD_SCHEMA.fields_dict["deleted"].default
         self.editableSchemaFieldInfo = list()
     
     
     @property
     def created(self) -> "AuditStampClass":
-        """An AuditStamp corresponding to the creation of this resource/association/sub-resource. A value of 0 for time indicates missing data."""
+        """Getter: An AuditStamp corresponding to the creation of this resource/association/sub-resource. A value of 0 for time indicates missing data."""
         return self._inner_dict.get('created')  # type: ignore
     
     @created.setter
     def created(self, value: "AuditStampClass") -> None:
+        """Setter: An AuditStamp corresponding to the creation of this resource/association/sub-resource. A value of 0 for time indicates missing data."""
         self._inner_dict['created'] = value
     
     
     @property
     def lastModified(self) -> "AuditStampClass":
-        """An AuditStamp corresponding to the last modification of this resource/association/sub-resource. If no modification has happened since creation, lastModified should be the same as created. A value of 0 for time indicates missing data."""
+        """Getter: An AuditStamp corresponding to the last modification of this resource/association/sub-resource. If no modification has happened since creation, lastModified should be the same as created. A value of 0 for time indicates missing data."""
         return self._inner_dict.get('lastModified')  # type: ignore
     
     @lastModified.setter
     def lastModified(self, value: "AuditStampClass") -> None:
+        """Setter: An AuditStamp corresponding to the last modification of this resource/association/sub-resource. If no modification has happened since creation, lastModified should be the same as created. A value of 0 for time indicates missing data."""
         self._inner_dict['lastModified'] = value
     
     
     @property
     def deleted(self) -> Union[None, "AuditStampClass"]:
-        """An AuditStamp corresponding to the deletion of this resource/association/sub-resource. Logically, deleted MUST have a later timestamp than creation. It may or may not have the same time as lastModified depending upon the resource/association/sub-resource semantics."""
+        """Getter: An AuditStamp corresponding to the deletion of this resource/association/sub-resource. Logically, deleted MUST have a later timestamp than creation. It may or may not have the same time as lastModified depending upon the resource/association/sub-resource semantics."""
         return self._inner_dict.get('deleted')  # type: ignore
     
     @deleted.setter
     def deleted(self, value: Union[None, "AuditStampClass"]) -> None:
+        """Setter: An AuditStamp corresponding to the deletion of this resource/association/sub-resource. Logically, deleted MUST have a later timestamp than creation. It may or may not have the same time as lastModified depending upon the resource/association/sub-resource semantics."""
         self._inner_dict['deleted'] = value
     
     
     @property
     def editableSchemaFieldInfo(self) -> List["EditableSchemaFieldInfoClass"]:
-        """Client provided a list of fields from document schema."""
+        """Getter: Client provided a list of fields from document schema."""
         return self._inner_dict.get('editableSchemaFieldInfo')  # type: ignore
     
     @editableSchemaFieldInfo.setter
     def editableSchemaFieldInfo(self, value: List["EditableSchemaFieldInfoClass"]) -> None:
+        """Setter: Client provided a list of fields from document schema."""
         self._inner_dict['editableSchemaFieldInfo'] = value
     
     
 class EnumTypeClass(DictWrapper):
     """Enum field type."""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.schema.EnumType")
     def __init__(self,
     ):
         super().__init__()
         
     
+    @classmethod
+    def construct_with_defaults(cls) -> "EnumTypeClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         pass
     
     
 class EspressoSchemaClass(DictWrapper):
     """Schema text of an espresso table schema."""
     
@@ -15208,48 +17768,64 @@
         tableSchema: str,
     ):
         super().__init__()
         
         self.documentSchema = documentSchema
         self.tableSchema = tableSchema
     
+    @classmethod
+    def construct_with_defaults(cls) -> "EspressoSchemaClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.documentSchema = str()
         self.tableSchema = str()
     
     
     @property
     def documentSchema(self) -> str:
-        """The native espresso document schema."""
+        """Getter: The native espresso document schema."""
         return self._inner_dict.get('documentSchema')  # type: ignore
     
     @documentSchema.setter
     def documentSchema(self, value: str) -> None:
+        """Setter: The native espresso document schema."""
         self._inner_dict['documentSchema'] = value
     
     
     @property
     def tableSchema(self) -> str:
-        """The espresso table schema definition."""
+        """Getter: The espresso table schema definition."""
         return self._inner_dict.get('tableSchema')  # type: ignore
     
     @tableSchema.setter
     def tableSchema(self, value: str) -> None:
+        """Setter: The espresso table schema definition."""
         self._inner_dict['tableSchema'] = value
     
     
 class FixedTypeClass(DictWrapper):
     """Fixed field type."""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.schema.FixedType")
     def __init__(self,
     ):
         super().__init__()
         
     
+    @classmethod
+    def construct_with_defaults(cls) -> "FixedTypeClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         pass
     
     
 class ForeignKeyConstraintClass(DictWrapper):
     """Description of a foreign key constraint in a schema."""
     
@@ -15263,83 +17839,102 @@
         super().__init__()
         
         self.name = name
         self.foreignFields = foreignFields
         self.sourceFields = sourceFields
         self.foreignDataset = foreignDataset
     
+    @classmethod
+    def construct_with_defaults(cls) -> "ForeignKeyConstraintClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.name = str()
         self.foreignFields = list()
         self.sourceFields = list()
         self.foreignDataset = str()
     
     
     @property
     def name(self) -> str:
-        """Name of the constraint, likely provided from the source"""
+        """Getter: Name of the constraint, likely provided from the source"""
         return self._inner_dict.get('name')  # type: ignore
     
     @name.setter
     def name(self, value: str) -> None:
+        """Setter: Name of the constraint, likely provided from the source"""
         self._inner_dict['name'] = value
     
     
     @property
     def foreignFields(self) -> List[str]:
-        """Fields the constraint maps to on the foreign dataset"""
+        """Getter: Fields the constraint maps to on the foreign dataset"""
         return self._inner_dict.get('foreignFields')  # type: ignore
     
     @foreignFields.setter
     def foreignFields(self, value: List[str]) -> None:
+        """Setter: Fields the constraint maps to on the foreign dataset"""
         self._inner_dict['foreignFields'] = value
     
     
     @property
     def sourceFields(self) -> List[str]:
-        """Fields the constraint maps to on the source dataset"""
+        """Getter: Fields the constraint maps to on the source dataset"""
         return self._inner_dict.get('sourceFields')  # type: ignore
     
     @sourceFields.setter
     def sourceFields(self, value: List[str]) -> None:
+        """Setter: Fields the constraint maps to on the source dataset"""
         self._inner_dict['sourceFields'] = value
     
     
     @property
     def foreignDataset(self) -> str:
-        """Reference to the foreign dataset for ease of lookup"""
+        """Getter: Reference to the foreign dataset for ease of lookup"""
         return self._inner_dict.get('foreignDataset')  # type: ignore
     
     @foreignDataset.setter
     def foreignDataset(self, value: str) -> None:
+        """Setter: Reference to the foreign dataset for ease of lookup"""
         self._inner_dict['foreignDataset'] = value
     
     
 class ForeignKeySpecClass(DictWrapper):
     """Description of a foreign key in a schema."""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.schema.ForeignKeySpec")
     def __init__(self,
         foreignKey: Union["DatasetFieldForeignKeyClass", "UrnForeignKeyClass"],
     ):
         super().__init__()
         
         self.foreignKey = foreignKey
     
+    @classmethod
+    def construct_with_defaults(cls) -> "ForeignKeySpecClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
-        self.foreignKey = DatasetFieldForeignKeyClass._construct_with_defaults()
+        self.foreignKey = DatasetFieldForeignKeyClass.construct_with_defaults()
     
     
     @property
     def foreignKey(self) -> Union["DatasetFieldForeignKeyClass", "UrnForeignKeyClass"]:
-        """Foreign key definition in metadata schema."""
+        """Getter: Foreign key definition in metadata schema."""
         return self._inner_dict.get('foreignKey')  # type: ignore
     
     @foreignKey.setter
     def foreignKey(self, value: Union["DatasetFieldForeignKeyClass", "UrnForeignKeyClass"]) -> None:
+        """Setter: Foreign key definition in metadata schema."""
         self._inner_dict['foreignKey'] = value
     
     
 class KafkaSchemaClass(DictWrapper):
     """Schema holder for kafka schema."""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.schema.KafkaSchema")
@@ -15348,36 +17943,45 @@
         keySchema: Union[None, str]=None,
     ):
         super().__init__()
         
         self.documentSchema = documentSchema
         self.keySchema = keySchema
     
+    @classmethod
+    def construct_with_defaults(cls) -> "KafkaSchemaClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.documentSchema = str()
         self.keySchema = self.RECORD_SCHEMA.fields_dict["keySchema"].default
     
     
     @property
     def documentSchema(self) -> str:
-        """The native kafka document schema. This is a human readable avro document schema."""
+        """Getter: The native kafka document schema. This is a human readable avro document schema."""
         return self._inner_dict.get('documentSchema')  # type: ignore
     
     @documentSchema.setter
     def documentSchema(self, value: str) -> None:
+        """Setter: The native kafka document schema. This is a human readable avro document schema."""
         self._inner_dict['documentSchema'] = value
     
     
     @property
     def keySchema(self) -> Union[None, str]:
-        """The native kafka key schema as retrieved from Schema Registry"""
+        """Getter: The native kafka key schema as retrieved from Schema Registry"""
         return self._inner_dict.get('keySchema')  # type: ignore
     
     @keySchema.setter
     def keySchema(self, value: Union[None, str]) -> None:
+        """Setter: The native kafka key schema as retrieved from Schema Registry"""
         self._inner_dict['keySchema'] = value
     
     
 class KeyValueSchemaClass(DictWrapper):
     """Schema text of a key-value store schema."""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.schema.KeyValueSchema")
@@ -15386,36 +17990,45 @@
         valueSchema: str,
     ):
         super().__init__()
         
         self.keySchema = keySchema
         self.valueSchema = valueSchema
     
+    @classmethod
+    def construct_with_defaults(cls) -> "KeyValueSchemaClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.keySchema = str()
         self.valueSchema = str()
     
     
     @property
     def keySchema(self) -> str:
-        """The raw schema for the key in the key-value store."""
+        """Getter: The raw schema for the key in the key-value store."""
         return self._inner_dict.get('keySchema')  # type: ignore
     
     @keySchema.setter
     def keySchema(self, value: str) -> None:
+        """Setter: The raw schema for the key in the key-value store."""
         self._inner_dict['keySchema'] = value
     
     
     @property
     def valueSchema(self) -> str:
-        """The raw schema for the value in the key-value store."""
+        """Getter: The raw schema for the value in the key-value store."""
         return self._inner_dict.get('valueSchema')  # type: ignore
     
     @valueSchema.setter
     def valueSchema(self, value: str) -> None:
+        """Setter: The raw schema for the value in the key-value store."""
         self._inner_dict['valueSchema'] = value
     
     
 class MapTypeClass(DictWrapper):
     """Map field type."""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.schema.MapType")
@@ -15424,86 +18037,117 @@
         valueType: Union[None, str]=None,
     ):
         super().__init__()
         
         self.keyType = keyType
         self.valueType = valueType
     
+    @classmethod
+    def construct_with_defaults(cls) -> "MapTypeClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.keyType = self.RECORD_SCHEMA.fields_dict["keyType"].default
         self.valueType = self.RECORD_SCHEMA.fields_dict["valueType"].default
     
     
     @property
     def keyType(self) -> Union[None, str]:
-        """Key type in a map"""
+        """Getter: Key type in a map"""
         return self._inner_dict.get('keyType')  # type: ignore
     
     @keyType.setter
     def keyType(self, value: Union[None, str]) -> None:
+        """Setter: Key type in a map"""
         self._inner_dict['keyType'] = value
     
     
     @property
     def valueType(self) -> Union[None, str]:
-        """Type of the value in a map"""
+        """Getter: Type of the value in a map"""
         return self._inner_dict.get('valueType')  # type: ignore
     
     @valueType.setter
     def valueType(self, value: Union[None, str]) -> None:
+        """Setter: Type of the value in a map"""
         self._inner_dict['valueType'] = value
     
     
 class MySqlDDLClass(DictWrapper):
     """Schema holder for MySql data definition language that describes an MySql table."""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.schema.MySqlDDL")
     def __init__(self,
         tableSchema: str,
     ):
         super().__init__()
         
         self.tableSchema = tableSchema
     
+    @classmethod
+    def construct_with_defaults(cls) -> "MySqlDDLClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.tableSchema = str()
     
     
     @property
     def tableSchema(self) -> str:
-        """The native schema in the dataset's platform. This is a human readable (json blob) table schema."""
+        """Getter: The native schema in the dataset's platform. This is a human readable (json blob) table schema."""
         return self._inner_dict.get('tableSchema')  # type: ignore
     
     @tableSchema.setter
     def tableSchema(self, value: str) -> None:
+        """Setter: The native schema in the dataset's platform. This is a human readable (json blob) table schema."""
         self._inner_dict['tableSchema'] = value
     
     
 class NullTypeClass(DictWrapper):
     """Null field type."""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.schema.NullType")
     def __init__(self,
     ):
         super().__init__()
         
     
+    @classmethod
+    def construct_with_defaults(cls) -> "NullTypeClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         pass
     
     
 class NumberTypeClass(DictWrapper):
     """Number data type: long, integer, short, etc.."""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.schema.NumberType")
     def __init__(self,
     ):
         super().__init__()
         
     
+    @classmethod
+    def construct_with_defaults(cls) -> "NumberTypeClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         pass
     
     
 class OracleDDLClass(DictWrapper):
     """Schema holder for oracle data definition language that describes an oracle table."""
     
@@ -15511,112 +18155,151 @@
     def __init__(self,
         tableSchema: str,
     ):
         super().__init__()
         
         self.tableSchema = tableSchema
     
+    @classmethod
+    def construct_with_defaults(cls) -> "OracleDDLClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.tableSchema = str()
     
     
     @property
     def tableSchema(self) -> str:
-        """The native schema in the dataset's platform. This is a human readable (json blob) table schema."""
+        """Getter: The native schema in the dataset's platform. This is a human readable (json blob) table schema."""
         return self._inner_dict.get('tableSchema')  # type: ignore
     
     @tableSchema.setter
     def tableSchema(self, value: str) -> None:
+        """Setter: The native schema in the dataset's platform. This is a human readable (json blob) table schema."""
         self._inner_dict['tableSchema'] = value
     
     
 class OrcSchemaClass(DictWrapper):
     """Schema text of an ORC schema."""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.schema.OrcSchema")
     def __init__(self,
         schema: str,
     ):
         super().__init__()
         
         self.schema = schema
     
+    @classmethod
+    def construct_with_defaults(cls) -> "OrcSchemaClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.schema = str()
     
     
     @property
     def schema(self) -> str:
-        """The native schema for ORC file format."""
+        """Getter: The native schema for ORC file format."""
         return self._inner_dict.get('schema')  # type: ignore
     
     @schema.setter
     def schema(self, value: str) -> None:
+        """Setter: The native schema for ORC file format."""
         self._inner_dict['schema'] = value
     
     
 class OtherSchemaClass(DictWrapper):
     """Schema holder for undefined schema types."""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.schema.OtherSchema")
     def __init__(self,
         rawSchema: str,
     ):
         super().__init__()
         
         self.rawSchema = rawSchema
     
+    @classmethod
+    def construct_with_defaults(cls) -> "OtherSchemaClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.rawSchema = str()
     
     
     @property
     def rawSchema(self) -> str:
-        """The native schema in the dataset's platform."""
+        """Getter: The native schema in the dataset's platform."""
         return self._inner_dict.get('rawSchema')  # type: ignore
     
     @rawSchema.setter
     def rawSchema(self, value: str) -> None:
+        """Setter: The native schema in the dataset's platform."""
         self._inner_dict['rawSchema'] = value
     
     
 class PrestoDDLClass(DictWrapper):
     """Schema holder for presto data definition language that describes a presto view."""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.schema.PrestoDDL")
     def __init__(self,
         rawSchema: str,
     ):
         super().__init__()
         
         self.rawSchema = rawSchema
     
+    @classmethod
+    def construct_with_defaults(cls) -> "PrestoDDLClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.rawSchema = str()
     
     
     @property
     def rawSchema(self) -> str:
-        """The raw schema in the dataset's platform. This includes the DDL and the columns extracted from DDL."""
+        """Getter: The raw schema in the dataset's platform. This includes the DDL and the columns extracted from DDL."""
         return self._inner_dict.get('rawSchema')  # type: ignore
     
     @rawSchema.setter
     def rawSchema(self, value: str) -> None:
+        """Setter: The raw schema in the dataset's platform. This includes the DDL and the columns extracted from DDL."""
         self._inner_dict['rawSchema'] = value
     
     
 class RecordTypeClass(DictWrapper):
     """Record field type."""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.schema.RecordType")
     def __init__(self,
     ):
         super().__init__()
         
     
+    @classmethod
+    def construct_with_defaults(cls) -> "RecordTypeClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         pass
     
     
 class SchemaFieldClass(DictWrapper):
     """SchemaField to describe metadata related to dataset schema."""
     
@@ -15664,208 +18347,242 @@
             # default: False
             self.isPartOfKey = self.RECORD_SCHEMA.fields_dict["isPartOfKey"].default
         else:
             self.isPartOfKey = isPartOfKey
         self.isPartitioningKey = isPartitioningKey
         self.jsonProps = jsonProps
     
+    @classmethod
+    def construct_with_defaults(cls) -> "SchemaFieldClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.fieldPath = str()
         self.jsonPath = self.RECORD_SCHEMA.fields_dict["jsonPath"].default
         self.nullable = self.RECORD_SCHEMA.fields_dict["nullable"].default
         self.description = self.RECORD_SCHEMA.fields_dict["description"].default
         self.label = self.RECORD_SCHEMA.fields_dict["label"].default
         self.created = self.RECORD_SCHEMA.fields_dict["created"].default
         self.lastModified = self.RECORD_SCHEMA.fields_dict["lastModified"].default
-        self.type = SchemaFieldDataTypeClass._construct_with_defaults()
+        self.type = SchemaFieldDataTypeClass.construct_with_defaults()
         self.nativeDataType = str()
         self.recursive = self.RECORD_SCHEMA.fields_dict["recursive"].default
         self.globalTags = self.RECORD_SCHEMA.fields_dict["globalTags"].default
         self.glossaryTerms = self.RECORD_SCHEMA.fields_dict["glossaryTerms"].default
         self.isPartOfKey = self.RECORD_SCHEMA.fields_dict["isPartOfKey"].default
         self.isPartitioningKey = self.RECORD_SCHEMA.fields_dict["isPartitioningKey"].default
         self.jsonProps = self.RECORD_SCHEMA.fields_dict["jsonProps"].default
     
     
     @property
     def fieldPath(self) -> str:
-        """Flattened name of the field. Field is computed from jsonPath field."""
+        """Getter: Flattened name of the field. Field is computed from jsonPath field."""
         return self._inner_dict.get('fieldPath')  # type: ignore
     
     @fieldPath.setter
     def fieldPath(self, value: str) -> None:
+        """Setter: Flattened name of the field. Field is computed from jsonPath field."""
         self._inner_dict['fieldPath'] = value
     
     
     @property
     def jsonPath(self) -> Union[None, str]:
-        """Flattened name of a field in JSON Path notation."""
+        """Getter: Flattened name of a field in JSON Path notation."""
         return self._inner_dict.get('jsonPath')  # type: ignore
     
     @jsonPath.setter
     def jsonPath(self, value: Union[None, str]) -> None:
+        """Setter: Flattened name of a field in JSON Path notation."""
         self._inner_dict['jsonPath'] = value
     
     
     @property
     def nullable(self) -> bool:
-        """Indicates if this field is optional or nullable"""
+        """Getter: Indicates if this field is optional or nullable"""
         return self._inner_dict.get('nullable')  # type: ignore
     
     @nullable.setter
     def nullable(self, value: bool) -> None:
+        """Setter: Indicates if this field is optional or nullable"""
         self._inner_dict['nullable'] = value
     
     
     @property
     def description(self) -> Union[None, str]:
-        """Description"""
+        """Getter: Description"""
         return self._inner_dict.get('description')  # type: ignore
     
     @description.setter
     def description(self, value: Union[None, str]) -> None:
+        """Setter: Description"""
         self._inner_dict['description'] = value
     
     
     @property
     def label(self) -> Union[None, str]:
-        """Label of the field. Provides a more human-readable name for the field than field path. Some sources will
+        """Getter: Label of the field. Provides a more human-readable name for the field than field path. Some sources will
     provide this metadata but not all sources have the concept of a label. If just one string is associated with
     a field in a source, that is most likely a description."""
         return self._inner_dict.get('label')  # type: ignore
     
     @label.setter
     def label(self, value: Union[None, str]) -> None:
+        """Setter: Label of the field. Provides a more human-readable name for the field than field path. Some sources will
+    provide this metadata but not all sources have the concept of a label. If just one string is associated with
+    a field in a source, that is most likely a description."""
         self._inner_dict['label'] = value
     
     
     @property
     def created(self) -> Union[None, "AuditStampClass"]:
-        """An AuditStamp corresponding to the creation of this schema field."""
+        """Getter: An AuditStamp corresponding to the creation of this schema field."""
         return self._inner_dict.get('created')  # type: ignore
     
     @created.setter
     def created(self, value: Union[None, "AuditStampClass"]) -> None:
+        """Setter: An AuditStamp corresponding to the creation of this schema field."""
         self._inner_dict['created'] = value
     
     
     @property
     def lastModified(self) -> Union[None, "AuditStampClass"]:
-        """An AuditStamp corresponding to the last modification of this schema field."""
+        """Getter: An AuditStamp corresponding to the last modification of this schema field."""
         return self._inner_dict.get('lastModified')  # type: ignore
     
     @lastModified.setter
     def lastModified(self, value: Union[None, "AuditStampClass"]) -> None:
+        """Setter: An AuditStamp corresponding to the last modification of this schema field."""
         self._inner_dict['lastModified'] = value
     
     
     @property
     def type(self) -> "SchemaFieldDataTypeClass":
-        """Platform independent field type of the field."""
+        """Getter: Platform independent field type of the field."""
         return self._inner_dict.get('type')  # type: ignore
     
     @type.setter
     def type(self, value: "SchemaFieldDataTypeClass") -> None:
+        """Setter: Platform independent field type of the field."""
         self._inner_dict['type'] = value
     
     
     @property
     def nativeDataType(self) -> str:
-        """The native type of the field in the dataset's platform as declared by platform schema."""
+        """Getter: The native type of the field in the dataset's platform as declared by platform schema."""
         return self._inner_dict.get('nativeDataType')  # type: ignore
     
     @nativeDataType.setter
     def nativeDataType(self, value: str) -> None:
+        """Setter: The native type of the field in the dataset's platform as declared by platform schema."""
         self._inner_dict['nativeDataType'] = value
     
     
     @property
     def recursive(self) -> bool:
-        """There are use cases when a field in type B references type A. A field in A references field of type B. In such cases, we will mark the first field as recursive."""
+        """Getter: There are use cases when a field in type B references type A. A field in A references field of type B. In such cases, we will mark the first field as recursive."""
         return self._inner_dict.get('recursive')  # type: ignore
     
     @recursive.setter
     def recursive(self, value: bool) -> None:
+        """Setter: There are use cases when a field in type B references type A. A field in A references field of type B. In such cases, we will mark the first field as recursive."""
         self._inner_dict['recursive'] = value
     
     
     @property
     def globalTags(self) -> Union[None, "GlobalTagsClass"]:
-        """Tags associated with the field"""
+        """Getter: Tags associated with the field"""
         return self._inner_dict.get('globalTags')  # type: ignore
     
     @globalTags.setter
     def globalTags(self, value: Union[None, "GlobalTagsClass"]) -> None:
+        """Setter: Tags associated with the field"""
         self._inner_dict['globalTags'] = value
     
     
     @property
     def glossaryTerms(self) -> Union[None, "GlossaryTermsClass"]:
-        """Glossary terms associated with the field"""
+        """Getter: Glossary terms associated with the field"""
         return self._inner_dict.get('glossaryTerms')  # type: ignore
     
     @glossaryTerms.setter
     def glossaryTerms(self, value: Union[None, "GlossaryTermsClass"]) -> None:
+        """Setter: Glossary terms associated with the field"""
         self._inner_dict['glossaryTerms'] = value
     
     
     @property
     def isPartOfKey(self) -> bool:
-        """For schema fields that are part of complex keys, set this field to true
+        """Getter: For schema fields that are part of complex keys, set this field to true
     We do this to easily distinguish between value and key fields"""
         return self._inner_dict.get('isPartOfKey')  # type: ignore
     
     @isPartOfKey.setter
     def isPartOfKey(self, value: bool) -> None:
+        """Setter: For schema fields that are part of complex keys, set this field to true
+    We do this to easily distinguish between value and key fields"""
         self._inner_dict['isPartOfKey'] = value
     
     
     @property
     def isPartitioningKey(self) -> Union[None, bool]:
-        """For Datasets which are partitioned, this determines the partitioning key."""
+        """Getter: For Datasets which are partitioned, this determines the partitioning key."""
         return self._inner_dict.get('isPartitioningKey')  # type: ignore
     
     @isPartitioningKey.setter
     def isPartitioningKey(self, value: Union[None, bool]) -> None:
+        """Setter: For Datasets which are partitioned, this determines the partitioning key."""
         self._inner_dict['isPartitioningKey'] = value
     
     
     @property
     def jsonProps(self) -> Union[None, str]:
-        """For schema fields that have other properties that are not modeled explicitly,
+        """Getter: For schema fields that have other properties that are not modeled explicitly,
     use this field to serialize those properties into a JSON string"""
         return self._inner_dict.get('jsonProps')  # type: ignore
     
     @jsonProps.setter
     def jsonProps(self, value: Union[None, str]) -> None:
+        """Setter: For schema fields that have other properties that are not modeled explicitly,
+    use this field to serialize those properties into a JSON string"""
         self._inner_dict['jsonProps'] = value
     
     
 class SchemaFieldDataTypeClass(DictWrapper):
     """Schema field data types"""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.schema.SchemaFieldDataType")
     def __init__(self,
         type: Union["BooleanTypeClass", "FixedTypeClass", "StringTypeClass", "BytesTypeClass", "NumberTypeClass", "DateTypeClass", "TimeTypeClass", "EnumTypeClass", "NullTypeClass", "MapTypeClass", "ArrayTypeClass", "UnionTypeClass", "RecordTypeClass"],
     ):
         super().__init__()
         
         self.type = type
     
+    @classmethod
+    def construct_with_defaults(cls) -> "SchemaFieldDataTypeClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
-        self.type = BooleanTypeClass._construct_with_defaults()
+        self.type = BooleanTypeClass.construct_with_defaults()
     
     
     @property
     def type(self) -> Union["BooleanTypeClass", "FixedTypeClass", "StringTypeClass", "BytesTypeClass", "NumberTypeClass", "DateTypeClass", "TimeTypeClass", "EnumTypeClass", "NullTypeClass", "MapTypeClass", "ArrayTypeClass", "UnionTypeClass", "RecordTypeClass"]:
-        """Data platform specific types"""
+        """Getter: Data platform specific types"""
         return self._inner_dict.get('type')  # type: ignore
     
     @type.setter
     def type(self, value: Union["BooleanTypeClass", "FixedTypeClass", "StringTypeClass", "BytesTypeClass", "NumberTypeClass", "DateTypeClass", "TimeTypeClass", "EnumTypeClass", "NullTypeClass", "MapTypeClass", "ArrayTypeClass", "UnionTypeClass", "RecordTypeClass"]) -> None:
+        """Setter: Data platform specific types"""
         self._inner_dict['type'] = value
     
     
 class SchemaMetadataClass(_Aspect):
     """SchemaMetadata to describe metadata related to store schema"""
 
 
@@ -15910,206 +18627,248 @@
         self.hash = hash
         self.platformSchema = platformSchema
         self.fields = fields
         self.primaryKeys = primaryKeys
         self.foreignKeysSpecs = foreignKeysSpecs
         self.foreignKeys = foreignKeys
     
+    @classmethod
+    def construct_with_defaults(cls) -> "SchemaMetadataClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.schemaName = str()
         self.platform = str()
         self.version = int()
         self.created = _json_converter.from_json_object(self.RECORD_SCHEMA.fields_dict["created"].default, writers_schema=self.RECORD_SCHEMA.fields_dict["created"].type)
         self.lastModified = _json_converter.from_json_object(self.RECORD_SCHEMA.fields_dict["lastModified"].default, writers_schema=self.RECORD_SCHEMA.fields_dict["lastModified"].type)
         self.deleted = self.RECORD_SCHEMA.fields_dict["deleted"].default
         self.dataset = self.RECORD_SCHEMA.fields_dict["dataset"].default
         self.cluster = self.RECORD_SCHEMA.fields_dict["cluster"].default
         self.hash = str()
-        self.platformSchema = EspressoSchemaClass._construct_with_defaults()
+        self.platformSchema = EspressoSchemaClass.construct_with_defaults()
         self.fields = list()
         self.primaryKeys = self.RECORD_SCHEMA.fields_dict["primaryKeys"].default
         self.foreignKeysSpecs = self.RECORD_SCHEMA.fields_dict["foreignKeysSpecs"].default
         self.foreignKeys = self.RECORD_SCHEMA.fields_dict["foreignKeys"].default
     
     
     @property
     def schemaName(self) -> str:
-        """Schema name e.g. PageViewEvent, identity.Profile, ams.account_management_tracking"""
+        """Getter: Schema name e.g. PageViewEvent, identity.Profile, ams.account_management_tracking"""
         return self._inner_dict.get('schemaName')  # type: ignore
     
     @schemaName.setter
     def schemaName(self, value: str) -> None:
+        """Setter: Schema name e.g. PageViewEvent, identity.Profile, ams.account_management_tracking"""
         self._inner_dict['schemaName'] = value
     
     
     @property
     def platform(self) -> str:
-        """Standardized platform urn where schema is defined. The data platform Urn (urn:li:platform:{platform_name})"""
+        """Getter: Standardized platform urn where schema is defined. The data platform Urn (urn:li:platform:{platform_name})"""
         return self._inner_dict.get('platform')  # type: ignore
     
     @platform.setter
     def platform(self, value: str) -> None:
+        """Setter: Standardized platform urn where schema is defined. The data platform Urn (urn:li:platform:{platform_name})"""
         self._inner_dict['platform'] = value
     
     
     @property
     def version(self) -> int:
-        """Every change to SchemaMetadata in the resource results in a new version. Version is server assigned. This version is differ from platform native schema version."""
+        """Getter: Every change to SchemaMetadata in the resource results in a new version. Version is server assigned. This version is differ from platform native schema version."""
         return self._inner_dict.get('version')  # type: ignore
     
     @version.setter
     def version(self, value: int) -> None:
+        """Setter: Every change to SchemaMetadata in the resource results in a new version. Version is server assigned. This version is differ from platform native schema version."""
         self._inner_dict['version'] = value
     
     
     @property
     def created(self) -> "AuditStampClass":
-        """An AuditStamp corresponding to the creation of this resource/association/sub-resource. A value of 0 for time indicates missing data."""
+        """Getter: An AuditStamp corresponding to the creation of this resource/association/sub-resource. A value of 0 for time indicates missing data."""
         return self._inner_dict.get('created')  # type: ignore
     
     @created.setter
     def created(self, value: "AuditStampClass") -> None:
+        """Setter: An AuditStamp corresponding to the creation of this resource/association/sub-resource. A value of 0 for time indicates missing data."""
         self._inner_dict['created'] = value
     
     
     @property
     def lastModified(self) -> "AuditStampClass":
-        """An AuditStamp corresponding to the last modification of this resource/association/sub-resource. If no modification has happened since creation, lastModified should be the same as created. A value of 0 for time indicates missing data."""
+        """Getter: An AuditStamp corresponding to the last modification of this resource/association/sub-resource. If no modification has happened since creation, lastModified should be the same as created. A value of 0 for time indicates missing data."""
         return self._inner_dict.get('lastModified')  # type: ignore
     
     @lastModified.setter
     def lastModified(self, value: "AuditStampClass") -> None:
+        """Setter: An AuditStamp corresponding to the last modification of this resource/association/sub-resource. If no modification has happened since creation, lastModified should be the same as created. A value of 0 for time indicates missing data."""
         self._inner_dict['lastModified'] = value
     
     
     @property
     def deleted(self) -> Union[None, "AuditStampClass"]:
-        """An AuditStamp corresponding to the deletion of this resource/association/sub-resource. Logically, deleted MUST have a later timestamp than creation. It may or may not have the same time as lastModified depending upon the resource/association/sub-resource semantics."""
+        """Getter: An AuditStamp corresponding to the deletion of this resource/association/sub-resource. Logically, deleted MUST have a later timestamp than creation. It may or may not have the same time as lastModified depending upon the resource/association/sub-resource semantics."""
         return self._inner_dict.get('deleted')  # type: ignore
     
     @deleted.setter
     def deleted(self, value: Union[None, "AuditStampClass"]) -> None:
+        """Setter: An AuditStamp corresponding to the deletion of this resource/association/sub-resource. Logically, deleted MUST have a later timestamp than creation. It may or may not have the same time as lastModified depending upon the resource/association/sub-resource semantics."""
         self._inner_dict['deleted'] = value
     
     
     @property
     def dataset(self) -> Union[None, str]:
-        """Dataset this schema metadata is associated with."""
+        """Getter: Dataset this schema metadata is associated with."""
         return self._inner_dict.get('dataset')  # type: ignore
     
     @dataset.setter
     def dataset(self, value: Union[None, str]) -> None:
+        """Setter: Dataset this schema metadata is associated with."""
         self._inner_dict['dataset'] = value
     
     
     @property
     def cluster(self) -> Union[None, str]:
-        """The cluster this schema metadata resides from"""
+        """Getter: The cluster this schema metadata resides from"""
         return self._inner_dict.get('cluster')  # type: ignore
     
     @cluster.setter
     def cluster(self, value: Union[None, str]) -> None:
+        """Setter: The cluster this schema metadata resides from"""
         self._inner_dict['cluster'] = value
     
     
     @property
     def hash(self) -> str:
-        """the SHA1 hash of the schema content"""
+        """Getter: the SHA1 hash of the schema content"""
         return self._inner_dict.get('hash')  # type: ignore
     
     @hash.setter
     def hash(self, value: str) -> None:
+        """Setter: the SHA1 hash of the schema content"""
         self._inner_dict['hash'] = value
     
     
     @property
     def platformSchema(self) -> Union["EspressoSchemaClass", "OracleDDLClass", "MySqlDDLClass", "PrestoDDLClass", "KafkaSchemaClass", "BinaryJsonSchemaClass", "OrcSchemaClass", "SchemalessClass", "KeyValueSchemaClass", "OtherSchemaClass"]:
-        """The native schema in the dataset's platform."""
+        """Getter: The native schema in the dataset's platform."""
         return self._inner_dict.get('platformSchema')  # type: ignore
     
     @platformSchema.setter
     def platformSchema(self, value: Union["EspressoSchemaClass", "OracleDDLClass", "MySqlDDLClass", "PrestoDDLClass", "KafkaSchemaClass", "BinaryJsonSchemaClass", "OrcSchemaClass", "SchemalessClass", "KeyValueSchemaClass", "OtherSchemaClass"]) -> None:
+        """Setter: The native schema in the dataset's platform."""
         self._inner_dict['platformSchema'] = value
     
     
     @property
     def fields(self) -> List["SchemaFieldClass"]:
-        """Client provided a list of fields from document schema."""
+        """Getter: Client provided a list of fields from document schema."""
         return self._inner_dict.get('fields')  # type: ignore
     
     @fields.setter
     def fields(self, value: List["SchemaFieldClass"]) -> None:
+        """Setter: Client provided a list of fields from document schema."""
         self._inner_dict['fields'] = value
     
     
     @property
     def primaryKeys(self) -> Union[None, List[str]]:
-        """Client provided list of fields that define primary keys to access record. Field order defines hierarchical espresso keys. Empty lists indicates absence of primary key access patter. Value is a SchemaField@fieldPath."""
+        """Getter: Client provided list of fields that define primary keys to access record. Field order defines hierarchical espresso keys. Empty lists indicates absence of primary key access patter. Value is a SchemaField@fieldPath."""
         return self._inner_dict.get('primaryKeys')  # type: ignore
     
     @primaryKeys.setter
     def primaryKeys(self, value: Union[None, List[str]]) -> None:
+        """Setter: Client provided list of fields that define primary keys to access record. Field order defines hierarchical espresso keys. Empty lists indicates absence of primary key access patter. Value is a SchemaField@fieldPath."""
         self._inner_dict['primaryKeys'] = value
     
     
     @property
     def foreignKeysSpecs(self) -> Union[None, Dict[str, "ForeignKeySpecClass"]]:
-        """Map captures all the references schema makes to external datasets. Map key is ForeignKeySpecName typeref."""
+        """Getter: Map captures all the references schema makes to external datasets. Map key is ForeignKeySpecName typeref."""
         return self._inner_dict.get('foreignKeysSpecs')  # type: ignore
     
     @foreignKeysSpecs.setter
     def foreignKeysSpecs(self, value: Union[None, Dict[str, "ForeignKeySpecClass"]]) -> None:
+        """Setter: Map captures all the references schema makes to external datasets. Map key is ForeignKeySpecName typeref."""
         self._inner_dict['foreignKeysSpecs'] = value
     
     
     @property
     def foreignKeys(self) -> Union[None, List["ForeignKeyConstraintClass"]]:
-        """List of foreign key constraints for the schema"""
+        """Getter: List of foreign key constraints for the schema"""
         return self._inner_dict.get('foreignKeys')  # type: ignore
     
     @foreignKeys.setter
     def foreignKeys(self, value: Union[None, List["ForeignKeyConstraintClass"]]) -> None:
+        """Setter: List of foreign key constraints for the schema"""
         self._inner_dict['foreignKeys'] = value
     
     
 class SchemalessClass(DictWrapper):
     """The dataset has no specific schema associated with it"""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.schema.Schemaless")
     def __init__(self,
     ):
         super().__init__()
         
     
+    @classmethod
+    def construct_with_defaults(cls) -> "SchemalessClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         pass
     
     
 class StringTypeClass(DictWrapper):
     """String field type."""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.schema.StringType")
     def __init__(self,
     ):
         super().__init__()
         
     
+    @classmethod
+    def construct_with_defaults(cls) -> "StringTypeClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         pass
     
     
 class TimeTypeClass(DictWrapper):
     """Time field type. This should also be used for datetimes."""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.schema.TimeType")
     def __init__(self,
     ):
         super().__init__()
         
     
+    @classmethod
+    def construct_with_defaults(cls) -> "TimeTypeClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         pass
     
     
 class UnionTypeClass(DictWrapper):
     """Union field type."""
     
@@ -16117,50 +18876,66 @@
     def __init__(self,
         nestedTypes: Union[None, List[str]]=None,
     ):
         super().__init__()
         
         self.nestedTypes = nestedTypes
     
+    @classmethod
+    def construct_with_defaults(cls) -> "UnionTypeClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.nestedTypes = self.RECORD_SCHEMA.fields_dict["nestedTypes"].default
     
     
     @property
     def nestedTypes(self) -> Union[None, List[str]]:
-        """List of types in union type."""
+        """Getter: List of types in union type."""
         return self._inner_dict.get('nestedTypes')  # type: ignore
     
     @nestedTypes.setter
     def nestedTypes(self, value: Union[None, List[str]]) -> None:
+        """Setter: List of types in union type."""
         self._inner_dict['nestedTypes'] = value
     
     
 class UrnForeignKeyClass(DictWrapper):
     """If SchemaMetadata fields make any external references and references are of type com.linkedin.pegasus2avro.common.Urn or any children, this models can be used to mark it."""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.schema.UrnForeignKey")
     def __init__(self,
         currentFieldPath: str,
     ):
         super().__init__()
         
         self.currentFieldPath = currentFieldPath
     
+    @classmethod
+    def construct_with_defaults(cls) -> "UrnForeignKeyClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.currentFieldPath = str()
     
     
     @property
     def currentFieldPath(self) -> str:
-        """Field in hosting(current) SchemaMetadata."""
+        """Getter: Field in hosting(current) SchemaMetadata."""
         return self._inner_dict.get('currentFieldPath')  # type: ignore
     
     @currentFieldPath.setter
     def currentFieldPath(self, value: str) -> None:
+        """Setter: Field in hosting(current) SchemaMetadata."""
         self._inner_dict['currentFieldPath'] = value
     
     
 class DataHubSecretValueClass(_Aspect):
     """The value of a DataHub Secret"""
 
 
@@ -16177,58 +18952,69 @@
         super().__init__()
         
         self.name = name
         self.value = value
         self.description = description
         self.created = created
     
+    @classmethod
+    def construct_with_defaults(cls) -> "DataHubSecretValueClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.name = str()
         self.value = str()
         self.description = self.RECORD_SCHEMA.fields_dict["description"].default
         self.created = self.RECORD_SCHEMA.fields_dict["created"].default
     
     
     @property
     def name(self) -> str:
-        """The display name for the secret"""
+        """Getter: The display name for the secret"""
         return self._inner_dict.get('name')  # type: ignore
     
     @name.setter
     def name(self, value: str) -> None:
+        """Setter: The display name for the secret"""
         self._inner_dict['name'] = value
     
     
     @property
     def value(self) -> str:
-        """The AES-encrypted value of the DataHub secret."""
+        """Getter: The AES-encrypted value of the DataHub secret."""
         return self._inner_dict.get('value')  # type: ignore
     
     @value.setter
     def value(self, value: str) -> None:
+        """Setter: The AES-encrypted value of the DataHub secret."""
         self._inner_dict['value'] = value
     
     
     @property
     def description(self) -> Union[None, str]:
-        """Description of the secret"""
+        """Getter: Description of the secret"""
         return self._inner_dict.get('description')  # type: ignore
     
     @description.setter
     def description(self, value: Union[None, str]) -> None:
+        """Setter: Description of the secret"""
         self._inner_dict['description'] = value
     
     
     @property
     def created(self) -> Union[None, "AuditStampClass"]:
-        """Created Audit stamp"""
+        """Getter: Created Audit stamp"""
         return self._inner_dict.get('created')  # type: ignore
     
     @created.setter
     def created(self, value: Union[None, "AuditStampClass"]) -> None:
+        """Setter: Created Audit stamp"""
         self._inner_dict['created'] = value
     
     
 class GlobalSettingsInfoClass(_Aspect):
     """DataHub Global platform settings. Careful - these should not be modified by the outside world!"""
 
 
@@ -16239,50 +19025,66 @@
     def __init__(self,
         views: Union[None, "GlobalViewsSettingsClass"]=None,
     ):
         super().__init__()
         
         self.views = views
     
+    @classmethod
+    def construct_with_defaults(cls) -> "GlobalSettingsInfoClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.views = self.RECORD_SCHEMA.fields_dict["views"].default
     
     
     @property
     def views(self) -> Union[None, "GlobalViewsSettingsClass"]:
-        """Settings related to the Views Feature"""
+        """Getter: Settings related to the Views Feature"""
         return self._inner_dict.get('views')  # type: ignore
     
     @views.setter
     def views(self, value: Union[None, "GlobalViewsSettingsClass"]) -> None:
+        """Setter: Settings related to the Views Feature"""
         self._inner_dict['views'] = value
     
     
 class GlobalViewsSettingsClass(DictWrapper):
     """Settings for DataHub Views feature."""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.settings.global.GlobalViewsSettings")
     def __init__(self,
         defaultView: Union[None, str]=None,
     ):
         super().__init__()
         
         self.defaultView = defaultView
     
+    @classmethod
+    def construct_with_defaults(cls) -> "GlobalViewsSettingsClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.defaultView = self.RECORD_SCHEMA.fields_dict["defaultView"].default
     
     
     @property
     def defaultView(self) -> Union[None, str]:
-        """The default View for the instance, or organization."""
+        """Getter: The default View for the instance, or organization."""
         return self._inner_dict.get('defaultView')  # type: ignore
     
     @defaultView.setter
     def defaultView(self, value: Union[None, str]) -> None:
+        """Setter: The default View for the instance, or organization."""
         self._inner_dict['defaultView'] = value
     
     
 class DataHubStepStatePropertiesClass(_Aspect):
     """The properties associated with a DataHub step state"""
 
 
@@ -16299,36 +19101,45 @@
         if properties is None:
             # default: {}
             self.properties = dict()
         else:
             self.properties = properties
         self.lastModified = lastModified
     
+    @classmethod
+    def construct_with_defaults(cls) -> "DataHubStepStatePropertiesClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.properties = dict()
-        self.lastModified = AuditStampClass._construct_with_defaults()
+        self.lastModified = AuditStampClass.construct_with_defaults()
     
     
     @property
     def properties(self) -> Dict[str, str]:
-        """Description of the secret"""
+        """Getter: Description of the secret"""
         return self._inner_dict.get('properties')  # type: ignore
     
     @properties.setter
     def properties(self, value: Dict[str, str]) -> None:
+        """Setter: Description of the secret"""
         self._inner_dict['properties'] = value
     
     
     @property
     def lastModified(self) -> "AuditStampClass":
-        """Audit stamp describing the last person to update it."""
+        """Getter: Audit stamp describing the last person to update it."""
         return self._inner_dict.get('lastModified')  # type: ignore
     
     @lastModified.setter
     def lastModified(self, value: "AuditStampClass") -> None:
+        """Setter: Audit stamp describing the last person to update it."""
         self._inner_dict['lastModified'] = value
     
     
 class TagPropertiesClass(_Aspect):
     """Properties associated with a Tag"""
 
 
@@ -16343,47 +19154,57 @@
     ):
         super().__init__()
         
         self.name = name
         self.description = description
         self.colorHex = colorHex
     
+    @classmethod
+    def construct_with_defaults(cls) -> "TagPropertiesClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.name = str()
         self.description = self.RECORD_SCHEMA.fields_dict["description"].default
         self.colorHex = self.RECORD_SCHEMA.fields_dict["colorHex"].default
     
     
     @property
     def name(self) -> str:
-        """Display name of the tag"""
+        """Getter: Display name of the tag"""
         return self._inner_dict.get('name')  # type: ignore
     
     @name.setter
     def name(self, value: str) -> None:
+        """Setter: Display name of the tag"""
         self._inner_dict['name'] = value
     
     
     @property
     def description(self) -> Union[None, str]:
-        """Documentation of the tag"""
+        """Getter: Documentation of the tag"""
         return self._inner_dict.get('description')  # type: ignore
     
     @description.setter
     def description(self, value: Union[None, str]) -> None:
+        """Setter: Documentation of the tag"""
         self._inner_dict['description'] = value
     
     
     @property
     def colorHex(self) -> Union[None, str]:
-        """The color associated with the Tag in Hex. For example #FFFFFF."""
+        """Getter: The color associated with the Tag in Hex. For example #FFFFFF."""
         return self._inner_dict.get('colorHex')  # type: ignore
     
     @colorHex.setter
     def colorHex(self, value: Union[None, str]) -> None:
+        """Setter: The color associated with the Tag in Hex. For example #FFFFFF."""
         self._inner_dict['colorHex'] = value
     
     
 class TelemetryClientIdClass(_Aspect):
     """A simple wrapper around a String to persist the client ID for telemetry in DataHub's backend DB"""
 
 
@@ -16394,25 +19215,33 @@
     def __init__(self,
         clientId: str,
     ):
         super().__init__()
         
         self.clientId = clientId
     
+    @classmethod
+    def construct_with_defaults(cls) -> "TelemetryClientIdClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.clientId = str()
     
     
     @property
     def clientId(self) -> str:
-        """A string representing the telemetry client ID"""
+        """Getter: A string representing the telemetry client ID"""
         return self._inner_dict.get('clientId')  # type: ignore
     
     @clientId.setter
     def clientId(self, value: str) -> None:
+        """Setter: A string representing the telemetry client ID"""
         self._inner_dict['clientId'] = value
     
     
 class TestDefinitionClass(DictWrapper):
     # No docs available.
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.test.TestDefinition")
@@ -16421,36 +19250,45 @@
         json: Union[None, str]=None,
     ):
         super().__init__()
         
         self.type = type
         self.json = json
     
+    @classmethod
+    def construct_with_defaults(cls) -> "TestDefinitionClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.type = TestDefinitionTypeClass.JSON
         self.json = self.RECORD_SCHEMA.fields_dict["json"].default
     
     
     @property
     def type(self) -> Union[str, "TestDefinitionTypeClass"]:
-        """The Test Definition Type"""
+        """Getter: The Test Definition Type"""
         return self._inner_dict.get('type')  # type: ignore
     
     @type.setter
     def type(self, value: Union[str, "TestDefinitionTypeClass"]) -> None:
+        """Setter: The Test Definition Type"""
         self._inner_dict['type'] = value
     
     
     @property
     def json(self) -> Union[None, str]:
-        """JSON format configuration for the test"""
+        """Getter: JSON format configuration for the test"""
         return self._inner_dict.get('json')  # type: ignore
     
     @json.setter
     def json(self, value: Union[None, str]) -> None:
+        """Setter: JSON format configuration for the test"""
         self._inner_dict['json'] = value
     
     
 class TestDefinitionTypeClass(object):
     # No docs available.
     
     
@@ -16475,58 +19313,69 @@
         super().__init__()
         
         self.name = name
         self.category = category
         self.description = description
         self.definition = definition
     
+    @classmethod
+    def construct_with_defaults(cls) -> "TestInfoClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.name = str()
         self.category = str()
         self.description = self.RECORD_SCHEMA.fields_dict["description"].default
-        self.definition = TestDefinitionClass._construct_with_defaults()
+        self.definition = TestDefinitionClass.construct_with_defaults()
     
     
     @property
     def name(self) -> str:
-        """The name of the test"""
+        """Getter: The name of the test"""
         return self._inner_dict.get('name')  # type: ignore
     
     @name.setter
     def name(self, value: str) -> None:
+        """Setter: The name of the test"""
         self._inner_dict['name'] = value
     
     
     @property
     def category(self) -> str:
-        """Category of the test"""
+        """Getter: Category of the test"""
         return self._inner_dict.get('category')  # type: ignore
     
     @category.setter
     def category(self, value: str) -> None:
+        """Setter: Category of the test"""
         self._inner_dict['category'] = value
     
     
     @property
     def description(self) -> Union[None, str]:
-        """Description of the test"""
+        """Getter: Description of the test"""
         return self._inner_dict.get('description')  # type: ignore
     
     @description.setter
     def description(self, value: Union[None, str]) -> None:
+        """Setter: Description of the test"""
         self._inner_dict['description'] = value
     
     
     @property
     def definition(self) -> "TestDefinitionClass":
-        """Configuration for the Test"""
+        """Getter: Configuration for the Test"""
         return self._inner_dict.get('definition')  # type: ignore
     
     @definition.setter
     def definition(self, value: "TestDefinitionClass") -> None:
+        """Setter: Configuration for the Test"""
         self._inner_dict['definition'] = value
     
     
 class TestResultClass(DictWrapper):
     """Information about a Test Result"""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.test.TestResult")
@@ -16535,36 +19384,45 @@
         type: Union[str, "TestResultTypeClass"],
     ):
         super().__init__()
         
         self.test = test
         self.type = type
     
+    @classmethod
+    def construct_with_defaults(cls) -> "TestResultClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.test = str()
         self.type = TestResultTypeClass.SUCCESS
     
     
     @property
     def test(self) -> str:
-        """The urn of the test"""
+        """Getter: The urn of the test"""
         return self._inner_dict.get('test')  # type: ignore
     
     @test.setter
     def test(self, value: str) -> None:
+        """Setter: The urn of the test"""
         self._inner_dict['test'] = value
     
     
     @property
     def type(self) -> Union[str, "TestResultTypeClass"]:
-        """The type of the result"""
+        """Getter: The type of the result"""
         return self._inner_dict.get('type')  # type: ignore
     
     @type.setter
     def type(self, value: Union[str, "TestResultTypeClass"]) -> None:
+        """Setter: The type of the result"""
         self._inner_dict['type'] = value
     
     
 class TestResultTypeClass(object):
     # No docs available.
     
     
@@ -16588,36 +19446,45 @@
         passing: List["TestResultClass"],
     ):
         super().__init__()
         
         self.failing = failing
         self.passing = passing
     
+    @classmethod
+    def construct_with_defaults(cls) -> "TestResultsClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.failing = list()
         self.passing = list()
     
     
     @property
     def failing(self) -> List["TestResultClass"]:
-        """Results that are failing"""
+        """Getter: Results that are failing"""
         return self._inner_dict.get('failing')  # type: ignore
     
     @failing.setter
     def failing(self, value: List["TestResultClass"]) -> None:
+        """Setter: Results that are failing"""
         self._inner_dict['failing'] = value
     
     
     @property
     def passing(self) -> List["TestResultClass"]:
-        """Results that are passing"""
+        """Getter: Results that are passing"""
         return self._inner_dict.get('passing')  # type: ignore
     
     @passing.setter
     def passing(self, value: List["TestResultClass"]) -> None:
+        """Setter: Results that are passing"""
         self._inner_dict['passing'] = value
     
     
 class CalendarIntervalClass(object):
     # No docs available.
     
     SECOND = "SECOND"
@@ -16645,47 +19512,57 @@
             # default: 'PARTITION'
             self.type = self.RECORD_SCHEMA.fields_dict["type"].default
         else:
             self.type = type
         self.partition = partition
         self.timePartition = timePartition
     
+    @classmethod
+    def construct_with_defaults(cls) -> "PartitionSpecClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.type = self.RECORD_SCHEMA.fields_dict["type"].default
         self.partition = str()
         self.timePartition = self.RECORD_SCHEMA.fields_dict["timePartition"].default
     
     
     @property
     def type(self) -> Union[str, "PartitionTypeClass"]:
         # No docs available.
         return self._inner_dict.get('type')  # type: ignore
     
     @type.setter
     def type(self, value: Union[str, "PartitionTypeClass"]) -> None:
+        # No docs available.
         self._inner_dict['type'] = value
     
     
     @property
     def partition(self) -> str:
-        """String representation of the partition"""
+        """Getter: String representation of the partition"""
         return self._inner_dict.get('partition')  # type: ignore
     
     @partition.setter
     def partition(self, value: str) -> None:
+        """Setter: String representation of the partition"""
         self._inner_dict['partition'] = value
     
     
     @property
     def timePartition(self) -> Union[None, "TimeWindowClass"]:
-        """Time window of the partition if applicable"""
+        """Getter: Time window of the partition if applicable"""
         return self._inner_dict.get('timePartition')  # type: ignore
     
     @timePartition.setter
     def timePartition(self, value: Union[None, "TimeWindowClass"]) -> None:
+        """Setter: Time window of the partition if applicable"""
         self._inner_dict['timePartition'] = value
     
     
 class PartitionTypeClass(object):
     # No docs available.
     
     FULL_TABLE = "FULL_TABLE"
@@ -16702,36 +19579,45 @@
         length: "TimeWindowSizeClass",
     ):
         super().__init__()
         
         self.startTimeMillis = startTimeMillis
         self.length = length
     
+    @classmethod
+    def construct_with_defaults(cls) -> "TimeWindowClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.startTimeMillis = int()
-        self.length = TimeWindowSizeClass._construct_with_defaults()
+        self.length = TimeWindowSizeClass.construct_with_defaults()
     
     
     @property
     def startTimeMillis(self) -> int:
-        """Start time as epoch at UTC."""
+        """Getter: Start time as epoch at UTC."""
         return self._inner_dict.get('startTimeMillis')  # type: ignore
     
     @startTimeMillis.setter
     def startTimeMillis(self, value: int) -> None:
+        """Setter: Start time as epoch at UTC."""
         self._inner_dict['startTimeMillis'] = value
     
     
     @property
     def length(self) -> "TimeWindowSizeClass":
-        """The length of the window."""
+        """Getter: The length of the window."""
         return self._inner_dict.get('length')  # type: ignore
     
     @length.setter
     def length(self, value: "TimeWindowSizeClass") -> None:
+        """Setter: The length of the window."""
         self._inner_dict['length'] = value
     
     
 class TimeWindowSizeClass(DictWrapper):
     """Defines the size of a time window."""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.timeseries.TimeWindowSize")
@@ -16744,36 +19630,45 @@
         self.unit = unit
         if multiple is None:
             # default: 1
             self.multiple = self.RECORD_SCHEMA.fields_dict["multiple"].default
         else:
             self.multiple = multiple
     
+    @classmethod
+    def construct_with_defaults(cls) -> "TimeWindowSizeClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.unit = CalendarIntervalClass.SECOND
         self.multiple = self.RECORD_SCHEMA.fields_dict["multiple"].default
     
     
     @property
     def unit(self) -> Union[str, "CalendarIntervalClass"]:
-        """Interval unit such as minute/hour/day etc."""
+        """Getter: Interval unit such as minute/hour/day etc."""
         return self._inner_dict.get('unit')  # type: ignore
     
     @unit.setter
     def unit(self, value: Union[str, "CalendarIntervalClass"]) -> None:
+        """Setter: Interval unit such as minute/hour/day etc."""
         self._inner_dict['unit'] = value
     
     
     @property
     def multiple(self) -> int:
-        """How many units. Defaults to 1."""
+        """Getter: How many units. Defaults to 1."""
         return self._inner_dict.get('multiple')  # type: ignore
     
     @multiple.setter
     def multiple(self, value: int) -> None:
+        """Setter: How many units. Defaults to 1."""
         self._inner_dict['multiple'] = value
     
     
 class DataHubUpgradeRequestClass(_Aspect):
     """Information collected when kicking off a DataHubUpgrade"""
 
 
@@ -16786,36 +19681,45 @@
         version: str,
     ):
         super().__init__()
         
         self.timestampMs = timestampMs
         self.version = version
     
+    @classmethod
+    def construct_with_defaults(cls) -> "DataHubUpgradeRequestClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.timestampMs = int()
         self.version = str()
     
     
     @property
     def timestampMs(self) -> int:
-        """Timestamp when we started this DataHubUpgrade"""
+        """Getter: Timestamp when we started this DataHubUpgrade"""
         return self._inner_dict.get('timestampMs')  # type: ignore
     
     @timestampMs.setter
     def timestampMs(self, value: int) -> None:
+        """Setter: Timestamp when we started this DataHubUpgrade"""
         self._inner_dict['timestampMs'] = value
     
     
     @property
     def version(self) -> str:
-        """Version of this upgrade"""
+        """Getter: Version of this upgrade"""
         return self._inner_dict.get('version')  # type: ignore
     
     @version.setter
     def version(self, value: str) -> None:
+        """Setter: Version of this upgrade"""
         self._inner_dict['version'] = value
     
     
 class DataHubUpgradeResultClass(_Aspect):
     """Information collected when a DataHubUpgrade successfully finishes"""
 
 
@@ -16828,36 +19732,45 @@
         result: Union[None, Dict[str, str]]=None,
     ):
         super().__init__()
         
         self.timestampMs = timestampMs
         self.result = result
     
+    @classmethod
+    def construct_with_defaults(cls) -> "DataHubUpgradeResultClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.timestampMs = int()
         self.result = self.RECORD_SCHEMA.fields_dict["result"].default
     
     
     @property
     def timestampMs(self) -> int:
-        """Timestamp when we started this DataHubUpgrade"""
+        """Getter: Timestamp when we started this DataHubUpgrade"""
         return self._inner_dict.get('timestampMs')  # type: ignore
     
     @timestampMs.setter
     def timestampMs(self, value: int) -> None:
+        """Setter: Timestamp when we started this DataHubUpgrade"""
         self._inner_dict['timestampMs'] = value
     
     
     @property
     def result(self) -> Union[None, Dict[str, str]]:
-        """Result map to place helpful information about this upgrade job"""
+        """Getter: Result map to place helpful information about this upgrade job"""
         return self._inner_dict.get('result')  # type: ignore
     
     @result.setter
     def result(self, value: Union[None, Dict[str, str]]) -> None:
+        """Setter: Result map to place helpful information about this upgrade job"""
         self._inner_dict['result'] = value
     
     
 class FieldUsageCountsClass(DictWrapper):
     """ Records field-level usage counts for a given resource """
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.usage.FieldUsageCounts")
@@ -16866,36 +19779,45 @@
         count: int,
     ):
         super().__init__()
         
         self.fieldName = fieldName
         self.count = count
     
+    @classmethod
+    def construct_with_defaults(cls) -> "FieldUsageCountsClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.fieldName = str()
         self.count = int()
     
     
     @property
     def fieldName(self) -> str:
         # No docs available.
         return self._inner_dict.get('fieldName')  # type: ignore
     
     @fieldName.setter
     def fieldName(self, value: str) -> None:
+        # No docs available.
         self._inner_dict['fieldName'] = value
     
     
     @property
     def count(self) -> int:
         # No docs available.
         return self._inner_dict.get('count')  # type: ignore
     
     @count.setter
     def count(self, value: int) -> None:
+        # No docs available.
         self._inner_dict['count'] = value
     
     
 class UsageAggregationClass(DictWrapper):
     """Usage data for a given resource, rolled up into a bucket."""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.usage.UsageAggregation")
@@ -16908,58 +19830,69 @@
         super().__init__()
         
         self.bucket = bucket
         self.duration = duration
         self.resource = resource
         self.metrics = metrics
     
+    @classmethod
+    def construct_with_defaults(cls) -> "UsageAggregationClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.bucket = int()
         self.duration = WindowDurationClass.YEAR
         self.resource = str()
-        self.metrics = UsageAggregationMetricsClass._construct_with_defaults()
+        self.metrics = UsageAggregationMetricsClass.construct_with_defaults()
     
     
     @property
     def bucket(self) -> int:
-        """ Bucket start time in milliseconds """
+        """Getter:  Bucket start time in milliseconds """
         return self._inner_dict.get('bucket')  # type: ignore
     
     @bucket.setter
     def bucket(self, value: int) -> None:
+        """Setter:  Bucket start time in milliseconds """
         self._inner_dict['bucket'] = value
     
     
     @property
     def duration(self) -> Union[str, "WindowDurationClass"]:
-        """ Bucket duration """
+        """Getter:  Bucket duration """
         return self._inner_dict.get('duration')  # type: ignore
     
     @duration.setter
     def duration(self, value: Union[str, "WindowDurationClass"]) -> None:
+        """Setter:  Bucket duration """
         self._inner_dict['duration'] = value
     
     
     @property
     def resource(self) -> str:
-        """ Resource associated with these usage stats """
+        """Getter:  Resource associated with these usage stats """
         return self._inner_dict.get('resource')  # type: ignore
     
     @resource.setter
     def resource(self, value: str) -> None:
+        """Setter:  Resource associated with these usage stats """
         self._inner_dict['resource'] = value
     
     
     @property
     def metrics(self) -> "UsageAggregationMetricsClass":
-        """ Metrics associated with this bucket """
+        """Getter:  Metrics associated with this bucket """
         return self._inner_dict.get('metrics')  # type: ignore
     
     @metrics.setter
     def metrics(self, value: "UsageAggregationMetricsClass") -> None:
+        """Setter:  Metrics associated with this bucket """
         self._inner_dict['metrics'] = value
     
     
 class UsageAggregationMetricsClass(DictWrapper):
     """Metrics for usage data for a given resource and bucket. Not all fields
     make sense for all buckets, so every field is optional."""
     
@@ -16975,69 +19908,81 @@
         
         self.uniqueUserCount = uniqueUserCount
         self.users = users
         self.totalSqlQueries = totalSqlQueries
         self.topSqlQueries = topSqlQueries
         self.fields = fields
     
+    @classmethod
+    def construct_with_defaults(cls) -> "UsageAggregationMetricsClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.uniqueUserCount = self.RECORD_SCHEMA.fields_dict["uniqueUserCount"].default
         self.users = self.RECORD_SCHEMA.fields_dict["users"].default
         self.totalSqlQueries = self.RECORD_SCHEMA.fields_dict["totalSqlQueries"].default
         self.topSqlQueries = self.RECORD_SCHEMA.fields_dict["topSqlQueries"].default
         self.fields = self.RECORD_SCHEMA.fields_dict["fields"].default
     
     
     @property
     def uniqueUserCount(self) -> Union[None, int]:
-        """ Unique user count """
+        """Getter:  Unique user count """
         return self._inner_dict.get('uniqueUserCount')  # type: ignore
     
     @uniqueUserCount.setter
     def uniqueUserCount(self, value: Union[None, int]) -> None:
+        """Setter:  Unique user count """
         self._inner_dict['uniqueUserCount'] = value
     
     
     @property
     def users(self) -> Union[None, List["UserUsageCountsClass"]]:
-        """ Users within this bucket, with frequency counts """
+        """Getter:  Users within this bucket, with frequency counts """
         return self._inner_dict.get('users')  # type: ignore
     
     @users.setter
     def users(self, value: Union[None, List["UserUsageCountsClass"]]) -> None:
+        """Setter:  Users within this bucket, with frequency counts """
         self._inner_dict['users'] = value
     
     
     @property
     def totalSqlQueries(self) -> Union[None, int]:
-        """ Total SQL query count """
+        """Getter:  Total SQL query count """
         return self._inner_dict.get('totalSqlQueries')  # type: ignore
     
     @totalSqlQueries.setter
     def totalSqlQueries(self, value: Union[None, int]) -> None:
+        """Setter:  Total SQL query count """
         self._inner_dict['totalSqlQueries'] = value
     
     
     @property
     def topSqlQueries(self) -> Union[None, List[str]]:
-        """ Frequent SQL queries; mostly makes sense for datasets in SQL databases """
+        """Getter:  Frequent SQL queries; mostly makes sense for datasets in SQL databases """
         return self._inner_dict.get('topSqlQueries')  # type: ignore
     
     @topSqlQueries.setter
     def topSqlQueries(self, value: Union[None, List[str]]) -> None:
+        """Setter:  Frequent SQL queries; mostly makes sense for datasets in SQL databases """
         self._inner_dict['topSqlQueries'] = value
     
     
     @property
     def fields(self) -> Union[None, List["FieldUsageCountsClass"]]:
-        """ Field-level usage stats """
+        """Getter:  Field-level usage stats """
         return self._inner_dict.get('fields')  # type: ignore
     
     @fields.setter
     def fields(self, value: Union[None, List["FieldUsageCountsClass"]]) -> None:
+        """Setter:  Field-level usage stats """
         self._inner_dict['fields'] = value
     
     
 class UserUsageCountsClass(DictWrapper):
     """ Records a single user's usage counts for a given resource """
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.usage.UserUsageCounts")
@@ -17048,47 +19993,57 @@
     ):
         super().__init__()
         
         self.user = user
         self.count = count
         self.userEmail = userEmail
     
+    @classmethod
+    def construct_with_defaults(cls) -> "UserUsageCountsClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.user = self.RECORD_SCHEMA.fields_dict["user"].default
         self.count = int()
         self.userEmail = self.RECORD_SCHEMA.fields_dict["userEmail"].default
     
     
     @property
     def user(self) -> Union[None, str]:
         # No docs available.
         return self._inner_dict.get('user')  # type: ignore
     
     @user.setter
     def user(self, value: Union[None, str]) -> None:
+        # No docs available.
         self._inner_dict['user'] = value
     
     
     @property
     def count(self) -> int:
         # No docs available.
         return self._inner_dict.get('count')  # type: ignore
     
     @count.setter
     def count(self, value: int) -> None:
+        # No docs available.
         self._inner_dict['count'] = value
     
     
     @property
     def userEmail(self) -> Union[None, str]:
-        """ If user_email is set, we attempt to resolve the user's urn upon ingest """
+        """Getter:  If user_email is set, we attempt to resolve the user's urn upon ingest """
         return self._inner_dict.get('userEmail')  # type: ignore
     
     @userEmail.setter
     def userEmail(self, value: Union[None, str]) -> None:
+        """Setter:  If user_email is set, we attempt to resolve the user's urn upon ingest """
         self._inner_dict['userEmail'] = value
     
     
 class DataHubViewDefinitionClass(DictWrapper):
     """A View definition."""
     
     RECORD_SCHEMA = get_schema_type("com.linkedin.pegasus2avro.view.DataHubViewDefinition")
@@ -17097,36 +20052,45 @@
         filter: "FilterClass",
     ):
         super().__init__()
         
         self.entityTypes = entityTypes
         self.filter = filter
     
+    @classmethod
+    def construct_with_defaults(cls) -> "DataHubViewDefinitionClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.entityTypes = list()
-        self.filter = FilterClass._construct_with_defaults()
+        self.filter = FilterClass.construct_with_defaults()
     
     
     @property
     def entityTypes(self) -> List[str]:
-        """The Entity Types in the scope of the View."""
+        """Getter: The Entity Types in the scope of the View."""
         return self._inner_dict.get('entityTypes')  # type: ignore
     
     @entityTypes.setter
     def entityTypes(self, value: List[str]) -> None:
+        """Setter: The Entity Types in the scope of the View."""
         self._inner_dict['entityTypes'] = value
     
     
     @property
     def filter(self) -> "FilterClass":
-        """The filter criteria, which represents the view itself"""
+        """Getter: The filter criteria, which represents the view itself"""
         return self._inner_dict.get('filter')  # type: ignore
     
     @filter.setter
     def filter(self, value: "FilterClass") -> None:
+        """Setter: The filter criteria, which represents the view itself"""
         self._inner_dict['filter'] = value
     
     
 class DataHubViewInfoClass(_Aspect):
     """Information about a DataHub View. -- TODO: Understand whether an entity type filter is required."""
 
 
@@ -17147,80 +20111,93 @@
         self.name = name
         self.description = description
         self.type = type
         self.definition = definition
         self.created = created
         self.lastModified = lastModified
     
+    @classmethod
+    def construct_with_defaults(cls) -> "DataHubViewInfoClass":
+        self = cls.construct({})
+        self._restore_defaults()
+        
+        return self
+    
     def _restore_defaults(self) -> None:
         self.name = str()
         self.description = self.RECORD_SCHEMA.fields_dict["description"].default
         self.type = DataHubViewTypeClass.PERSONAL
-        self.definition = DataHubViewDefinitionClass._construct_with_defaults()
-        self.created = AuditStampClass._construct_with_defaults()
-        self.lastModified = AuditStampClass._construct_with_defaults()
+        self.definition = DataHubViewDefinitionClass.construct_with_defaults()
+        self.created = AuditStampClass.construct_with_defaults()
+        self.lastModified = AuditStampClass.construct_with_defaults()
     
     
     @property
     def name(self) -> str:
-        """The name of the View"""
+        """Getter: The name of the View"""
         return self._inner_dict.get('name')  # type: ignore
     
     @name.setter
     def name(self, value: str) -> None:
+        """Setter: The name of the View"""
         self._inner_dict['name'] = value
     
     
     @property
     def description(self) -> Union[None, str]:
-        """Description of the view"""
+        """Getter: Description of the view"""
         return self._inner_dict.get('description')  # type: ignore
     
     @description.setter
     def description(self, value: Union[None, str]) -> None:
+        """Setter: Description of the view"""
         self._inner_dict['description'] = value
     
     
     @property
     def type(self) -> Union[str, "DataHubViewTypeClass"]:
-        """The type of View"""
+        """Getter: The type of View"""
         return self._inner_dict.get('type')  # type: ignore
     
     @type.setter
     def type(self, value: Union[str, "DataHubViewTypeClass"]) -> None:
+        """Setter: The type of View"""
         self._inner_dict['type'] = value
     
     
     @property
     def definition(self) -> "DataHubViewDefinitionClass":
-        """The view itself"""
+        """Getter: The view itself"""
         return self._inner_dict.get('definition')  # type: ignore
     
     @definition.setter
     def definition(self, value: "DataHubViewDefinitionClass") -> None:
+        """Setter: The view itself"""
         self._inner_dict['definition'] = value
     
     
     @property
     def created(self) -> "AuditStampClass":
-        """Audit stamp capturing the time and actor who created the View."""
+        """Getter: Audit stamp capturing the time and actor who created the View."""
         return self._inner_dict.get('created')  # type: ignore
     
     @created.setter
     def created(self, value: "AuditStampClass") -> None:
+        """Setter: Audit stamp capturing the time and actor who created the View."""
         self._inner_dict['created'] = value
     
     
     @property
     def lastModified(self) -> "AuditStampClass":
-        """Audit stamp capturing the time and actor who last modified the View."""
+        """Getter: Audit stamp capturing the time and actor who last modified the View."""
         return self._inner_dict.get('lastModified')  # type: ignore
     
     @lastModified.setter
     def lastModified(self, value: "AuditStampClass") -> None:
+        """Setter: Audit stamp capturing the time and actor who last modified the View."""
         self._inner_dict['lastModified'] = value
     
     
 class DataHubViewTypeClass(object):
     # No docs available.
     
     
@@ -17906,208 +20883,208 @@
 
 _json_converter = avrojson.AvroJsonConverter(use_logical_types=False, schema_types=__SCHEMA_TYPES)
 
 
     
 
 ASPECT_CLASSES: List[Type[_Aspect]] = [
-    GlobalSettingsInfoClass,
-    DataHubAccessTokenInfoClass,
-    MLHyperParamClass,
+    EditableDataJobPropertiesClass,
+    DataFlowInfoClass,
+    EditableDataFlowPropertiesClass,
+    DataJobInputOutputClass,
+    DataJobInfoClass,
+    VersionInfoClass,
+    DatahubIngestionRunSummaryClass,
+    DatahubIngestionCheckpointClass,
+    EmbedClass,
+    InputFieldsClass,
+    CostClass,
+    SubTypesClass,
+    GlobalTagsClass,
+    SiblingsClass,
+    OperationClass,
+    BrowsePathsClass,
+    GlossaryTermsClass,
+    OriginClass,
+    DataPlatformInstanceClass,
+    InstitutionalMemoryClass,
+    DeprecationClass,
+    OwnershipClass,
+    StatusClass,
+    SourceCodeClass,
+    EditableMLModelPropertiesClass,
+    EditableMLPrimaryKeyPropertiesClass,
     EvaluationDataClass,
+    EditableMLFeatureTablePropertiesClass,
     MLPrimaryKeyPropertiesClass,
+    MLHyperParamClass,
+    MLModelDeploymentPropertiesClass,
+    CaveatsAndRecommendationsClass,
     MLMetricClass,
-    EditableMLFeaturePropertiesClass,
-    MetricsClass,
-    EditableMLFeatureTablePropertiesClass,
-    SourceCodeClass,
-    IntendedUseClass,
-    EditableMLPrimaryKeyPropertiesClass,
-    MLModelPropertiesClass,
     TrainingDataClass,
-    QuantitativeAnalysesClass,
-    MLModelDeploymentPropertiesClass,
-    EthicalConsiderationsClass,
-    MLModelFactorPromptsClass,
     MLModelGroupPropertiesClass,
-    CaveatsAndRecommendationsClass,
-    EditableMLModelPropertiesClass,
-    EditableMLModelGroupPropertiesClass,
+    MetricsClass,
+    MLModelFactorPromptsClass,
+    EthicalConsiderationsClass,
     MLFeaturePropertiesClass,
+    MLModelPropertiesClass,
+    EditableMLFeaturePropertiesClass,
+    EditableMLModelGroupPropertiesClass,
     MLFeatureTablePropertiesClass,
-    DataHubViewInfoClass,
-    DataProcessInstanceOutputClass,
-    DataProcessInstanceRunEventClass,
-    DataProcessInstanceRelationshipsClass,
-    DataProcessInstancePropertiesClass,
-    DataProcessInfoClass,
-    DataProcessInstanceInputClass,
-    ChartInfoClass,
-    EditableChartPropertiesClass,
-    ChartQueryClass,
-    ChartUsageStatisticsClass,
-    NotebookInfoClass,
-    NotebookContentClass,
-    EditableNotebookPropertiesClass,
-    RoleMembershipClass,
-    InviteTokenClass,
-    GroupMembershipClass,
-    NativeGroupMembershipClass,
-    CorpGroupEditableInfoClass,
-    CorpUserEditableInfoClass,
-    CorpUserInfoClass,
-    CorpUserCredentialsClass,
-    CorpUserSettingsClass,
-    CorpUserStatusClass,
-    CorpGroupInfoClass,
-    DataPlatformInstancePropertiesClass,
-    AssertionRunEventClass,
-    AssertionInfoClass,
+    QuantitativeAnalysesClass,
+    IntendedUseClass,
+    DataHubPolicyInfoClass,
+    DataHubRoleInfoClass,
     DataHubStepStatePropertiesClass,
-    DataHubSecretValueClass,
-    TagPropertiesClass,
+    DataPlatformInfoClass,
     ExecutionRequestResultClass,
     ExecutionRequestInputClass,
     ExecutionRequestSignalClass,
-    DashboardInfoClass,
-    DashboardUsageStatisticsClass,
-    EditableDashboardPropertiesClass,
-    EditableDataJobPropertiesClass,
-    DataJobInputOutputClass,
-    EditableDataFlowPropertiesClass,
-    VersionInfoClass,
-    DataFlowInfoClass,
-    DataJobInfoClass,
-    DatahubIngestionRunSummaryClass,
-    DatahubIngestionCheckpointClass,
-    DataHubRetentionConfigClass,
-    EditableSchemaMetadataClass,
-    SchemaMetadataClass,
-    DataPlatformInfoClass,
-    TelemetryClientIdClass,
-    DataHubIngestionSourceInfoClass,
+    ChartQueryClass,
+    EditableChartPropertiesClass,
+    ChartUsageStatisticsClass,
+    ChartInfoClass,
+    EditableContainerPropertiesClass,
+    ContainerPropertiesClass,
+    ContainerClass,
+    GlossaryNodeInfoClass,
     GlossaryTermInfoClass,
     GlossaryRelatedTermsClass,
-    GlossaryNodeInfoClass,
-    DomainsClass,
+    TagPropertiesClass,
+    QuerySubjectsClass,
+    QueryPropertiesClass,
+    TelemetryClientIdClass,
     DomainPropertiesClass,
-    PostInfoClass,
+    DomainsClass,
+    EditableSchemaMetadataClass,
+    SchemaMetadataClass,
+    DataHubIngestionSourceInfoClass,
+    ViewPropertiesClass,
     DatasetDeprecationClass,
-    EditableDatasetPropertiesClass,
+    DatasetUpstreamLineageClass,
     DatasetUsageStatisticsClass,
+    DatasetPropertiesClass,
     UpstreamLineageClass,
     DatasetProfileClass,
-    DatasetPropertiesClass,
-    DatasetUpstreamLineageClass,
-    ViewPropertiesClass,
-    EditableContainerPropertiesClass,
-    ContainerClass,
-    ContainerPropertiesClass,
-    TestInfoClass,
-    TestResultsClass,
-    QuerySubjectsClass,
-    QueryPropertiesClass,
-    DataHubPolicyInfoClass,
-    DataHubRoleInfoClass,
-    DashboardKeyClass,
-    GlobalSettingsKeyClass,
-    DataHubSecretKeyClass,
+    EditableDatasetPropertiesClass,
+    EditableDashboardPropertiesClass,
+    DashboardUsageStatisticsClass,
+    DashboardInfoClass,
+    DataHubRetentionConfigClass,
+    CorpUserStatusClass,
+    CorpUserCredentialsClass,
+    CorpUserEditableInfoClass,
+    InviteTokenClass,
+    CorpUserInfoClass,
+    RoleMembershipClass,
+    GroupMembershipClass,
+    CorpUserSettingsClass,
+    CorpGroupEditableInfoClass,
+    NativeGroupMembershipClass,
+    CorpGroupInfoClass,
+    DataHubAccessTokenInfoClass,
+    DataProcessInstanceRunEventClass,
+    DataProcessInstanceInputClass,
+    DataProcessInstancePropertiesClass,
+    DataProcessInstanceOutputClass,
+    DataProcessInfoClass,
+    DataProcessInstanceRelationshipsClass,
+    AssertionInfoClass,
+    AssertionRunEventClass,
+    NotebookContentClass,
+    NotebookInfoClass,
+    EditableNotebookPropertiesClass,
+    PostInfoClass,
+    DataHubUpgradeResultClass,
+    DataHubUpgradeRequestClass,
     MLFeatureTableKeyClass,
-    TelemetryKeyClass,
-    DataHubAccessTokenKeyClass,
-    DataHubPolicyKeyClass,
-    TestKeyClass,
-    DataHubIngestionSourceKeyClass,
-    AssertionKeyClass,
-    PostKeyClass,
-    MLFeatureKeyClass,
-    TagKeyClass,
-    DomainKeyClass,
-    DataHubViewKeyClass,
-    MLPrimaryKeyKeyClass,
-    DataHubStepStateKeyClass,
-    DataHubUpgradeKeyClass,
-    GlossaryNodeKeyClass,
-    MLModelDeploymentKeyClass,
-    DataHubRoleKeyClass,
-    DataPlatformKeyClass,
     ContainerKeyClass,
-    DataPlatformInstanceKeyClass,
+    DataHubRetentionKeyClass,
     DataJobKeyClass,
-    ExecutionRequestKeyClass,
-    DataProcessKeyClass,
-    CorpUserKeyClass,
-    NotebookKeyClass,
+    MLModelDeploymentKeyClass,
     SchemaFieldKeyClass,
+    DataProcessKeyClass,
+    CorpGroupKeyClass,
+    MLPrimaryKeyKeyClass,
+    DataFlowKeyClass,
+    DashboardKeyClass,
     MLModelGroupKeyClass,
+    TelemetryKeyClass,
+    GlossaryTermKeyClass,
+    GlossaryNodeKeyClass,
     DataProcessInstanceKeyClass,
-    QueryKeyClass,
+    DataHubRoleKeyClass,
     MLModelKeyClass,
-    GlossaryTermKeyClass,
-    DatasetKeyClass,
-    InviteTokenKeyClass,
-    CorpGroupKeyClass,
-    DataHubRetentionKeyClass,
-    DataFlowKeyClass,
+    DataHubViewKeyClass,
+    QueryKeyClass,
+    CorpUserKeyClass,
+    DataPlatformInstanceKeyClass,
+    NotebookKeyClass,
+    MLFeatureKeyClass,
     ChartKeyClass,
-    GlossaryTermsClass,
-    EmbedClass,
-    DataPlatformInstanceClass,
-    InputFieldsClass,
-    InstitutionalMemoryClass,
-    OwnershipClass,
-    SubTypesClass,
-    OriginClass,
-    GlobalTagsClass,
-    StatusClass,
-    OperationClass,
-    SiblingsClass,
-    BrowsePathsClass,
-    DeprecationClass,
-    CostClass,
-    DataHubUpgradeResultClass,
-    DataHubUpgradeRequestClass
+    AssertionKeyClass,
+    DataHubSecretKeyClass,
+    DataHubPolicyKeyClass,
+    TestKeyClass,
+    DataHubAccessTokenKeyClass,
+    DataHubUpgradeKeyClass,
+    DataPlatformKeyClass,
+    InviteTokenKeyClass,
+    PostKeyClass,
+    ExecutionRequestKeyClass,
+    DataHubIngestionSourceKeyClass,
+    DomainKeyClass,
+    DatasetKeyClass,
+    DataHubStepStateKeyClass,
+    GlobalSettingsKeyClass,
+    TagKeyClass,
+    GlobalSettingsInfoClass,
+    TestResultsClass,
+    TestInfoClass,
+    DataPlatformInstancePropertiesClass,
+    DataHubViewInfoClass,
+    DataHubSecretValueClass
 ]
 
 KEY_ASPECTS: Dict[str, Type[_Aspect]] = {
-    'dashboard': DashboardKeyClass,
-    'globalSettings': GlobalSettingsKeyClass,
-    'dataHubSecret': DataHubSecretKeyClass,
     'mlFeatureTable': MLFeatureTableKeyClass,
-    'telemetry': TelemetryKeyClass,
-    'dataHubAccessToken': DataHubAccessTokenKeyClass,
-    'dataHubPolicy': DataHubPolicyKeyClass,
-    'test': TestKeyClass,
-    'dataHubIngestionSource': DataHubIngestionSourceKeyClass,
-    'assertion': AssertionKeyClass,
-    'post': PostKeyClass,
-    'mlFeature': MLFeatureKeyClass,
-    'tag': TagKeyClass,
-    'domain': DomainKeyClass,
-    'dataHubView': DataHubViewKeyClass,
-    'mlPrimaryKey': MLPrimaryKeyKeyClass,
-    'dataHubStepState': DataHubStepStateKeyClass,
-    'dataHubUpgrade': DataHubUpgradeKeyClass,
-    'glossaryNode': GlossaryNodeKeyClass,
-    'dataHubRole': DataHubRoleKeyClass,
-    'dataPlatform': DataPlatformKeyClass,
     'container': ContainerKeyClass,
-    'dataPlatformInstance': DataPlatformInstanceKeyClass,
+    'dataHubRetention': DataHubRetentionKeyClass,
     'dataJob': DataJobKeyClass,
-    'dataHubExecutionRequest': ExecutionRequestKeyClass,
-    'corpuser': CorpUserKeyClass,
-    'notebook': NotebookKeyClass,
     'schemaField': SchemaFieldKeyClass,
+    'corpGroup': CorpGroupKeyClass,
+    'mlPrimaryKey': MLPrimaryKeyKeyClass,
+    'dataFlow': DataFlowKeyClass,
+    'dashboard': DashboardKeyClass,
     'mlModelGroup': MLModelGroupKeyClass,
+    'telemetry': TelemetryKeyClass,
+    'glossaryTerm': GlossaryTermKeyClass,
+    'glossaryNode': GlossaryNodeKeyClass,
     'dataProcessInstance': DataProcessInstanceKeyClass,
-    'query': QueryKeyClass,
+    'dataHubRole': DataHubRoleKeyClass,
     'mlModel': MLModelKeyClass,
-    'glossaryTerm': GlossaryTermKeyClass,
-    'dataset': DatasetKeyClass,
+    'dataHubView': DataHubViewKeyClass,
+    'query': QueryKeyClass,
+    'corpuser': CorpUserKeyClass,
+    'dataPlatformInstance': DataPlatformInstanceKeyClass,
+    'notebook': NotebookKeyClass,
+    'mlFeature': MLFeatureKeyClass,
+    'chart': ChartKeyClass,
+    'assertion': AssertionKeyClass,
+    'dataHubSecret': DataHubSecretKeyClass,
+    'dataHubPolicy': DataHubPolicyKeyClass,
+    'test': TestKeyClass,
+    'dataHubAccessToken': DataHubAccessTokenKeyClass,
+    'dataHubUpgrade': DataHubUpgradeKeyClass,
+    'dataPlatform': DataPlatformKeyClass,
     'inviteToken': InviteTokenKeyClass,
-    'corpGroup': CorpGroupKeyClass,
-    'dataHubRetention': DataHubRetentionKeyClass,
-    'dataFlow': DataFlowKeyClass,
-    'chart': ChartKeyClass
+    'post': PostKeyClass,
+    'dataHubExecutionRequest': ExecutionRequestKeyClass,
+    'dataHubIngestionSource': DataHubIngestionSourceKeyClass,
+    'domain': DomainKeyClass,
+    'dataset': DatasetKeyClass,
+    'dataHubStepState': DataHubStepStateKeyClass,
+    'globalSettings': GlobalSettingsKeyClass,
+    'tag': TagKeyClass
 }
 
 # fmt: on
```

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/schemas/MetadataChangeEvent.avsc` & `acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/schemas/MetadataChangeEvent.avsc`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/schemas/MetadataChangeProposal.avsc` & `acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/schemas/MetadataChangeProposal.avsc`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/metadata/schemas/__init__.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/metadata/schemas/__init__.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/specific/custom_properties.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/specific/custom_properties.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/specific/dataset.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/specific/dataset.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/telemetry/stats.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/telemetry/stats.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/telemetry/telemetry.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/telemetry/telemetry.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/upgrade/upgrade.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/upgrade/upgrade.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/bigquery_sql_parser.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/bigquery_sql_parser.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/checkpoint_state_util.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/checkpoint_state_util.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/delayed_iter.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/delayed_iter.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/file_backed_collections.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/file_backed_collections.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/hive_schema_to_avro.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/hive_schema_to_avro.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/logging_manager.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/logging_manager.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/lossy_collections.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/lossy_collections.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/mapping.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/mapping.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/memory_footprint.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/memory_footprint.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/memory_leak_detector.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/memory_leak_detector.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/parsing_util.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/parsing_util.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/perf_timer.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/perf_timer.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/registries/domain_registry.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/registries/domain_registry.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/sample_data.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/sample_data.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/server_config_util.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/server_config_util.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/source_helpers.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/source_helpers.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/sql_formatter.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/sql_formatter.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/sql_lineage_parser_impl.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/sql_lineage_parser_impl.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/sql_parser.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/sql_parser.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/sqlalchemy_query_combiner.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/sqlalchemy_query_combiner.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/sqllineage_patch.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/sqllineage_patch.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/stats_collections.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/stats_collections.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/tee_io.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/tee_io.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/type_annotations.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/type_annotations.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/urn_encoder.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/urn_encoder.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/urns/corp_group_urn.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/urns/corp_group_urn.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/urns/corpuser_urn.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/urns/corpuser_urn.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/urns/data_flow_urn.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/urns/data_flow_urn.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/urns/data_job_urn.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/urns/data_job_urn.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/urns/data_platform_urn.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/urns/data_platform_urn.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/urns/data_process_instance_urn.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/urns/data_process_instance_urn.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/urns/dataset_urn.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/urns/dataset_urn.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/urns/domain_urn.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/urns/domain_urn.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/urns/notebook_urn.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/urns/notebook_urn.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/urns/tag_urn.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/urns/tag_urn.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/urns/urn.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/urns/urn.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub/utilities/urns/urn_iter.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub/utilities/urns/urn_iter.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub_provider/__init__.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub_provider/__init__.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub_provider/_airflow_shims.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub_provider/_airflow_shims.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub_provider/_lineage_core.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub_provider/_lineage_core.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub_provider/_plugin.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub_provider/_plugin.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub_provider/client/airflow_generator.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub_provider/client/airflow_generator.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub_provider/entities.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub_provider/entities.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub_provider/example_dags/generic_recipe_sample_dag.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub_provider/example_dags/generic_recipe_sample_dag.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub_provider/example_dags/lineage_backend_demo.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub_provider/example_dags/lineage_backend_demo.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub_provider/example_dags/lineage_backend_taskflow_demo.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub_provider/example_dags/lineage_backend_taskflow_demo.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub_provider/example_dags/lineage_emission_dag.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub_provider/example_dags/lineage_emission_dag.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub_provider/example_dags/mysql_sample_dag.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub_provider/example_dags/mysql_sample_dag.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub_provider/example_dags/snowflake_sample_dag.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub_provider/example_dags/snowflake_sample_dag.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub_provider/hooks/datahub.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub_provider/hooks/datahub.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub_provider/lineage/datahub.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub_provider/lineage/datahub.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub_provider/operators/datahub.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub_provider/operators/datahub.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub_provider/operators/datahub_assertion_operator.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub_provider/operators/datahub_assertion_operator.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub_provider/operators/datahub_assertion_sensor.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub_provider/operators/datahub_assertion_sensor.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub_provider/operators/datahub_operation_operator.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub_provider/operators/datahub_operation_operator.py`

 * *Files identical despite different names*

### Comparing `acryl-datahub-tc-0.10.2.0rc3/src/datahub_provider/operators/datahub_operation_sensor.py` & `acryl-datahub-tc-0.10.2rc1/src/datahub_provider/operators/datahub_operation_sensor.py`

 * *Files identical despite different names*

